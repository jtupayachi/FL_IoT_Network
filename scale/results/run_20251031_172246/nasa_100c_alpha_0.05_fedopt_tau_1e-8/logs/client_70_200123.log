[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77ea7c21-250f-4e84-bb4a-46fd8ee5c549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e2bf92a-1318-498b-8926-d08939c8e63d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adf5899e-829f-4ab7-ae04-f23d39c5e7f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1843aa4f-98fa-4441-bc61-dd7885162392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e640bb33-270d-4f25-a0ce-c45d4174dd7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eb608ab-7277-4d93-834e-23dc5b53f28e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39fdec5c-86b9-430a-a189-251424ca7f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 993dd45e-dbe6-401c-90d4-c155af08bf3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f096bd8c-afb6-485e-b3b6-d4d622be1e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58dbd933-d8e1-4cc4-ae03-e46b7191f19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5e4792f-9ff3-4422-9cda-98eb29b9faac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b04e756-3047-453f-976d-050703c4632c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92dc4f32-625c-4aaf-83a2-80ac922194f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2934a451-1ee9-45db-a116-cb96f4d8a2f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41e111b4-8a55-472d-9616-a48b828ed293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67e7bd92-c1b1-4ec0-aad6-5f4d63229487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 401a8b26-2c20-4c88-bd16-8c2f38ca6bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4319adaf-e8bf-4f65-abf7-fcf86bca53e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c42a9b2-2f7d-4c84-9df1-65e567ba7dfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da374a04-bf58-4d88-8252-f72272e703b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6d056eb-9d1a-41c4-a654-f55e07a4db67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c46493f5-2cf4-4aa5-8100-a4cfcaebbc3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0495f94-597b-49c3-b00f-0a0e45970386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6ec41fa-7da8-4b58-8db5-c125d54c1d75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a8c4681-5045-4051-97e2-49d0a9fc8569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd0e8f99-334a-4ddb-8843-0087dc701191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fb4657d-7002-4705-8364-ac3515f04dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edc1eaf4-f63c-465a-87c0-71a87003113e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9878443e-d6cc-4014-9cb1-6d1ce4d4fc3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 169897b5-e2ed-4358-a570-7e4d79e95d37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c22068a1-95f0-4dfd-8f2e-8e21572000ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8f13063-2d3f-43ee-a84e-1f3116a5411c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd737165-27c9-4187-abeb-3916c8c82382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f3a418f-d3a0-467c-9526-81fbe25037a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a667a0c9-c836-4a9a-b430-bdc2a86bab55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52bc2760-9239-43d1-a506-0ced8b9155ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbf171eb-cc23-44a2-944a-b99239d23732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 924e5e59-d04c-477e-97c7-5972eaf9f180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c64076f-58de-4b37-a3b9-87908a9c55d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10145d1f-3250-4817-9653-ae09f6584a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbe190ef-ae9e-4157-9d1b-9035b36581ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9ebf80a-3cd0-4ea6-9acc-f5a6c6ccfbe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46832a83-ca31-41ce-87a6-9adf617ee5cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48e40159-0c58-480d-a77b-5f29b1664d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c60ee62-886e-4d79-b247-2d6c52a914b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c86fec1-c1f7-4cf3-8e4b-78103d85514a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9d457ef-ed6d-4e32-b952-f87f58ca80f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6594ba2-a967-41fe-9ed5-a50bf504c9ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4566ed4-0f7b-4fcf-a1e7-40e6e4453755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66a0f167-dea4-4dee-b6e8-369e2573a67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab7e40cb-ba79-4bbe-b0c6-a4d4b44ac085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6506eaeb-e340-4e1a-990d-bc5f2921b4b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 951f7e73-9f39-470b-aa2d-01cd139be3ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 982db9fd-96ac-4b7e-9797-6842f433ae0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5072427-6554-4637-8f14-eac70055f330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a67b8d3-3883-41c4-96af-9e02c9c507f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5826ded7-e7b4-4a81-8754-a976019d2a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fa98f97-2ebf-47c2-9bcd-7ca563bf1a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3115c7f6-0814-4e8a-bd72-0eab8bb717d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03f3053c-b3f7-402e-935b-239d0072c8c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a60f7d0e-8add-4eb1-b82b-66b10e186897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7529c4e0-4d11-4351-bcc4-1568b834fb6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06b5b544-92e3-41f5-8453-0671168b740c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c37354ee-c136-4a01-b105-fbaf12ab6a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a99ac21-8b0b-4893-ad5b-1ea9af18dcd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2483977e-056d-4ce2-8c77-df3085583973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ad0aca0-93ce-46e2-89e5-b94c5b3bb470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ecd265f-d64e-4a6e-8c8e-7604d14de35b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e76b886-0939-4924-bd91-ff9b288b852f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e66cdbde-8746-46a4-93ee-8735385bf70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ae51b6-11fe-4286-99df-adc8e948879f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27308f1c-1adc-4a1d-8d95-75ead7395b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2b64198-3c4f-4c1c-bd10-cc36de58fa0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 786a9a9e-f73b-4351-af3f-e1b999a334b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09f1a07a-4bd9-4735-ad8a-10760a9963e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eb6b8cf-5954-4a95-958a-459683812f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6973fb7-ec4a-4af9-b456-ffb86a1c886d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19dc79f2-da90-4b68-b39b-7cde7e3b8b17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db3f522e-95a2-4d9a-b673-62b011389634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7638d369-c273-4188-9d75-935feb44fd77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6488c2cf-dfc8-4d3a-a23c-b13b752c338f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 162ba616-2b3c-43a5-9246-06bca193abc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8355b4ba-229a-4c00-917d-2aa28fe1584f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dcfbf2a-97ec-47a0-b35c-142a18f08b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd304959-796a-4ab7-ace5-e5778e3a78fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61c0d636-8184-4935-8911-85749bf3c619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c345da46-893e-41b8-93aa-c08f5405369f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4cb2ef7-6e26-4e8e-9b68-35c80c5df2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69167e5f-c65f-4566-bc9a-dce7678c3f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc504774-8b49-44f4-b0a3-3c31aa8da154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0fb7991-6377-4ad8-ac45-c249ea48f1ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6527b32-b3ab-4b47-9b86-7c37bb13d10e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95d0edd9-aa7a-4861-b74e-1ca4e3204739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ce3ba7b-2c13-4b2d-a03a-73ea613ea794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9993743-b614-439a-89f8-9cc8f51bf870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a043730-70a1-4f49-84c1-a5c4e2da1da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a241bc6-7a77-4e9b-a1da-ceb5dda5d847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d9316af-12ba-4711-8b44-6bf44bb7a32e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10abe0af-3ada-4bf5-b213-741ce19fa4ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fcaffa7-e77d-4601-a25e-9c7d654a7ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed2b4382-9ef8-48be-9ae2-5a18d169f530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5688b8ac-cb3c-427b-be6d-ca6a5ed8fd6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f3154e8-c823-4643-b733-924b1117d8f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0cca9d3-551b-425e-954f-ee462b5f455b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7edb1503-98aa-489f-a84b-3e8ba29037e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8978237-ec9d-43cd-90b1-41bc065f4a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 795953cc-f48e-4568-afe3-cd68d983aaf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2069c3-78e8-4fa4-b44c-23b1362069fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c080385f-316d-4e22-9ee2-9c1132137603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9257a299-0f63-4d1c-b0b3-f499bfc192eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56c9a097-0e54-4f9c-9b8f-b636fde9d55e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b9658e1-319e-46c4-9aca-730abd5deae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05634b8e-202d-4493-a31e-5dbd49c7547c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fafc676-abe5-468d-b1f5-369c06bfc72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c87a5aaf-2238-4fb9-ba7b-20543e82dc44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3892083a-557d-430c-95f9-62433f49d9c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 427af444-7d31-4043-aa1a-805ae0dbdc28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 660dfe63-1a83-4527-90e1-ca4c91fab3cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0f89f46-28a1-4153-ac6e-cfd459c1224b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23a8cd78-136f-4d58-ab24-e60e908cb466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65a23fbf-1395-4ef9-aee4-770d641f3ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1776890b-899f-4aa2-9e8b-f3169e62c913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f2d9334-2f53-4e1d-9d21-c1497378d31e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1250ed7b-e470-4ec5-88cf-5b647791a705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0503cf28-d3d9-43eb-8c6e-5ecc8027df52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5c4043b-dd2c-446c-b075-5a6f979f54a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db8366a2-acdd-4a8c-9f4e-20a5b8308cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6909d16-def1-4ad1-ada1-acc2472d4317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b562d5e3-bdc7-466b-a5e5-e7c7f08412d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82004e41-a082-40fa-9009-dc566fd60df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8f127f0-d21d-4238-89b1-3e796195e2e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9de5cd1a-8e1d-4b13-9597-e88a23dc1fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f9b317c-a0d6-43ea-a81b-47048695948d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bafb503-d0bf-4d21-9cdf-ed8d1954277d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78951985-f986-432b-a3b2-6aaae07559a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80018e25-6f76-4a78-9510-c82d3c8b01dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e99a7e4-9d20-4e4d-944d-31277166781d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50e15f58-ca88-4930-a912-daaedd68b579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2591fe24-2a46-4a1a-a606-1b455403fd65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3e1fb25-03a2-4280-a057-374597d93bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c44bebd7-34ca-4344-83a8-508762f32ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03989988-9775-447a-a2e9-4c5a556e27d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 079c40de-861c-40cb-a037-305859e668ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89a17e45-bf3a-4e2c-8c85-77d9ae824d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79f004cb-dd50-4ab2-9752-9cde6e0827d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17fe1ea3-86c2-4c20-a483-3dd52d3abc3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b936a6f4-0ea6-4b12-bef0-434817ec1a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3d11fef-fc14-4106-aa3f-c9c76f9dc918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ddef9bb-c3f0-4efe-806a-742ff39739b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc3edf9a-4a39-483c-b40d-385f0f3a2fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27b9fc60-37c1-43c5-83a4-8be3f8eaffca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82336409-fe06-4248-b540-5886eb5f99df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca00e7da-603c-40df-8844-20236d3c96c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ca7358c-b3c7-44ba-84ef-9ddeef768f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd809f7-9a03-4e5a-b3d3-947792e4080f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e85d0a08-60f9-4ede-aced-1d7d776858eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd557643-8925-4b83-8461-fec872a2abdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e594914c-7cfc-469b-ba0f-48be0fa6e345
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_70
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/test_labels.txt

📊 Raw data loaded:
   Train: X=(1108, 24), y=(1108,)
   Test:  X=(278, 24), y=(278,)

⚠️  Limiting training data: 1108 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  269 samples, 5 features
✅ Client client_70 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2463, R²: -0.0065

============================================================
🔄 Round 3 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0911 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0828, val=0.0905 (↓), lr=0.001000
   • Epoch   3/100: train=0.0825, val=0.0905, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0822, val=0.0905, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0820, val=0.0905, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0807, val=0.0913, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 3 Summary - Client client_70
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0084
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0034
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2466, R²: -0.0061

============================================================
🔄 Round 7 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0832 (↓), lr=0.000250
   • Epoch   2/100: train=0.0853, val=0.0832, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0850, val=0.0833, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0849, val=0.0833, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0847, val=0.0835, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0843, val=0.0836, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 7 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0010
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0324
============================================================


============================================================
🔄 Round 13 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0875 (↓), lr=0.000063
   • Epoch   2/100: train=0.0848, val=0.0874, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0847, val=0.0874, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0846, val=0.0872, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0845, val=0.0872, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0842, val=0.0868, patience=4/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0840, val=0.0866, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 13 Summary - Client client_70
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0020
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0440
============================================================


============================================================
🔄 Round 16 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0871 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   • Epoch   2/100: train=0.0854, val=0.0870, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0853, val=0.0870, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0853, val=0.0870, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0853, val=0.0870, patience=4/15, lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0853, val=0.0869, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 16 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0169
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0245
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2478, R²: -0.0269

============================================================
🔄 Round 20 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0835 (↓), lr=0.000004
   📉 Epoch 2: LR reduced 0.000004 → 0.000002
   • Epoch   2/100: train=0.0867, val=0.0835, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0866, val=0.0834, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0866, val=0.0834, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0866, val=0.0834, patience=4/15, lr=0.000002
   📉 Epoch 10: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0866, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 20 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0180
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0211
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2478, R²: -0.0269

============================================================
🔄 Round 21 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 21 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0215
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0071
============================================================


============================================================
🔄 Round 23 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 23 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0216
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0069
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2478, R²: -0.0269

============================================================
🔄 Round 25 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 25 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0239
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0758
============================================================


============================================================
🔄 Round 26 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 26 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0150
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0343
============================================================


============================================================
🔄 Round 27 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 27 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0173
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0264
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2478, R²: -0.0269

============================================================
🔄 Round 28 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 28 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0192
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0181
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2478, R²: -0.0269

============================================================
🔄 Round 29 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 29 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0226
   Val:   Loss=0.0787, RMSE=0.2804, R²=-0.0023
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2478, R²: -0.0269

📊 Round 29 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2478, R²: -0.0269

============================================================
🔄 Round 35 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 35 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0211
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0118
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2478, R²: -0.0269

============================================================
🔄 Round 36 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 36 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0158
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0298
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2478, R²: -0.0269

📊 Round 36 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2478, R²: -0.0269

============================================================
🔄 Round 41 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 41 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0147
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0405
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2478, R²: -0.0268

📊 Round 41 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2478, R²: -0.0269

📊 Round 41 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2478, R²: -0.0269

============================================================
🔄 Round 44 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 44 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0203
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0118
============================================================


============================================================
🔄 Round 46 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 46 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0165
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0318
============================================================


============================================================
🔄 Round 47 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 47 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0184
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0204
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2478, R²: -0.0269

============================================================
🔄 Round 49 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 49 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0149
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0350
============================================================


============================================================
🔄 Round 50 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 50 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0173
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0535
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2478, R²: -0.0269

============================================================
🔄 Round 52 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 52 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0174
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0476
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

📊 Round 52 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

============================================================
🔄 Round 55 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 55 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0201
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0134
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

============================================================
🔄 Round 56 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0998 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0998, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0998, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0998, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0998, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0998, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0998)

============================================================
📊 Round 56 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0128
   Val:   Loss=0.0998, RMSE=0.3160, R²=-0.0422
============================================================


============================================================
🔄 Round 57 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 57 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0220
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0108
============================================================


============================================================
🔄 Round 58 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 58 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0232
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0176
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

============================================================
🔄 Round 62 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 62 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0225
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0048
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

============================================================
🔄 Round 64 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 64 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0178
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0246
============================================================


============================================================
🔄 Round 66 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 66 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0160
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0351
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

============================================================
🔄 Round 67 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 67 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0136
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0400
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

📊 Round 67 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

📊 Round 67 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

📊 Round 67 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

📊 Round 67 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

📊 Round 67 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

📊 Round 67 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

============================================================
🔄 Round 76 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 76 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0167
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0327
============================================================


============================================================
🔄 Round 77 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 77 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0186
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0189
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

============================================================
🔄 Round 79 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 79 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0140
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0424
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

📊 Round 79 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0270

============================================================
🔄 Round 81 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 81 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0206
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0125
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

============================================================
🔄 Round 82 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 82 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0189
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0211
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0269

============================================================
🔄 Round 83 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 83 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0131
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0430
============================================================


============================================================
🔄 Round 87 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 87 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0130
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0424
============================================================


============================================================
🔄 Round 88 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 88 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0198
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0138
============================================================


============================================================
🔄 Round 90 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 90 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0220
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0135
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0270

📊 Round 90 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0270

============================================================
🔄 Round 93 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 93 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0179
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0296
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0270

📊 Round 93 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0270

📊 Round 93 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0270

📊 Round 93 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0270

📊 Round 93 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0270

📊 Round 93 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0270

============================================================
🔄 Round 104 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 104 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0178
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0277
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0270

============================================================
🔄 Round 106 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 106 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0177
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0223
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0270

============================================================
🔄 Round 107 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 107 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0185
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0391
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0270

📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0270

============================================================
🔄 Round 111 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 111 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0225
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0047
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

============================================================
🔄 Round 113 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 113 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0131
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0399
============================================================


============================================================
🔄 Round 114 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 114 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0162
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0442
============================================================


============================================================
🔄 Round 115 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 115 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0223
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0058
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

📊 Round 115 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

📊 Round 115 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

📊 Round 115 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

============================================================
🔄 Round 122 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 122 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0149
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0384
============================================================


============================================================
🔄 Round 123 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 123 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0183
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0204
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

============================================================
🔄 Round 125 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 125 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0176
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0300
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

============================================================
🔄 Round 126 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 126 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0215
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0111
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

📊 Round 126 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

============================================================
🔄 Round 128 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 128 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0139
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0378
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

============================================================
🔄 Round 131 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 131 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0223
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0110
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

📊 Round 131 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

📊 Round 131 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

============================================================
🔄 Round 136 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 136 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0163
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0328
============================================================


============================================================
🔄 Round 137 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 137 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0139
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0545
============================================================


============================================================
🔄 Round 138 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 138 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0177
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0229
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

============================================================
🔄 Round 142 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 142 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0192
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0280
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

============================================================
🔄 Round 143 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 143 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0108
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0618
============================================================


============================================================
🔄 Round 144 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 144 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0162
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0381
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

============================================================
🔄 Round 146 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 146 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0193
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0202
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

============================================================
🔄 Round 147 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 147 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0155
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0341
============================================================


============================================================
🔄 Round 148 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 148 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0194
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0172
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

============================================================
🔄 Round 149 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 149 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0140
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0379
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

============================================================
🔄 Round 151 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 151 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0113
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0826
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

📊 Round 151 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

📊 Round 151 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

📊 Round 151 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

============================================================
🔄 Round 158 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 158 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0189
   Val:   Loss=0.0942, RMSE=0.3068, R²=-0.0245
============================================================


============================================================
🔄 Round 160 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 160 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0180
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0420
============================================================


============================================================
🔄 Round 161 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 161 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0184
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0226
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0272

============================================================
🔄 Round 163 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 163 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0159
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0692
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0272

============================================================
🔄 Round 164 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 164 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0172
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0253
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

📊 Round 164 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

📊 Round 164 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0271

============================================================
🔄 Round 169 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 169 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0153
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0333
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0272

============================================================
🔄 Round 174 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 174 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0251
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0035
============================================================


============================================================
🔄 Round 175 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 175 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0216
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0107
============================================================


============================================================
🔄 Round 176 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 176 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0158
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0324
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0272

============================================================
🔄 Round 180 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 180 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0171
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0267
============================================================


============================================================
🔄 Round 183 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 183 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0220
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0084
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0272

============================================================
🔄 Round 184 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 184 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0213
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0240
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0272

📊 Round 184 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0272

============================================================
🔄 Round 188 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 188 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0179
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0237
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0272

📊 Round 188 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2479, R²: -0.0272

❌ Client client_70 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
