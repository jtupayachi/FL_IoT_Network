[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d046e29-f30a-4691-9851-7d52e1429645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb1bd385-5663-48a0-baf2-9100e31b5edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3d6c81d-de86-4377-bae9-5ad53c40a0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d69aae1-21ce-465c-87d3-cabf827b60a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14ed3933-279e-4788-8152-5b64d26c115f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db0ec89e-62bf-45b1-9c7d-f4d924a4bec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad82389a-e4d1-478a-bad6-21eaf6b5019e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 649e6200-b363-4609-a805-bad3e5c96238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1981f77-f9ed-4f48-892d-b7becd5efe2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a645e451-459b-4afb-8843-15556ced2efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab5f7aa5-e066-443d-9bbb-384093c0ee1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0518b5e-7dc5-458d-bfc4-408aba73f066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73498f34-cc8d-4fe5-85fa-d36aab5de556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aad803d4-854c-4b4f-a868-693a04bdc51e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72574a6d-b443-4c55-b62c-d4e70a42c3de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 845a6119-7f12-4a5c-a591-826e28907723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71ca2b94-ad24-4c63-b942-b7218fad5725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2bd6e04-3666-4d9f-b5fc-27688d8d71d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2db8ac19-7ce3-4523-a8f6-eda8713e1d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f226d6f-e964-4e99-9a0f-97cd6e99094f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 783a5d01-166f-4613-acf7-4f11081a2dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6847e0c-b606-49e1-b1f2-4d965ad40e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79614c9e-943b-4264-b2b3-49505f122950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 299828ee-73c1-4763-8209-bd2125f2df65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfe432cb-4338-40ac-a783-594a9652d722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9baa6150-2bc4-4953-8e23-de0fe65efacd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4edd7b36-062d-4909-a42b-af9ccfaecb60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4da6ad6e-43bc-4972-a17b-c77a081b03ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad97bcb4-03be-42fc-9d79-c3f8f862f664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb29db8-1a72-486e-bb62-69d27e4e6bed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80841a24-c841-48ec-a465-2e3a6b78ce53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c44dbbb5-b0dd-4438-93d7-6f02e7779d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29a44ed7-0612-4fae-9420-742c120a079a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c548cf8-00ff-4354-a507-c1cfb57da5ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4694b99-addf-4c42-97c2-546add5fce23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71470ce3-e23e-468b-bfea-00e8e0b18847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a2a85a3-e502-42a1-bbf1-5f8eb0cab824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7503f235-5d11-44ae-be09-62a29bb84837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e3864bd-d2c3-4878-8cfc-a837bce04561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00b51ac3-a0b0-4b4f-8d8a-ffdc5a34ca5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db8edb9f-a2f7-4709-b210-0975a4964ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f3aa352-0de5-4cb5-9b67-d5320a0eb14b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbaa2cef-5bfa-4b96-916f-7ab8390f4287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c618bcb-6851-40de-be06-7b810172be80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb69454f-e1c4-4473-ab5e-e285929cb897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2acaa2c7-5321-41a7-9e0b-9d78c781a9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aac6939c-0a19-4ab9-84f6-be47072a4234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7893c51b-f9f6-4345-8b3e-4a122122695c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d14467f3-1788-47e7-8338-6aa0c5f07eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 542ebdad-6e81-4ceb-ae06-18ff08b9466d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70650657-999a-4476-85b1-a8376475be21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b87f633a-434c-4e54-bf49-868922eba846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65e19e85-220b-4c04-9249-2d5ecadb52f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c330abb-a402-475a-8a48-cd458fd461d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7033fd1-1b44-4805-9fab-4d6e9f7c3f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79f2441b-861e-4150-b6d1-db282db52fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de40d549-4b82-47aa-80c9-58c817cdbd50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e662598-50b4-451e-8dc0-86ad345585d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9052b8a7-42d8-4b94-afdf-aa76cacfdde7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b32ae046-f79b-412d-aa0a-4c9d5d0418f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67d7b786-40f0-4163-ac67-e8a02b66cc42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 066c4984-a68e-4f80-904b-06b29c1419b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c69cbcbb-9721-4235-972d-1ee1e531e3ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c276da0e-7d35-4d9b-b364-2eb263e60da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8a51f8e-4998-41fb-ae56-491a4e7e83dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35a234c3-b635-4908-b337-a5fff48f807a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53895df3-3aeb-45fe-99da-59e13a22d33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 065a4ca6-aba8-463a-af75-96245c6bb521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bef7ab4-b86a-408d-a264-39fe586af381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1eb587e-eca5-483d-80c3-cc663aee8133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09c7d06c-0ed6-41b3-b11b-8cf0dc16f431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2d8d618-8d22-412b-8eeb-2aca3c0e2ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0afa6b93-ea45-4077-ba3b-c8f64723a8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 871f8888-14c9-46d0-a8ab-d6f4165624a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5c80cfd-bb5d-45ec-b357-057474173ea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14b01584-446e-4294-9ce9-57515542670f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bff1d1f-38db-4009-997a-36373a23c39a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bafa5340-d269-4b42-b58e-8cf40b7438ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e376bf12-10b9-44f5-9458-66edef9def91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66f903b1-b276-4ce3-93c3-ca0e8675acb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c9b867c-3e40-47c4-b514-1268bbf6f6fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d61f1a3f-b875-462a-9894-3c4f9a417e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abb96676-3a45-4725-9cf3-7556acc4aaee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45536e9f-c140-4622-a663-70155b98982e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96fc298b-49d2-49e8-b387-a39da8a7062e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb23a76-4e7c-4a29-9ada-7970526b7013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6274aeb3-49cc-4c11-92ec-19ff393ac291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 201b9c63-d455-46e0-beba-e08868ee2cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac9f6631-7f20-45e0-85d8-769aa052fac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f0b3b04-d298-446f-9d5a-0a9a1b6fbed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77470bef-e442-4e56-a9dc-feca2f907e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 651456c8-d570-4ab6-8dd4-1bcca69f6de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd9da651-b07f-470f-a45f-986ae4241236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a885964-1c59-41a8-aebe-198b0e33b60b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b1f62e3-a4dc-4ecb-addf-eb3b29cd5b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59de8c90-86fa-4847-9353-bf4dddabad18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d325ee49-c78d-4d44-a9a1-151fd468843d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2260a9b-6218-430a-bc83-b47319d3db5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 784b39ad-27d4-4f70-a54c-be36469ac2a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4eddde4-5729-48b5-a6a7-d91d4499aafa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14bbe2b3-c06d-421a-b617-d258acb651bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7110b55-fd1a-4848-963a-f7b3911f6881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65fd550a-1539-4262-8a94-87b66fbbd976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb4236d2-390a-4f7b-bcb2-68a9f76c1ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb1792fc-c8ba-4c0e-a158-d9fd0788804e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 525709ef-4dd8-44ab-b569-65433cb0f728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5b2f11f-5ae2-4347-b3c1-d4ae49adad9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab26b172-2f56-4a45-b677-fd93b94f1dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57adfb35-6dc6-46b6-9f44-4e22020977d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f71aef2-62aa-480d-b7c3-857fdf98f1ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8cb8ec0-4c05-4683-a8e0-f0c081d1b9eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58cb61e1-1b7e-4d49-98c0-c68d092f63ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aed8bb66-18a5-4feb-b78f-464dcc9b2084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 150d980c-58d4-40e0-a4e3-6be347b14695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f941811-b986-4971-86c0-ff2ec05d7e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35670be3-ea41-4821-bdc9-54950a3a3b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb2feac3-d821-418b-994e-8f2ecefa6740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4dbcd58-28a2-46bf-a231-675c1da0c061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faaf5d65-2d22-43b7-9ea5-71667bf299d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6da91b8e-53ae-4398-b4b0-b9247d71e513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message add1e434-c4d3-4577-a3a4-73b9a19f698c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 505c2847-42d9-4011-8410-55d1a68e0f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6308e434-a24a-4e56-88af-0ef5cbd47e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8e89d56-b17e-4145-8e51-c938ef5a3a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54b5e0bc-fb8c-48be-9c1d-40189e1077d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f18de274-e908-4941-8a6b-b47ebe53a617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2a752ac-a849-48ea-b5d1-3ce93095cfec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2630dece-8be3-45fb-95d3-1951153ae821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d4799f9-57d1-401c-b3f0-606512ed96df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa0b9559-abf4-4816-9090-5c135a0f7298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3350a9a5-19f3-4780-98c4-10b8e22f2e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d0a7897-6e53-41d8-bf7d-2943dd0ec294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1130de9-8d4c-4e8a-b201-bf623a0baeff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7711670e-49d1-4131-953e-41a504f77f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 748b00a0-29ee-466a-8c52-1971f90f919c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92f1ea52-2949-4257-a9df-e5174823ef56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5553a5fd-8d93-4039-b9a7-11f44afb1e90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd56fe6f-3394-4aed-bd0c-90dbb0b1e3aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5527275e-890c-4df9-9d54-f54907f723f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebc1bbef-a6d3-4bb7-8b41-c6836f656c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c95f846-3d83-4021-8dac-568b39f464c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57953fea-b810-4df4-812c-1fff215c31ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 569c17bc-498b-4ef9-a6f6-8de93b6b248c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd59d667-57c0-45b4-9580-419a3a216903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 193d9af0-37a1-4a35-a1a0-35e32d346b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c6d2bbd-8f22-41bf-9c52-af4893940fc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a0e9520-1c50-4bd4-92b7-f08c5b87bc1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be7ce36c-944a-4fd8-b525-f601ffc4b736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc125e6b-baa9-4dc1-9707-a7b46fb1ba84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf7a7789-6455-433f-bb73-898703b5cf5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5853d90-a11a-4b6b-9124-2033f4d7cd49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa9c4de-4b41-4c32-9870-b1f38e5820db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27c06e12-ef0a-4db0-8ae4-07203cbd5f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 168d47f2-6326-429a-b3f6-f2bf558ee09f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_72
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/test_labels.txt

📊 Raw data loaded:
   Train: X=(2172, 24), y=(2172,)
   Test:  X=(543, 24), y=(543,)

⚠️  Limiting training data: 2172 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  534 samples, 5 features
✅ Client client_72 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2461, R²: 0.0044

============================================================
🔄 Round 4 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0847 (↓), lr=0.001000
   • Epoch   2/100: train=0.0845, val=0.0843, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0845, val=0.0839 (↓), lr=0.001000
   • Epoch   4/100: train=0.0845, val=0.0835, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0845, val=0.0833 (↓), lr=0.001000
   • Epoch  11/100: train=0.0823, val=0.0842, patience=6/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500
   📉 Epoch 20: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 4 Summary - Client client_72
   Epochs: 20/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0211
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0136
============================================================


============================================================
🔄 Round 8 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0910 (↓), lr=0.000250
   • Epoch   2/100: train=0.0818, val=0.0908, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0816, val=0.0905 (↓), lr=0.000250
   • Epoch   4/100: train=0.0814, val=0.0902, patience=1/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0813, val=0.0900 (↓), lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0807, val=0.0893, patience=3/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0803, val=0.0889, patience=1/15, lr=0.000063
   📉 Epoch 24: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0801, val=0.0887, patience=11/15, lr=0.000031
   📉 Epoch 32: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 8 Summary - Client client_72
   Epochs: 35/100 (early stopped)
   LR: 0.000250 → 0.000016 (4 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0285
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0438
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2453, R²: 0.0124

============================================================
🔄 Round 10 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0776 (↓), lr=0.000016
   • Epoch   2/100: train=0.0852, val=0.0776, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0852, val=0.0776, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0851, val=0.0776, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0851, val=0.0776, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0850, val=0.0776, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 10 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000008 (1 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0133
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0096
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2450, R²: 0.0151

============================================================
🔄 Round 11 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0872 (↓), lr=0.000008
   • Epoch   2/100: train=0.0827, val=0.0872, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0827, val=0.0872, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0826, val=0.0873, patience=3/15, lr=0.000008
   📉 Epoch 5: LR reduced 0.000008 → 0.000004
   • Epoch   5/100: train=0.0826, val=0.0873, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0825, val=0.0873, patience=10/15, lr=0.000004
   📉 Epoch 13: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 11 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0138
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0050
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2449, R²: 0.0151

============================================================
🔄 Round 12 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0830 (↓), lr=0.000002
   • Epoch   2/100: train=0.0837, val=0.0830, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0837, val=0.0830, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0837, val=0.0830, patience=3/15, lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   • Epoch   5/100: train=0.0837, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 12 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0129
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0096
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0154

📊 Round 12 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 15 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 15 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0127
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0119
============================================================


============================================================
🔄 Round 18 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 18 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0145
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0034
============================================================


============================================================
🔄 Round 19 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 19 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0114
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0130
============================================================


============================================================
🔄 Round 20 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 20 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0126
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0011
============================================================


============================================================
🔄 Round 29 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 29 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0126
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0026
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

📊 Round 29 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

📊 Round 29 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 33 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 33 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0109
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0166
============================================================


============================================================
🔄 Round 34 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 34 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0149
   Val:   Loss=0.0957, RMSE=0.3093, R²=-0.0330
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 39 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 39 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0132
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0068
============================================================


============================================================
🔄 Round 40 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 40 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0136
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0039
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

📊 Round 40 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 46 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 46 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0064
   Val:   Loss=0.0882, RMSE=0.2971, R²=0.0348
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 48 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0971, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 48 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0143
   Val:   Loss=0.0971, RMSE=0.3116, R²=0.0069
============================================================


============================================================
🔄 Round 49 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 49 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0125
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0003
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 53 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 53 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0080
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0202
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

📊 Round 53 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 56 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 56 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0153
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0004
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 57 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 57 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0115
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0118
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

📊 Round 57 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 59 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 59 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0077
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0303
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

📊 Round 59 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

📊 Round 59 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 63 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 63 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0096
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0166
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

📊 Round 63 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 65 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 65 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0109
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0165
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 67 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 67 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0117
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0109
============================================================


============================================================
🔄 Round 70 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 70 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0059
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0295
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 72 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 72 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0088
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0264
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 74 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 74 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0107
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0204
============================================================


============================================================
🔄 Round 75 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 75 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0132
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0052
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 77 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 77 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0133
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0088
============================================================


============================================================
🔄 Round 79 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 79 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0136
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0183
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

📊 Round 79 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 84 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 84 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0093
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0170
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

📊 Round 84 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 87 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 87 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0171
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0113
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 91 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 91 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0156
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0012
============================================================


============================================================
🔄 Round 92 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 92 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0140
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0114
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

📊 Round 92 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 97 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 97 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0141
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0000
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 99 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 99 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0123
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0113
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

📊 Round 99 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0155

============================================================
🔄 Round 101 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 101 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0161
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0025
============================================================


============================================================
🔄 Round 102 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 102 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0096
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0213
============================================================


============================================================
🔄 Round 104 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 104 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0148
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0172
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 104 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 104 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 110 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 110 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0168
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0146
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 111 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 111 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0127
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0123
============================================================


============================================================
🔄 Round 112 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 112 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0164
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0150
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 115 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 115 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0125
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0101
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 118 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 118 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0179
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0140
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 118 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 122 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 122 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0156
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0001
============================================================


============================================================
🔄 Round 123 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 123 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0077
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0327
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 124 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 124 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0128
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0032
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 124 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 126 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 126 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0154
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0003
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 127 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 127 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0092
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0274
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 128 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 128 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0151
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0030
============================================================


============================================================
🔄 Round 129 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 129 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0129
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0086
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 130 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 130 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0158
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0215
============================================================


============================================================
🔄 Round 132 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 132 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0152
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0007
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 132 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 132 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 137 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 137 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0093
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0007
============================================================


============================================================
🔄 Round 140 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 140 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0144
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0077
============================================================


============================================================
🔄 Round 141 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 141 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0159
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0094
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 141 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 141 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 148 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 148 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0122
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0063
============================================================


============================================================
🔄 Round 149 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 149 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0186
   Val:   Loss=0.0968, RMSE=0.3112, R²=-0.0081
============================================================


============================================================
🔄 Round 150 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 150 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0107
   Val:   Loss=0.0923, RMSE=0.3039, R²=0.0192
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 150 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 150 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 150 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 150 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 155 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 155 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0115
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0101
============================================================


============================================================
🔄 Round 156 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 156 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0050
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0204
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 156 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 160 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 160 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0100
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0033
============================================================


============================================================
🔄 Round 161 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 161 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0123
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0138
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 163 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 163 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0165
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0047
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 163 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 163 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 163 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 168 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 168 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0135
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0091
============================================================


============================================================
🔄 Round 169 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 169 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0107
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0156
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 169 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 171 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 171 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0120
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0108
============================================================


============================================================
🔄 Round 172 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 172 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0136
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0074
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 174 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 174 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0067
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0300
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 176 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 176 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0134
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0136
============================================================


============================================================
🔄 Round 177 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 177 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0190
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0149
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 178 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 178 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0149
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0064
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 180 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 180 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0153
   Val:   Loss=0.0689, RMSE=0.2626, R²=-0.0012
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

============================================================
🔄 Round 183 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 183 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0124
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0124
============================================================


============================================================
🔄 Round 185 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 185 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0122
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0131
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

📊 Round 185 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: 0.0156

❌ Client client_72 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
