[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57d9a877-87a9-4060-b1e3-92958504bf65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 367f6fb2-7398-427a-b0c6-71c8243cd6ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50748bc1-c8b7-48ad-aaa1-c6c7b2dfc997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0143c4b-7072-4b0b-8e56-6b465fc097ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb456b75-223f-41d5-a7dd-fa0abc569cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4309d313-adc3-44db-bcf3-e6038eed689d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab995ea6-c857-46ee-a030-8031003cfc5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ca31a66-0159-4766-9457-25634056da8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 830e603b-095a-47a4-b416-ef036123e816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58ff5b99-3493-4848-991d-8932637246ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07ff9f98-d6a5-4de0-a950-1568cf22a1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 966dad3b-7a46-4182-89c0-e412b21ac334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7586d52d-570f-462e-99e9-268abb1af8f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2072442e-ddde-4e93-9d6a-2074acb8a30a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4392abda-895d-4bd2-8a3f-50ae82682d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 227ba56f-fc78-42a3-b3a8-50a47b9dc4ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f33c9fa1-003f-4234-b9d3-bc7623c7a1ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ddc3382-0c88-4d91-8455-e1afa5afbeaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84f9b919-d209-4ac7-8ada-c54f3b38b1a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a64a1703-02a5-4b19-a05d-a90b7301ad47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 692304d3-e7d0-406e-9142-cccbfea09dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8a1a901-d55a-4382-9936-f9ef1114bd22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e9341c0-ff7a-4be5-988e-f8c4e0c751df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68a0e5bc-aff2-4246-9cc2-31dcdcb2d979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2ff5266-b727-4efc-a265-d1cf80b692c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43e6d3d5-31f5-421f-ad3b-4edede40dca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c77b6cd-0f31-4e6e-8847-16f82229bebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6986b644-5b81-4f2b-888c-d50435fd42c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32660652-64d6-475b-8437-76f7b8b8437a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22ccf0fd-9b12-4f66-b087-ef4f0742c3a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fa96061-e309-431a-b0d5-98392416464f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84c8de22-166b-4a7c-9b0f-2fe524fb3aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab9e827-34dd-4f7c-8519-86ef43405a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16c16edd-22ca-49b9-b6be-cad01b4c08a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 919fed41-3ea1-40ce-89c7-7bb751f24984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51f52592-d56a-4491-87b3-a650ca85b63d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab23c36c-8301-4ae4-8068-0235986ae742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d11c1fb-ad34-4ec0-be60-f0063e13ba14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43cab58e-0220-49b8-b352-6bb40a6bc76b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbba8309-e0e2-4d52-9ec0-686910dcca3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd5ba69e-c54b-4465-b326-831807e82284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdb01a8a-f889-401c-89aa-f4dd4961c968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64022dbf-1b61-4af1-b4d4-eeaa200491db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e88567c-b447-44a8-b565-9b3e93dc11b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d62d65e-ca4a-4fb9-abe7-dc3ccd56994f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28ec7dfd-6577-45be-ba20-6b68ae733b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f571b5a0-6de9-48c6-a342-c519dbf05585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71f76122-c5a8-42b2-ae0f-b86d8f9b2f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0d0d91a-90bc-4b76-a212-bedac09fa534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f655d6b-cd16-4a3a-b80e-15e080eb4a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85db9031-6532-4c09-9fd0-4265ec197b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message befec3ef-716c-4963-a70a-dd4f173bd1fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 541f7ed0-bca2-48f2-9c99-7586ca68149c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51fc4cfb-4528-449c-9701-69417b404fe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db7c4f4b-2cf5-4f54-ad81-48eecfbfd01d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60d280d9-d750-466e-9c72-bce409bf1f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b9cff8f-7d15-4614-91ed-4045b3d6f475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df45e863-c5bb-4618-8cf3-f20604c176c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57bd056e-1164-4bc7-80f9-88ed86753d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06a8dd51-0714-4de1-9afb-4074d369f713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0507e13a-1def-44bf-99ba-0f59d9b89a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23530e14-dc20-46a6-bffa-192dac008c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ac32eff-19a8-4bbb-9d7f-f85be15a7ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e950e956-8322-4309-98f5-89f0e7d73442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d82b86f1-daa4-484d-899c-6f2242d4b6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1ea58d5-2c70-4714-96bd-bc5b8fdc68cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95edf2b8-986a-44cb-80f3-4ee4d352f891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a46334c8-a493-488d-9abd-858ff2873f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcab7d14-8dd2-4b29-826b-7384dba765d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebd716da-8ac1-4703-8f88-38fe036deaf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cfacfd7-27c6-4bdd-a065-6289661a6719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10dcd66a-1fd6-4340-92d7-019e10e1f64b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a6dab7a-824c-4f6f-bc63-e3cf89d4f488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37a50d1f-4d18-42e5-b145-694a46b8ed25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96da996c-ec0c-418f-818d-cea5ba29f0cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1ff5c04-8342-4ddb-be4e-4067310d411a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46907f20-2724-4e15-81bd-9cd9a637bb30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fc7d662-9914-4738-8ed3-ca0219c15441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a46f1fa-80ae-484b-92c2-13abb4b82bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4be1f05a-39cb-4b7b-b661-a6751a9a31ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccc2d512-d043-4534-bcda-0186525302e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5be74e3-5786-4df3-b866-a5ce9081eae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e286edee-e03c-47e5-9416-bfe8e844f320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07437764-1a44-4fc4-8633-353a345a7b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dc72276-b19e-4068-b0f7-8de60144a1eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02d89618-0a25-4a1f-ad1d-0c4d94b27377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fee0f9b8-359f-40e5-94b0-5f31854ee8bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1c98bd3-23f4-4d5e-ab28-fb6f3516cf93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2be56319-f8a0-4f50-ba7e-584dc8b6ded3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e4380fc-e563-47ef-a5b4-507044ce24ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb564b1a-5d2a-40e8-bcec-107ece269a0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f02dc6e8-c01c-4245-bda0-68f04ae52026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70b39a90-b01f-4af8-8f22-6aad9b70335a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32bc4486-001f-42c8-997a-a94e86904210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f4424c8-61dd-4c78-94e7-0f7bcaefc761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6478fe83-5bde-49a5-8abd-c10ae06f520e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86409b7a-e641-4a89-9777-d86bf6e01ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29aca5db-7120-4436-aaf5-221fbe6762f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7aa1d4c-e620-4386-af00-ad0c2d6719a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3b18ca2-5961-4514-a811-b421aa56ae54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d8b475e-bd2b-41d4-8098-8af0c6b214d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d425f07c-e11b-4501-8067-526c34bb3197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d225f872-41e3-4b1c-b946-7d0129f9287b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08fce88b-5d20-415a-8296-ecd79806284a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2baf54fc-3227-4ce4-a5d8-da6129c94c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72593abe-bf03-4e5a-a613-633ce30541f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40e4e537-b5c8-4f18-9044-0d4b4ed27aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26efb70f-ab21-415e-802f-b670b6373921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3556b8d0-d1b6-402e-ac92-545b65756ce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e3e075a-1a32-42b1-913d-10cbc0181ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fae8f9f-7253-4b7d-9ee5-54dc23f4be7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7df71c4-543e-4908-8c3b-ded29de3bb1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f5d4ac1-89b5-46f8-9a48-076e27d9a19a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc2a0557-85ed-4409-b53b-06266e4f1b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5517a8e6-c604-46a0-98e8-4c0afa06f91b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9502fd29-e748-43d6-8c85-aa7ac386f0c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2470e496-88bd-496e-a812-48e24d11f892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f112bdd3-fea5-4c9a-8005-a3c1e20968df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b69c6366-c12d-493a-a0f7-a015b7423edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 502a351c-e6d7-4497-92ee-7828388081c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db62c0ba-3982-4f41-9d2a-bc00901bc79c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c813d5ec-3b4f-4c22-b878-6250956d643e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d570df7d-af49-4f34-a820-4e56a14a6d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 605f5a26-abc2-4f74-802c-9617e957a938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a907649f-c383-4310-a4b4-83f1f0842837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70e242c2-1706-4ec6-85ee-c94258e545e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bba52042-b845-42c8-b1f4-3ae80be5be8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2222cea0-8e70-4a65-ad80-b4afbae9149f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01254df6-7e93-4512-aa08-fa2742329e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33d642f0-a819-44f4-bb04-3b06b5a6d322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84debaa8-3b2f-46c3-a04a-c93d9e2dd5b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ed4eb92-1b98-4eaf-b5e7-6227979a934a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46852375-2b18-447b-b7c6-3e63895db439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e8eb732-426f-46aa-9e81-0c70322ec42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7a31070-c12e-460d-afb1-1b782509a854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8fe5ec5-4d0a-4f4d-8ca9-ef00b87ac773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f93be497-1c57-4181-b2f9-306f640fca02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f93f2062-579c-44e3-b765-3844e375f1fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5764400e-86cf-4d92-9016-b5d1ad1829fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5140b817-3d66-40fe-bf9d-05c75d9032ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf75527c-0be5-4eba-8539-eb43dd2a2ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc39de27-8653-4867-84a7-d185ff47fe2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e92fd88-a75d-46b6-ada3-7da5f28a4324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07580cb8-087a-4d46-ae03-1af7f6db6046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60ed42f0-ab37-413f-82b1-7e8365bb90fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7821252-59b2-4e0f-9afa-10157eefc834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71a7c9a9-1ca9-4f6b-8ee2-43e9cea68198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 970c8f00-424e-44a5-9e12-dedff1a305f7
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_73
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/test_labels.txt

📊 Raw data loaded:
   Train: X=(1311, 24), y=(1311,)
   Test:  X=(328, 24), y=(328,)

⚠️  Limiting training data: 1311 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  319 samples, 5 features
✅ Client client_73 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2462, R²: 0.0062

============================================================
🔄 Round 2 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0879 (↓), lr=0.001000
   • Epoch   2/100: train=0.0829, val=0.0897, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0844, val=0.0868 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0837, val=0.0858 (↓), lr=0.001000
   • Epoch   5/100: train=0.0821, val=0.0858, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0803, val=0.0860, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 2 Summary - Client client_73
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0118
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0031
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2441, R²: 0.0228

📊 Round 2 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2433, R²: 0.0302

📊 Round 2 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: 0.0396

📊 Round 2 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2382, R²: 0.0651

📊 Round 2 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2367, R²: 0.0739

============================================================
🔄 Round 11 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0742 (↓), lr=0.000250
   • Epoch   2/100: train=0.0802, val=0.0737, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0798, val=0.0735 (↓), lr=0.000250
   • Epoch   4/100: train=0.0795, val=0.0733, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0792, val=0.0735, patience=2/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0781, val=0.0736, patience=8/15, lr=0.000125
   📉 Epoch 18: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 11 Summary - Client client_73
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0512
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0663
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2364, R²: 0.0758

📊 Round 11 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2363, R²: 0.0763

============================================================
🔄 Round 15 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0757 (↓), lr=0.000063
   • Epoch   2/100: train=0.0796, val=0.0758, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0795, val=0.0758, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0794, val=0.0757, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0793, val=0.0757, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0788, val=0.0754, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 15 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0493
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0204
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2360, R²: 0.0775

============================================================
🔄 Round 17 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0751 (↓), lr=0.000016
   • Epoch   2/100: train=0.0798, val=0.0751, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0798, val=0.0751, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0797, val=0.0751, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0797, val=0.0751, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0795, val=0.0752, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 17 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0428
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0464
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2360, R²: 0.0776

============================================================
🔄 Round 18 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0841 (↓), lr=0.000004
   • Epoch   2/100: train=0.0777, val=0.0841, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0777, val=0.0841, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0777, val=0.0841, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0777, val=0.0841, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0776, val=0.0841, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 18 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0412
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0493
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2360, R²: 0.0776

📊 Round 18 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2360, R²: 0.0777

📊 Round 18 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2360, R²: 0.0777

📊 Round 18 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2360, R²: 0.0777

📊 Round 18 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2360, R²: 0.0777

📊 Round 18 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2360, R²: 0.0777

📊 Round 18 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2360, R²: 0.0777

============================================================
🔄 Round 33 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 33 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0411
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0483
============================================================


============================================================
🔄 Round 35 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 35 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0436
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0278
============================================================


============================================================
🔄 Round 36 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 36 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0452
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0371
============================================================


============================================================
🔄 Round 37 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 37 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0385
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0617
============================================================


============================================================
🔄 Round 38 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 38 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0474
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0268
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0778

============================================================
🔄 Round 41 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 41 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0412
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0405
============================================================


============================================================
🔄 Round 44 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 44 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0388
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0633
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0778

============================================================
🔄 Round 46 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 46 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0463
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0304
============================================================


============================================================
🔄 Round 47 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 47 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0461
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0337
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0778

============================================================
🔄 Round 49 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 49 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0419
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0458
============================================================


============================================================
🔄 Round 51 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 51 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0493
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0185
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0778

============================================================
🔄 Round 52 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 52 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0414
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0510
============================================================


============================================================
🔄 Round 53 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 53 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0525
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0263
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0778

============================================================
🔄 Round 54 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 54 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0424
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0449
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0778

============================================================
🔄 Round 57 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 57 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0487
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0111
============================================================


============================================================
🔄 Round 58 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 58 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0402
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0542
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0778

📊 Round 58 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0778

============================================================
🔄 Round 61 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 61 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0418
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0507
============================================================


============================================================
🔄 Round 62 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 62 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0451
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0337
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0778

📊 Round 62 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0778

============================================================
🔄 Round 64 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 64 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0432
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0416
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0778

============================================================
🔄 Round 65 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 65 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0447
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0346
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0779

============================================================
🔄 Round 68 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 68 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0360
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0749
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0779

============================================================
🔄 Round 74 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 74 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0374
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0678
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0779

📊 Round 74 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0779

📊 Round 74 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0779

============================================================
🔄 Round 82 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 82 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0442
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0118
============================================================


============================================================
🔄 Round 83 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 83 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0406
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0519
============================================================


============================================================
🔄 Round 84 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 84 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0323
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0811
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0779

============================================================
🔄 Round 86 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 86 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0482
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0221
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0779

============================================================
🔄 Round 87 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 87 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0426
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0385
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0779

============================================================
🔄 Round 91 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0667 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0667, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0667, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0667, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0667, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0667)

============================================================
📊 Round 91 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0376
   Val:   Loss=0.0667, RMSE=0.2583, R²=0.0698
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0779

============================================================
🔄 Round 92 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 92 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0391
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0606
============================================================


============================================================
🔄 Round 94 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 94 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0412
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0367
============================================================


============================================================
🔄 Round 95 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 95 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0472
   Val:   Loss=0.0792, RMSE=0.2813, R²=0.0267
============================================================


============================================================
🔄 Round 96 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 96 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0540
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0015
============================================================


============================================================
🔄 Round 97 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 97 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0403
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0545
============================================================


============================================================
🔄 Round 98 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 98 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0361
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0674
============================================================


============================================================
🔄 Round 99 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 99 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0426
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0209
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0779

============================================================
🔄 Round 101 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 101 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0429
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0433
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0779

============================================================
🔄 Round 103 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 103 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0416
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0510
============================================================


============================================================
🔄 Round 106 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 106 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0471
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0250
============================================================


============================================================
🔄 Round 107 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 107 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0401
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0447
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

============================================================
🔄 Round 108 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 108 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0439
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0421
============================================================


============================================================
🔄 Round 109 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 109 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0469
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0286
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

📊 Round 109 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

============================================================
🔄 Round 112 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 112 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0482
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0171
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

============================================================
🔄 Round 114 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 114 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0521
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0001
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

📊 Round 114 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

============================================================
🔄 Round 116 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 116 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0510
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0145
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

============================================================
🔄 Round 117 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 117 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0434
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0410
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

============================================================
🔄 Round 118 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 118 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0487
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0160
============================================================


============================================================
🔄 Round 120 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 120 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0500
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0204
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

📊 Round 120 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

============================================================
🔄 Round 124 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 124 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0406
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0516
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

📊 Round 124 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

📊 Round 124 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

============================================================
🔄 Round 130 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 130 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0377
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0674
============================================================


============================================================
🔄 Round 132 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 132 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0363
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0671
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

📊 Round 132 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

============================================================
🔄 Round 138 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 138 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0436
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0361
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0780

============================================================
🔄 Round 139 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 139 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0436
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0411
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2360, R²: 0.0781

============================================================
🔄 Round 144 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 144 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0501
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0162
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2359, R²: 0.0781

📊 Round 144 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2359, R²: 0.0781

📊 Round 144 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2359, R²: 0.0781

📊 Round 144 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2359, R²: 0.0781

============================================================
🔄 Round 151 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 151 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0497
   Val:   Loss=0.0781, RMSE=0.2796, R²=0.0187
============================================================


============================================================
🔄 Round 152 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 152 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0528
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0033
============================================================


============================================================
🔄 Round 153 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 153 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0445
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0388
============================================================


============================================================
🔄 Round 155 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 155 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0460
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0309
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2359, R²: 0.0781

============================================================
🔄 Round 158 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 158 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0389
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0653
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2359, R²: 0.0781

============================================================
🔄 Round 160 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 160 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0426
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0208
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2359, R²: 0.0781

============================================================
🔄 Round 164 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 164 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0369
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0719
============================================================


============================================================
🔄 Round 165 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 165 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2828, R²=0.0369
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0690
============================================================


============================================================
🔄 Round 166 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 166 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0488
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0226
============================================================


============================================================
🔄 Round 168 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 168 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0402
   Val:   Loss=0.0707, RMSE=0.2658, R²=0.0486
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2359, R²: 0.0781

============================================================
🔄 Round 169 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 169 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0471
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0307
============================================================


============================================================
🔄 Round 170 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 170 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0462
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0329
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2359, R²: 0.0781

============================================================
🔄 Round 171 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 171 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0489
   Val:   Loss=0.0731, RMSE=0.2705, R²=0.0122
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2359, R²: 0.0782

============================================================
🔄 Round 172 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 172 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0415
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0475
============================================================


============================================================
🔄 Round 173 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 173 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0451
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0350
============================================================


============================================================
🔄 Round 174 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 174 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0477
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0154
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2359, R²: 0.0782

============================================================
🔄 Round 179 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 179 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0430
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0405
============================================================


============================================================
🔄 Round 180 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 180 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0479
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0141
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2359, R²: 0.0782

============================================================
🔄 Round 181 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 181 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0444
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0414
============================================================


============================================================
🔄 Round 182 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 182 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0447
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0390
============================================================


============================================================
🔄 Round 184 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 184 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0401
   Val:   Loss=0.0920, RMSE=0.3034, R²=0.0524
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2359, R²: 0.0782

❌ Client client_73 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
