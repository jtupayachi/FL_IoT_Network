[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16be95fd-eaee-4a43-9d07-b5aae15dfb7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc9e1128-fde2-43bc-8113-359e60c18bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49c129fa-675c-4dd1-95ba-b7a80273e9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36fdabe3-b992-48c4-ae1b-53cf35192c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a68b3745-aeef-47ed-85c4-315ed0f7ffe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 877c6abc-d416-4197-bbbf-d09176ab4b8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47a11bc9-5933-4bb5-aa1a-215cf344f554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0fa8802-af28-4745-9599-30e13df99216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59b05288-6ded-4bfc-8c84-4cca1e467f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cb49ced-4960-4588-b297-c281a92a3cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e61fb4e-2a5e-4372-a827-be3b9f51eda5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52569ec5-4c51-4cd1-bb43-495ac792bc61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00f87fd4-df00-435c-b8b2-34e9fc7f3635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b96765c4-e6b1-49fb-af80-33cf6c9b3180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2847b2c7-c7b7-4931-83d9-07ab08b49c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79a12366-1700-4d45-95cf-f0b5d17f87e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 416b1dc4-436e-41a1-8865-73b59ddaf233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86a17609-61ac-45a3-b6bc-676f650ade12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fe9f91a-3d46-4a72-984a-8d1c0d171fd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a813759-2b12-4737-9d41-e0eb07b43ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4721eb9-27d8-47d1-8066-fd1ef046bb50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 527489f1-e77c-47e1-9198-2b2230acab14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1675e35d-0cfb-4fa6-befe-d7ee34378003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d866eaa-6824-4546-a5bf-b54ad2a7c59c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db3a628f-cd9e-4930-b539-450185ea08a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f95704-0b97-46aa-9654-25b0ed18104b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af199708-38a0-4656-b274-0280f557b634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f00375a-7482-4983-8c1c-7d30273ade7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd0bedf0-0966-4e0e-950c-7f92a0d06eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c43402b-3938-44f7-a8c6-8b80ef6c4588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f88a6c42-70bd-4295-8ec0-32eeae9a09fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c885beb-48e8-4584-80da-fb4ac760cfa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cf39e57-7b3c-4b19-a779-1ce91c206827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 186cbf34-17e9-4c1b-8813-320af44553b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cbffe7d-86ab-440b-b43f-d40c578a1fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92b59f6b-2850-4911-9427-37e12d2cc1b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9817f3f3-ebf2-4600-9087-2fbbeabcef16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f86cf567-99ea-487f-a854-bc9732d4c50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f67f258-9dcd-4f79-bab1-7b9409cffadd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98a6e291-8a4d-4d25-9887-8deb7d82e760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2afaad9-2570-4a3d-bf2a-47b3eecbe6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93be85c1-d049-432c-b2ba-8b108e760834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c7624b3-cdd3-4e86-b5f6-60054984adee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e3cf656-a17a-4636-b5ef-f07909786dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4cea461-cc5a-4f27-a247-50d80a79d4cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b251d51c-2089-4c3d-be3f-c77b8e6796c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed321116-71e7-47ed-a6ca-3cbd72d554c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a066849b-8ea9-451c-9a7e-f41de924a97d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46f2a81e-2312-4d6b-8ac4-fcf57428e11a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4466ca3d-cc14-46c0-b6b8-81655b44e79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b9c5f8e-8076-4973-9cd6-c7029fee7a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 094da29d-5d58-417b-bc51-7f533f0e5ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1e6b548-6d52-48f9-963b-29bcf0b8ad52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3784bd47-bece-4322-b0fc-7005ef1032c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a6dad07-2c57-47a6-82ca-6307fc031d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d7aaf20-3abc-499a-9cff-a7faab88a8b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 880df6b5-a6fd-47b3-ade9-37890c841018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2316ceca-12d3-482b-8ca3-f8cd08cc026b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bff50a3-c0c1-471d-b937-ed093e1194d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c98c3acc-2a54-4229-be32-62d74d3b8599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aafdc7c6-073c-4ab4-a51e-13e97c33d035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4203392-bd0a-4e0f-8254-8943f64599db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28b686b6-35b1-42c3-987f-eff4e53fc584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e08ed2d-b68d-4f14-9464-517cf7a955ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9260b08-b4c9-485d-8bd7-29161c611617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d7b93db-865f-449b-9a97-09171fe83bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64487961-6eb9-4bba-8de3-e048a0aeb524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0411192-5d10-4aaa-9cfa-c01f18967ee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9511fd3e-4ee2-4ac8-8e66-f13f58dc1350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccc7db19-bfe0-4ad6-ac2d-e73e3b0b2ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6566dd27-2795-4fc2-8f34-1afc30d4ae13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99ab3eda-12bb-46a6-85b5-664998cbb195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f95994d-6e24-4f90-b0a1-c547476f150d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a79c52b7-fa51-4cea-852e-fd2751cc8785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b845b947-3d15-401d-b2fc-304bb01579b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d542cd6-d7a3-4e65-b623-24c1ccf59568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a122610-6dc0-4d34-8bce-8879360881a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44759f60-8618-4a15-8e54-fe6f6889abd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a54f5ac-2500-4ea6-8594-14a1301f0ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2913537-7e2f-4830-b7e9-92e2e81c1045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9db1878e-1094-4e4d-9e25-91ce4a6669d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 817b9e03-4132-4842-8358-d900e2288ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05d069c3-b97c-417d-bc6e-43b1308e3b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d598ab7b-33ef-41e9-a9ab-d7286e3b3679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fcbb8f2-f36a-4547-bff0-053d4095beed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0debeeee-f159-44ad-a6ab-98ca6b4c13e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb587267-1c32-406a-b68c-d1430cd8c2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3664187-f43e-4ce9-9195-a4e761197483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60d04a43-b58e-4f24-8716-06f2e77fc48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca5a9cb1-3e21-4c49-9597-387ec3ea41d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be0fcb9-7a91-470c-96d5-267a054345ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5973ebc6-21ce-4136-9e25-b4c5e4691162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c26b791-afd8-4a12-a9d3-7f846e8f5f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 038d7b2e-4397-4ac8-8770-5b1e9fcd0172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f06394e-df95-48c3-abc8-d2ca2864bc6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37b0530a-a980-41a6-be71-68af011d7692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e8d2b5a-12bc-459f-b3ef-d3137513b004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36298cde-b9df-426b-bf16-a0173819bba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 052b0962-cc7a-48c2-83b9-a1b9b512dd73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06ce3948-8a64-459d-a782-3ea07eb0ab6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5309ab7-16bb-4f7a-89db-8ec5336fb9a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 876bfac7-35a2-4aa4-a386-aa4911367648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b15a37a-c457-46a3-b2ca-32eecef5ba05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b65e7c5-234c-412e-ab27-d38f5091b420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 596d5ac4-c54d-4ba3-a04a-a75a15927ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dfc1553-28ed-4b4e-81d1-a9258c5efc0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ab5f417-367b-45ce-87d3-fd7fb1060a99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e1898bb-e6ed-43e6-8b3b-70834c1a9ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c097a984-9b3a-4f47-a92b-e51fa12cc501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7b348bc-abeb-41e9-8cfc-8ff1d135d19a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a44f178a-620b-4efc-8194-7d536eb519df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c54a038d-e7bf-4168-b1f5-0169d9ef8208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79939a6b-9f8b-4e60-bc57-2c17de08beb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a0fb8d7-bdba-4f07-aeb0-cdede43fce5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca1d26d4-3223-49bd-808b-5560c6ac5a95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53fd7ad8-bc4a-4de1-ad63-14e31709f34c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 056b77ce-fd37-4eb2-9235-6b86f1f74441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc0f918e-8c35-4fc2-b040-9030274081f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49ee994f-4796-45b6-a7b0-7b710f6260c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c21f3dd1-17de-40c7-b693-80687218fe83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8666e7b-7bc3-4c88-92d0-c170181ea2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a07ffd6-748e-4be0-b8e0-0b55df82dfbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afd8188b-bd43-4fb3-a23e-d43709610047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fb7c32f-59b9-4880-a6b3-4104abd25672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea68bf6b-bc18-4dce-b79b-94670a079ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 128c9adb-9723-4fe6-afa2-a76a6ee21e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4385af0d-5cb0-4336-a78d-bc3b995ff742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12ab12eb-cd04-4e66-bd5e-032b8e65c2cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b8bf74c-882d-4a48-911f-c3dd2c17815f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9f43717-934d-4823-a40e-ec888f06df44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1395ca37-115a-4507-a359-9478f5f133b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d62a9868-7265-4bb8-adae-929c1aa96798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39b176c8-a6e9-4092-a826-f183501ed524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 829a803d-7f2f-40d2-bb8f-4367fd9bae81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b253a22-e540-497f-918e-6d76a909918d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddbbd6eb-49cb-4972-818f-25008c51731f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18d1b929-c003-4b0d-b467-833a103b2817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 882bf114-6c3b-4fd6-a735-eda1edb80011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78298b61-c4f0-441b-b26d-0b0036dbedb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 510cd01d-bf58-4e1f-bd9c-767f5e4bb43a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d8ca2df-5997-42e7-9ae8-dbace96e2dee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26ae9ae8-3ec8-448b-ae3c-9293bc4457c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa5bcea7-85d7-44fa-896c-ff05b7ada610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97bcd276-32ef-4fe5-9d96-242b6366a351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e3c5441-3d9e-4769-a03e-93d8358e1a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 009563da-4d56-4984-b5ad-b7acc53500ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 554cde35-c483-4fa1-9605-dd06bb6ba04e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fce8f583-1d71-4566-aa06-034605b2aa94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7982d218-d2ae-47d6-afd8-9c0b508b1e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38e54925-308b-4926-a92a-27fdbf91dab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 236beddc-62d8-4340-adc8-9b6a9c2778bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9adc3cc6-ff5a-4dbf-a195-e3ef2e0fc8a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca505431-92f9-4ef9-b0ee-bc1f411502d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a30486f5-73a6-4c80-b99f-43b6171f31dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message affdcb15-fbfe-466c-91e6-2b619aada45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24a5aed5-3fa6-4e54-95ad-6a944df6621b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0afc715-5e3c-43b0-8470-a8140a9f890c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98dc88c3-e2ee-423e-b111-b4a5f494b6cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aef21b6-0d39-425c-bb8c-eab7d834976c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33a19ed9-23ae-4b4c-8ba3-f6efa2ab0127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abb0fb22-465e-46bf-9645-05bf9fc3afd7
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_74
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/test_labels.txt

📊 Raw data loaded:
   Train: X=(1660, 24), y=(1660,)
   Test:  X=(416, 24), y=(416,)

⚠️  Limiting training data: 1660 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  407 samples, 5 features
✅ Client client_74 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3191, val=0.0938 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0919, val=0.0867 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0807, val=0.0862 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0776, val=0.0843 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0777, val=0.0837 (↓), lr=0.001000
   ✓ Epoch  11/100: train=0.0776, val=0.0831 (↓), lr=0.001000
   • Epoch  21/100: train=0.0772, val=0.0829, patience=10/15, lr=0.001000
   📉 Epoch 22: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 1 Summary - Client client_74
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0030
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0009
============================================================


============================================================
🔄 Round 3 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0761 (↓), lr=0.000500
   • Epoch   2/100: train=0.0798, val=0.0759, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0794, val=0.0761, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0794, val=0.0762, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0793, val=0.0763, patience=4/15, lr=0.000500
   📉 Epoch 8: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0786, val=0.0766, patience=10/15, lr=0.000250
   📉 Epoch 16: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 3 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0022
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0044
============================================================


============================================================
🔄 Round 4 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0829 (↓), lr=0.000125
   • Epoch   2/100: train=0.0775, val=0.0830, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0775, val=0.0830, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0774, val=0.0830, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0774, val=0.0831, patience=4/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0772, val=0.0832, patience=10/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 4 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0033
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0015
============================================================


============================================================
🔄 Round 7 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0757 (↓), lr=0.000031
   • Epoch   2/100: train=0.0791, val=0.0758, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0791, val=0.0758, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0790, val=0.0758, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0790, val=0.0758, patience=4/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0789, val=0.0759, patience=10/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 7 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0061
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0067
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2494, R²: -0.0071

📊 Round 7 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2493, R²: -0.0054

============================================================
🔄 Round 12 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0821 (↓), lr=0.000008
   • Epoch   2/100: train=0.0773, val=0.0821, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0773, val=0.0822, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0773, val=0.0822, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0772, val=0.0822, patience=4/15, lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0772, val=0.0822, patience=10/15, lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 12 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0098
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0097
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2493, R²: -0.0045

============================================================
🔄 Round 13 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0688 (↓), lr=0.000002
   • Epoch   2/100: train=0.0807, val=0.0688, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0807, val=0.0688, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0807, val=0.0688, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0807, val=0.0688, patience=4/15, lr=0.000002
   📉 Epoch 8: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0807, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 13 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0014
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0250
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2493, R²: -0.0045

============================================================
🔄 Round 17 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 17 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0046
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0103
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2493, R²: -0.0048

============================================================
🔄 Round 18 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 18 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0035
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0119
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2493, R²: -0.0045

============================================================
🔄 Round 20 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 20 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0058
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0187
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2492, R²: -0.0044

============================================================
🔄 Round 22 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 22 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0045
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0106
============================================================


============================================================
🔄 Round 23 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 23 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0054
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0025
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2492, R²: -0.0043

📊 Round 23 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2492, R²: -0.0043

============================================================
🔄 Round 26 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 26 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0027
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0154
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2492, R²: -0.0043

============================================================
🔄 Round 29 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 29 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0050
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0028
============================================================


============================================================
🔄 Round 32 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 32 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0042
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0196
============================================================


============================================================
🔄 Round 33 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 33 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0070
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0016
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2492, R²: -0.0043

============================================================
🔄 Round 35 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0661 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0661, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0661, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0661, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0661, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0661, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0661)

============================================================
📊 Round 35 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0038
   Val:   Loss=0.0661, RMSE=0.2570, R²=0.0127
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2492, R²: -0.0043

============================================================
🔄 Round 36 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 36 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0088
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0271
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2492, R²: -0.0043

📊 Round 36 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 42 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 42 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0050
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0121
============================================================


============================================================
🔄 Round 43 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 43 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0067
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0016
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

📊 Round 43 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

📊 Round 43 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 49 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 49 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0091
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0136
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

📊 Round 49 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 52 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 52 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0098
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0144
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

📊 Round 52 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 54 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 54 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0098
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0108
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 56 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 56 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0079
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0029
============================================================


============================================================
🔄 Round 58 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 58 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0040
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0037
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 59 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 59 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0046
   Val:   Loss=0.0680, RMSE=0.2608, R²=0.0113
============================================================


============================================================
🔄 Round 60 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 60 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0025
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0167
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 62 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 62 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0022
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0173
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 64 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 64 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0034
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0047
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 67 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 67 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0091
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0095
============================================================


============================================================
🔄 Round 68 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 68 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0040
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0011
============================================================


============================================================
🔄 Round 69 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 69 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0060
   Val:   Loss=0.0783, RMSE=0.2797, R²=-0.0197
============================================================


============================================================
🔄 Round 70 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 70 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0040
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0006
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

📊 Round 70 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 72 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 72 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0057
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0036
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 73 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 73 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0027
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0014
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 76 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 76 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0065
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0005
============================================================


============================================================
🔄 Round 77 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 77 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.0073
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0031
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

📊 Round 77 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 79 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 79 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0036
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0027
============================================================


============================================================
🔄 Round 80 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 80 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0113
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0142
============================================================


============================================================
🔄 Round 82 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 82 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0047
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0105
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

📊 Round 82 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0040

============================================================
🔄 Round 84 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 84 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0003
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0133
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 85 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 85 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0090
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0073
============================================================


============================================================
🔄 Round 86 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0592 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0592, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0592, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0592, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0592, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0592, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0592)

============================================================
📊 Round 86 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0082
   Val:   Loss=0.0592, RMSE=0.2433, R²=-0.0098
============================================================


============================================================
🔄 Round 87 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 87 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0047
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0097
============================================================


============================================================
🔄 Round 88 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 88 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0002
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0293
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 93 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 93 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0022
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0187
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 94 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 94 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0067
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0021
============================================================


============================================================
🔄 Round 95 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 95 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0043
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0114
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 96 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 96 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0016
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0203
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 98 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 98 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0090
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0131
============================================================


============================================================
🔄 Round 99 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 99 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0057
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0061
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

📊 Round 99 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

📊 Round 99 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 103 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 103 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0068
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0012
============================================================


============================================================
🔄 Round 104 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 104 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0067
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0009
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

📊 Round 104 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

📊 Round 104 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

📊 Round 104 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 111 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 111 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0014
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0009
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

📊 Round 111 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 117 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 117 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0084
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0144
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

📊 Round 117 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 119 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 119 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0084
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0191
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

📊 Round 119 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 122 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 122 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0004
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0257
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 127 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 127 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0027
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0144
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 128 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 128 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0048
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0093
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 130 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 130 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0063
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0164
============================================================


============================================================
🔄 Round 131 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 131 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0073
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0074
============================================================


============================================================
🔄 Round 132 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 132 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0038
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0119
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 137 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 137 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0094
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0109
============================================================


============================================================
🔄 Round 138 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 138 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0018
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0131
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 139 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 139 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0023
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0129
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 141 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 141 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0104
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0135
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

📊 Round 141 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

📊 Round 141 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 146 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 146 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0061
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0047
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 149 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 149 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0044
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0013
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 151 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 151 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0106
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0145
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 152 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 152 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0028
   Val:   Loss=0.0897, RMSE=0.2994, R²=0.0145
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

📊 Round 152 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 154 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 154 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0044
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0061
============================================================


============================================================
🔄 Round 156 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 156 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0072
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0008
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 158 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 158 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0081
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0065
============================================================


============================================================
🔄 Round 159 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 159 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0055
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0016
============================================================


============================================================
🔄 Round 160 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 160 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0065
   Val:   Loss=0.0672, RMSE=0.2593, R²=-0.0026
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 162 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 162 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0028
   Val:   Loss=0.0714, RMSE=0.2671, R²=0.0176
============================================================


============================================================
🔄 Round 163 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 163 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0072
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0007
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

📊 Round 163 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

📊 Round 163 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 166 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 166 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0012
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0252
============================================================


============================================================
🔄 Round 167 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 167 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0067
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0006
============================================================


============================================================
🔄 Round 169 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 169 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0075
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0074
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0040

📊 Round 169 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0040

============================================================
🔄 Round 174 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 174 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0007
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0247
============================================================


============================================================
🔄 Round 178 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 178 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0056
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0065
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0040

============================================================
🔄 Round 179 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 179 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0024
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0149
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

📊 Round 179 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 183 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 183 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0052
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0033
============================================================


============================================================
🔄 Round 188 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 188 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0039
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0135
============================================================


============================================================
🔄 Round 190 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 190 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2769, R²=0.0042
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0055
============================================================


❌ Client client_74 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
