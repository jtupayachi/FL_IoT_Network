[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 791a68c4-cf79-4ccd-922b-fe495bd5f257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73ef6715-4f13-4aac-8e01-a292100c442f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a024655-6dfa-4429-97cd-0b7585c39543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41d77f4a-a055-4e82-9bd0-ad5631b31fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f075a61c-446f-4b77-8ba6-42e0dc510258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e771983-349f-42e6-b312-2ec854076343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f48607ed-c775-4f36-9988-5ff33a7c12fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 740d2feb-48f7-4a87-b62f-10112b542e45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e44f37d0-5af7-405c-b51e-5f41f9891459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5d47544-9834-4399-9690-52eec36a7ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3583d663-5d86-4022-9c34-b625466ad701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4dff55c-6f4f-4f0b-a263-2ef1d9705268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 853c310a-6d50-408e-b084-cf2cb0483b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8a69876-76cf-4c8f-806e-88390b1842ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 721f66fb-a6e0-405a-8ff5-1cc7fc795463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62b7942a-c66c-4495-85e0-2ce156e49d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de95257f-aaad-4f83-a0f4-0a8489385e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 787044e8-3bf2-44c3-aedc-e36c9b54c7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68b23140-f6a1-4ca3-9fde-e7679c1d2084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 040fce94-bc41-4595-b123-0cf5480d904c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e48c7032-ff7b-4169-ab24-63650158639a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2133c602-edf7-48b5-8280-9a2727f1e375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efe30a9d-1632-4a9c-8c47-e70a49c360fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3e0a3ee-3e3d-4d67-987e-3ac6a816fd9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 452174ed-1730-4480-bef6-e99bcec2a3b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 864d8769-6006-44f4-a1c5-59ae2fd52848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 200c93ee-b92b-41c0-9d0f-fef27c2d7a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83b0495e-23dd-4edc-9036-1340f8943ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a48d8a7d-f398-427a-a3da-a27168d47986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a297477-8580-4e45-b91c-7ce821173812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa3fccf5-5290-4f5b-9611-ca8e896ef930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c1864ae-d707-4ded-a83a-38af808f6b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b2b404-debd-4757-b6c8-3cc3afedf0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38ae698c-c7d5-4a69-8f8f-30c8c87b7d4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f22acefd-1115-4534-bc95-14bb5eed59e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f7e511d-5702-4baa-a801-889c77295a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 114d6d03-6946-405c-8fdb-a7768e2a7a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac6f299-f1ad-4e4d-9d52-93ffc7079c7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dc79233-df7d-402f-b625-3b5d354e4e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb01bb8f-d22c-47fa-99ef-ea3333ef9c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74e16da7-5a57-4371-a083-b4d8a78d9adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02f75acb-51bb-4c8d-bf5c-16711394fae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7be4eff7-5902-4fce-8b61-042f4d128748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42dcb540-f5a4-4e79-8b49-5de4a235b0dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68dcda05-373f-476e-96df-4efca8229467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4943941-d135-4acf-af02-dcbb8adf4e90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92412aaf-80f3-4a1c-993f-faa6934afad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c11a971a-817c-4423-ab49-463b24ccf3d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e172fa16-1db8-46ce-951e-1d04115feeb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84c7f020-79d5-4d4c-93e4-608ed39d98de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12c57c04-cca5-4b0a-bf95-02989e998e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d56ef1d7-426c-4ae3-bb84-aa7ff59532c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3db92d9-5ada-4b7d-a9df-8b6dc6a94462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42163532-eba7-4a58-b015-d914f1dbea39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3071655-ccb7-4a5a-b1a4-b4dca5474c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b1cac80-26bf-4737-9389-4abc58e5e464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4056eb2-c428-4f83-9f18-00b234e6c5a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 803be917-7660-48f0-8aed-60c1429e8ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baad5b60-4187-4d15-a374-38bb4bb7e293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2d6b6ff-04eb-49a7-a0b6-176e43b8bd84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18ba584d-1eb6-4c12-a8cf-21b3670e441c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3e414d0-4bc2-4391-9fc5-9d569e51c49c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d8fe880-c80c-4deb-80bf-29d6a6a86ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba088468-1e9b-4c13-bb72-5b4d7d967ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d07f4d7-8a68-439b-b9df-7cb34778f6db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e14f2e76-a839-4ce7-b516-7f8d6b3115c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eff6bed0-e07d-4850-8c59-e56f77e3bb2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b23d6ef4-3049-4b62-8d82-413ea749c445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a020e18f-5d6e-4a9d-9f3e-870b00e603a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a1d4823-6d7b-4854-bfcd-62129e2bd530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6868d87-d422-4285-94d5-e824f3dcd849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab86538d-8243-4eb3-ab7b-64e1055489e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6976210-0347-4d28-982d-a88fe5dc3ff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e91aa48-6758-49d8-8c0d-fc2ae0aee0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cfb7a2d-2747-420b-a1e3-1ea0eadc1322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3cbb29e-65d6-4eda-a136-2496b098e2ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 486a3420-e38d-43fc-adb3-ab0ef7b1ea42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cc35647-1618-40e6-8300-3fd89354c1b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf2d57ef-b761-4995-a376-e4b2a48f6584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 677997ce-69ca-4380-950d-3f135db24e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb8e1472-930d-413d-acaa-470eaa4c7e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dca5481-3bcf-474f-beb8-08b4ad37697f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd13edf2-0686-4cb7-b6da-ec77dd304513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309c8e07-03ec-4669-a3e6-779c6ffa632e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab5b9478-4a5a-42de-a93e-85c73ba348ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68489244-d22c-4ae1-a07e-e8fccf7060f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3a1cf78-9aa8-4dd8-9ae2-8ca14e12c76c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c48020b0-6b9e-4617-bfb1-fce866dadcac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb6d927c-0e5b-4389-88cb-ddafaecef78e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ac4e077-a090-41cc-a829-9e8a93281021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6ca9a60-2b38-439b-b942-6b8d74c0e537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3dde893-1f65-4a18-a69b-2cda495c7dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faf651f8-d0d2-4180-bf5d-d81ddbc74e63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c51aad5-f8d8-427b-b89e-dee3a66a9068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 143f9c51-bd8c-498b-a873-e53c31e60912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac61f029-a245-482a-8388-3aa611ab0941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00199207-9f00-42da-8c55-08fcd6cecd6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87f3e8f7-4416-4487-9e9b-6e19ac8982ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bd63a9e-7534-4a37-810f-dbc10449bb3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10e0be14-3aaa-4b24-84fc-d89d5b2f768f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6d46cfd-b75b-45d3-9d0d-923e21e8a330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3127cb67-5582-4a69-b9d9-0495151138cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d369417a-576b-4883-b929-5f94d98dd012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaf5037d-3072-428e-a40f-329ba2d87e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48bd948e-016f-46a5-a26f-af47949b3e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d08219f-7f6e-48fe-91e0-49f3e85b1a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b7704de-c994-46cf-acb7-33f3e5e053b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16befdd6-8dff-4ad7-8ab2-02d6c4e786cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61b8b230-0da4-4b9f-980c-7a91b1dbc073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10e67892-ce13-4ff4-ac4e-06cf240b6f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae7bd4e2-8511-4b9c-ab6e-8d4208a388a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a006544-3794-4836-b23a-64e18c2ea8a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c45ba4de-15b5-4d50-9881-eba8af5f3cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63dbdffd-ba36-4cfa-8d59-07152a8ae779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6acec6f-62ca-4bc2-8012-7c5646720637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 251dbd0b-2307-44ae-b212-aff0e78c0a8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 200ac39a-8b9a-441f-887c-931b8e6339e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99c4e5b1-0992-4483-b513-7fcd97321763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c0a9112-89e8-4964-b7de-f5814b1d1d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55996cd7-d09c-4134-95dd-6d3dc22f285f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4fdf1ad-72c4-4b98-9363-2ae7f75e200f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaf69c5a-8b15-48d9-a94b-83ef511863ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c410f39-ac76-4e97-ba26-9f55faebf81d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1d98fc7-fe1a-4019-a757-d8601a997728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 238d26d5-7753-4b10-b5df-372061f2ee65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eb7b891-4bf2-4e12-bb08-d602b05cde17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dd4876c-152e-4efa-990c-9d937ab9ff4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d7757d8-6cd4-4f8c-adb8-210c2b03f95f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d15a260f-ab27-41f2-86b1-cd795db3f327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42970220-adaf-476e-a2cd-f5c3c254d996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d41349b4-d875-42ca-bb26-68d73166a596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65713cde-ecab-47ae-b599-a78c9b12f779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79286bff-9c93-43c0-8c8c-5005887a9b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 031eaffd-c38a-4db5-a280-a029202d247a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11d249cc-abd3-47b6-8dea-efdf11a69159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5637b18-c8c2-4304-94ae-099237e288e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2b02604-e282-4225-8699-a46fa3245da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4e9ed29-db86-4a72-b487-93448562dc62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f86eb46-5627-4d12-b063-ff95f8e09ab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdc45009-4bdb-476e-aa60-e538fd942ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b757953-681e-4810-b67a-4c74df836a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1330b253-5145-4176-98b0-63f80e2bc649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9a85246-c8e2-4a2f-b84c-f38ba58b3480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0017f433-ba95-493a-b5e4-9891f43b884f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7b4b5f7-5e27-4b96-ab95-6ea426220949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 020b2024-dc12-4169-a2d0-21ecc80e20aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dff597e-21cd-412a-b44c-0358a6a7e8fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46ef4d05-9ad5-49bd-85d1-a64cfa60bb99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3a9bb57-3857-4fc5-b17f-cef628f7a947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3edd783b-05d1-4955-a2c1-e8208db727b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5891c087-7883-4022-be6e-4f87f3854603
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_75
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/test_labels.txt

📊 Raw data loaded:
   Train: X=(883, 24), y=(883,)
   Test:  X=(221, 24), y=(221,)

⚠️  Limiting training data: 883 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  212 samples, 5 features
✅ Client client_75 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2438, R²: 0.0090

============================================================
🔄 Round 3 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0850 (↓), lr=0.001000
   • Epoch   2/100: train=0.0835, val=0.0861, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0834, val=0.0854, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0825, val=0.0849, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0819, val=0.0847, patience=4/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0779, val=0.0809 (↓), lr=0.001000
   • Epoch  21/100: train=0.0701, val=0.0819, patience=7/15, lr=0.001000
   📉 Epoch 22: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 3 Summary - Client client_75
   Epochs: 29/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0740, RMSE=0.2721, R²=0.1135
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0618
============================================================


============================================================
🔄 Round 4 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0839, val=0.0799 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0846, val=0.0791 (↓), lr=0.000250
   • Epoch   3/100: train=0.0833, val=0.0791, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0833, val=0.0791, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0832, val=0.0791, patience=3/15, lr=0.000250
   • Epoch  11/100: train=0.0824, val=0.0790, patience=9/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 4 Summary - Client client_75
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0200
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0184
============================================================


============================================================
🔄 Round 6 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0809 (↓), lr=0.000250
   • Epoch   2/100: train=0.0821, val=0.0809, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0820, val=0.0807, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0817, val=0.0807, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0815, val=0.0807, patience=4/15, lr=0.000250
   📉 Epoch 6: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0806, val=0.0804, patience=10/15, lr=0.000125
   📉 Epoch 14: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0797, val=0.0802, patience=7/15, lr=0.000063
   📉 Epoch 22: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 6 Summary - Client client_75
   Epochs: 29/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0531
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0222
============================================================


============================================================
🔄 Round 8 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0816, val=0.0794 (↓), lr=0.000016
   • Epoch   2/100: train=0.0815, val=0.0793, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0814, val=0.0793, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0813, val=0.0792, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0813, val=0.0791, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0809, val=0.0787, patience=4/15, lr=0.000016
   • Epoch  21/100: train=0.0806, val=0.0786, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 8 Summary - Client client_75
   Epochs: 22/100 (early stopped)
   LR: 0.000031 → 0.000016 (1 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0432
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0218
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2398, R²: 0.0402

============================================================
🔄 Round 10 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0857 (↓), lr=0.000016
   • Epoch   2/100: train=0.0788, val=0.0856, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0787, val=0.0855, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0786, val=0.0854, patience=3/15, lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   • Epoch   5/100: train=0.0785, val=0.0854, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0783, val=0.0854, patience=10/15, lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 10 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0461
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0051
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2399, R²: 0.0399

============================================================
🔄 Round 12 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0702 (↓), lr=0.000004
   • Epoch   2/100: train=0.0831, val=0.0703, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0831, val=0.0703, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0830, val=0.0703, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0830, val=0.0704, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0829, val=0.0704, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 12 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0400
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0226
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2398, R²: 0.0411

📊 Round 12 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2398, R²: 0.0409

📊 Round 12 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2397, R²: 0.0417

📊 Round 12 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0423

============================================================
🔄 Round 18 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 18 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0384
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0499
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

============================================================
🔄 Round 22 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 22 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0383
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0456
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

📊 Round 22 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

============================================================
🔄 Round 24 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 24 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0451
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0209
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

📊 Round 24 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

============================================================
🔄 Round 26 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 26 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0312
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0792
============================================================


============================================================
🔄 Round 28 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 28 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0459
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0129
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

============================================================
🔄 Round 32 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 32 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0489
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0012
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

============================================================
🔄 Round 37 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 37 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0449
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0124
============================================================


============================================================
🔄 Round 38 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 38 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0373
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0460
============================================================


============================================================
🔄 Round 39 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 39 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0476
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0085
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

============================================================
🔄 Round 41 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 41 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0401
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0446
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

============================================================
🔄 Round 42 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 42 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0398
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0350
============================================================


============================================================
🔄 Round 43 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 43 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0395
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0464
============================================================


============================================================
🔄 Round 44 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 44 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0369
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0574
============================================================


============================================================
🔄 Round 45 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 45 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0390
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0215
============================================================


============================================================
🔄 Round 46 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 46 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0342
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0626
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

============================================================
🔄 Round 48 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 48 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0388
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0473
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

============================================================
🔄 Round 49 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 49 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0387
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0180
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

📊 Round 49 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

============================================================
🔄 Round 52 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 52 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0335
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0462
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

📊 Round 52 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

============================================================
🔄 Round 55 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 55 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0416
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0342
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

📊 Round 55 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

============================================================
🔄 Round 58 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 58 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0391
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0485
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

📊 Round 58 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

📊 Round 58 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

============================================================
🔄 Round 61 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 61 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0409
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0193
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

============================================================
🔄 Round 65 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 65 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0402
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0396
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

📊 Round 65 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0424

============================================================
🔄 Round 69 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 69 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0502
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0070
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

============================================================
🔄 Round 70 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 70 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0463
   Val:   Loss=0.0866, RMSE=0.2944, R²=0.0176
============================================================


============================================================
🔄 Round 72 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 72 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0398
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0444
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

============================================================
🔄 Round 73 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 73 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0417
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0382
============================================================


============================================================
🔄 Round 75 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 75 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0356
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0608
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

📊 Round 75 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

📊 Round 75 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

📊 Round 75 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

============================================================
🔄 Round 82 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 82 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0470
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0102
============================================================


============================================================
🔄 Round 83 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 83 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0445
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0199
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

📊 Round 83 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

============================================================
🔄 Round 87 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 87 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0318
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0770
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

============================================================
🔄 Round 88 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 88 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0408
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0306
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

📊 Round 88 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

============================================================
🔄 Round 91 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 91 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0328
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0701
============================================================


============================================================
🔄 Round 93 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 93 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0335
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0703
============================================================


============================================================
🔄 Round 94 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 94 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0457
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0201
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

============================================================
🔄 Round 95 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 95 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0367
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0422
============================================================


============================================================
🔄 Round 96 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 96 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0444
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0286
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0425

📊 Round 96 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 101 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 101 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0386
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0484
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

📊 Round 101 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 103 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 103 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0377
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0145
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 107 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 107 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0432
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0320
============================================================


============================================================
🔄 Round 108 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 108 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0357
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0612
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 111 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 111 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0374
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0566
============================================================


============================================================
🔄 Round 113 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 113 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0435
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0320
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 114 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 114 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0412
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0381
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 115 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 115 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0393
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0488
============================================================


============================================================
🔄 Round 117 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 117 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0385
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0493
============================================================


============================================================
🔄 Round 118 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 118 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0339
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0670
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 119 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 119 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0445
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0191
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

📊 Round 119 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

📊 Round 119 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 123 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 123 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0385
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0511
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 125 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 125 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0443
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0240
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0427

📊 Round 125 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0427

============================================================
🔄 Round 130 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 130 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0354
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0598
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0427

============================================================
🔄 Round 133 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 133 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0442
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0255
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0427

📊 Round 133 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 135 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 135 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0352
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0678
============================================================


============================================================
🔄 Round 141 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 141 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0461
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0166
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

📊 Round 141 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

📊 Round 141 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 145 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 145 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0399
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0437
============================================================


============================================================
🔄 Round 147 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 147 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0453
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0173
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

📊 Round 147 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 151 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 151 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0366
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0584
============================================================


============================================================
🔄 Round 152 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 152 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0384
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0517
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 156 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 156 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0415
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0402
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 158 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 158 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0444
   Val:   Loss=0.0803, RMSE=0.2835, R²=0.0263
============================================================


============================================================
🔄 Round 159 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 159 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0424
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0342
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

📊 Round 159 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

📊 Round 159 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 164 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 164 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0471
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0005
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

============================================================
🔄 Round 170 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 170 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0410
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0201
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0427

📊 Round 170 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0427

============================================================
🔄 Round 177 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 177 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0439
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0321
============================================================


============================================================
🔄 Round 181 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 181 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0383
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0330
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0427

📊 Round 181 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0426

📊 Round 181 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0427

============================================================
🔄 Round 186 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 186 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0411
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0308
============================================================


============================================================
🔄 Round 187 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 187 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0388
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0448
============================================================


============================================================
🔄 Round 189 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 189 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0385
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0449
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0427

============================================================
🔄 Round 190 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 190 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0392
   Val:   Loss=0.0684, RMSE=0.2616, R²=0.0517
============================================================


❌ Client client_75 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
