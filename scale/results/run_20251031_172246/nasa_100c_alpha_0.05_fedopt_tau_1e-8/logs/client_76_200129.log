[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adbc533e-e92f-4817-9fb1-901b17f9c0f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc35a0d2-b615-44ec-a6ce-58262c8ced9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dc4e0f7-1063-4a6b-806f-cd007fdeebad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72b05bdd-37e6-4173-83bc-76051b8ca250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfcd053e-05a5-486a-ba9e-b628a3328bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34e8533d-d2e0-4f32-a440-ba9c7fb24713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50e5fbcd-7d1b-47e1-afcd-27748b005b2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55cbb9a8-27f8-4c58-b25c-80dfc4f7c061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d655827f-c238-4b5f-9aa7-40a733c1eecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9917b903-8f42-4c05-adb5-28bb0cf521e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb6ca189-0b02-40cc-a566-8a352d48926d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beca3c75-d69d-4ee9-b765-36ebca10b648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8346edae-fe18-4f42-8c50-f13572e3ef66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30a128dd-0303-49d2-9635-f5f950e6206b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c450467-2138-48ac-a34e-27f294f72a64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33809081-6b97-45b3-bc35-55df4e96dafd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d1fa635-4a19-4725-ae5f-22efb7391945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36c43dae-dada-4d54-80d2-0e59c8c5cfe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6e7155b-212d-4bab-a19e-9a6f93bf74c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f2c366f-3345-4986-bc08-508d04127492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4177128-2da2-4e56-9303-d8e5638f3b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8556190a-edb9-4deb-a8f3-c524c0f084d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1816c88f-c349-4241-af73-0497971b64f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 518c367b-d3ed-4a34-8431-2bede9331c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd4ee92c-7fd7-4020-aaef-03d3b1b5827b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cd100d4-dd23-468a-8eb7-9308a208ac47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eec6e678-0690-46d1-bf37-ac76a2027bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81803792-a132-4002-b9d3-ca00400c9c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddf48572-6cb7-45dd-8060-9f1f9af6f2bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaa96466-412a-402a-a89d-2290ec124964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77415d0a-722d-4552-9bb6-e295711e2da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c77b4eb4-950a-4122-a9b6-8ae70dcba3fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 275c68d1-5075-4244-b503-1423af2e5ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53978774-ffd4-4ea5-928b-01965955f749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 139adbb2-a93f-4058-890e-c74c71924109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e472d2c-5aee-430c-b5e1-48ec5cb07e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67336986-5284-4e84-9ddf-c74bb2281ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d54c84b-5810-4ad0-872c-163af20209f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 810e9e3f-3bf3-458b-83ea-63136ffbd988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1096a01b-9312-4884-abbb-fb65e7659103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21dd4f92-ae29-4d93-b23d-ec61fdad4630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9e19619-9e60-459f-9669-f000298a9da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfffc7e4-fbf7-44d6-b01b-65002f7a665f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00567641-2d5b-4e30-9864-9be244ac654b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf5a4d8-1fc4-46aa-ae4f-a31b259d196b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 535f7288-66c9-4c4d-9698-ee25433c8755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d09000d-d412-4eed-8f21-c3f7b0310a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d43ca7f-7aa8-4a58-b0bb-b69b1809805e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 665cd0ba-58c2-4e2d-a3d8-2ccc8273337c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac60cfe7-8f21-4d29-8e07-2b2a72af5ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7fd5770-fc7d-41c1-8e65-a2b2314105b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5e4de63-dfc4-4cf3-a29c-bfc0447441af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c806cd5e-af46-4a78-be0a-6df798b09372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fd12263-856e-4e8f-8409-c90b789a8402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f13191f1-1cf4-4050-980a-d0b9cd20e452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24c5ed06-5113-41b0-b2c7-5c6c0dbe9239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c218430-6071-4a68-9e10-4854ea4dbc05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59683aba-a28d-4364-8748-fb0a7b9598fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b6066c8-3e26-4471-92f4-3422ddbc8c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc9b77d7-7af7-4d73-a75c-1252076ccd3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8542b06b-78d6-426a-b0f5-0c734a1b4839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a12092da-bd7f-4b86-a45a-c6a29a3e3f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68c4a4cb-272f-463f-94d4-5b991940c48a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fddaa60-fbe3-4ade-8576-d385480edfb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9991b124-44a0-400b-8263-b95fa045706a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fa75863-b2ae-43d2-9b61-866d5116f5e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6f97169-4894-4592-89a8-1e9306584737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4da6d57a-18d5-474f-b10e-ea5b1b24d959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e04ff404-9b2f-4062-8d29-a0ecdee919be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4259a75d-7b13-46f8-b9db-52d1c98620d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cf4b6bc-afa9-411e-90a1-8f6bc4047099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae69b8a2-6aa7-4d62-9021-cfb3dc89140f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08b17b4d-98b2-4057-93ed-5a5aa0487d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d7bd3ab-9203-4202-9ec3-f3cc22f37d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 639a5e5a-33d8-44b5-be0c-cc66f3ab4502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24bcf6b6-f51c-43a9-9229-94bd7f27c7b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d48e0ad5-7469-489b-98b9-2a8acd179331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fc3406d-5e39-45b7-8e8a-205d1033c4d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 979ef3eb-22a2-48c8-bf45-625a2be979e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b56492-ce99-48cd-a07c-34ab036a4815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bd6cea5-1fae-41ce-a4a8-ecca69134d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91b78c1d-4482-43e0-9d05-29bfc1bfc6a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7862278-58a4-4708-acec-cb70a2270a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a19036f-2f61-401c-914c-8dac592d821f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97d32fc6-83d8-43e2-a8e3-4312f48102a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61f3d0a6-627e-4a3e-bc55-908ea311999e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98d88aba-4810-47d9-8332-c98bfb7f3ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13ba3cc7-69e8-4cb2-a3e6-491e81fbc085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59246cfa-ded6-4f5d-b560-5d62cdf94897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24c81e34-0449-457f-827f-d64d76226dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d239bae-1d2b-4f01-8582-6aad2e66ac8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be2404c1-7567-411d-8e40-cf7ca9dd99c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33daec84-994f-46b5-bc71-4dcecc259528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2780c080-d75e-4587-a9e4-42d9942232bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40ea1558-ae6d-44c3-be14-02dba5aa1e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8be4a6e-36d0-4dce-8509-d56842eae92a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5a92e8d-fb0c-420d-923e-c7a45e4152fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea8673fa-0e86-4915-bb51-6305fddcb018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6416097-be25-4331-ae0b-7d2084839f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77f041ca-681c-48e8-8445-d371e16986ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e92fcc67-0792-4e9c-996f-544c7eb1584b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3446c2c-5cd3-4c59-aca0-6a06f2348b9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d7b86ad-e3b4-4945-8711-6f076714d118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b772a876-9d04-4151-b801-1b2e407a3b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3c90efe-00c7-45e5-a6f5-5222448944fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc8cbe0a-bb65-4fa6-bf38-12c85d8a4365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 693ce91b-c0a0-4cd6-b3a3-5db5b7efaac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d0fd3c1-a091-4386-8905-f28d7e9a24d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d0fac9a-c606-4dd1-9960-601eacc60dea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd483dbb-13d8-43ae-807f-18726af7d423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6639fcd-7e36-4f48-aa2c-1b6f9733f2e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 837b8dd4-934d-4ef2-b875-b6c28d58afe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ecc7f2e-0a99-4533-bb73-d0fa9e5578f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 237305c6-0267-449d-bd7b-a05aa44e3697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc56e555-4580-4b88-9eb2-c8780273709e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1661c53e-f8ed-41a5-96b7-c06b42c11e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5168943f-30e8-43a7-b2b8-ea0e463dcd8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c5dcfa4-4853-4a27-8380-8c03f27f8ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8342005-ac91-4de5-9498-f78273834569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77508f9c-b3fb-46a6-8da9-193b8ecf7029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bade0a89-c96b-4067-8d19-7f312a8455c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf69f7cb-05ff-4aee-b803-f891371fc784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2c3645a-d54d-41a3-822f-8150740c303c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1482b608-865d-498e-b1d6-4680ca2de0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47dcebd7-3f13-4e25-992a-8a5a86e1eadb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d07f65f-accb-456b-8b11-11bc16727d58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee54b152-4f02-4064-846e-1937ec14436b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35e41aa4-ef92-4b2b-b259-21100f4d3e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9332519-70f3-4e1c-af8f-1a4f6d957f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5cbf8f2-5e6e-41c3-9514-1f715ec887cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2120f0ca-3094-4a00-94ef-32cf080bbc62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f81f138-77de-4fe5-8c80-f54483d14889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 692497ec-9e82-4fa4-86c8-1578caa77932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3995b3bf-3427-4370-b6ac-76a604ed2768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97f42f05-7a9d-42e3-9f87-e3e45184544e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0d71c84-a6e0-42bf-a1b9-9a24c67a7907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51dd9f4f-cf99-49f2-894a-c82f73ba62c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d42e11fb-2b43-47d4-b866-29bfb1098324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aeb9a6b-5833-492f-af4c-cc802d076c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9f35472-6305-4091-848a-5bb52abafeef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d69118e9-adb8-4ac4-8de8-1ab822eff2fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cf50571-9928-4ddf-bb17-f2a4118328d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af688d00-177e-4b4e-a095-97c3eff87d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f3f373c-50fc-493a-98a5-d9b7f324dc96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fc1f559-f665-41bf-9b60-7c292339a4f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df8be879-e494-4f7c-9d14-7b97042a5d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d87edb3-236d-4da3-ac57-6a0e8163b7c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1654dcda-6ec6-48e0-862f-c08d5dcc5ed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d637cbe1-8c34-476d-8cb7-6819de4b2e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b16a7bf6-e56f-40b0-992a-70fa01b2bbf7
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_76
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/test_labels.txt

📊 Raw data loaded:
   Train: X=(608, 24), y=(608,)
   Test:  X=(152, 24), y=(152,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 599 samples, 5 features
   Test:  143 samples, 5 features
✅ Client client_76 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2524, R²: -0.0087

📊 Round 0 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2499, R²: 0.0058

📊 Round 0 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2498, R²: 0.0081

📊 Round 0 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2479, R²: 0.0207

📊 Round 0 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2463, R²: 0.0334

📊 Round 0 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2442, R²: 0.0476

============================================================
🔄 Round 9 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0723 (↓), lr=0.001000
   • Epoch   2/100: train=0.0765, val=0.0765, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0750, val=0.0747, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0725, val=0.0735, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0708, val=0.0737, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0630, val=0.0691, patience=3/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0579, val=0.0655, patience=5/15, lr=0.000250
   📉 Epoch 23: LR reduced 0.000250 → 0.000125
   📉 Epoch 31: LR reduced 0.000125 → 0.000063
   • Epoch  31/100: train=0.0560, val=0.0646, patience=15/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0648)

============================================================
📊 Round 9 Summary - Client client_76
   Epochs: 31/100 (early stopped)
   LR: 0.001000 → 0.000063 (4 reductions)
   Train: Loss=0.0585, RMSE=0.2419, R²=0.3095
   Val:   Loss=0.0648, RMSE=0.2545, R²=0.1703
============================================================


============================================================
🔄 Round 12 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0709 (↓), lr=0.000063
   • Epoch   2/100: train=0.0777, val=0.0705, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0772, val=0.0703 (↓), lr=0.000063
   • Epoch   4/100: train=0.0769, val=0.0701, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0767, val=0.0700, patience=2/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0760, val=0.0694, patience=4/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0755, val=0.0690, patience=6/15, lr=0.000016
   📉 Epoch 24: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 12 Summary - Client client_76
   Epochs: 30/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.1089
   Val:   Loss=0.0692, RMSE=0.2630, R²=0.1034
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0565

============================================================
🔄 Round 15 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0764 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   • Epoch   2/100: train=0.0767, val=0.0763, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0766, val=0.0763, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0766, val=0.0762, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0765, val=0.0762, patience=4/15, lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0762, val=0.0759, patience=1/15, lr=0.000002
   📉 Epoch 18: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0760, val=0.0757, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 15 Summary - Client client_76
   Epochs: 25/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0826
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.1076
============================================================


============================================================
🔄 Round 16 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 16 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0793
   Val:   Loss=0.0681, RMSE=0.2609, R²=0.0908
============================================================


============================================================
🔄 Round 17 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 17 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0793
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0835
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0581

📊 Round 17 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0579

============================================================
🔄 Round 21 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 21 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0886
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0509
============================================================


============================================================
🔄 Round 22 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 22 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0812
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0726
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

============================================================
🔄 Round 26 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 26 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0848
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0661
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

📊 Round 26 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

📊 Round 26 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

============================================================
🔄 Round 32 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 32 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0832
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0569
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

============================================================
🔄 Round 34 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 34 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0829
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0643
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

📊 Round 34 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

📊 Round 34 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0576

============================================================
🔄 Round 41 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 41 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0821
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.0758
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

============================================================
🔄 Round 43 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 43 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0817
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0650
============================================================


============================================================
🔄 Round 44 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 44 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0753
   Val:   Loss=0.0693, RMSE=0.2633, R²=0.1076
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0576

============================================================
🔄 Round 46 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 46 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0800
   Val:   Loss=0.0677, RMSE=0.2602, R²=0.0763
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0576

============================================================
🔄 Round 47 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 47 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0763
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0873
============================================================


============================================================
🔄 Round 49 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 49 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0770
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0856
============================================================


============================================================
🔄 Round 51 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 51 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0827
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0772
============================================================


============================================================
🔄 Round 52 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 52 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0870
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0613
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0576

📊 Round 52 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0576

============================================================
🔄 Round 57 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 57 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0787
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0920
============================================================


============================================================
🔄 Round 58 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 58 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0834
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0719
============================================================


============================================================
🔄 Round 60 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 60 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0839
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0660
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0576

============================================================
🔄 Round 61 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 61 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0752
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.1082
============================================================


============================================================
🔄 Round 63 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 63 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2749, R²=0.0798
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0840
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

📊 Round 63 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

📊 Round 63 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

📊 Round 63 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

============================================================
🔄 Round 67 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 67 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0842
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0558
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0576

============================================================
🔄 Round 68 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 68 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2779, R²=0.0801
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0840
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0576

📊 Round 68 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0576

📊 Round 68 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

📊 Round 68 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

============================================================
🔄 Round 78 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 78 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0877
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0520
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

📊 Round 78 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0577

============================================================
🔄 Round 80 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 80 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.0844
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0727
============================================================


============================================================
🔄 Round 85 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 85 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0786
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0921
============================================================


============================================================
🔄 Round 86 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 86 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0792
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.0869
============================================================


============================================================
🔄 Round 87 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 87 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0826
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0767
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0578

============================================================
🔄 Round 89 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 89 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0787
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0945
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0578

📊 Round 89 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0578

📊 Round 89 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0578

📊 Round 89 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0578

============================================================
🔄 Round 93 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 93 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2761, R²=0.0853
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0579
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0578

📊 Round 93 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2429, R²: 0.0578

============================================================
🔄 Round 96 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 96 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0789
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0859
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2429, R²: 0.0578

============================================================
🔄 Round 98 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 98 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0867
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0571
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2429, R²: 0.0578

============================================================
🔄 Round 99 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 99 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0811
   Val:   Loss=0.0697, RMSE=0.2641, R²=0.0734
============================================================


============================================================
🔄 Round 100 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 100 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0814
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0748
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2429, R²: 0.0579

📊 Round 100 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2429, R²: 0.0579

📊 Round 100 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2429, R²: 0.0579

============================================================
🔄 Round 105 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 105 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0741
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.1126
============================================================


============================================================
🔄 Round 107 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 107 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0777
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0920
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2429, R²: 0.0579

============================================================
🔄 Round 108 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 108 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0831
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0654
============================================================


============================================================
🔄 Round 109 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 109 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0808
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0861
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2429, R²: 0.0579

📊 Round 109 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2429, R²: 0.0579

============================================================
🔄 Round 114 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 114 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0774
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0989
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2429, R²: 0.0579

📊 Round 114 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0579

============================================================
🔄 Round 117 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 117 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0828
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0732
============================================================


============================================================
🔄 Round 118 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 118 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0807
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0840
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0580

============================================================
🔄 Round 120 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0660 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0660, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0659, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0659, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0659, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0658, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0660)

============================================================
📊 Round 120 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0871
   Val:   Loss=0.0660, RMSE=0.2568, R²=0.0522
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0580

============================================================
🔄 Round 122 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 122 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0855
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0661
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0580

============================================================
🔄 Round 124 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 124 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0829
   Val:   Loss=0.0747, RMSE=0.2732, R²=0.0542
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0580

============================================================
🔄 Round 125 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 125 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0820
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0802
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0580

📊 Round 125 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0580

============================================================
🔄 Round 128 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 128 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2705, R²=0.0847
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0734
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0580

📊 Round 128 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0581

============================================================
🔄 Round 136 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0660 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0660, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0660, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0660, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0660, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0660, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0660)

============================================================
📊 Round 136 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0821
   Val:   Loss=0.0660, RMSE=0.2570, R²=0.0736
============================================================


============================================================
🔄 Round 137 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0647 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0647, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0646, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0646, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0646, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0645, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0647)

============================================================
📊 Round 137 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0812
   Val:   Loss=0.0647, RMSE=0.2543, R²=0.0855
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0580

============================================================
🔄 Round 139 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 139 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0838
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0708
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0580

============================================================
🔄 Round 142 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 142 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0834
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0735
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0580

============================================================
🔄 Round 145 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0663 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0663, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0663, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0662, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0662, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0661, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0663)

============================================================
📊 Round 145 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0847
   Val:   Loss=0.0663, RMSE=0.2575, R²=0.0676
============================================================


============================================================
🔄 Round 147 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 147 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0872
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0591
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0581

📊 Round 147 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0581

============================================================
🔄 Round 155 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 155 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0870
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0593
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0581

============================================================
🔄 Round 157 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 157 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0866
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0604
============================================================


============================================================
🔄 Round 158 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 158 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0762
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.1056
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0581

📊 Round 158 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0581

============================================================
🔄 Round 162 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 162 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0843
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0639
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0581

============================================================
🔄 Round 163 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 163 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0809
   Val:   Loss=0.0668, RMSE=0.2585, R²=0.0849
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0580

============================================================
🔄 Round 167 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 167 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0811
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0740
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0580

============================================================
🔄 Round 168 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 168 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0879
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0576
============================================================


============================================================
🔄 Round 170 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 170 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0752
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0811
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0580

============================================================
🔄 Round 173 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 173 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.0873
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0559
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0581

📊 Round 173 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0581

============================================================
🔄 Round 175 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0653 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0653, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0653, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0653, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0653, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0652, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0653)

============================================================
📊 Round 175 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0788
   Val:   Loss=0.0653, RMSE=0.2556, R²=0.0885
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0580

============================================================
🔄 Round 176 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 176 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0767
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0902
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0580

============================================================
🔄 Round 177 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 177 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0837
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0750
============================================================


============================================================
🔄 Round 178 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 178 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0861
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0586
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0581

📊 Round 178 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0581

============================================================
🔄 Round 182 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 182 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0793
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0916
============================================================


============================================================
🔄 Round 184 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 184 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2701, R²=0.0876
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0476
============================================================


============================================================
🔄 Round 186 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 186 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0830
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0781
============================================================


============================================================
🔄 Round 187 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 187 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2741, R²=0.0906
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0441
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0581

📊 Round 187 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2428, R²: 0.0581

❌ Client client_76 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
