[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c44ef64-c07d-443f-bd0a-1da01470bb52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f57869b8-c2ce-44c0-ad90-8f616f751c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7acce159-b6e1-48f1-ba8a-eda6a3be82dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c4574ad-6e12-4d48-a15d-630bc33a8b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1131091c-f215-4e24-9de3-6a064fc371c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58579423-400e-4e6a-8e3e-078b20159f09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb0dc836-ec86-4fd6-8a3e-114d62d33200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b348d4b-db7e-4e32-8b40-5aa045aeeb41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b4ff3b9-5b8f-4e96-ba5c-69cb219d1c7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee482c70-20e5-4d56-9db0-128adaabfd03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f40809d2-0d74-4735-a180-c61006acd3fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83cc5f47-ce49-4ac9-b425-f8c70aa7d0cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a27978c1-39d7-472e-8a3d-ba4940eb332f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8132432-8183-4e7e-a643-9efaef6f918c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0985e1e8-74a8-46f2-a94d-4b70c2cc1275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61e8efd2-1070-43cc-84c3-566fdacedf12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c42517-a473-4eaf-83d5-c898e586d805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6ff169d-0515-4963-95c7-14012ce8bb67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39e3c59c-11a8-496c-b0eb-20c5c946e564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01d32a1f-bfa2-4057-9ae5-b8596b974f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 960c05af-72d3-4ed2-abb8-479a47962398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ba0f2a6-5445-4eb6-acbb-ec90c44b41a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22020cb3-3088-49f3-8de4-5a254acf08a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f139dac2-952a-4da0-87ed-697d315bd80d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61be3bfe-a835-4b5e-9ac2-803bd87a3ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5468d58d-c637-48a3-92e0-bc9d2582bb08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ace8bb8b-6da3-4251-ab00-a525d077e50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51de777f-2e7f-4c78-a71c-5d0439f16557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0f3c875-f98f-415f-93ed-f79aee2da83e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f0616a5-7df4-4664-938a-ff71af08f16c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01915528-0078-4078-9758-bda5a05569d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4663bdbd-c638-405d-bddd-589594a9c920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbb145f2-72ca-408c-bbcd-c933617f5a0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d5eb148-259c-4e83-b950-c6167c9aa4c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7834b900-7845-43f0-968b-6f686a2b1dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa99a4da-da96-4bf6-8985-2a56a2bdb366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f03388b-6554-4121-acfd-d9224683f06a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32fc3f33-e224-4590-a8ce-933d2e8eb3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e57d1fa1-55b3-4e48-81de-8a862be49691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 100c6db1-14e0-477c-8a92-681a7a160323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feb662c4-b0a9-4a39-89a9-d1c18f3334d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8812da65-35d9-4be4-a753-018668f9bdce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dccb251a-52ab-47c0-878d-ae30f36e1a4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88917832-c857-42a3-a6fa-d273efa4982c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd37d7d1-1be8-41b3-811d-ad18ba64d15d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19304ed5-3004-4020-8abe-5d52e290272a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d79c6a06-61c3-4f36-9aea-8436cc54d9f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 199510db-d40b-40d3-82c3-6775cdbd0cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93d61b4d-2e69-4b6d-8541-2973b7cb2e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 125808bf-e0da-4cf1-bd22-e67cd0139517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f9e14f3-dcda-4f3c-9952-cfb16af5fd02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c877a662-9dfa-4aad-92e4-583bc1ae209a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f766abfc-eb0f-4a3d-a75a-def8a0561ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70714f72-ffed-4775-b639-66828a4b6f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a178fc4e-f069-4ef4-84bc-07af38a0205a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e0ef47e-6de9-4de1-a72d-c01f442fa595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6621d15e-42c2-4c2a-bdf6-ff456c6c6655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b73272-d56e-4ffd-8c69-c32e22e1d3df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0720110c-dde3-4eeb-ae31-69d773f9980f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f1caca9-cf42-4509-9651-ee211dfe4ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35e5ea39-c7a9-4108-856f-6de12f0a596a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 488b3556-dc34-4725-9ccd-6fa13228f3f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4d4b9fe-678b-46a5-a94a-142d0c8afc7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20253df4-3387-4a62-8ea7-ab3d99825479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 855a1ee8-d663-440c-86a0-e36cc963f512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fab8a9b2-8562-4231-96d8-7bc2a9b507ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 715d671a-0f4d-4548-89f0-7b834a512849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb9ca44f-2072-4e1a-b900-b24dc3177cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04c8f471-b3d5-475f-b0bc-7d5771c5d517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8000560-e9b0-42f6-a116-3dc71e00b5c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6664c0e-16f5-427b-bdf3-537de97653b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24e42a44-e1dd-490d-94aa-8e78e4e59176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9feb702-554c-4272-b016-3b8794d87d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0f71595-82ab-4dbb-94d1-5c72460ef3e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14682d40-65a6-4362-88ed-31219d53044b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c4a8ea9-0d9c-49c6-8c7f-f4832cab327d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0983153-6de2-4793-a50c-820912e7104f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6268c27-b86c-4ad6-94d1-147a2dfd3ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de6c32d-b97c-4a7a-b49b-80277bddb05e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9fb508f-e710-4aa3-852e-565075e491d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 194678fa-8942-458f-8fad-d6fd360d28f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb59d91f-4a5f-4a2f-ba81-d11b756ebab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57c39bdc-4b57-4457-a316-560afe718b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f509d811-850f-40f9-a964-b92c12feb1a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ba67907-17b5-468e-b288-bac5a65e9e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6dbdf2e-301e-47fe-8839-a112098a031b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef3e48e0-3fbc-439a-9295-63335aca5d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aa87a9f-701e-4dec-b80e-83688036aec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 917d54a9-9541-4f11-8230-6ebb17769cbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae0cae88-913a-4eb9-b494-5f30f5042f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e8f4769-2343-41da-9628-46db08a4cc2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8183174f-bbe6-4343-a4c6-5c569e06d871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99f10677-76bc-456b-8da7-4a262a79b2db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9239102-072d-407b-ac79-e22adc8c6e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e38b7d73-da0d-4a1d-8ca2-60e13e9da371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7c5df15-72d5-425c-8009-301259fd0f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbf4c777-f68d-4f96-ba7a-b6326a669f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 292214e0-8fcf-49f4-b408-9fba029d5c0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d0c0b72-9c8b-47e7-b675-522e6a95de28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42bdf398-fd6e-41ea-826d-bdce99dbf358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94083ed7-8fc4-4331-9e28-b199a5e7be99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d2e3604-3c10-4612-928a-4f2fdb45464c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f1c1845-cafb-4573-b5fd-2753b1983fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6ebff09-7a98-4dd5-8e81-eb35001ab6ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eff3a24-2a74-4650-bd14-415064b9f295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82102347-d809-40e0-9a2c-dea56ea87fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fe0bf6e-b2e6-4989-8c43-9c0b3afc93c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5688c25e-458f-4b42-af12-08a8735a5467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 054c111d-8975-4276-af1f-c8e9a8487484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d09c39b2-b283-493c-981d-da558e11c58d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69723da8-54f4-4fde-81a1-40d9002737b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77a8a018-4246-4f92-8028-8377a6cbd6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42e6a093-2042-4990-b4ff-36c4d653144f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c549f42d-d15c-403d-ad63-bba4cfa4c69b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e6b5348-73a9-4c82-9ace-020e0b9cfb8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be947633-fddd-458d-b933-06a15fa627b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 231053d7-e4cb-4c58-adb5-e0dcec2e6966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd84a1a2-5d33-4485-9a7f-84e0d093460d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e03d6e3c-290e-4675-b356-a6c0f1b36e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5123799b-ea7a-491d-8d29-faae77322a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29d9b587-acad-4049-939e-a4577a31872e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a99d3b33-f85f-477d-b37e-bd3e061e333b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68944fa9-572a-4e61-b202-2704dafd477c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff101a3a-e73b-471e-a4a5-a9c1a3ef7c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82cb8f5f-0781-4b29-b0fb-8fe6948f5f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcdc5a00-aab8-4dfd-bb35-cecec14ffbc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d12fc6c-afe0-42cd-be1d-56b295b306f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce800605-258e-4514-87b3-330536fa24d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 770a38ef-336b-4b7c-9ab6-85660f4bce68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e73d452-74c4-403a-b691-1ceffa5f9992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9054a97-d33c-40ac-9d9f-5ad076c55c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64c0e0a0-6bb3-42a6-826b-a750dfd8e6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d31ed6a4-d1c6-4442-ba2e-695e7aa45718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37f18efe-943d-4246-9b56-519027433d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ce7f593-b463-4cf6-9058-d51caf61ffaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26f8b2b6-50bf-4fd4-b2c3-0b6c767c3222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 859c06fc-7fec-4e51-8cff-4b9035277a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12fa6ad2-b45b-46c2-bd95-e52516049897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 649cd55a-2b0e-4fd7-a8ce-80d1789dcd88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b2f9f77-9fcb-4940-99f7-ecac45f7db04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f13c7390-a7a2-440f-87d6-58e909c5018c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3ba3e16-dd72-4830-8e0b-1f41c657e3de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f659a15d-5c95-4b07-b1bb-45454abe653c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c07b254b-70ca-4701-8d1a-a34a0061056a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccb8cb7c-2d42-460d-aa5f-5ab2fd1ffaf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59805c9c-267c-4f23-9f4e-6cc37313ce1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55c90c3f-8ded-4aee-8967-d1269c6fca85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 263578e4-8a90-40d0-9a70-79c4388a5960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2edb21e6-578d-4131-b22b-729e94064505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01e79fde-42c0-4b8e-accc-ea11a981b86c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48edb82f-fe0c-45a7-b332-fe616c3def51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 018a97db-4000-4f27-9784-32637a21c4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fee0123b-ce45-4873-9cff-be09c6fee6f0
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_77
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/test_labels.txt

📊 Raw data loaded:
   Train: X=(1518, 24), y=(1518,)
   Test:  X=(380, 24), y=(380,)

⚠️  Limiting training data: 1518 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  371 samples, 5 features
✅ Client client_77 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0836 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0816, val=0.0829 (↓), lr=0.001000
   • Epoch   3/100: train=0.0814, val=0.0828, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0812, val=0.0828, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0810, val=0.0828, patience=3/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0793, val=0.0824 (↓), lr=0.001000
   📉 Epoch 17: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0720, val=0.0859, patience=10/15, lr=0.000500
   📉 Epoch 25: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 2 Summary - Client client_77
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0411
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0063
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2556, R²: 0.0022

============================================================
🔄 Round 4 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0790 (↓), lr=0.000250
   • Epoch   2/100: train=0.0817, val=0.0790, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0816, val=0.0790, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0815, val=0.0790, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0814, val=0.0790, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0810, val=0.0790, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 4 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0114
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0043
============================================================


============================================================
🔄 Round 5 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0800 (↓), lr=0.000063
   • Epoch   2/100: train=0.0811, val=0.0800, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0810, val=0.0801, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0810, val=0.0801, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0809, val=0.0801, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0807, val=0.0802, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 5 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0126
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0124
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2550, R²: 0.0076

============================================================
🔄 Round 8 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0800 (↓), lr=0.000016
   • Epoch   2/100: train=0.0800, val=0.0800, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0799, val=0.0799, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0799, val=0.0798, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0798, val=0.0798, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0797, val=0.0797, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 8 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0178
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0328
============================================================


============================================================
🔄 Round 10 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0836 (↓), lr=0.000004
   • Epoch   2/100: train=0.0786, val=0.0836, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0786, val=0.0837, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0786, val=0.0837, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0786, val=0.0837, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0785, val=0.0838, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 10 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0248
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0151
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2538, R²: 0.0144

📊 Round 10 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2536, R²: 0.0158

============================================================
🔄 Round 12 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 12 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0296
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0120
============================================================


============================================================
🔄 Round 13 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 13 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0274
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0219
============================================================


============================================================
🔄 Round 14 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 14 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0256
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0222
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2535, R²: 0.0165

============================================================
🔄 Round 17 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 17 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0316
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0061
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2534, R²: 0.0167

============================================================
🔄 Round 21 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 21 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0289
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0202
============================================================


============================================================
🔄 Round 22 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 22 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0302
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0095
============================================================


============================================================
🔄 Round 23 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 23 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0284
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0059
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0169

============================================================
🔄 Round 24 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 24 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0248
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0355
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0169

============================================================
🔄 Round 25 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 25 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0297
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0184
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0169

============================================================
🔄 Round 26 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 26 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0272
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0287
============================================================


============================================================
🔄 Round 28 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 28 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0280
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0131
============================================================


============================================================
🔄 Round 29 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 29 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0208
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0299
============================================================


============================================================
🔄 Round 30 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 30 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0256
   Val:   Loss=0.0672, RMSE=0.2593, R²=0.0347
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0170

📊 Round 30 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0170

============================================================
🔄 Round 36 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 36 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0303
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0158
============================================================


============================================================
🔄 Round 38 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 38 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0229
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0364
============================================================


============================================================
🔄 Round 40 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 40 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0280
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0255
============================================================


============================================================
🔄 Round 41 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 41 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0246
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0286
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0170

📊 Round 41 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0170

============================================================
🔄 Round 44 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 44 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0245
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0216
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0170

📊 Round 44 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0170

📊 Round 44 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0170

============================================================
🔄 Round 47 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 47 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0230
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0146
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0170

============================================================
🔄 Round 49 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 49 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2779, R²=0.0316
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0130
============================================================


============================================================
🔄 Round 50 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 50 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0201
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0258
============================================================


============================================================
🔄 Round 51 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 51 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0225
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0415
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0170

============================================================
🔄 Round 52 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 52 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0262
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0318
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0170

============================================================
🔄 Round 53 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 53 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0207
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0468
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0170

============================================================
🔄 Round 54 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 54 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0293
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0170
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0170

============================================================
🔄 Round 56 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 56 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0301
   Val:   Loss=0.0897, RMSE=0.2994, R²=0.0161
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0170

============================================================
🔄 Round 57 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 57 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0206
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0555
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0170

📊 Round 57 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0170

============================================================
🔄 Round 59 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 59 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0240
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0388
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0170

📊 Round 59 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0170

📊 Round 59 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0170

📊 Round 59 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2534, R²: 0.0170

============================================================
🔄 Round 68 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 68 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0253
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0309
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0170

============================================================
🔄 Round 74 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 74 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0304
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0151
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 75 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 75 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0209
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0520
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 76 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 76 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0266
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0304
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

📊 Round 76 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 79 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 79 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0345
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0043
============================================================


============================================================
🔄 Round 80 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 80 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0206
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0329
============================================================


============================================================
🔄 Round 82 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 82 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0261
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0332
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 84 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 84 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0254
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0360
============================================================


============================================================
🔄 Round 88 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 88 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0194
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0560
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 92 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 92 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0301
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0174
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

📊 Round 92 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

📊 Round 92 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 101 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 101 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0271
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0228
============================================================


============================================================
🔄 Round 102 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 102 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0287
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0220
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 103 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 103 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0272
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0279
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 106 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 106 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0265
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0270
============================================================


============================================================
🔄 Round 107 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 107 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0300
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0143
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 109 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 109 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0259
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0293
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

📊 Round 109 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 111 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 111 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0285
   Val:   Loss=0.0771, RMSE=0.2778, R²=0.0233
============================================================


============================================================
🔄 Round 112 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 112 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0274
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0282
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 119 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 119 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0310
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0078
============================================================


============================================================
🔄 Round 120 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 120 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0265
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0229
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

📊 Round 120 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

📊 Round 120 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

📊 Round 120 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

📊 Round 120 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

============================================================
🔄 Round 128 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 128 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0269
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0290
============================================================


============================================================
🔄 Round 129 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 129 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0196
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0605
============================================================


============================================================
🔄 Round 130 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 130 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0280
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0158
============================================================


============================================================
🔄 Round 131 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 131 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0181
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0640
============================================================


============================================================
🔄 Round 132 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 132 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0257
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0217
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

============================================================
🔄 Round 133 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 133 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0221
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0491
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

============================================================
🔄 Round 134 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 134 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0215
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0306
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 137 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 137 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0237
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0407
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

📊 Round 137 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 144 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 144 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0238
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0369
============================================================


============================================================
🔄 Round 145 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 145 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0238
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0274
============================================================


============================================================
🔄 Round 146 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 146 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0319
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0075
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 149 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 149 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0261
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0337
============================================================


============================================================
🔄 Round 150 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 150 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0254
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0329
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 154 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 154 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0273
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0289
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 155 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 155 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0253
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0345
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

📊 Round 155 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

============================================================
🔄 Round 160 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 160 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0276
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0167
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

============================================================
🔄 Round 161 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 161 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0304
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0069
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0171

📊 Round 161 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

📊 Round 161 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

📊 Round 161 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

============================================================
🔄 Round 168 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 168 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0199
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0383
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

📊 Round 168 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

📊 Round 168 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

📊 Round 168 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

============================================================
🔄 Round 174 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 174 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0310
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0139
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

📊 Round 174 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

============================================================
🔄 Round 177 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 177 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0306
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0154
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

============================================================
🔄 Round 178 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 178 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0223
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0473
============================================================


============================================================
🔄 Round 182 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 182 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0347
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0124
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

============================================================
🔄 Round 183 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 183 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0220
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0432
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

📊 Round 183 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2534, R²: 0.0172

============================================================
🔄 Round 185 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 185 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0239
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0430
============================================================


============================================================
🔄 Round 186 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 186 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0307
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0006
============================================================


============================================================
🔄 Round 189 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 189 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0265
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0157
============================================================


❌ Client client_77 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
