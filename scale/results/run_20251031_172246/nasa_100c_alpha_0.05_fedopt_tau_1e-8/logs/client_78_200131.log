[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3208c756-022a-44a5-916d-8cb49286074d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca105428-05be-44c9-a038-01a868a22762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ea22c99-4695-4be6-9d7f-7d5f210789a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9716fe8a-70ef-4205-b89d-663ee03c6095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d089305-c034-4994-904e-3c3dd2b30b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a41cd83-9f60-4d16-a212-696f5dc26dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa7e953f-9f9b-4910-9751-a8053c64a5ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bffca41-9536-470f-b932-56df759d4241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50b49afd-90b4-4f59-909b-26a196312204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22d326a1-8b58-422f-9f63-c4427141f925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ffeee80-4e17-48a9-a9f6-fc9571c4189b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40885d93-1335-4767-9014-1fe9eb1be4e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f47fad7b-9f2a-4c89-8817-2e16fb1f66b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbeed682-43ba-4af3-ab0c-157f78a12207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c113b0c-3d0d-4469-8e50-1fa03680466f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0f6340a-7840-45fe-9b73-9226f47892cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9314dbfb-29bf-4a57-8f6c-8bc10a03d1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24cac50e-faab-4054-a681-45fd34480501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f01d7fdf-2570-4c82-bb5a-beda4ea49a29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aff7a956-7361-4e4b-86eb-40a3a90917e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d9715ab-c453-4f53-825d-7dbbce6aa7e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 861b9800-f00a-47c6-b877-fe69f373f232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5adb8cc7-a062-4840-a3fe-99a5726c8a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a21bb9c-d3a3-4545-85bb-6bd5932d1bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0f0ce7a-12ec-4068-90f0-123dc317bb51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44f16e89-4c0c-4180-aada-10f985322492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f165a68-431f-48a8-b7ca-58bd34a5d68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19c4e616-931c-48ea-aa93-fc970f7aec4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3ff2cc1-400c-4682-bc6d-a3ec4a94729d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66f0f4ad-a9aa-4702-a88c-c81f94c0aa1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a44c92f-c263-4909-be9c-5ed94ba24b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b8f15e9-7690-487e-9c69-b4ca6bd5a095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e2bb60c-16ad-4f2a-907f-f657a45bf582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ff4292a-1d4d-41d7-bac0-9bd7e4b9678b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00c50d9b-73e9-4054-9500-f32ad7daf43d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b4873e0-885c-4c3e-bde8-d99b4200ebbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40025d32-1eee-4dea-a01d-d2da093cb63f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e002b0d-b008-4d5c-b6be-04d5bf0172cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89017877-218a-4b51-aaaa-784833dce475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64c5a5d7-24fe-4f2f-beb5-f5161fd6544a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a8856bd-f3f0-40cd-86b8-964523104c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e4d33a8-dcda-4f0a-a32e-7672267d3539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fe805de-ffe1-475e-9ca2-6d2f94c2397a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d6022fd-14ad-41d2-9400-8206769a337b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f712cc51-c452-4e55-bea1-6b74f04c4a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bc3b576-0e18-43ba-8357-834e877a61c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ef11735-3627-4f81-ab3f-6326e333eb3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f506bf9-0b85-4f8c-a921-786eeb3b15cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2134f289-a116-49a1-93ba-9906e4d9aa1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feb21da6-b7f2-4804-af0e-973df3f61fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa902e7f-4964-49f8-b6bc-f3322c06ef63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3dfaf35-28ce-41ef-b5e6-827774ff36ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67cf2d23-4d82-424a-8c6b-c73308b5ea1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07b59cca-aec3-4a54-b5f9-61944cd093a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f0df7f0-bdd5-4d09-816c-10ca2deaf425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d4d6918-c7be-41e5-9b48-37f33810e657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f338a485-d20b-41bb-b2a8-3985860430f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac6dda05-3e9d-43c4-885d-d3be4cdccc5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 480d3fb1-9ff3-4ba3-8913-ddde7051a0cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a55ddb2-3728-4c97-a5d9-ddc356cd6d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0116f472-f927-4f2c-a39d-bf77514e703c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31c8f850-5d39-4bc3-a5ed-2f9e39758366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8c8102b-7561-4271-8a5d-2a079d2efe9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8a0df31-46a0-4063-bc1f-51594591ab65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49587e83-0ec7-464c-a3a0-5384a8c28472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05ba7ffd-2b4a-47c7-af1c-0f578c3bf95b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43172542-a841-4ea6-bb3c-28e102df4b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5afa7ec2-c06f-49ac-8d83-3981855d2b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85077c1f-854c-4d7a-b187-c047c828ea15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eee4236f-80c7-4e85-a923-e3528aac4526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b94b5840-8fb9-475a-b6b6-4b15b694228f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f99aeb0-4634-4896-a8a2-554bb5fc75ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01a824db-9ae1-49f7-a343-2ac35a254d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79f2afb6-49a2-4383-8794-2d89ec7029aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53b08775-8faa-40b2-8b6c-025bf79b449a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 576e81b7-823e-4894-91e9-c4c4faf241e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c080a6f-3e48-4190-96cf-e9aa340d620c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b7b6642-5321-4bc3-acc6-ee0028692cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36e6710f-0a75-40d3-acb2-8f7df91bb2d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c91d2d8c-aa2c-4077-866e-a52096a13597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf4fd5ae-313f-47a0-9817-e5b612d3dd4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08fc92de-0101-4f0b-b237-622cc9e84ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76c02c57-fada-43b0-86fc-2f44276d05be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeadeaa5-6efd-4d53-8354-3d63c19d1ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 067055ef-29a0-4165-af55-f6608951ecef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 500cefb5-5359-4ed1-a16d-cf58e3d008e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d126e47a-e777-40d2-bf95-87b6839242dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba094fa4-7c74-4801-a743-35c9c54cb7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d68ada6-defe-4c7f-98cc-b15feb06fe86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0fd6447-b82f-44e8-9356-20e3512785a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c18a148d-f9d8-405e-af99-a7d51352b045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fa45137-b131-4aab-b208-a0c89ac17065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 279022d7-bea0-450e-91ad-952a105593c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 153464ef-761d-4b7e-a529-3d86cab5f16b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb40a21f-7e87-42ed-9ac0-bacf8a71a7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec707f0f-9394-435a-8abd-8ab1d1f2fd03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a866816-ad9e-41e9-8378-422a670532c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c125cb74-3eb9-42e3-821c-0f371a1d00dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7667be4-3aba-4e5d-9eea-376b5edcd4c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9488b723-2ec7-4d20-a9b4-4206d39a335a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35ca59a0-7c96-43b6-bff6-012b9e72eecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d225dfc9-fe1b-433f-b0b0-669592cfa7f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39cba255-10a5-4eab-b359-4fc9ca830345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05661fa5-8ed5-46a0-8fd9-5eb74b721184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 578cba3f-23e6-4fd1-bdc3-dec27aa15a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4976f9cf-aab2-4c1b-b3b3-31b419143408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 320b5221-d052-4f03-bd51-689715fcbad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60bde8a3-bf03-4365-8d5e-f4e6a3c9cb22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3681a556-efa2-4ee0-95e0-a43ee7691d21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4beb622-96a8-46d5-9726-1acef491f0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3b5b876-c013-4870-9e59-5193a07468ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c43ab89-3107-4fc1-83d6-6c55cdb9db56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcb26d68-6616-4ab9-b2f2-90baa4e29c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89fc3d38-38a0-4543-8c27-9167b554f6cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5979597-4ae8-4c94-b7b6-a0588e59ecbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcb7034b-ebfa-4758-a3cf-00a8ad86bdd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a572565-94fe-4488-b850-8083ec20a20f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65afedb4-817d-4065-8c54-a435fc4b87e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90efa110-317d-466d-bf6c-5f1422a4816f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db2d1ec2-1e04-4549-bc08-f1c5aea7c82c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7784ca47-211d-406b-87d0-ccc0656a6143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d60837e3-9e1b-4b25-a29f-47766980e3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2d310be-5464-4673-843c-6be5e8d7d3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a3213f7-d204-480e-bc0d-b81539957cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 326e25e2-ae1f-456a-ba72-a40382489359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6a7da85-ad0c-4e00-a901-60b74b10c1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5501f48c-2b59-40ae-96f0-e2d2708398c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8920e71a-f3ac-4bc2-809f-71b8445aa8a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1ac8947-a115-40ed-bf1d-5f887a39d714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59acac2d-ae37-4226-ab72-8f1c067d482d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aec70093-1a28-421e-9e04-28f77f2fd767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73176f34-65bb-48ad-b44a-398831f21c60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab4807a-bbf9-4f0b-81dc-6f259def7e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ca7cdf8-c00f-4c6f-bd34-25a41aec9543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55a4a6eb-e691-46e2-9591-3e89234be72c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11cca5d2-5d55-4ff4-b3a0-9fe3390100c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ca01818-409e-41cd-b798-5e8fbe5d160c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af039e3f-f714-4aff-a8d8-beaa35cf6181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d4544b2-6cff-43c3-9862-07a8be91d81b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cdd36f9-6a3d-4c1e-b331-951e420e5f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c8af27a-038f-4a44-8a2b-c48fcfbcdef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a74facc4-a08d-4b53-a6b7-1445dead43da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b421747d-9f82-43a5-8ac6-37a39e2931fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2bdd4ec-897a-4c8e-996d-261d89fab2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27f261e6-044c-47c8-bdca-7cd374c2d724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f97a93c-14eb-479e-8621-f42963eacf43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f23f373a-23b5-4db9-b3ce-63798402c23a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 112bdd49-3660-4aa2-b497-fcfa5880f777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a714f82c-8702-4c5a-9fb6-52dd258d7a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 147641b8-0d6e-4a8f-8412-bd07adbc9f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa0ede0a-dbb4-497c-a867-89d3a77ce492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bf46b90-af6f-4ed0-bed1-30e64f0c7176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f8cbd2c-94bc-4872-8e7c-dafb614704b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71bcf5f4-eaff-4983-849c-3a3311eaafbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e59b5c5-8ab8-438c-b526-d91856efd6fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0534055b-0f0b-448a-aca7-1c3d8c76165a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8167cf33-6b2a-4118-a75e-b2695fd9254e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f249a0c1-72b9-4055-80c3-f336b3d89f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d57ffec1-3ee8-4f82-b72d-8c3472a2a05f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49b53966-cb48-4bf1-af8a-72d13c4ce725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42645a23-602a-4f2f-b904-421b526185d1
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_78
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_78
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_78/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_78/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_78/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_78/test_labels.txt

📊 Raw data loaded:
   Train: X=(512, 24), y=(512,)
   Test:  X=(129, 24), y=(129,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 503 samples, 5 features
   Test:  120 samples, 5 features
✅ Client client_78 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2511, R²: 0.0134

============================================================
🔄 Round 3 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0783 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0833, val=0.0753 (↓), lr=0.001000
   • Epoch   3/100: train=0.0819, val=0.0764, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0816, val=0.0762, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0812, val=0.0759, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0777, val=0.0763, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 3 Summary - Client client_78
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0255
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0029
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2505, R²: 0.0168

📊 Round 3 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2495, R²: 0.0268

============================================================
🔄 Round 6 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0834 (↓), lr=0.000250
   • Epoch   2/100: train=0.0797, val=0.0835, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0795, val=0.0838, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0792, val=0.0839, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0790, val=0.0841, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0781, val=0.0846, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 6 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0269
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0101
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2469, R²: 0.0450

============================================================
🔄 Round 9 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0740 (↓), lr=0.000063
   • Epoch   2/100: train=0.0817, val=0.0739, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0816, val=0.0739, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0815, val=0.0738, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0814, val=0.0737, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0810, val=0.0736, patience=10/15, lr=0.000063
   • Epoch  21/100: train=0.0806, val=0.0732, patience=8/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 9 Summary - Client client_78
   Epochs: 28/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0358
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0674
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2455, R²: 0.0528

============================================================
🔄 Round 11 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0732 (↓), lr=0.000063
   • Epoch   2/100: train=0.0817, val=0.0732, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0816, val=0.0732, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0815, val=0.0732, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0813, val=0.0732, patience=4/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0809, val=0.0732, patience=10/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 11 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0345
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0520
============================================================


============================================================
🔄 Round 12 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0778 (↓), lr=0.000016
   • Epoch   2/100: train=0.0792, val=0.0778, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0792, val=0.0779, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0792, val=0.0779, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0791, val=0.0779, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0790, val=0.0780, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 12 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0353
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0461
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2449, R²: 0.0558

============================================================
🔄 Round 14 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0913 (↓), lr=0.000004
   • Epoch   2/100: train=0.0766, val=0.0913, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0766, val=0.0913, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0766, val=0.0913, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0766, val=0.0913, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0765, val=0.0913, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 14 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0330
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0537
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2448, R²: 0.0561

📊 Round 14 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2447, R²: 0.0567

============================================================
🔄 Round 16 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 16 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0323
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0616
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2447, R²: 0.0566

============================================================
🔄 Round 17 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 17 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0430
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0080
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2446, R²: 0.0571

============================================================
🔄 Round 19 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 19 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0349
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0460
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2446, R²: 0.0572

📊 Round 19 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2446, R²: 0.0572

============================================================
🔄 Round 21 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 21 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0350
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0118
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2446, R²: 0.0572

📊 Round 21 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2446, R²: 0.0572

📊 Round 21 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2446, R²: 0.0572

============================================================
🔄 Round 30 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 30 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0298
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0561
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2446, R²: 0.0572

============================================================
🔄 Round 36 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 36 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0416
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0419
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2446, R²: 0.0571

============================================================
🔄 Round 38 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 38 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0448
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0033
============================================================


============================================================
🔄 Round 39 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 39 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0448
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0033
============================================================


============================================================
🔄 Round 40 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 40 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0478
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0099
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2446, R²: 0.0572

============================================================
🔄 Round 42 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 42 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0271
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0483
============================================================


============================================================
🔄 Round 43 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 43 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0401
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0187
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2446, R²: 0.0572

============================================================
🔄 Round 44 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 44 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0427
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0140
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

============================================================
🔄 Round 45 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 45 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0320
   Val:   Loss=0.0707, RMSE=0.2658, R²=0.0672
============================================================


============================================================
🔄 Round 47 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 47 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0410
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0260
============================================================


============================================================
🔄 Round 48 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 48 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0372
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0345
============================================================


============================================================
🔄 Round 50 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 50 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0400
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0326
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

============================================================
🔄 Round 57 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 57 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0405
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0228
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

============================================================
🔄 Round 58 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 58 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0382
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0376
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

============================================================
🔄 Round 61 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 61 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0322
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0604
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

📊 Round 61 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

============================================================
🔄 Round 68 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 68 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0376
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0419
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

📊 Round 68 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

============================================================
🔄 Round 70 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 70 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0402
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0305
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

============================================================
🔄 Round 71 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 71 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0358
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0467
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

📊 Round 71 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 79 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 79 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0406
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0290
============================================================


============================================================
🔄 Round 80 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 80 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0312
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0425
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

📊 Round 80 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2445, R²: 0.0575

============================================================
🔄 Round 84 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 84 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0392
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0358
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

📊 Round 84 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

============================================================
🔄 Round 89 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 89 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0455
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0037
============================================================


============================================================
🔄 Round 90 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 90 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0386
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0351
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 91 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 91 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0436
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0094
============================================================


============================================================
🔄 Round 92 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 92 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0420
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0217
============================================================


============================================================
🔄 Round 94 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 94 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0272
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0851
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

📊 Round 94 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

📊 Round 94 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 97 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 97 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0365
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0438
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

📊 Round 97 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

📊 Round 97 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

📊 Round 97 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

📊 Round 97 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 107 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 107 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0375
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0396
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

📊 Round 107 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 111 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 111 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0216
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0942
============================================================


============================================================
🔄 Round 112 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 112 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0454
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0057
============================================================


============================================================
🔄 Round 113 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 113 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0431
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0121
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

📊 Round 113 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

📊 Round 113 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 117 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 117 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0527
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0393
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 118 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 118 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0411
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0284
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 119 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 119 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0391
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0361
============================================================


============================================================
🔄 Round 121 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 121 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0385
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0025
============================================================


============================================================
🔄 Round 122 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 122 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0329
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0422
============================================================


============================================================
🔄 Round 123 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 123 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0424
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0223
============================================================


============================================================
🔄 Round 125 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 125 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0356
   Val:   Loss=0.0686, RMSE=0.2619, R²=0.0427
============================================================


============================================================
🔄 Round 126 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 126 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0421
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0199
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2445, R²: 0.0575

============================================================
🔄 Round 128 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 128 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0405
   Val:   Loss=0.0744, RMSE=0.2729, R²=0.0259
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2445, R²: 0.0575

📊 Round 128 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2445, R²: 0.0575

============================================================
🔄 Round 132 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 132 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0348
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0513
============================================================


============================================================
🔄 Round 136 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 136 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0404
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0301
============================================================


============================================================
🔄 Round 137 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 137 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0360
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0358
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 138 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 138 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0397
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0121
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 139 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 139 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0385
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0330
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 140 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 140 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0337
   Val:   Loss=0.0679, RMSE=0.2605, R²=0.0619
============================================================


============================================================
🔄 Round 141 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 141 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0292
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0713
============================================================


============================================================
🔄 Round 142 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 142 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0385
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0311
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

📊 Round 142 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

============================================================
🔄 Round 146 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 146 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0384
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0038
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

============================================================
🔄 Round 147 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 147 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0427
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0048
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

============================================================
🔄 Round 149 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 149 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0375
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0376
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

============================================================
🔄 Round 150 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 150 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0397
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0031
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

📊 Round 150 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

============================================================
🔄 Round 153 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 153 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0410
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0279
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 154 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 154 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0372
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0397
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

📊 Round 154 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

============================================================
🔄 Round 157 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 157 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0375
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0414
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0573

============================================================
🔄 Round 158 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 158 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0467
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0019
============================================================


============================================================
🔄 Round 160 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 160 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0386
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0309
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 163 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 163 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0332
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0378
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 165 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 165 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0365
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0469
============================================================


============================================================
🔄 Round 167 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 167 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0428
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0210
============================================================


============================================================
🔄 Round 169 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 169 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0436
   Val:   Loss=0.0966, RMSE=0.3108, R²=0.0223
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2445, R²: 0.0575

============================================================
🔄 Round 171 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 171 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0439
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0117
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2445, R²: 0.0575

============================================================
🔄 Round 173 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 173 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0360
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0004
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2445, R²: 0.0575

============================================================
🔄 Round 174 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 174 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0409
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0160
============================================================


============================================================
🔄 Round 175 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 175 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0355
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0484
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2445, R²: 0.0575

============================================================
🔄 Round 176 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 176 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0366
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0424
============================================================


============================================================
🔄 Round 177 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 177 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0351
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0543
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2445, R²: 0.0575

============================================================
🔄 Round 179 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 179 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0432
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0131
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2445, R²: 0.0575

============================================================
🔄 Round 182 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 182 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0360
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0480
============================================================


============================================================
🔄 Round 184 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 184 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0408
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0109
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 186 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 186 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0438
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0166
============================================================


============================================================
🔄 Round 187 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 187 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0257
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0750
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

============================================================
🔄 Round 189 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 189 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0262
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0788
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: 0.0574

❌ Client client_78 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
