[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9d93f37-4725-4688-a746-5c3285253266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 950e3503-6efc-45e0-a10b-4130201a832f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 073e096d-c58b-4cb3-9de6-0d29e8a41935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42229b92-34fb-4295-8638-27eef5084d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c57b5af3-0deb-4bd1-bb31-7d9a1a6e4c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95b6cc24-d534-4dde-becf-8e4244e31bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16b730c0-d48c-4402-a944-38976f0fe390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c9eb821-c499-4a68-97ba-fc1e230c8722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9a54269-df8b-4fab-a8d2-a13124d1b2a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ace5063-18b2-479c-8494-e2967e09edad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2dc6c47-ecfa-4104-817f-87d058f568c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4866d2b7-1040-466f-9ede-d08831c45169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e4f427f-5080-4b18-8bf6-096e5b46f051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3c55164-4390-47b7-a529-4d633ccc3f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42a6c657-48b7-4dcc-a04d-bfca0a01f84f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 199d76a0-983c-4f82-bc22-806e27e7f18e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d7be327-ab6e-4264-a32c-73036169bda7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2e3a09d-9706-40a8-8e87-9c95593e1eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab0327df-256e-42d6-aaf3-5912dd81438d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15de859e-7d27-4e06-834f-0bdac4189861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05c96f33-0c1d-4195-b826-84f83eaf9806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c353fa4-4ab4-4f29-8d41-8ca224222d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 938569c9-fdd9-40b4-b010-45b9cabc95f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d95573-afae-48d6-8116-76049b270684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99cdbb0c-c07b-453d-8678-cdaa03a88e94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c9464d8-1660-480f-9d52-8dfd6518a608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 158bcb70-0333-4bec-9181-26ae12c793dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2df4eebd-d97c-4893-8e37-878df92ce5c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b037aac-78d3-42db-b3f6-8cc9fe86253c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2133504-fde0-49cd-ab68-be6034d1c129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 426f5a56-11fa-44a3-a2a3-09c412ccb7cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dee1e9de-a3f5-46b4-9024-23051d78817b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe518a26-0b5c-4f7e-bb8b-4b8ac1fbeb65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3d68416-0ae0-4150-97d8-9038c63a1d39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a07e701-16c2-4af5-bb59-0e76b07c4073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 585d58c3-e89a-46cc-b451-be28e516a09e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86c426af-0a10-433b-88f8-dc94f7b6e4aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aac61d1-977f-4959-9cb2-634562930584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9afb5f8-cda4-4852-951c-6dd2f22fccfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 006e599c-1190-412d-9fca-e3ec200944f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ba776e6-0491-481f-a54c-fc6c52f15d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 382b16b4-5106-46ff-9aa4-b56a93906615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85233c31-2ba1-44c4-861c-cd033a92db2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54e4d6a6-3263-4d72-bc12-6abef88ef397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9577d052-3854-41f6-bf49-4e805a0ee43b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80bac079-3ffc-4d98-98f4-efbfea5e4113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f02f9df-0678-480b-afec-baf1f99d513e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda861e9-2fca-4db8-b3c8-bb14c852e820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f6df4d9-2f0d-4125-b53c-30c8f437d593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b141fa76-a951-463b-a242-bd57d2c7f806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e61a1de3-9c98-4682-a695-6243df8ce795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2fe5734-04e8-4893-8cb6-5c10c2e274a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6336ef46-6665-4567-93d2-e0f62b089823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02c1fa65-cc30-4a01-bd77-dae1e7223f69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aac5ce5d-5283-482a-9ac2-83399efca943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94d36b4e-d4d5-45b5-a530-98e83907e8c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7538118e-48ed-4401-9c98-b716ccd598e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4578de1-2b9f-4d54-81f1-5810a09247c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94522d84-6133-446a-8585-c7d081f38bdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f257a69d-958d-440f-8355-c79b9036014e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d78fc680-cae5-484a-b42b-0df8ea96823d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fd0a439-c80d-44fe-a063-5f7a7c50eba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ae1558f-4109-4c6f-984a-b210fd98e916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62b5bfa2-478f-49a2-b304-275be57579f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1dd01d0-eec0-4276-ae22-79b6393bc370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec788351-ca0f-4cbd-92e1-e81262ca470b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5dc32cc-ba10-4d21-a9a2-b7b0dc1cce89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2a1f0d3-86f7-456e-849e-6f9b7999d32b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f11e40ae-124f-4636-9665-9b01c82e31ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94fd5b28-b29c-43b5-914f-751dced9bf48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b1c9a63-a124-48a9-baec-01963e26bf21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e208e1a3-bd75-4b2d-9220-da06a17aa412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d513bc23-2510-45dc-a06e-eda35ff31b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e29c30f0-684d-4e03-a038-b0858031f1ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 017959b7-10ee-4f4a-9c37-324967d8a647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a3676b3-0285-44fa-b494-095982085a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d83606a-5870-4704-b2a2-d200f4e1099d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d62d28-6071-4cd2-b4a7-4baeabcdf76f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a88076c-0c2c-4ecb-ac02-441f8e5b9318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b80b7705-c0a4-4660-9383-3f1d7e86c9bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 230cd317-d6a0-4498-89d2-2eba948aed64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6f3b541-6c32-447c-adb6-ec0eb27094b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62bac7d8-6039-4716-b988-4f27247780eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f872e5e-162b-414b-a017-b1732a6a5427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 658fed56-005a-49fd-bc0e-7bc26b465414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66fe3363-7ede-4e85-a1cb-2427ad597a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41fb18b3-48e8-4e88-8639-ce3c4b1c7d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31fd83d4-44a1-4039-aefd-b9c1af056fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95154f60-a4cc-4d88-8986-113e8da01b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cf62bf2-c175-458f-a41f-575441b2a2a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c19909b5-cdfa-4d54-a90b-f610c9a32c6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ea58e8a-da67-4480-9d1c-3c8e8018e4ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7ee8c0f-cbb3-43e6-aaad-69ce04730d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10260fe5-75a5-4c0a-8411-bc6f3223b0ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cf0c4b9-261c-4fb0-a1b7-7822c6a5afac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2286113e-0ca9-4a89-a9ab-33eb2f37869b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 786eb7cd-924e-4068-8870-1dc40d0ed2f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7cb95e5-e8db-41c0-88a6-56308c0d568d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 360fe87c-16fe-4ab8-8f8c-c906201390a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dae1d2b4-4522-4fba-b2d6-5b1808c767e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd291e7d-a688-400f-8a45-95bc510a4735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cccc55e3-5f42-414c-a823-075813fe09db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36eda717-df57-4cc5-9777-1351a052b64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e38039e9-d3c5-4b17-acd4-7e71b7bb37ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43e9ae00-5e5c-4c07-a073-45d193fb922d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d08857c-4c85-4b80-abf5-4d7e815bba0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec1236d5-723a-4886-b989-1c9f7ff9c38a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2272c6c9-6b4c-4701-b7cb-b83d82d98235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33a55a56-f890-4efb-a8b4-54c048c5ccf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3227c3f3-9e55-4fa6-a80a-a243e2340b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b588ba09-21e1-4541-977f-6c8c58d199d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 343d1d3d-d742-4d45-aea5-0e420cc1ba43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f911eac8-dd78-45ed-9a06-2c55a27d3f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faa22bfc-8eee-4ada-972c-9e6aed89392e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18b1f82e-3c1a-49e5-bf2b-4df228028cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a88a41a2-8983-4652-a230-d1d3cdc4ef11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66d4469d-f0cb-4c66-933b-d352b0e87942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 947b0db4-b617-49e8-9fb0-2805b4887ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 612debc7-ada7-40aa-876f-6d7c5466c6b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 164db103-b3d0-4014-b4c3-7afa8e504a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3862cdda-850a-48ec-97a0-d1308fdfec7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c8d334-79ee-4dd2-85f2-f3c6efeac74e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 289cc9f5-cd3a-43a8-9764-7e75780a66eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d5d729e-759d-4092-8367-00ea452313ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 179f0628-24a5-401a-b438-fe14263bcf39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9f9e2af-6f7b-4bfd-a545-670f0ade1f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0405a86-b909-4d2a-80c8-35f8666069a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb71dee5-30be-4340-a3ac-366dcdbbafdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a77b75d-da07-4971-a8a2-49cffaf7e1ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc9411f9-b016-4332-9661-7ff356db546d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df32e1ce-76c9-44fc-b54e-e718e9aaabd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 612cea3f-d072-4ed0-8e19-f8b78a8432c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3589078e-2557-44ba-b757-5d52460bd967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d7eba16-f880-4c96-b817-c52943b40812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0178ea5a-f9ec-40d6-9cbf-7962fd572219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2e499a4-76fd-4aa9-91c2-c76a8fb97370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50eb9803-8b14-48e7-91a8-72f0e40dd761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74dd261c-9608-4982-a3b0-a002c7a347a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9a9e076-0b80-4cf8-a354-162f86da8ddd
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_79
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/test_labels.txt

📊 Raw data loaded:
   Train: X=(1288, 24), y=(1288,)
   Test:  X=(322, 24), y=(322,)

⚠️  Limiting training data: 1288 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  313 samples, 5 features
✅ Client client_79 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 4 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0789 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0843, val=0.0768 (↓), lr=0.001000
   • Epoch   3/100: train=0.0839, val=0.0764, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0836, val=0.0764, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0834, val=0.0763, patience=3/15, lr=0.001000
   • Epoch  11/100: train=0.0818, val=0.0775, patience=5/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500
   📉 Epoch 20: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0771, val=0.0821, patience=15/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 4 Summary - Client client_79
   Epochs: 21/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0169
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0283
============================================================


============================================================
🔄 Round 5 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0835 (↓), lr=0.000250
   • Epoch   2/100: train=0.0822, val=0.0831, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0819, val=0.0830 (↓), lr=0.000250
   • Epoch   4/100: train=0.0818, val=0.0829, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0817, val=0.0829, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0812, val=0.0829, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 5 Summary - Client client_79
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0088
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0153
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0026

📊 Round 5 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2479, R²: 0.0023

📊 Round 5 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 10 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0764 (↓), lr=0.000063
   • Epoch   2/100: train=0.0837, val=0.0762, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0836, val=0.0762, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0834, val=0.0762, patience=3/15, lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   • Epoch   5/100: train=0.0833, val=0.0763, patience=4/15, lr=0.000031
   • Epoch  11/100: train=0.0829, val=0.0763, patience=10/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 10 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0063
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0135
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2472, R²: 0.0054

============================================================
🔄 Round 14 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0847 (↓), lr=0.000016
   • Epoch   2/100: train=0.0820, val=0.0848, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0819, val=0.0848, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0818, val=0.0849, patience=3/15, lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   • Epoch   5/100: train=0.0817, val=0.0849, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0816, val=0.0850, patience=10/15, lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 14 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0071
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0068
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2471, R²: 0.0055

============================================================
🔄 Round 18 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0827 (↓), lr=0.000004
   • Epoch   2/100: train=0.0824, val=0.0827, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0824, val=0.0826, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0824, val=0.0826, patience=3/15, lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0823, val=0.0825, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0823, val=0.0824, patience=10/15, lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 18 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0070
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0181
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0053

📊 Round 18 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0053

📊 Round 18 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0053

============================================================
🔄 Round 22 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 22 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0042
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0051
============================================================


============================================================
🔄 Round 25 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 25 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0055
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0026
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0053

📊 Round 25 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0053

📊 Round 25 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0053

📊 Round 25 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0053

📊 Round 25 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0053

============================================================
🔄 Round 31 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 31 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0069
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0061
============================================================


============================================================
🔄 Round 32 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 32 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0052
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0041
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0053

📊 Round 32 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0053

============================================================
🔄 Round 38 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 38 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0045
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0066
============================================================


============================================================
🔄 Round 39 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 39 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0078
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0161
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0053

📊 Round 39 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0053

============================================================
🔄 Round 43 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 43 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0097
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0223
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 44 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 44 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0037
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0079
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

📊 Round 44 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 48 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 48 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0034
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0064
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

📊 Round 48 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 51 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 51 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0043
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0015
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 52 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 52 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0007
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0171
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 53 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 53 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0066
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0048
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

📊 Round 53 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 55 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 55 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0053
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0010
============================================================


============================================================
🔄 Round 56 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 56 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0013
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0178
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 59 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 59 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0021
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0063
============================================================


============================================================
🔄 Round 61 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 61 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0080
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0175
============================================================


============================================================
🔄 Round 63 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 63 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0085
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0329
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

📊 Round 63 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 65 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 65 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0081
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0682
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 67 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 67 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0033
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0050
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 69 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 69 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0042
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0058
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 70 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 70 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0032
   Val:   Loss=0.0672, RMSE=0.2592, R²=-0.0110
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 77 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 77 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0056
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0014
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 80 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 80 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0008
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0242
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 84 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 84 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0026
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0132
============================================================


============================================================
🔄 Round 85 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 85 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0008
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0166
============================================================


============================================================
🔄 Round 88 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 88 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0124
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0303
============================================================


============================================================
🔄 Round 89 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 89 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0048
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0030
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

📊 Round 89 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

📊 Round 89 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 98 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 98 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0052
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0025
============================================================


============================================================
🔄 Round 100 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 100 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0037
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0024
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 105 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 105 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0005
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0173
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 106 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 106 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0027
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0004
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 107 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 107 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0052
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0009
============================================================


============================================================
🔄 Round 109 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 109 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0005
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0183
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 110 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 110 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0010
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0166
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

📊 Round 110 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 115 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 115 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0010
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0150
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 118 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 118 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0019
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0331
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

📊 Round 118 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 124 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 124 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0074
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0280
============================================================


============================================================
🔄 Round 125 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 125 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0043
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0009
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 126 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 126 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0062
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0045
============================================================


============================================================
🔄 Round 127 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 127 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0013
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0224
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0051

============================================================
🔄 Round 129 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 129 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0100
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0246
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0051

============================================================
🔄 Round 133 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 133 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0057
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0179
============================================================


============================================================
🔄 Round 134 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 134 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0057
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0025
============================================================


============================================================
🔄 Round 135 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 135 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0113
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0219
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

📊 Round 135 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 139 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 139 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0011
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0172
============================================================


============================================================
🔄 Round 140 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 140 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0013
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0026
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 143 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 143 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0003
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0188
============================================================


============================================================
🔄 Round 144 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 144 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0042
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0031
============================================================


============================================================
🔄 Round 145 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 145 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0054
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0012
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

📊 Round 145 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 148 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 148 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0014
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0091
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 154 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 154 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0034
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0209
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 157 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 157 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0014
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0165
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 159 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 159 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0042
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0058
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 161 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 161 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0037
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0056
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 164 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 164 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0024
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0129
============================================================


============================================================
🔄 Round 165 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 165 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0079
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0122
============================================================


============================================================
🔄 Round 166 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 166 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0098
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0251
============================================================


============================================================
🔄 Round 167 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 167 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0037
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0084
============================================================


============================================================
🔄 Round 168 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 168 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0014
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0133
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0051

============================================================
🔄 Round 170 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 170 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0026
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0163
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0051

📊 Round 170 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0051

============================================================
🔄 Round 173 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 173 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0068
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0060
============================================================


============================================================
🔄 Round 174 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 174 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0042
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0053
============================================================


============================================================
🔄 Round 175 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 175 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0038
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0028
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0051

============================================================
🔄 Round 181 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 181 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0052
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0020
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 183 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 183 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0050
   Val:   Loss=0.0903, RMSE=0.3006, R²=0.0012
============================================================


============================================================
🔄 Round 184 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 184 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0083
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0107
============================================================


============================================================
🔄 Round 187 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 187 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0076
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0146
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: 0.0052

============================================================
🔄 Round 188 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 188 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0089
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0188
============================================================


❌ Client client_79 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
