[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0331571-6e0b-47d6-8c13-66c6b59ce3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af8d0f4f-fac4-4a62-a82c-2de7d9ca3c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79e8c01b-dd9d-4793-bc0f-9a85ea3309ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dd259c2-396e-415a-8e50-cf0874148ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e62bbe83-59b9-43ac-8f1e-c22ec480b0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76df464e-06d9-4042-8516-9646e6d6cff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b244e41-9ddd-41fa-b049-e8b444e09c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ee9b445-ff4d-429a-a32d-0f4676fce6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85ce1060-d2dd-4e01-8dd6-6444ab447915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4501273-73bf-4439-831c-0ccd3bc73868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57cfc557-5539-43c3-a6c7-16f575ae8ce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78364132-3f34-4556-849d-e49b55f3be02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 236edb84-3840-4129-8288-d139c80ab65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7351aab7-7a2c-4063-b27f-15975db8aaf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77b96e23-78a9-49e5-b3e1-10b1fc9d5e6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baaca233-f444-4692-9cc2-8750e171b96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41bc52c0-3d4a-4b73-ab7c-8195c1d1627c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d2ee1d3-bb9b-4e89-a76b-20e7f938bdc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de9df3e9-8588-4e8e-972c-7fb89e91ec86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e79057b3-137d-4403-8a46-d511e64f9209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2c475eb-3514-4aa3-9750-f4bede44afef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85adf75d-b744-402f-ba13-19f76371f25f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d48bd95-08c1-4eec-8f54-c1ef1dedfa48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a1bb15d-ce86-4c21-a513-dbaa6504b9b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f696dfc-5a8d-4ffe-9634-b45f5578087e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a58abf7-251d-4e1d-8d5d-fd42a857fd79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa3150e-f4a3-47bd-8e5f-9498aa36dcc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d12b4aac-e0f7-4f87-8e3b-266a96e6c497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27bf4a19-8b98-40ce-9c2a-df53daab600c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d85277e1-20d2-4d8d-96d0-74028b056fc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fafa3446-e60d-48bd-8051-d80d4ff925ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8e9f808-cbae-46ea-a9df-4a2852b75a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93ad3094-2b4f-41de-bc44-80ece87b9b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fc031e2-359b-493a-bede-9ef38af6f8fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 591b5713-e1e8-4a3b-930f-cbf993b8c509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c3f6741-0cb0-41fc-b8ac-6c333a88dec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87f07eb7-1363-4aa2-a8d9-4e7e9b884e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf25ba00-98a0-4fe0-aa25-be347964935f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fab34c3-635e-4475-9715-5a769f0b825d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4302b973-2aa9-493c-b325-0e09efe88638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e96d1bf-8f2d-48e4-9264-d9e6409ecb7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9286f975-288c-480b-857a-d5cd300af271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd8fedce-e264-4092-be45-a9d77f9a09db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7032680a-e06e-43e3-97f7-dab2a3fb4ea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e7bd8b5-5599-4509-8fad-778bff1a7d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cafd5e4-f406-42ec-ac52-b3a63f373dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3576461-3df6-4d38-aa0f-0aa1ee99ffd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 136dff4f-1e75-409f-9fc9-266c50f423e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b12bd03-deb1-4ed7-938d-68b92d5ee352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04597438-e459-4a4f-84a2-e38a4758fa16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dfc4ffd-768e-4b7e-b325-ca82036fc9b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e73f20d-a314-4f13-9e7b-892023f1a281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1481fc23-d8bb-40f5-a7fa-72bcd4aff2a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96d47bba-0e72-4bfc-b093-19eeffba746a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c0133c-52a8-492d-9ed8-c1614d8a725d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 248e899e-7940-4e29-a961-d9f018c33a0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 073fb887-5ce3-4b59-b743-bace031e8195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 418a5532-7919-42f3-8585-42340dbfac2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6d79f24-eadd-431b-9459-0923bf41a29f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbb29331-fbca-4663-b814-4779c78303ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f84ed488-59f0-4b1f-a774-730dc953d960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06da49aa-54f7-48bb-8b39-95d4e04dd975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edd6e868-274a-4dce-beae-232556554952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fd3de26-41cb-43fb-9428-d1a07ca9afd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43da0054-0b8f-40cd-a459-5e0d9fb32b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de965a94-2f8f-4f0c-86d7-3ecd2015890f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27fba36d-8858-4c32-8e9f-1bcd255466ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1464ee76-a203-4602-89c3-7face72db98e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8baa2fe5-e318-4b90-85c4-0973a2224270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0ba1ac8-015c-4875-a496-1a50f6dc7ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b01d112-c8fc-45fa-90b4-f8c78a7a2609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d003dd2-432f-485e-a506-71780a26585d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99b77972-0295-424c-9ec1-305aaf741499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 197700e6-1b8d-4ec0-889d-87da66ca6fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb111be7-44c0-4623-b6cb-92fcc7b316fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de97fe60-f248-4ff5-ab63-846e7497a6a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 177aecf5-2b2a-48b5-8429-7a92c670eee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0708696-8f60-40e9-ac82-e208b55ee72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f543aae-939d-40ea-83bf-c3b41e71b870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9d52cd8-9310-4d27-9710-d228d42067fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b674ef4a-f571-46ee-816c-4e2993df84ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85269a8f-9858-4e8d-90d4-29385c8f7bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 792bdadb-6068-4167-a032-49787a3be438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a004d83c-5610-482a-b205-18f18f09e5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c01ffe7-db59-45bf-ab32-eef21351bcb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12f2a989-6818-479d-aac6-6d995e0e61ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a7031d8-0dcd-421f-b800-9e271eebccd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 999f8739-dd53-4a13-81f5-8342142c80c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fde01e6-66f6-4f4e-9e8b-d90acca7af63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe90e141-5c39-41d1-9cdd-001b68f90d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49c70cbc-71e5-4f59-b242-b5376e939cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b9fe74c-2e42-425d-8a50-90b55338b6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abc3ac34-d547-4896-b781-d60ccd63ff91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1177fe22-44cd-41db-afe4-6223927757e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388bbc62-e86b-4f66-a2d9-cd7465d852a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c2872e5-4380-4825-b786-9d462d58687a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15b48a3a-7d88-4daf-b824-2f483e6db656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b111aadb-98ae-4715-8d35-0010937a8dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c4af975-b994-4f02-9c3b-a697b1596b7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d842a550-2a33-4a0e-9864-97de45c60a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 598c078a-6261-47c6-a515-f3b46ae974f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49181c6c-73b7-4bd0-a8f0-5f23f5331f09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de547a13-e2eb-4515-bdc7-152b4daac05e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86dda316-98fa-407e-8547-de3468cc3393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5208210-ab64-4cb6-ae9c-fd500fd249c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 318f8ea8-1068-478a-b73b-017878e4b4e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72600b2b-17f2-4598-9e5b-cd5bdfb09c25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80ddac91-eb49-4312-bada-7345bd8f7e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce606b8d-a769-4438-90df-9ff87d2c9559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99d388bf-b0af-464c-930c-1d65242988f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93707149-3e4e-4086-9bd0-329f5482bb3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acc4f87a-b991-45a1-9f77-1277507e6b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8762d743-b51c-42e9-bc9a-3c7a82ae293b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebd19083-6615-44b8-8719-7b5937e17ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcd089d9-cd24-4f40-b0b4-b7151cb94234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f8bca3c-5639-4d4d-9e17-52a849969f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ae88d1d-a37f-456c-986f-810d0a9d66b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6af97230-484f-4a42-9638-26fe87e7bf13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ac3fbda-2081-41fd-a1d6-3895fcefc135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a2d5c2f-dff1-4ee4-a096-f6ba26d91079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c619ed4-e9ac-444d-ac21-00cf89702e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e884b6e-8c80-49f6-bc9f-c39521fc2a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88f083d-2947-4bc5-a1a8-2dbe365a3ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05cde23f-b2b8-4229-8043-fa313c34cbe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e3b1c00-1548-4d6c-aa58-93dfb923a39e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d171d587-0848-491c-b6a5-99cafed9c512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce574462-7805-4793-8a9e-3c2ef164f641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 409740e8-fddd-41d1-ba68-dff9094c9167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2bb64b4-aeab-47ae-a9b6-73154a3c8cfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c1ff97e-4592-45f7-a1c4-e785a6545c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6085c283-f7e7-4d04-b30f-bebfa14b2dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a8c388b-f436-44ea-be2b-fbb986e8610c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45e36266-6e43-4796-91cf-f67f89fa1a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77372d26-d5c4-48cb-8ddd-f0f7e8eec05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49445c4d-844c-4774-9f31-4240bd8f91b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e70a3c2b-d784-41a3-b72c-a08eb3a900df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5487854e-a985-45dd-98bb-772b059793fb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_7
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_7
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_7/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_7/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_7/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_7/test_labels.txt

📊 Raw data loaded:
   Train: X=(1690, 24), y=(1690,)
   Test:  X=(423, 24), y=(423,)

⚠️  Limiting training data: 1690 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  414 samples, 5 features
✅ Client client_7 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2531, R²: 0.0047

📊 Round 0 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0094

============================================================
🔄 Round 4 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0839 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0835, val=0.0804 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0828, val=0.0795 (↓), lr=0.001000
   • Epoch   4/100: train=0.0815, val=0.0792, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0805, val=0.0791, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0777, val=0.0786, patience=5/15, lr=0.001000
   📉 Epoch 15: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0700, val=0.0831, patience=15/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 4 Summary - Client client_7
   Epochs: 21/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0517
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0391
============================================================


============================================================
🔄 Round 6 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0822 (↓), lr=0.000500
   📉 Epoch 2: LR reduced 0.000500 → 0.000250
   • Epoch   2/100: train=0.0806, val=0.0817, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0792, val=0.0818, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0787, val=0.0819, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0785, val=0.0820, patience=4/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0770, val=0.0824, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 6 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0351
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0116
============================================================


============================================================
🔄 Round 7 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0792 (↓), lr=0.000125
   📉 Epoch 2: LR reduced 0.000125 → 0.000063
   ✓ Epoch   2/100: train=0.0808, val=0.0787 (↓), lr=0.000063
   • Epoch   3/100: train=0.0807, val=0.0785, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0806, val=0.0783, patience=2/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0804, val=0.0781 (↓), lr=0.000063
   • Epoch  11/100: train=0.0800, val=0.0772, patience=3/15, lr=0.000063
   ✓ Epoch  21/100: train=0.0794, val=0.0760 (↓), lr=0.000063
   • Epoch  31/100: train=0.0788, val=0.0752, patience=3/15, lr=0.000063
   • Epoch  41/100: train=0.0784, val=0.0746, patience=5/15, lr=0.000063
   • Epoch  51/100: train=0.0779, val=0.0741, patience=6/15, lr=0.000063
   • Epoch  61/100: train=0.0774, val=0.0735, patience=6/15, lr=0.000063
   • Epoch  71/100: train=0.0769, val=0.0729, patience=7/15, lr=0.000063
   • Epoch  81/100: train=0.0765, val=0.0723, patience=7/15, lr=0.000063
   • Epoch  91/100: train=0.0761, val=0.0718, patience=7/15, lr=0.000063

============================================================
📊 Round 7 Summary - Client client_7
   Epochs: 100/100
   LR: 0.000125 → 0.000063 (1 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0913
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.1499
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2461, R²: 0.0519

============================================================
🔄 Round 14 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0835 (↓), lr=0.000063
   • Epoch   2/100: train=0.0777, val=0.0833, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0775, val=0.0831, patience=2/15, lr=0.000063
   ✓ Epoch   4/100: train=0.0773, val=0.0828 (↓), lr=0.000063
   • Epoch   5/100: train=0.0771, val=0.0826, patience=1/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0766, val=0.0820, patience=3/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0762, val=0.0817, patience=4/15, lr=0.000016
   📉 Epoch 22: LR reduced 0.000016 → 0.000008
   📉 Epoch 30: LR reduced 0.000008 → 0.000004
   • Epoch  31/100: train=0.0761, val=0.0815, patience=14/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 14 Summary - Client client_7
   Epochs: 32/100 (early stopped)
   LR: 0.000063 → 0.000004 (4 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0660
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0766
============================================================


============================================================
🔄 Round 15 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0811 (↓), lr=0.000004
   • Epoch   2/100: train=0.0789, val=0.0811, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0788, val=0.0811, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0788, val=0.0810, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0788, val=0.0810, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0787, val=0.0809, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 15 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0508
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0359
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0554

============================================================
🔄 Round 23 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 23 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0567
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0056
============================================================


============================================================
🔄 Round 24 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 24 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0431
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0604
============================================================


============================================================
🔄 Round 25 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 25 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0495
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0401
============================================================


============================================================
🔄 Round 26 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 26 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0460
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0322
============================================================


============================================================
🔄 Round 29 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 29 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0458
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0535
============================================================


============================================================
🔄 Round 30 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 30 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0512
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0290
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0555

📊 Round 30 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0555

============================================================
🔄 Round 32 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 32 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0434
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0450
============================================================


============================================================
🔄 Round 34 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 34 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0443
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0525
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0555

============================================================
🔄 Round 40 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 40 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0442
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0617
============================================================


============================================================
🔄 Round 41 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 41 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0427
   Val:   Loss=0.0737, RMSE=0.2716, R²=0.0697
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0555

============================================================
🔄 Round 42 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 42 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0450
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0513
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0555

📊 Round 42 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0556

============================================================
🔄 Round 45 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 45 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0435
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0644
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0556

============================================================
🔄 Round 47 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 47 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0406
   Val:   Loss=0.0700, RMSE=0.2646, R²=0.0775
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0556

============================================================
🔄 Round 48 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 48 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0474
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0395
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0556

============================================================
🔄 Round 50 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 50 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0404
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0737
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0556

============================================================
🔄 Round 54 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 54 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0506
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0052
============================================================


============================================================
🔄 Round 55 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 55 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0526
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0296
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0556

📊 Round 55 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0556

📊 Round 55 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0557

============================================================
🔄 Round 60 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 60 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0451
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0575
============================================================


============================================================
🔄 Round 62 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 62 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0513
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0299
============================================================


============================================================
🔄 Round 64 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 64 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0470
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0501
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0556

📊 Round 64 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0556

============================================================
🔄 Round 68 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 68 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0476
   Val:   Loss=0.0866, RMSE=0.2944, R²=0.0461
============================================================


============================================================
🔄 Round 71 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 71 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0467
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0517
============================================================


============================================================
🔄 Round 72 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 72 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0475
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0413
============================================================


============================================================
🔄 Round 75 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 75 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0514
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0289
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0557

📊 Round 75 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0557

============================================================
🔄 Round 78 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 78 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0538
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0100
============================================================


============================================================
🔄 Round 81 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 81 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0533
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0195
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0557

📊 Round 81 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0557

============================================================
🔄 Round 83 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 83 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0527
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0285
============================================================


============================================================
🔄 Round 84 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 84 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0404
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0803
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0557

============================================================
🔄 Round 85 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 85 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0526
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0267
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0557

📊 Round 85 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0557

📊 Round 85 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0557

============================================================
🔄 Round 93 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 93 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0511
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0359
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: 0.0557

============================================================
🔄 Round 94 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 94 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0380
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0685
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0557

============================================================
🔄 Round 97 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 97 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0555
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0131
============================================================


============================================================
🔄 Round 98 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 98 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0441
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0576
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0557

============================================================
🔄 Round 99 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 99 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0462
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0537
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0557

============================================================
🔄 Round 100 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 100 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0497
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0408
============================================================


============================================================
🔄 Round 101 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 101 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0465
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0520
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0557

📊 Round 101 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0557

📊 Round 101 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0558

============================================================
🔄 Round 108 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 108 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0506
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0355
============================================================


============================================================
🔄 Round 109 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 109 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0527
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0276
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0558

📊 Round 109 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0558

============================================================
🔄 Round 116 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 116 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0463
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0516
============================================================


============================================================
🔄 Round 117 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 117 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0445
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0542
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0558

============================================================
🔄 Round 119 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 119 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0489
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0257
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0558

============================================================
🔄 Round 124 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 124 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0426
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0684
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0558

============================================================
🔄 Round 125 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 125 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0433
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0661
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0558

============================================================
🔄 Round 126 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 126 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0493
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0422
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0558

============================================================
🔄 Round 128 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 128 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0503
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0282
============================================================


============================================================
🔄 Round 129 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 129 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0537
   Val:   Loss=0.0809, RMSE=0.2843, R²=0.0220
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0558

============================================================
🔄 Round 131 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 131 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0490
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0418
============================================================


============================================================
🔄 Round 134 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 134 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0537
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0246
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0558

============================================================
🔄 Round 135 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 135 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0485
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0454
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0558

============================================================
🔄 Round 138 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 138 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0517
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0208
============================================================


============================================================
🔄 Round 140 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 140 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0483
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0458
============================================================


============================================================
🔄 Round 141 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 141 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0522
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0236
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0557

📊 Round 141 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2456, R²: 0.0557

============================================================
🔄 Round 149 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 149 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0528
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0235
============================================================


============================================================
🔄 Round 152 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 152 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0504
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0358
============================================================


============================================================
🔄 Round 155 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 155 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0509
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0347
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0558

============================================================
🔄 Round 157 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 157 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0464
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0529
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0558

📊 Round 157 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0558

============================================================
🔄 Round 159 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 159 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0437
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0398
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0558

============================================================
🔄 Round 161 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 161 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0465
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0527
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0559

============================================================
🔄 Round 166 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 166 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0483
   Val:   Loss=0.0706, RMSE=0.2658, R²=0.0450
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0559

============================================================
🔄 Round 167 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 167 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0448
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.0574
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0559

============================================================
🔄 Round 168 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 168 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0463
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0523
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0559

📊 Round 168 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0559

============================================================
🔄 Round 173 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 173 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0492
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0067
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0559

============================================================
🔄 Round 175 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 175 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0470
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0501
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0559

============================================================
🔄 Round 177 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 177 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0500
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0402
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0559

============================================================
🔄 Round 178 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 178 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0420
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0719
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0559

============================================================
🔄 Round 181 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 181 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0433
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0669
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0559

============================================================
🔄 Round 184 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 184 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0482
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0475
============================================================


============================================================
🔄 Round 185 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 185 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0456
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0588
============================================================


============================================================
🔄 Round 186 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 186 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0408
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0679
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0559

============================================================
🔄 Round 188 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 188 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0371
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0823
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2455, R²: 0.0559

❌ Client client_7 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
