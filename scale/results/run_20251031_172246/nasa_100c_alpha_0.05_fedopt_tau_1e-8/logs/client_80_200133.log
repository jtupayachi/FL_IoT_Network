[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e470ef4-c627-46a7-9d42-919220aefd15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ab5ebb9-31a7-43a5-a998-e99507793d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ea95143-b1c6-4e5b-a5c5-b97801c7573b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 561112e6-0c84-433d-b3f6-ebc4a3f978b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc136951-bc71-402a-8a56-68d531c70bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c542ec9-8db1-48fc-bc58-f2205092c165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6f315c4-b071-468d-ac17-33592d4699d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ba2e07a-180b-43d9-8712-b5479608b5e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 171a9063-bd19-43fd-80d4-4f08f8c4ed11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b86de1e6-db7b-4a88-be32-18e4707a1a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37063fa6-4ab0-4c7b-b516-1ec97154b956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04917a94-f9ed-4865-beed-330458e6df48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17759193-0aeb-43dc-b92d-47769a441a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bd0d116-a687-43f4-a61b-e672d2f8511a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cd7cb19-6e6c-4ba5-8047-337283f4a5b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a79c18e7-f538-4c8f-ae7f-c42168a6f6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3a9aab1-3726-4092-a02c-da089181505f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1027cb48-0a8f-497b-9e09-1276157241d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ea7b920-39a7-45e0-a09c-dacffc58001d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ef152a-c2be-45a1-9e11-641061d2f9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b0631b7-037c-4eb2-b5a2-b04ad2099c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d521c815-ed07-4936-a0ae-ff38c232238f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de37c617-37a5-4609-96a8-dfe9dbfebfd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fa3dc7e-71a6-48fe-b76c-b76b21348941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd1819bc-6048-4255-8d19-efea97ace682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4202c9e-c9fb-4f57-b644-a8090d76d788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5741e8bf-a42e-440f-b04a-8b79fa7c14f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7db7323d-807d-455c-8aa1-c5442e2f427a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bd8e723-ca2d-4f37-bd85-8b675eee0679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3cc3d3f-cec0-445c-99d4-e4e8819008a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b369eefc-276d-4d5b-85bc-ce1d1e523642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fca92ca5-c097-4f78-baf1-37ba375d8e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2360e3e2-5e38-4204-9723-1e081d03c4b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f29062b5-1879-4475-a88e-f0dbd356fd4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdae90fc-6895-420d-9032-ac54e12de5a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9612bc8b-d170-4db3-952c-7a5e6e8f9077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 078ded71-b53d-4109-86fc-192477538c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 631652b0-2a51-4d1b-bfc2-12721e86b87d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df050873-db75-418b-88e9-83474921caa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec8e85ff-efc2-489c-9a94-0bff98d56f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20b05525-f7b5-475e-a8b4-7aa7d64f809d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c54b3ce-abda-45d8-9289-e24882c5e962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe6c708c-a121-4e38-a8b5-0b0896c8c0fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e880203-0edf-431f-a689-cd56301a27e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0dbe105-8d19-4bf6-aa79-69ad979aa9b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e153b41f-9765-4b47-b167-61d6d3225690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc811893-beb6-4a63-8a32-95b98b1b923e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98e69976-7825-423b-b2ab-c1c1e1f45452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a22dec5f-9913-4a6f-b3b6-f3da7a53fbfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96564853-6c60-4cfb-9d5a-cb29c967eaba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be108b34-e695-44fe-8f9b-96b0c00b29ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75da6634-e182-4ca7-bdb3-14c84df4b6cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bf06cba-be71-4acc-b15c-af7a165eafcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81d3bf01-bc33-447c-a053-50062ac644eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 941e50c8-5a76-4928-a14d-e99b2293b92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf1e1696-3402-4e5f-ac3b-fe2da6c0c44b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 946981c5-44e4-4d8d-a6a2-3102d0a5b646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af4af132-d011-4fd2-af68-8f21ec6a7fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae42393e-1eee-49b8-844c-9ed07948a20c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81e78c07-dc97-46cd-b0d1-a9a165b7ee44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af0e6424-c390-4200-b594-baabdbbb8fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 379026be-3ec9-405e-95af-038be3fdc887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a37997a-eac1-447c-a82e-b00968b9fc93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1ff9ad2-faf3-41d1-9515-a6ec4eb2b332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f41a138-00cd-4093-9e28-e61d09b0eada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d562bc5d-02a3-47fc-b9a3-c98020cf6635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 574ada1a-6dd2-430d-96aa-fcb7561ff926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 169975d0-4119-448e-8a70-59813b70aca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7b04cab-0682-462d-9473-6c20b416cc79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7e1d839-83ac-4f3a-9b03-5b0206f48780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78974ba2-4666-42c0-bf12-a20151fbeaff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cec6138-87d2-47b5-be80-371c941cf890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0341ad21-5b05-469a-9f4d-681fa99f572f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05689aba-0b32-4243-9f5f-c96b1711457c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed87acd7-7f58-45f3-8d32-6fbd4f792a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ae43c48-8051-4a73-977c-c4ab7c929f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68308c01-8ee4-43e7-a13a-d1539bb81e3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 469a44b8-e5aa-41c9-ae31-545526d0832d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 827560a2-8bdc-447a-89c9-a5c7c3f95f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e37878b-0323-4810-b207-ec35c6a75454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79bd8c3b-528d-463a-a89c-245ad1775825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b43d168d-6e23-4d87-ad81-d967b32c9dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e23e228e-91d9-4fdf-ba33-a68cca094e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c380e8a-b56a-4c71-afec-f14507dd0b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa07a330-b1b8-4829-bf93-8afc0762b1cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f62b1836-1e48-4617-8cd3-2d190dc96ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba69d7b7-9524-440b-ac13-b134014c5abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a19fe0d-ceaa-4305-bf6d-33c80d538182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 549881f1-ffb5-4868-b8d7-d4eb65d1bc71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0351b038-57e2-4cc0-bad6-317b53e5c51e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db45b210-4e0b-4e6a-91cc-c6c68bc5776d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 611e5de0-1809-44b8-b15d-bfb5ea9d731b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d97b7c7-99cc-4708-8084-7ab75c94bdca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 985673a2-fd93-4507-96bf-31c570e718e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 440b0efe-55ba-44b0-bb60-e824c805f328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 433d1e86-34f7-4117-9a2d-4e2d49c26e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfd2d7f4-8034-4e85-9992-edb1758389b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f24f78c7-9be2-45a6-bba5-addb6ae00581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2080bd2f-a8a7-4cf6-8eca-daf2aca9573f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d64feb4a-58b6-4d74-88c6-8f2f807e1325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d007806-a23b-4e45-9613-ef317156f3e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78660ed1-4bb2-4589-80f5-117d14dd6c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0d3da63-6b34-4bb6-8925-366f5ed86cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 293a4ab9-9882-440d-bd4d-c6b2a4575a54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fad3d24e-cd08-4e91-8178-470394ceab6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4483f931-4c25-4bc2-a780-062bb3152b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79e358f4-d351-43ff-9411-9dc9a6dc07ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7be67e8b-54fa-4eab-ac14-90753f3dd75f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f249b8a5-c2a3-49b5-beff-383ff66ea187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9418e47-8c4c-421c-a846-4fa9388283d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c46c04e-631a-4db6-83aa-3677684e4725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc34c891-a5f3-4065-97f8-ce56b5160d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b65e30c1-4d0e-49a9-b297-29e9c631090b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b41ba2dc-d738-4dec-9fa7-c1488576f6eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb9dbaec-e7c2-4aa4-8235-e59727d96f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e45fc697-f590-40e5-b1c7-8a443ce0a2ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1253b09e-9bfd-4fea-b864-fe1ef33b36f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fc1dce9-7c07-49c4-96f8-4b0fc356ed15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 140ed517-c1ed-408c-8d99-ce4bbcc2691b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 597a3b9f-05fc-461b-b02e-02cccf359b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2da7c83a-5129-4fef-9901-b868540cdc6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8af4a910-c52e-473c-9dcf-7da1e1f2abad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ba390bd-4fe6-432c-a293-b4f6382ca5eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25e759b4-eb3b-463f-b6a4-98a0d56c39b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6abfc0fe-a9e2-40aa-8c12-992600c83ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af8e68e7-cebd-4c4d-ac2c-93d91dafebe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15d93c30-a743-47ff-b114-ffa966ee988d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f677c357-3714-4cea-ac68-a9d637b38c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a5362ac-ca60-4c36-bfbf-25a85fe753ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f7d42eb-6298-464a-8827-c15145b301b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54c43c4e-ac67-4e91-beec-7a6256781125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc128e81-59f0-4df7-8493-bbdee306939b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6881e2c-fc20-47a4-9116-cf29c70c0ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3176bde9-b027-4ca8-9b2a-e0addaf71d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aae44ed-36e5-49eb-a121-15eb2d50593e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d60ffc0a-a4d6-463b-95b5-5d18ff762e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c78fca6-bb94-47d9-aaed-15c69cb29fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed3cae86-e57e-478c-8601-20fff808e298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b226e66-a511-4d50-9c59-edeace332727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f553d08f-4929-45b2-930c-d8600a53dfbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26f18fe4-79e5-4c6a-806b-44d8c6288cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84d86f9a-5688-472d-898a-23ebf76319b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e08b6706-ace8-43a3-9353-6c9a21b5f487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ac4f3e0-a408-4e8a-9b18-f4e96b995acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fda9d359-9f34-464a-8e70-00c66f020d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e7b5c6b-4de4-42d4-839c-f9546de73630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0b86dae-1771-4152-a82a-c87dae95bd43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fd82210-44be-4dc4-a9a7-14cc92984b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cda4a3a-99a5-4910-b62e-4622dc19cfb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff3a2cc1-2a17-4ea8-bad9-8f9f6bcfe98a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db43d60c-64b5-430b-a77f-d91ea29340cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66b4e04b-7bdb-4c21-84a8-f3e9500ba1b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e982245c-fa36-4ae9-af8b-13232c764c20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d898fde-bde1-4596-94d7-f03f75c4734d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a56718-cd2e-405b-a861-1a08f0441aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a027ebf2-d008-4054-894d-08bc01c528fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8690a80-0228-40c2-b6be-d92927527fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3145cdd8-3eaa-41a3-a10b-adb90849cc63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9b6ef6b-cfcd-4db0-9ab6-c99c7fa4c2c0
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_80
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_80
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_80/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_80/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_80/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_80/test_labels.txt

📊 Raw data loaded:
   Train: X=(1172, 24), y=(1172,)
   Test:  X=(294, 24), y=(294,)

⚠️  Limiting training data: 1172 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  285 samples, 5 features
✅ Client client_80 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2418, R²: 0.0033

============================================================
🔄 Round 2 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0839 (↓), lr=0.001000
   • Epoch   2/100: train=0.0833, val=0.0884, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0847, val=0.0865, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0843, val=0.0840, patience=3/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0828, val=0.0832 (↓), lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0736, val=0.0844, patience=6/15, lr=0.000500
   📉 Epoch 19: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0631, val=0.0759, patience=1/15, lr=0.000250
   📉 Epoch 27: LR reduced 0.000250 → 0.000125
   • Epoch  31/100: train=0.0613, val=0.0763, patience=11/15, lr=0.000125
   📉 Epoch 35: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 2 Summary - Client client_80
   Epochs: 35/100 (early stopped)
   LR: 0.001000 → 0.000063 (4 reductions)
   Train: Loss=0.0627, RMSE=0.2505, R²=0.2537
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0704
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2418, R²: 0.0123

============================================================
🔄 Round 3 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0702 (↓), lr=0.000063
   • Epoch   2/100: train=0.0847, val=0.0703, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0846, val=0.0703, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0845, val=0.0703, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0845, val=0.0703, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0842, val=0.0701, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 3 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0213
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0209
============================================================


============================================================
🔄 Round 4 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0777 (↓), lr=0.000063
   • Epoch   2/100: train=0.0820, val=0.0777, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0818, val=0.0777, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0817, val=0.0777, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0816, val=0.0777, patience=4/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0813, val=0.0776, patience=10/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 4 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0319
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0169
============================================================


============================================================
🔄 Round 5 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0727 (↓), lr=0.000016
   • Epoch   2/100: train=0.0824, val=0.0727, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0823, val=0.0727, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0822, val=0.0726, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0822, val=0.0726, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0820, val=0.0726, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 5 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0395
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0310
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0765, RMSE: 0.2765, MAE: 0.2400, R²: 0.0284

📊 Round 5 Test Metrics:
   Loss: 0.0750, RMSE: 0.2739, MAE: 0.2376, R²: 0.0467

============================================================
🔄 Round 8 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0724 (↓), lr=0.000004
   • Epoch   2/100: train=0.0795, val=0.0723, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0795, val=0.0723, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0795, val=0.0723, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0794, val=0.0723, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0793, val=0.0722, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 8 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0624
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0856
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0750, RMSE: 0.2738, MAE: 0.2376, R²: 0.0472

============================================================
🔄 Round 9 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 9 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0702
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0551
============================================================


============================================================
🔄 Round 11 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 11 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0779
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0801
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2357, R²: 0.0597

============================================================
🔄 Round 13 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 13 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0784
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0947
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2355, R²: 0.0617

📊 Round 13 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2355, R²: 0.0617

📊 Round 13 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2354, R²: 0.0621

============================================================
🔄 Round 21 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 21 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0781
   Val:   Loss=0.0693, RMSE=0.2633, R²=0.1104
============================================================


============================================================
🔄 Round 22 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 22 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0903
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0563
============================================================


============================================================
🔄 Round 24 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 24 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0842
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0763
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2354, R²: 0.0622

📊 Round 24 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2354, R²: 0.0622

============================================================
🔄 Round 27 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 27 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0816
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0946
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2354, R²: 0.0622

============================================================
🔄 Round 30 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 30 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2725, R²=0.0848
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0813
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2354, R²: 0.0622

============================================================
🔄 Round 33 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 33 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0768
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.1085
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2354, R²: 0.0622

============================================================
🔄 Round 35 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 35 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0855
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0765
============================================================


============================================================
🔄 Round 36 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 36 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0846
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0828
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2354, R²: 0.0622

============================================================
🔄 Round 37 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 37 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0854
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0637
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2354, R²: 0.0622

📊 Round 37 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2354, R²: 0.0622

============================================================
🔄 Round 40 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 40 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0841
   Val:   Loss=0.0678, RMSE=0.2603, R²=0.0787
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2354, R²: 0.0622

📊 Round 40 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2354, R²: 0.0623

📊 Round 40 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0623

📊 Round 40 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0623

============================================================
🔄 Round 50 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 50 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0812
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0893
============================================================


============================================================
🔄 Round 51 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 51 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0842
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0841
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0623

📊 Round 51 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0623

📊 Round 51 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0624

============================================================
🔄 Round 57 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 57 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0876
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0574
============================================================


============================================================
🔄 Round 58 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 58 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0853
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0788
============================================================


============================================================
🔄 Round 61 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 61 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0873
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0706
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0624

============================================================
🔄 Round 62 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 62 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0888
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0576
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0624

============================================================
🔄 Round 63 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 63 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0787
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.1011
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0624

============================================================
🔄 Round 67 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 67 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0915
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0531
============================================================


============================================================
🔄 Round 68 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 68 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0818
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0728
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0624

============================================================
🔄 Round 69 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 69 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0878
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0691
============================================================


============================================================
🔄 Round 70 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 70 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0946
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0363
============================================================


============================================================
🔄 Round 72 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 72 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0777
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0912
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0624

============================================================
🔄 Round 73 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 73 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2714, R²=0.0957
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0337
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0624

============================================================
🔄 Round 74 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 74 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0742
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.1192
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0624

============================================================
🔄 Round 76 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 76 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0904
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0577
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 77 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 77 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0821
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0930
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 80 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 80 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0765
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.1171
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

📊 Round 80 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 83 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 83 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0858
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0778
============================================================


============================================================
🔄 Round 85 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 85 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0851
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0677
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0624

📊 Round 85 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0624

📊 Round 85 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0624

============================================================
🔄 Round 89 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 89 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0896
   Val:   Loss=0.0728, RMSE=0.2697, R²=0.0438
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 93 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 93 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0711
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.1206
============================================================


============================================================
🔄 Round 94 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 94 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0920
   Val:   Loss=0.0803, RMSE=0.2835, R²=0.0500
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 95 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 95 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0831
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0885
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

📊 Round 95 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 97 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 97 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0781
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.1066
============================================================


============================================================
🔄 Round 99 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 99 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0907
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0497
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 102 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 102 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0883
   Val:   Loss=0.0677, RMSE=0.2602, R²=0.0616
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 103 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 103 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0917
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0509
============================================================


============================================================
🔄 Round 104 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 104 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0821
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0853
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 105 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 105 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0798
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0927
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

📊 Round 105 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 109 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 109 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0792
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0912
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 110 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 110 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0887
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0644
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

📊 Round 110 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 112 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 112 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0893
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0629
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 115 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 115 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0738
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.1226
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0626

============================================================
🔄 Round 116 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 116 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0886
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0689
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 120 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 120 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.0854
   Val:   Loss=0.0897, RMSE=0.2994, R²=0.0756
============================================================


============================================================
🔄 Round 121 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 121 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0782
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.1090
============================================================


============================================================
🔄 Round 122 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 122 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0913
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0550
============================================================


============================================================
🔄 Round 123 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 123 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0789
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.1054
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0626

============================================================
🔄 Round 124 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 124 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0920
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0339
============================================================


============================================================
🔄 Round 125 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 125 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0807
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0988
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0626

============================================================
🔄 Round 126 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 126 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0851
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0821
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0626

============================================================
🔄 Round 130 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 130 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0792
   Val:   Loss=0.0676, RMSE=0.2600, R²=0.0940
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0626

============================================================
🔄 Round 132 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 132 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0829
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0906
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 140 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 140 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0893
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0585
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 145 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0647 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0647, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0647, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0647, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0647, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0647, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0647)

============================================================
📊 Round 145 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0789
   Val:   Loss=0.0647, RMSE=0.2543, R²=0.0803
============================================================


============================================================
🔄 Round 147 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 147 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0815
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0970
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 148 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 148 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0811
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0979
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

📊 Round 148 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 150 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 150 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0813
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0973
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0626

============================================================
🔄 Round 154 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 154 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0810
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.1000
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0626

============================================================
🔄 Round 155 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 155 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0795
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0970
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0625

============================================================
🔄 Round 161 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 161 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0879
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0700
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0626

============================================================
🔄 Round 162 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 162 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0821
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0889
============================================================


============================================================
🔄 Round 163 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 163 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0816
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0957
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0626

📊 Round 163 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0627

📊 Round 163 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0627

============================================================
🔄 Round 168 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 168 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0881
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0643
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0627

📊 Round 168 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0627

📊 Round 168 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0627

📊 Round 168 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0627

============================================================
🔄 Round 174 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 174 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0873
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0729
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0627

📊 Round 174 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0627

============================================================
🔄 Round 176 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 176 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0898
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0620
============================================================


============================================================
🔄 Round 178 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 178 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0878
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0693
============================================================


============================================================
🔄 Round 179 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 179 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0719
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.1362
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0627

📊 Round 179 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0627

📊 Round 179 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0627

📊 Round 179 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0627

============================================================
🔄 Round 186 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 186 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0856
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0782
============================================================


============================================================
🔄 Round 187 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 187 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0812
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0980
============================================================


============================================================
🔄 Round 188 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 188 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0800
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.1031
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0738, RMSE: 0.2716, MAE: 0.2353, R²: 0.0627

❌ Client client_80 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
