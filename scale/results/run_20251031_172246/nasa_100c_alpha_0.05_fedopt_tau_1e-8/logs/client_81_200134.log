[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d368c67-e39d-4c2a-88f9-9bc4f8cc8b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ae33edc-98e7-4372-b190-b122393e9682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b30572c-ef89-4e5f-978c-59e91b9c10e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98f2fcf7-0537-48ce-8a5a-91fa3600933e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af195584-2b4d-498c-aab6-cbd9af914815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b21935d3-6a8e-4e90-9dcc-c69f9198bc24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86ec036f-a18c-4eae-a2e7-bd3505d83b8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8f42fa4-dab7-45fe-8d71-a9f38363f622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c77ed57-cd03-40f0-83e6-e62eae2a435d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c443a6-4a08-4e86-980b-aeec4d16fcee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3627544b-4e25-4d84-8cb9-f97aab885647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79b779e7-2296-42cb-bf7a-d1b0f257fc05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c03652aa-1676-4695-b0b6-82b94c39cba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54cbc63a-9404-43ba-a99d-47cd6585c013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40ba1e1b-54a9-4ab8-80ca-245273759edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6b0df99-9932-48e0-bc5a-ffedec840a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3d348cd-df0c-4862-970a-9b5be37d273d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af088344-5b73-4139-82a9-07dd99a29a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c31caa3-b8c1-4aee-b24d-ca5e88f34b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 482f4a37-330e-415d-85ba-0cefe7d2b257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4ee3510-4fe6-4c26-a278-2cdbb46c906e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da873178-d04a-47e6-8028-4b5ed9592680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 843e36a6-8931-47e3-9ea9-8526090d40f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db7dbce7-3ff9-43f1-93bc-eecd4e51bc97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8892852-5d8d-43f5-9bd2-6f5bc204f583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf13ed36-ca9c-45ff-be4b-1d16e7096223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 580e94dc-cac9-43a7-8fd9-6a5d17b322e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abcfe557-1a08-4380-8f60-3f0f75dab6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aecf304-894a-41e9-9384-7ece50d3c7f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4f900f1-6245-4d2c-887b-c63df7cb8696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cb68087-f2da-4640-990e-ec96a7423204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e84634c-a9d5-43d9-b31b-119f2d55e502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ed9fd85-13a2-43d7-8d6b-87be7b1234c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4747b49a-adf8-4ca5-9755-76f09421a00a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf83a716-9ff7-4401-a6fa-03abf1cc2e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b76404e8-1d06-4ae9-b9db-ff4986efa49b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a10bf31-cc99-4eb1-bb88-2c56eaecb871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5ab9601-02e7-460b-b9c5-09e726e08eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01f29b9d-c244-443c-aad3-1832934ce049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 956b1afb-dfdc-45c7-a31d-d3383db02a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9d5636a-8b7a-45d6-99ed-0d2815c9dd1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 874b2a45-c6a5-4b79-bcf6-6181e30b5228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51cebbd1-35b6-4e27-8b29-3d31c5b16652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7169929-53d9-47ea-a2c3-cad7d2615726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5dc41bf-1471-44d5-a36c-9400c4329b4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d0b562a-3302-4d3e-9440-66c56d58b70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e60e0d7a-662d-47ff-bed2-b88d09e8a7a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03846fd9-5366-4ca3-97de-d2f2d294f539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd86a6c3-2358-45a9-8e9a-be0380ff48cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b75814c3-7ed7-4cca-9453-f403f28ac718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b99424c-91d6-4c16-a0cc-13d9ba87da8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a291dd-d9cc-4792-9a73-44fdaa0d5f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f776aaea-46a7-4638-a599-3de97a984dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d62a1aff-36a7-4a63-9ac2-637708e7e012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed1ddf9b-6941-4386-b38b-c308beaabf91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5001fb9e-5566-4ce4-8359-6f1f2ed5115c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b55f918-f6ba-4c5c-ad2c-9f14385705a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12a9b787-7739-497c-a678-0868d43ffa36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 098c4019-4a4e-47c5-80f1-ac006170429e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b108239-c3f2-4cf7-9739-051a7e18afbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b572f186-b6ba-44fc-b9b0-4704765e1ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b5b19bd-b6cb-47f9-b326-2f3d8c0d0344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dd65ef9-3b60-4dc1-b9e1-0360d42678e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e829483f-2df3-4203-8ca8-4bbe4971e946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2a29744-7a53-4703-abca-e02bf9c76c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 077eb536-661f-4645-abe2-85dc39be1036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef80fa96-f04c-47ab-9df2-652261691f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52c787f5-37ba-4815-8fcc-6fc05d199623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fe8449b-57c8-488d-aa62-01c436242b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 757337e2-8000-4385-a49b-eeb413562563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79a59c1a-b2f9-4c90-873d-64416e3de9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e5be940-4e8e-47e2-9e4a-841ab28c0563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ee14f7e-117b-48dd-9ecf-0f5f45daa19c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4797fbf-0371-447d-b14b-3950af09c852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a61e30e-bbc7-474f-a612-979497d046bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32d09dc4-5316-4a74-a182-282fee10405c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 974e6b66-3fb0-4feb-bd69-1d8401edd98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8a59a67-e934-4635-9a79-03dc9816ff8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc8cf2bc-3c12-4887-80c3-b54316111630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 544145aa-80f3-47a0-a8b4-c0cb11277768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 223a52fe-ecbc-4e17-af49-a2566ea14ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 474e9cf4-ee91-4b9c-9240-6152d64844f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29a25126-9565-4f3d-8458-682675c5a939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5d04463-7135-42b7-8002-5b528a9683f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74e31db0-15b0-492c-9ce6-359fa5887169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a27f893-26a8-414f-a5da-339979e4b004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 717a1499-d7a4-456e-8198-4be397945e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aebfd260-4076-4eaa-a082-e0613676930a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0910977-7721-4a08-b185-a215c45a4613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb5b1c39-291a-4e2e-9df6-707a2f567725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8712b6df-13b6-4b31-bf98-f531413fca50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 623d922a-6829-495a-8213-0193a5095e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8952cc5-ed09-4e14-9276-fe433accb7ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0838768e-d452-4e86-8048-02ae462f0cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7139a7e9-13d3-4bb5-b2fb-da81b23bb9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 714eac16-46d0-4447-9655-31cbc85a51c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d450ed1d-b1bd-44d0-8858-4b498d86f47f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 810bea1c-431b-4605-a2d6-e7c1170ec790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f0f24fc-dd5e-4c15-8ed3-d126536ac20b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87396138-212f-41e3-88ae-b4038a574650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c1b7184-0f79-4926-a6e6-95438ad34f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf870f16-9dbc-4508-aa74-fb31ebe1a9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbd54dcd-5d1f-4d19-9f3f-54dd6d3f346e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf528061-f59c-4d27-b8ea-96dbc290b2be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b881999-9a97-439f-9a36-6ae404707fe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fbe61f4-7664-4a3f-9a83-1539e1cde519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a4824bb-93d8-4e2d-bb06-5545b7f98391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82afc333-da7e-46dc-b92f-9a645a6beba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6af7c08f-00f4-4d8f-825f-8f5c8cc84143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c528161-6954-4c64-a881-8b9967df7940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 956117bf-828f-4f94-9ec7-fc2c3c00bfc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f18b5ebf-a892-47e5-91c4-de86fc31ca95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e9beeb2-5485-4113-9669-1a0a16f6f9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67d82051-0ee1-4333-b680-4d53e1fdb010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1613c1bb-3c1a-48cb-a435-8ecdd4aeba22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8625d1d-acd9-405a-b751-866793e72b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81b597e1-5d61-48d4-bc9e-631fba6acbea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc0d4478-3fdf-4d95-b949-d1e5a827543d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2066473d-4dce-4f79-a901-1cd8c67ad3f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5abe840-ccf6-4a7c-8bbd-9c9c7b5de246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6d2152c-4287-45ec-b139-bd3fe155a742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84f8fcf7-a17d-4ffa-95d0-6811faf0f7f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b724818d-2202-4392-a50e-486902efbeba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0667ef49-c78a-4455-88a8-a925cd5b9b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11bdf03a-ceba-4d38-8010-bd8f6ab7bb38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edaeaabc-5b8a-4afe-9b4a-9444b5df5ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5776423f-9b90-404a-9c25-161d5dd49b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6284a61a-78ba-4447-9ea6-8998338d3fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4ec1705-681f-4d08-a910-c36553c69186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ef864e4-7bad-4733-8817-1735157ed822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d606322-136f-4fe0-a46f-668fe0aa9141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 140df1c8-7b3f-40f1-913c-8232c8945d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc6e02bb-4d60-42c1-87f2-a9aab289013c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 686a91ae-6151-4ce5-8f14-351b0af700e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 787ef1c5-1457-488b-b726-95fb4c1fa5ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c8cea29-acdb-4368-844f-aa6895812106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f4e4234-4ff5-4138-8c78-b840c2cbc59c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6927b6e6-9a2a-4bd7-a244-e17fb16cf503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fa94ef8-65f9-4155-9d9f-f6f0efc49e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 619dc54c-369f-403c-aa79-61f31fdef65b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99863120-1f0f-4130-acc4-e043e7f7766d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e6f915c-e4f5-4ebf-a821-2d81ffccc8e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 578a58a4-20de-47cc-b84e-acd6fc9b1052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 089f006b-9f09-421d-8b8f-85230bfdffc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 226605ab-1d7e-44d1-abfa-3ee45e4cf5f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8494df41-09b8-4e26-a0d4-66c325457343
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_81
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/test_labels.txt

📊 Raw data loaded:
   Train: X=(1208, 24), y=(1208,)
   Test:  X=(303, 24), y=(303,)

⚠️  Limiting training data: 1208 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  294 samples, 5 features
✅ Client client_81 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2557, R²: -0.0229

============================================================
🔄 Round 2 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0894 (↓), lr=0.001000
   • Epoch   2/100: train=0.0804, val=0.0915, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0810, val=0.0914, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0810, val=0.0902, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0804, val=0.0895, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0781, val=0.0898, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 2 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0115
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0157
============================================================


============================================================
🔄 Round 3 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0805 (↓), lr=0.000250
   • Epoch   2/100: train=0.0822, val=0.0801, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0818, val=0.0797 (↓), lr=0.000250
   • Epoch   4/100: train=0.0816, val=0.0795, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0814, val=0.0794, patience=2/15, lr=0.000250
   • Epoch  11/100: train=0.0807, val=0.0793, patience=8/15, lr=0.000250
   📉 Epoch 14: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 3 Summary - Client client_81
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0084
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0036
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2535, R²: -0.0058

📊 Round 3 Test Metrics:
   Loss: 0.0834, RMSE: 0.2887, MAE: 0.2529, R²: -0.0033

============================================================
🔄 Round 5 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0788 (↓), lr=0.000125
   • Epoch   2/100: train=0.0828, val=0.0785, patience=1/15, lr=0.000125
   ✓ Epoch   3/100: train=0.0825, val=0.0783 (↓), lr=0.000125
   • Epoch   4/100: train=0.0824, val=0.0781, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0822, val=0.0780, patience=2/15, lr=0.000125
   • Epoch  11/100: train=0.0815, val=0.0776, patience=2/15, lr=0.000125
   • Epoch  21/100: train=0.0807, val=0.0773, patience=12/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 5 Summary - Client client_81
   Epochs: 24/100 (early stopped)
   LR: 0.000125 → 0.000125 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0158
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0045
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2525, R²: -0.0015

============================================================
🔄 Round 7 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0762 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0832, val=0.0756 (↓), lr=0.000125
   • Epoch   3/100: train=0.0830, val=0.0754, patience=1/15, lr=0.000125
   • Epoch   4/100: train=0.0828, val=0.0752, patience=2/15, lr=0.000125
   ✓ Epoch   5/100: train=0.0827, val=0.0750 (↓), lr=0.000125
   • Epoch  11/100: train=0.0820, val=0.0744, patience=1/15, lr=0.000125
   • Epoch  21/100: train=0.0810, val=0.0738, patience=2/15, lr=0.000125
   📉 Epoch 28: LR reduced 0.000125 → 0.000063
   • Epoch  31/100: train=0.0799, val=0.0737, patience=12/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 7 Summary - Client client_81
   Epochs: 34/100 (early stopped)
   LR: 0.000125 → 0.000063 (1 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0296
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0157
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2518, R²: 0.0020

📊 Round 7 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0014

📊 Round 7 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2518, R²: 0.0008

============================================================
🔄 Round 15 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0846 (↓), lr=0.000063
   • Epoch   2/100: train=0.0808, val=0.0845, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0806, val=0.0845, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0803, val=0.0844, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0802, val=0.0844, patience=4/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0796, val=0.0845, patience=10/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 15 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0010
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0004
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2516, R²: 0.0010

============================================================
🔄 Round 16 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0854 (↓), lr=0.000016
   • Epoch   2/100: train=0.0809, val=0.0854, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0808, val=0.0854, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0807, val=0.0854, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0806, val=0.0853, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0804, val=0.0852, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 16 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0078
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0304
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0008

============================================================
🔄 Round 19 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0781 (↓), lr=0.000004
   • Epoch   2/100: train=0.0826, val=0.0781, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0826, val=0.0781, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0825, val=0.0781, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0825, val=0.0781, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0824, val=0.0782, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 19 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0054
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0071
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

📊 Round 19 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

📊 Round 19 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

📊 Round 19 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

============================================================
🔄 Round 26 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 26 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0013
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0029
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

📊 Round 26 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

============================================================
🔄 Round 29 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 29 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0021
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0007
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

📊 Round 29 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

📊 Round 29 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

============================================================
🔄 Round 32 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 32 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0000
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0108
============================================================


============================================================
🔄 Round 33 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 33 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0030
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0029
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

============================================================
🔄 Round 34 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 34 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0010
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0025
============================================================


============================================================
🔄 Round 37 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 37 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0009
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0104
============================================================


============================================================
🔄 Round 39 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 39 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0017
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0008
============================================================


============================================================
🔄 Round 40 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 40 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0047
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0104
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

📊 Round 40 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

============================================================
🔄 Round 44 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 44 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0013
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0181
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

============================================================
🔄 Round 45 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 45 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0001
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0098
============================================================


============================================================
🔄 Round 46 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 46 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0050
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0122
============================================================


============================================================
🔄 Round 48 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 48 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0024
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0174
============================================================


============================================================
🔄 Round 49 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 49 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0027
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0200
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

============================================================
🔄 Round 50 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 50 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0035
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0294
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

📊 Round 50 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

============================================================
🔄 Round 55 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 55 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0048
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0095
============================================================


============================================================
🔄 Round 56 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 56 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0039
   Val:   Loss=0.0968, RMSE=0.3112, R²=-0.0230
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

📊 Round 56 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

📊 Round 56 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0006

============================================================
🔄 Round 60 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 60 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0043
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0010
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

============================================================
🔄 Round 66 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 66 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0124
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0373
============================================================


============================================================
🔄 Round 67 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 67 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0004
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0115
============================================================


============================================================
🔄 Round 70 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 70 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0072
   Val:   Loss=0.0688, RMSE=0.2624, R²=0.0130
============================================================


============================================================
🔄 Round 72 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 72 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0021
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0189
============================================================


============================================================
🔄 Round 73 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 73 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0036
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0073
============================================================


============================================================
🔄 Round 74 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 74 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0057
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0335
============================================================


============================================================
🔄 Round 75 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 75 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0052
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0155
============================================================


============================================================
🔄 Round 77 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 77 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0007
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0088
============================================================


============================================================
🔄 Round 80 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 80 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0018
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0014
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

📊 Round 80 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

============================================================
🔄 Round 82 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 82 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0014
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0048
============================================================


============================================================
🔄 Round 83 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 83 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0026
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0188
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

📊 Round 83 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

📊 Round 83 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0007

============================================================
🔄 Round 90 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 90 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0004
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0090
============================================================


============================================================
🔄 Round 93 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 93 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0004
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0089
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0008

============================================================
🔄 Round 101 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 101 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0017
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0023
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0008

📊 Round 101 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0008

============================================================
🔄 Round 108 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 108 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0034
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0068
============================================================


============================================================
🔄 Round 109 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 109 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0038
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0210
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0008

============================================================
🔄 Round 110 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 110 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0015
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0130
============================================================


============================================================
🔄 Round 111 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 111 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0010
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0153
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0008

📊 Round 111 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0008

📊 Round 111 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0008

============================================================
🔄 Round 118 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 118 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0020
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0125
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0008

============================================================
🔄 Round 119 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 119 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0016
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0070
============================================================


============================================================
🔄 Round 120 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 120 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0081
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0044
============================================================


============================================================
🔄 Round 121 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 121 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0049
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0125
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 122 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 122 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0034
   Val:   Loss=0.0919, RMSE=0.3031, R²=0.0061
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 124 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0995 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0995, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0995, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0994, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0994, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0994, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0995)

============================================================
📊 Round 124 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=-0.0043
   Val:   Loss=0.0995, RMSE=0.3154, R²=0.0000
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

📊 Round 124 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 126 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 126 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0053
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0090
============================================================


============================================================
🔄 Round 129 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 129 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0060
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0076
============================================================


============================================================
🔄 Round 130 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 130 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0007
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0028
============================================================


============================================================
🔄 Round 131 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 131 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0038
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0025
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 132 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 132 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0007
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0088
============================================================


============================================================
🔄 Round 133 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 133 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0006
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0081
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 136 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 136 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0019
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0280
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

📊 Round 136 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 144 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 144 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0003
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0087
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 145 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 145 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0102
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0143
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 146 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 146 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0025
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0149
============================================================


============================================================
🔄 Round 148 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 148 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0081
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0481
============================================================


============================================================
🔄 Round 149 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 149 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0006
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0086
============================================================


============================================================
🔄 Round 151 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 151 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0031
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0507
============================================================


============================================================
🔄 Round 153 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 153 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0083
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0135
============================================================


============================================================
🔄 Round 155 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 155 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0036
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0083
============================================================


============================================================
🔄 Round 158 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 158 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0087
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0280
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

📊 Round 158 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 160 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 160 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0018
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0067
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

📊 Round 160 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 163 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 163 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0034
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0308
============================================================


============================================================
🔄 Round 164 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 164 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0057
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0190
============================================================


============================================================
🔄 Round 165 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 165 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0057
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0167
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 168 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 168 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0009
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0241
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 170 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 170 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0061
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0165
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 172 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 172 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0027
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0180
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 173 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 173 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0037
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0094
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 174 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 174 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0015
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0004
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 178 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 178 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0043
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0097
============================================================


============================================================
🔄 Round 179 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 179 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0050
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0241
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

============================================================
🔄 Round 180 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 180 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0011
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0116
============================================================


============================================================
🔄 Round 181 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 181 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0054
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0151
============================================================


============================================================
🔄 Round 182 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 182 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0019
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0131
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2516, R²: 0.0010

📊 Round 182 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2516, R²: 0.0010

============================================================
🔄 Round 188 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 188 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0105
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0164
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0010

============================================================
🔄 Round 190 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 190 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0032
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0141
============================================================


❌ Client client_81 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
