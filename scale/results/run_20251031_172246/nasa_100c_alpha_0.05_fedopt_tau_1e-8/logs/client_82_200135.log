[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5173bb87-95cb-4ee3-9d1f-944e95310728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 240ea2dc-993d-4970-b36f-48a81c01de4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa6d0b62-3ec7-4c34-8182-43094768f100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60aabd41-e365-42c3-ac9c-9db469dd112e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f6be9cb-ba4a-4773-8bce-8f77d2a86413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87de61c0-1ce7-4c9f-b633-fecd6c6a760e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2955e945-f46c-4a86-ba65-6c1e9c425d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bf427d4-ff12-4d50-9fb0-bfefd93c85ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6f96f8a-61bf-45d2-a14a-6af727ca7413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8982da6-95f9-4dc3-89a0-62f87016fbd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d93fbea-c65a-4c3a-a8dc-2caa9325d57c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7db9de9d-b53c-4195-ae5b-4b25ac47a896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a51c6c95-e415-4268-817c-b6154c15194f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1463c603-6e5e-4593-934f-8c2a815d091e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ff25e34-3e1a-468c-973a-8d4894427d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 741606a6-efff-4402-bfb5-1602df85e762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d97ed02e-022f-4737-81fa-1d541d57ce0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50b12043-bd31-4c69-b814-b59b68bed976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1268304-b117-42bc-b478-3b476ccc6077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32254cdd-4dd7-4303-b729-575ee440beb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 068dbc10-ff4e-462a-9d4c-2758fe734dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb01fac3-85dd-4f46-90db-a584f08ee8c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1220a623-408a-4c7e-ac9e-0d361b39a65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bf9a933-d183-46aa-ae54-e429a459e7f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d90e0361-e62e-40ce-adf1-a61c4e56711e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd2b0e5b-5463-457f-9da0-a6afa1150eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc971f46-5188-432b-930f-2095294c843c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beae82b8-a20b-4832-846d-e4301a67df24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1014eda-209a-48c3-9bac-0484f5a2d00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 947ece5f-8167-40bb-9380-e124c4265e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 150fd3f2-05d3-4ec1-99f4-d05b7a99a61a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e9f9fba-27b6-4a99-8a3a-26a22ac39949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d70dcf62-81d1-4604-a030-d940ec4d5f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3007ed0-7b1f-4946-9e94-b034efedda7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58d8f397-e679-4cf0-aeff-f80d17ef3108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d89396a5-330d-4b40-8477-a0d8bd2532f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6699f116-a5cc-4142-95fe-95206b2a05db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 703e7fba-bd9c-4910-a79a-cd4e6b523ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7da755c-87da-4272-ab7b-5a55823b94d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 520efcdb-1a2a-4ce4-9563-5ba38b2361fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff0453f4-b1c2-4bff-b23e-fd87ec4d0ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c7f3d1f-6354-4ce1-b002-80f87fbfcbfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fea8f0f-c9bd-4551-8260-67bddd78ad27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5627cb85-2a50-4ec5-a6a6-6e5739e32874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3676a10a-88bb-4be5-9669-2b2db26f0867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 692390b6-5f65-47a0-b9fe-34527f30f113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f83f011-9fd5-4f79-a797-95cdc447c986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0176a35-99cf-4a10-9c75-1f259ed25f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bda8250-a2b8-4b7e-89fc-c11a66133ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 575818dd-e0bd-4fd6-a7ed-c1afaa15ce69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07b1ba26-1022-493b-b18f-198e8eee6c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 976ed36f-93c4-4ec5-995f-7c8fc1d2737a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b73f9f64-4c53-4dca-a8de-8085c4abce42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9b9d78f-dcc1-4ea9-ab82-b529f2b71151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d90b55f-2ec7-4ad7-a022-0f6d6f10280c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4e6f3c7-096b-412f-a458-addf2084d1ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4831ff0a-ccbf-403d-a44d-33e2fa7f5839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbbe4bc8-99ee-47be-bab8-c2a4d5d3f57c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 713ad987-c1e3-4445-ad39-4c4b85b4c224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c4d1c8b-febd-4431-90ac-9a7b371ab523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 733218d7-9201-4534-8cb2-838f13832152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd34a2c3-2531-443f-a73d-5bdf380bdd00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dd18e4a-794d-437f-aff4-66038eb63399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e0af493-7ba6-4e4e-a01e-6d86d7c96f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 771bfc20-9e3b-487d-b638-1338fa45150d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b16191ab-835d-4246-8014-1aab584e1fea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c401144b-1285-4401-b43c-bdd64c290464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30093d97-8b05-41bd-a510-f264e7b1a325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6f76ba0-7bdf-4f12-8370-d376701a75b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64e1adf1-4b88-4a91-a58e-df6cf6e08d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df7dd0f8-4e0a-4fd2-95e5-a8e6bdbecbb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 418b827c-d1a3-4395-8d31-393a5daea2fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ebf1299-1f06-4805-bd53-da6e3567d725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5652250c-e306-4585-90e9-5ce43e5acb83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17c1e2ae-b337-402a-9ecf-7714e3a7d4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cac9eed2-79a5-4c5a-bf8c-0a0e83707b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f075b472-a30f-40ea-bc28-56212ea839ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37c6319b-4423-4dde-b725-56f2c906f332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1008f7f-2a6b-478c-bacc-b32ee59ac975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d38530a-378d-4070-941a-ab8a5764213d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 621afe39-cc1a-4c7f-a853-13d9332d57e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc716124-fd12-4c45-9b71-a97f024ef009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7640fffe-6a00-4152-9973-90500b555b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e16cb1-7806-4cb6-8f08-6c8f09bfe132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67cfdaef-09a8-4ab9-8aa1-10f7d1b9f482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2aeb27e-9e87-4f2b-b465-04ebed07f582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b49f3017-67b5-454a-a7f4-8721972f28ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72ca116c-fb63-44cd-9ac7-c2e5034a16ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3650ae4b-0aa0-4841-a423-d08108d4aa22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 331d67e1-e780-4cdd-b859-3e0377aaba63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4a48e36-d8b4-4d47-ba8d-bd69d1d37ddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac9c8f0-736e-4a12-8c83-3f74a2e17b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b2cc876-6bce-48c7-8160-45567243f84b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 788e335b-63b7-4518-8a20-c395efa7b087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7edc1452-1fc5-44ca-b83c-87960d57e9b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88c26df-a69e-4c40-8088-b3ae8ff0a0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7bf1daa-875d-459c-a24e-a7d22869c39d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5bb67ad-7cc4-466c-8bce-4b3814cab3dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d09bc3e8-36bb-4c6b-88c7-61c6dc2d1513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41a71bc6-2f67-4968-9c41-8b9a53613a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea859e71-e176-4b6e-885f-44c9c6e8fa4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9dc7a38-ef9a-455e-bff9-dca6ba06750c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 967e90e9-f148-48f0-98e7-2341ac80a913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e96f125-a87b-4922-9423-1f193cf651cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 140b3fd8-9cfc-4e8a-8dea-7d24fc9e294d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 820c053b-3d7b-4cae-8c7f-45c29d976d5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd297c95-ff29-4244-9fd2-c7fa3344b004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2975410f-d474-4753-bbbc-d8e5974e74f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23677d6c-18f5-486f-9616-09dcc9d8118a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc21d6cf-8827-479b-b3b2-fc14347f7b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7f60c30-30e2-4db0-8981-ad7fd69f2c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61c09a45-745b-4af5-a08a-adb2d8b5dc1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52c0b645-f326-4ed6-a969-62c8e9a1f080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 264bba05-6455-45e0-accd-0d7f69cd7e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ee831ea-0458-492b-a5d0-f53503b70e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07e11201-cd59-4381-8a85-309b04d5d003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f56ae4e3-27a1-4625-ad9d-07f655bbfc73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55c87bb4-6c0c-45ea-9db0-0a5b88c56f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d8459b6-2b97-40ea-addc-7398e06119ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4c2bbb2-fb04-4586-8c71-5dc147ff13dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aa698d4-db4f-4d1f-af33-e6e289f0a15f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 625d8c36-7032-4be0-90e4-0cbc6cdf2d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e77466e3-8ceb-4495-801f-6d4816f27687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44b245b9-94dc-4517-aedb-42acfcda572f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7fd7053-08ab-483c-88d9-f539594af599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 349b247f-69ba-4bc3-bfe6-b6d174b0409c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afaa8554-5e4f-4c22-8d72-b9b603ddf455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eeb66c7-011f-4f76-903b-30f2d89e9227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37ffeeca-7a83-4100-aa5c-f38e6b75ae8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 054e58ff-1e68-4c7b-8377-c7d3042092e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee92eae2-ff4b-4465-ae39-1a9fddf16990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3759d82a-ef8a-41a9-9065-d4bdda7b982f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7db23ec7-2ba3-4133-8f07-16aff4d8ce7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d41f1631-2788-4a18-baa1-d2e31dc501bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9b0d668-4f2d-46ea-8a77-7f68328841df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90e671e2-ac2d-4077-b6f3-30052c271074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ddd4a64-fb1c-4cca-a119-f7febcc14879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 370ee9fd-c97e-4d9a-a3b4-ee7032aa0d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19b8b0e9-0ebe-4ff7-b3a7-fb101b3e7421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 894e216d-07a8-4b6c-adce-242275ace57d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dfdb6c3-0f8c-4f86-845d-97d300c7ccf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58368aa0-35c5-42a9-b371-04b6c4a26bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d44803b-5193-4e95-bcf4-95f4f4e0adb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de8a5d68-3d10-4777-aede-f136f4a7b6ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3dd3d1c-ada1-47c0-8506-13c34834a8df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f90621b2-f7d5-4b0e-a3ec-dacf0721a8a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c2f97e-b636-41a1-b31b-fb48736d7f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a265d60-9dd6-4016-8b73-9c74a8e268d8
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_82
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/test_labels.txt

📊 Raw data loaded:
   Train: X=(1604, 24), y=(1604,)
   Test:  X=(401, 24), y=(401,)

⚠️  Limiting training data: 1604 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  392 samples, 5 features
✅ Client client_82 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 4 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0785 (↓), lr=0.001000
   • Epoch   2/100: train=0.0858, val=0.0783, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0856, val=0.0781, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0853, val=0.0779 (↓), lr=0.001000
   • Epoch   5/100: train=0.0852, val=0.0778, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0841, val=0.0771, patience=2/15, lr=0.001000
   📉 Epoch 18: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0766, val=0.0811, patience=12/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 4 Summary - Client client_82
   Epochs: 24/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0240
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0065
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2547, R²: 0.0015

📊 Round 4 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2548, R²: 0.0004

============================================================
🔄 Round 6 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0825 (↓), lr=0.000500
   📉 Epoch 2: LR reduced 0.000500 → 0.000250
   • Epoch   2/100: train=0.0843, val=0.0824, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0839, val=0.0825, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0839, val=0.0825, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0838, val=0.0824, patience=4/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0834, val=0.0822, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 6 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0061
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0107
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2542, R²: 0.0052

============================================================
🔄 Round 7 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0733 (↓), lr=0.000125
   • Epoch   2/100: train=0.0859, val=0.0734, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0858, val=0.0734, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0857, val=0.0734, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0856, val=0.0734, patience=4/15, lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0853, val=0.0735, patience=10/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 7 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0104
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0131
============================================================


============================================================
🔄 Round 9 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0782 (↓), lr=0.000031
   • Epoch   2/100: train=0.0845, val=0.0782, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0844, val=0.0782, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0844, val=0.0781, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0844, val=0.0781, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0842, val=0.0781, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 9 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0130
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0068
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2535, R²: 0.0099

============================================================
🔄 Round 10 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0804 (↓), lr=0.000008
   • Epoch   2/100: train=0.0837, val=0.0804, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0836, val=0.0804, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0836, val=0.0804, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0836, val=0.0804, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0836, val=0.0804, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 10 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0117
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0198
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2531, R²: 0.0125

============================================================
🔄 Round 12 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0846 (↓), lr=0.000002
   • Epoch   2/100: train=0.0824, val=0.0846, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0824, val=0.0847, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0824, val=0.0847, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0824, val=0.0847, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0824, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 12 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0130
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0302
============================================================


============================================================
🔄 Round 14 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 14 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0128
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0138
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2530, R²: 0.0131

============================================================
🔄 Round 15 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 15 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0115
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0220
============================================================


============================================================
🔄 Round 16 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 16 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0129
   Val:   Loss=0.0731, RMSE=0.2705, R²=0.0217
============================================================


============================================================
🔄 Round 17 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 17 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0198
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0099
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2530, R²: 0.0130

============================================================
🔄 Round 18 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 18 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0173
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0038
============================================================


============================================================
🔄 Round 19 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 19 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0122
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0215
============================================================


============================================================
🔄 Round 20 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 20 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0109
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0256
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2529, R²: 0.0136

📊 Round 20 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2529, R²: 0.0136

📊 Round 20 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0136

============================================================
🔄 Round 29 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 29 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0170
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0019
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0136

============================================================
🔄 Round 32 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 32 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0153
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0111
============================================================


============================================================
🔄 Round 35 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 35 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0163
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0057
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0136

============================================================
🔄 Round 36 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 36 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0158
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0064
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0136

📊 Round 36 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0137

📊 Round 36 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0137

============================================================
🔄 Round 42 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 42 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0156
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0087
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0137

============================================================
🔄 Round 47 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 47 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0183
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0071
============================================================


============================================================
🔄 Round 49 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 49 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0070
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0277
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 52 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 52 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0109
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0262
============================================================


============================================================
🔄 Round 53 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 53 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0167
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0053
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 56 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 56 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0181
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0088
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 57 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 57 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0147
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0028
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

📊 Round 57 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 62 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 62 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0176
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0028
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

📊 Round 62 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 67 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 67 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0114
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0264
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 68 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 68 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0155
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0092
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

📊 Round 68 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

📊 Round 68 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

📊 Round 68 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 74 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 74 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0184
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0089
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

📊 Round 74 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0139

📊 Round 74 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0139

============================================================
🔄 Round 80 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 80 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0174
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0009
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0139

============================================================
🔄 Round 81 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 81 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0193
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0132
============================================================


============================================================
🔄 Round 83 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 83 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0125
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0241
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0139

📊 Round 83 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0139

============================================================
🔄 Round 85 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 85 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0070
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0411
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 86 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 86 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0170
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0275
============================================================


============================================================
🔄 Round 89 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 89 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0173
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0004
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 91 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 91 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0109
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0302
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

📊 Round 91 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 94 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 94 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0152
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0243
============================================================


============================================================
🔄 Round 95 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 95 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0143
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0113
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 99 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 99 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0168
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0038
============================================================


============================================================
🔄 Round 101 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 101 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0116
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0476
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 103 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 103 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0087
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0400
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 105 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 105 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0075
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0375
============================================================


============================================================
🔄 Round 107 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 107 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0096
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0210
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 109 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 109 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0150
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0061
============================================================


============================================================
🔄 Round 110 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0971, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 110 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0193
   Val:   Loss=0.0970, RMSE=0.3115, R²=-0.0270
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0138

============================================================
🔄 Round 111 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 111 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0121
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0237
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0138

============================================================
🔄 Round 117 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 117 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0150
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0110
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

📊 Round 117 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

📊 Round 117 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

📊 Round 117 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 122 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 122 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0123
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0166
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 124 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 124 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0156
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0035
============================================================


============================================================
🔄 Round 125 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 125 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0125
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0169
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

📊 Round 125 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 128 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 128 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0192
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0173
============================================================


============================================================
🔄 Round 129 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 129 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0082
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0373
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0138

📊 Round 129 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

📊 Round 129 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0138

============================================================
🔄 Round 134 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 134 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0203
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0092
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 135 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 135 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0117
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0198
============================================================


============================================================
🔄 Round 136 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 136 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0131
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0193
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0137

============================================================
🔄 Round 138 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 138 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0090
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0186
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0137

📊 Round 138 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 142 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 142 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0137
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0146
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 147 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 147 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0161
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0153
============================================================


============================================================
🔄 Round 148 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 148 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0103
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0077
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0137

📊 Round 148 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0137

============================================================
🔄 Round 151 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 151 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0147
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0122
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0137

============================================================
🔄 Round 155 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 155 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0179
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0000
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0137

============================================================
🔄 Round 158 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 158 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0118
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0130
============================================================


============================================================
🔄 Round 159 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 159 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0131
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0140
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 161 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 161 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0062
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0345
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 163 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 163 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0132
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0198
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

📊 Round 163 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 165 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 165 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0129
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0187
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0139

📊 Round 165 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0139

📊 Round 165 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0139

============================================================
🔄 Round 171 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 171 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0142
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0230
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0139

📊 Round 171 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0139

📊 Round 171 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0139

📊 Round 171 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2528, R²: 0.0139

📊 Round 171 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 182 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 182 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0157
   Val:   Loss=0.0959, RMSE=0.3096, R²=0.0106
============================================================


============================================================
🔄 Round 183 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 183 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0139
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0128
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

============================================================
🔄 Round 186 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 186 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0125
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0228
============================================================


============================================================
🔄 Round 187 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 187 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0127
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0120
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

📊 Round 187 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2529, R²: 0.0138

❌ Client client_82 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
