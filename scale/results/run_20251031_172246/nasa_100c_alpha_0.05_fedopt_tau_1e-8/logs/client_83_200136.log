[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e7b3595-ac1d-4dff-acc5-26e019abdf5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0460ae33-9b19-425a-9240-bcb554a480ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab57a5c1-ea85-44e4-939c-293441510bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ee55a5-b307-420b-bae1-1b975ebf862d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f8b2623-679a-4bd8-8867-6f83cfe4562b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd76fad8-d513-43d7-b64b-5049e0932706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c245f6a-5c90-465c-8d46-982f4b334366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7686b83-1067-4d4e-ba2f-d3d8a9d3d57e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07335ada-cc60-4fcc-9924-3c161d660758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a278c348-3da8-4f96-ad74-ac589f0c7b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95027f84-c706-4538-bdf4-f5c335c84460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d34b0b51-355d-4ac0-92a6-3ef7c7710024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96f2eea8-174c-4789-a542-c6095a4bd58c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ee7ace7-0c0d-4a15-bb05-3ddc3e184999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c60a5709-618a-4017-bf01-53f2a7d67e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e35f99d-6bb0-45d7-8903-98d0a92ce5bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 197cb5c8-6ff3-48b4-bd96-64974e2d1336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc4face5-1c80-48be-9e98-46b1f437678a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32e6414f-c229-4ac4-b6f1-2ccd54de63ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c22ddd99-ea06-47fd-bd54-d6431f300f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d51b23f8-8c7e-4ccd-a168-016cb10432f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c25f928e-545c-402e-9888-7b18c51df451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb075c44-1aff-41e8-bca0-d78e7852885b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aac1a3d9-16e2-4765-ae1e-bac9ff3aa727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 460b9994-6ef7-47e4-b73e-144efcb0e924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dfd31ba-3771-4372-86aa-dd57f80e0a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abea7a13-1f1c-4ba3-bb05-bf6036a18bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74460b94-309c-4006-9095-73afd0dc39ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e837439-f6b4-4e54-8f73-853e5965c644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 299594da-9cd9-4586-b4cc-ba4af25cc071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d321d716-b17c-4216-8c15-5d47575e4d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6859896-2d1f-4639-bc52-a47559272e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a4611ec-34ba-45e8-8349-8ef9346ebe9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ad6af7f-8622-4158-a97c-bab2c8e7a4d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 117c5a79-7d6b-4e80-9f1d-bfbfc11a6678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 314d3118-0c54-4616-bf9d-2ff8e202482f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcbdd88b-61d6-41c3-850d-016b491aad00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d4f4c91-24c8-4a25-9ea1-20c61bcc2312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb057fac-df01-485a-a8bb-927dc3fdeba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0157563-f1d1-40b8-8585-fb576c8746da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3833046-1281-4185-94e1-55509f762f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7acddafb-5411-4642-8fbe-243e783834b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 912900f5-9465-4a7d-88bc-0b10deaf3784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e831c2e-30df-4a1c-bb6e-5cd17da20139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0658c8f3-be8e-4c46-b54c-d48a07dda4d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb40f069-91b9-49a5-b728-ffe23b1f077b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99c8ba26-2c89-4811-a855-bc7476205890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28030685-136b-4dd2-838b-63bef557b622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e1ccff5-d585-43c3-a294-7164b90fbff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e35ac45-d192-4832-87d4-7a86dfcd1de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eb9e568-8f48-4b3b-8c50-e4bbc8e0d8a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a238075-dd85-44de-8677-e8622f8b553f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f906348-74a4-40ce-b2b0-4cd7b3864e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e328184-ff2a-4969-b203-9a2ec38ea548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b7e2d62-416a-43e8-b70c-3220732fb91f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87e711b8-391a-4a85-ac63-58a02e6dab91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 331132d4-225a-4a30-868c-57e4a726e7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c15b4d92-adcd-40ec-a9b7-6c05f022d6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e69504a-9ee7-43f2-8841-d08261800da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cfacdb5-c2a6-4967-b9cf-cc617fde344e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1babf27-b1ca-4690-8c27-e72fd658039c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47d07251-f2c8-4600-a32f-48361b965d21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 158475bd-f2b3-45c9-9138-3a63d96e5317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c13b24a2-2b2f-4856-a2bf-d8b69117a6a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab71a4c3-b847-42a8-8eb7-667b3543ea83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3e6fdf2-66de-40b7-ac55-231afc31464b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f2c9ae2-6317-4908-acd3-3d5c938f8a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1cb8fa1-8fde-465e-a1f1-8f9bdb912b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c4305f5-5ee7-45eb-bd0c-3dff6e1b5856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b115452-e5d8-478e-ac22-1a768aada040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9658d5e-e06f-4275-b8d4-753d7a8b4d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5ea7acc-986d-454f-ac8c-83b40208de99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9e6cf8f-1097-4c77-8d61-39ed1b0e6742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e610ac51-629e-4670-89c9-da6db776c4b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09ead726-e411-4718-8b3f-8e62467468dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d48dba8-7ec9-4305-b388-a617f4618711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd927c52-fa23-49db-82a1-fd7d6d0a932c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 220d49f7-730e-4410-a7f5-11b111dd7a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 389b333e-c00b-4149-9783-7836d62d4a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e284e35-cc71-4d77-9263-ea12f50dd052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31aac161-f199-4c6d-88a9-2c636437670d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aa9fbbc-644d-4ac1-9a1a-794f4ee297a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 692a28ea-7396-46f9-a291-c945ec0e90e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e60b9c2-aa07-4c32-b468-23e15cd69de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 622029f8-284a-48c4-b109-889717fc776e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6c2d1cc-88ab-4fd7-ada8-4f1f31b0ef41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3719d3c8-548d-44d6-9a67-885c834318f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c6c1da9-bc09-4da3-a34d-0c907c4571c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 006492e2-233f-48bf-97c3-ff7a09062208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1224a76-4a48-4a2a-825f-a73ba00c5269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 733226df-703b-408e-a275-a94b0a98f0a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f24bbec-91c3-4fd8-a866-01c7bda912f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 506d9470-c3f6-43dd-a657-2bbd0e963dac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9b81856-5fc3-4c28-b489-5428f6934182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b79834a-9fae-459f-95a8-674ae7396c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15de56e6-0e73-4d96-8638-c8607f606dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf5e7d9b-2a9b-45ee-9fe9-a91f3bfbd5be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56a2f4c6-5574-426c-a4a4-03b241c81bea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8d06c2f-3093-491e-bb11-98fec820a52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e04c9c-8222-4761-93d0-1290786243bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74bf1474-8a56-43ed-ba77-a0066fc9a353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d40cb9a5-3e12-46aa-85a7-55f09da90104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d6c9709-db1a-4c50-b8bd-e00cb913b9b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30b69970-b540-4da8-b59b-d74f04f1b564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7aca841-ad6b-4c41-8963-48aee5b80f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef1f8d82-c631-43d7-b0d2-090bb29c7d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63ba73ca-1571-4898-824b-7a6cf2c34d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65972ff0-031f-4378-ba75-c5fcdc3ccd44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c9498bd-ec4a-42a1-940d-046ecaafa8dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c77e672f-90ac-4a30-bfd1-742e26d4f118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34d41f51-135b-4619-b21c-d55a606adfb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 964be19a-fe23-48d2-9764-354b3f810dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0065f64-5f5f-4a1f-92d6-ff0210099228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71c2626-6fad-43f6-b5c4-822ebee148e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f756d882-b28e-443d-b471-37299ae0c685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0315e2ae-5411-4475-918d-c3c286b6076e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44ec9724-c487-42b4-8da9-b149e237a1c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6683ef13-2074-4543-9916-4dd4c60c64f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac728b44-ee3f-4ab0-ba51-9c7ef22a3aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07395656-e536-4f90-9171-73989fe0e062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6fffa98-ef6b-4805-8bcc-8917b5c7b3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 648f8439-b578-4722-9df9-9389ff238348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12e2d728-bb62-4b16-976d-288acbe71a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c8f8dbc-dad8-443a-ab73-9e363a207f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9650729f-2af6-4750-9083-f0b285f2e089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 509ec0f2-e3d5-4939-9430-fc06fd0583f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d9f7c2d-2f1b-41e4-87dc-a17ef360d276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96b105f6-f1c3-4b51-bb35-ae5966fd43e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d38bf22-b62e-4e8f-a09e-ff4a98d7ebda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0e5d641-453b-47b4-bba9-f0bc2961df6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75a60139-4efd-4cce-ad1d-cb3fdc19fdcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b82c67da-b918-4b29-91b8-9e276bdc71e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3c13987-b513-4d26-b97a-dd26ab55a98e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5114b4b8-487a-4226-a46c-b61e14f951d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7860ad4f-5362-4b7b-a73b-83e39dc5489a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67052453-b35f-4c35-b99b-2bb748948429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 252b30e6-ef3d-4429-bd6e-acb33d4f653d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38211077-efc2-4000-accb-5bf6fd849221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93e7494a-6808-487e-b7a1-334f8e93099d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c64a7f07-f590-4078-8be7-5cc73ef9c368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e1bbca5-7e62-4306-bd87-0aa40805888b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3adc2e2e-0dc1-47cd-aa09-4f9fffd45db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ddf6a0-d5e7-42c8-b050-64e5c3ec3fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33490fd6-6f20-4c1f-97a3-e1ccffcdb91e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53e9a49e-c297-4609-be70-dfc88de3aa8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca23df59-5a6f-4bc6-8b2e-133249d85cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b438dcb0-b8a2-48b0-8c7f-dad61054f4c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa43bf8c-62ca-4564-92fa-fa50d6538ace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa2a186d-91c1-42c5-bf3a-a4fae1e2da2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d3c8deb-c36b-4286-a5a4-6b838c990f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f9bf80f-826e-4572-ba82-82a06c0ed677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a0cd5ac-11fc-42b2-9c25-da5ede6ddfcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 152d38bd-135e-46fc-967f-ec52fcde2cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fb26a78-ea40-44a1-bdff-2ca266ee729b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ba5ce06-6e58-4b36-98e2-8e1c3a59cd07
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_83
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/test_labels.txt

📊 Raw data loaded:
   Train: X=(559, 24), y=(559,)
   Test:  X=(140, 24), y=(140,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 550 samples, 5 features
   Test:  131 samples, 5 features
✅ Client client_83 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2623, R²: -0.0070

📊 Round 0 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2613, R²: 0.0046

============================================================
🔄 Round 4 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0896 (↓), lr=0.001000
   • Epoch   2/100: train=0.0791, val=0.0892, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0772, val=0.0892, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0766, val=0.0894, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0755, val=0.0901, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0714, val=0.0888, patience=2/15, lr=0.000500
   • Epoch  21/100: train=0.0686, val=0.0881, patience=4/15, lr=0.000500
   📉 Epoch 30: LR reduced 0.000500 → 0.000250
   • Epoch  31/100: train=0.0650, val=0.0880, patience=14/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 4 Summary - Client client_83
   Epochs: 32/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0684, RMSE=0.2616, R²=0.1441
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0088
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2602, R²: 0.0101

============================================================
🔄 Round 6 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0705 (↓), lr=0.000250
   • Epoch   2/100: train=0.0824, val=0.0703, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0820, val=0.0702, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0815, val=0.0700, patience=3/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0812, val=0.0699 (↓), lr=0.000250
   ✓ Epoch  11/100: train=0.0798, val=0.0693 (↓), lr=0.000250
   • Epoch  21/100: train=0.0781, val=0.0680, patience=1/15, lr=0.000250
   • Epoch  31/100: train=0.0766, val=0.0668, patience=2/15, lr=0.000250
   • Epoch  41/100: train=0.0752, val=0.0660, patience=6/15, lr=0.000250
   • Epoch  51/100: train=0.0740, val=0.0657, patience=8/15, lr=0.000250
   📉 Epoch 58: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 6 Summary - Client client_83
   Epochs: 58/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.1084
   Val:   Loss=0.0659, RMSE=0.2567, R²=0.1103
============================================================


============================================================
🔄 Round 8 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0855 (↓), lr=0.000125
   • Epoch   2/100: train=0.0790, val=0.0854, patience=1/15, lr=0.000125
   ✓ Epoch   3/100: train=0.0787, val=0.0850 (↓), lr=0.000125
   • Epoch   4/100: train=0.0785, val=0.0845, patience=1/15, lr=0.000125
   ✓ Epoch   5/100: train=0.0783, val=0.0841 (↓), lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0775, val=0.0831, patience=4/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0770, val=0.0827, patience=8/15, lr=0.000031
   📉 Epoch 24: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 8 Summary - Client client_83
   Epochs: 28/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0445
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0016
============================================================


============================================================
🔄 Round 10 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0885 (↓), lr=0.000016
   • Epoch   2/100: train=0.0783, val=0.0883, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0782, val=0.0882, patience=2/15, lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   • Epoch   4/100: train=0.0781, val=0.0882, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0780, val=0.0882, patience=4/15, lr=0.000008
   ✓ Epoch  11/100: train=0.0777, val=0.0880 (↓), lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004
   📉 Epoch 20: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0775, val=0.0879, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 10 Summary - Client client_83
   Epochs: 26/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0315
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0102
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2581, R²: 0.0087

============================================================
🔄 Round 13 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0711 (↓), lr=0.000002
   📉 Epoch 2: LR reduced 0.000002 → 0.000001
   • Epoch   2/100: train=0.0836, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 13 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0049
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0908
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2580, R²: 0.0087

============================================================
🔄 Round 15 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 15 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0168
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0025
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0057

📊 Round 15 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0057

📊 Round 15 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2583, R²: 0.0053

============================================================
🔄 Round 19 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 19 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0023
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0354
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0054

📊 Round 19 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

============================================================
🔄 Round 22 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0664 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0663, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0663, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0663, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0664)

============================================================
📊 Round 22 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0201
   Val:   Loss=0.0664, RMSE=0.2576, R²=-0.0335
============================================================


============================================================
🔄 Round 23 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 23 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0196
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0147
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

============================================================
🔄 Round 26 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 26 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0229
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0266
============================================================


============================================================
🔄 Round 27 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 27 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0064
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0157
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 28 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 28 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0217
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0255
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

📊 Round 28 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 33 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 33 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0106
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0103
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

📊 Round 33 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0056

📊 Round 33 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0056

============================================================
🔄 Round 42 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 42 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0023
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0649
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

============================================================
🔄 Round 43 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 43 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0239
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0408
============================================================


============================================================
🔄 Round 44 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 44 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0154
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0074
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 45 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 45 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0157
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0433
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0054

📊 Round 45 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 49 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 49 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0140
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0029
============================================================


============================================================
🔄 Round 51 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 51 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0025
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0319
============================================================


============================================================
🔄 Round 53 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 53 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0249
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0512
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 56 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 56 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0020
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0581
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 57 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 57 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0017
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0452
============================================================


============================================================
🔄 Round 59 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 59 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0144
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0034
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 61 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 61 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0162
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0053
============================================================


============================================================
🔄 Round 64 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 64 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0193
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0163
============================================================


============================================================
🔄 Round 65 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 65 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0069
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0327
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

============================================================
🔄 Round 66 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 66 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0134
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0123
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

============================================================
🔄 Round 70 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 70 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0036
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0459
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

📊 Round 70 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

============================================================
🔄 Round 73 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 73 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0069
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0293
============================================================


============================================================
🔄 Round 75 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 75 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0141
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0061
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 77 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 77 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0085
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0220
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0053

============================================================
🔄 Round 78 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 78 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0096
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0204
============================================================


============================================================
🔄 Round 80 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 80 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0091
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0232
============================================================


============================================================
🔄 Round 81 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 81 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0054
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0172
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0053

📊 Round 81 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0053

============================================================
🔄 Round 86 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 86 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0192
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0258
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 89 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 89 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0033
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0442
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0053

📊 Round 89 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

📊 Round 89 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 94 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 94 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0095
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0152
============================================================


============================================================
🔄 Round 95 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 95 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0111
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0065
============================================================


============================================================
🔄 Round 96 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 96 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0207
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0257
============================================================


============================================================
🔄 Round 99 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 99 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0188
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0184
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0053

============================================================
🔄 Round 100 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 100 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0100
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0179
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0053

📊 Round 100 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0053

============================================================
🔄 Round 102 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 102 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0091
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0242
============================================================


============================================================
🔄 Round 108 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 108 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0148
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0031
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0053

📊 Round 108 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0052

============================================================
🔄 Round 113 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 113 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0074
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0296
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0052

============================================================
🔄 Round 114 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 114 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0141
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0156
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0053

📊 Round 114 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0053

============================================================
🔄 Round 120 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 120 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0197
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0198
============================================================


============================================================
🔄 Round 121 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 121 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0052
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0708
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0052

============================================================
🔄 Round 124 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 124 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0074
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0268
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0052

📊 Round 124 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0051

============================================================
🔄 Round 126 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 126 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0010
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0532
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0051

============================================================
🔄 Round 129 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 129 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0242
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0685
============================================================


============================================================
🔄 Round 130 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 130 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0180
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0318
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0051

============================================================
🔄 Round 132 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 132 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0078
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0212
============================================================


============================================================
🔄 Round 134 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 134 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0129
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0076
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0052

============================================================
🔄 Round 135 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 135 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0174
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0151
============================================================


============================================================
🔄 Round 137 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 137 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0223
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0294
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 139 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 139 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0167
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0067
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

📊 Round 139 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 141 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 141 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0050
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0560
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 143 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 143 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0191
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0341
============================================================


============================================================
🔄 Round 144 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 144 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0206
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0239
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

============================================================
🔄 Round 147 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 147 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0044
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0231
============================================================


============================================================
🔄 Round 148 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 148 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0074
   Val:   Loss=0.0946, RMSE=0.3076, R²=0.0217
============================================================


============================================================
🔄 Round 150 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 150 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0033
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0417
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

============================================================
🔄 Round 153 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 153 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0171
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0127
============================================================


============================================================
🔄 Round 154 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 154 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0069
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0138
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

📊 Round 154 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

============================================================
🔄 Round 157 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 157 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0077
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0040
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

============================================================
🔄 Round 161 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 161 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0077
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0268
============================================================


============================================================
🔄 Round 162 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0649 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0649, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0649, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0649, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0649, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0648, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0649)

============================================================
📊 Round 162 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0032
   Val:   Loss=0.0649, RMSE=0.2548, R²=0.0766
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

📊 Round 162 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 165 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 165 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0274
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0524
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 166 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 166 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0104
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0045
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

📊 Round 166 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 168 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 168 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0128
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0055
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 172 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 172 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0168
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0095
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 173 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 173 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0108
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0154
============================================================


============================================================
🔄 Round 175 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 175 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0106
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0167
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 176 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0632 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0631, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0631, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0631, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0631, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0631, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0632)

============================================================
📊 Round 176 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0051
   Val:   Loss=0.0632, RMSE=0.2513, R²=0.0457
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2582, R²: 0.0054

============================================================
🔄 Round 179 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 179 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0076
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0136
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0056

📊 Round 179 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0056

📊 Round 179 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

📊 Round 179 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0056

============================================================
🔄 Round 184 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 184 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0039
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0359
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

============================================================
🔄 Round 185 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 185 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0125
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0084
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

============================================================
🔄 Round 188 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 188 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0032
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0459
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

📊 Round 188 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2582, R²: 0.0055

============================================================
🔄 Round 190 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 190 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0091
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0567
============================================================


❌ Client client_83 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
