[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a01ebff9-157b-4885-a6fe-720f2666abf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26350d86-0093-4283-97ed-27db8f0d4bbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce2659f0-0512-4344-8cb4-beac740228bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8813fc81-ec65-4e27-a465-6e342d70195d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61ae6c59-0524-4c8f-a36b-d48e3cd21338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4726eacb-d323-458f-8a00-2591fd369bac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46ab2fed-be85-4900-9126-99e6ff94144b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d43593e-c46e-4749-9741-584c834213e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 838093cf-a153-4313-b37d-fe02483f22fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d72aaf08-65dc-4bdb-88d6-cb6e75ba046a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff7767dd-3a8f-4d86-ab82-cf935b3a2f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a48b16e0-a49c-4020-8b04-ae032717a8e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef665d6a-69fa-4553-bdbb-8dcdde3f629f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09052c9d-4ca2-4df8-8d8f-4f58ef651520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bef1ae0-a0df-409f-a27e-d7bb87b3bd08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66918724-c3d9-4267-aa82-394ce96fe37f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52bbef67-ea82-454c-925f-5fb1946fc067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d72a849-8430-4ad6-adf4-8ec5eb1275b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5950ceb2-9810-4289-9cbe-23e69b2bf18f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e6f39a4-ca9f-4fa1-a769-d875829dd3ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9764dd01-8224-4fd0-a0d9-1bbe38d83ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dec2c68d-9b9c-41ff-b0ac-0b1ee3a2ed93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e983263-f6da-4d45-a8e0-38b89caad09c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9819a75a-59c1-40d5-aa27-4699d147726a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96fa9ea6-6318-4f36-88d0-cddeb71fdbaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d9c4ad7-ce1f-45f6-b90c-da68c7816de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa49818-0145-4778-98fd-d67649de2a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 932ff373-f1ba-4f80-8578-fd58710c9140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02c5c35a-9391-429d-8793-5cd507f6d7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49a2ce85-dfc8-4b64-abf2-891fc4ed648d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 368ccdc6-0d97-41f8-adf8-cf093a08119c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb699ef5-eb62-4ad3-90e7-3676015681a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d460528-1cdd-4270-bfd6-65afb6a84043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1af6dec7-8289-4af0-8aa7-fc060aa454b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 137e712c-65aa-4ee3-9abd-57f2b15db2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c48778e3-e78b-48f0-ab82-c1d57282c652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cdf7091-ef99-4d77-8e8b-7b2b478a1e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 550dcef4-e859-40dc-8a48-9e667bc4dc31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1aaff43-3440-4c55-af03-7b9134287a0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04ecf4c9-b07b-40bb-bd7b-15e907fe3242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84a4202f-7633-49d3-8d40-02e76d9a7d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5ad0538-32d1-4c10-b5e3-e4041ae19faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82adf3c7-b5db-463b-a08c-a34d841936a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ece9ca30-b2bd-40d5-b0bc-295f60dba6fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3243a4d4-dc2a-4931-b7b4-dddc02a757a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bccbac09-4bc5-412d-b2f5-da7e698b5e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27776a5b-57ad-4c04-948c-3e84094cbe5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0782eb5b-bc30-4642-8627-407b22b77381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf091c94-aa1d-4a2c-bd75-fd01a8ae57f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31657686-6b84-4e38-a06f-19586dd8a7d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 969caa11-977f-498d-8281-10486135c74a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51aba6af-9afa-4be2-abeb-601108206914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea9bb76-9da7-419b-a21d-ec88ca3204bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a23ed0d-0cae-43ec-92fc-c64b6e353502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49bbfd4b-6f52-456e-b882-97275d4a1462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d4f8dc-07be-459b-9f54-ba91321e48ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad7a827d-ecf6-4386-b8ef-576bca1635a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80715143-c385-4b87-aa58-3010605889fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e723553-5868-4618-ad41-1a216a7f0546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e259cf3-95fe-4693-8c61-12defa989f2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8727300-9740-4bd7-a07a-907a0c46976c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccf310fb-259e-442b-b347-7e99804bccb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 722092f8-739b-44a6-b157-77cb385b33d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d5d5d6e-fdee-45e7-a0f1-2492745c72fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b74f7cbb-7626-4b2a-ae22-b5e059b83e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c021487-8b56-4029-87ab-de3781dbe9ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19df957d-eee5-4e47-b74d-62595926a9b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92096a28-2ae8-435a-b9f9-0d02224b24b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 540699eb-cac4-4390-9f04-12ba1d908b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7eaef00-a2ec-4fce-801a-c291bd0e19e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f441dcb-a4ba-49ac-9485-faa3bfa8d0ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0386eb34-2bce-4f87-a6e4-82f2b3f6791d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baaef591-c634-41ac-8895-a6752fbd61ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f10e927-4a7a-4ff6-8d4a-413b6e026b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c0c2581-54b9-4afa-b3a7-e24f46a4b0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0323b87-1d0a-4f6f-a9c6-658659c90bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0f6cf93-7c6f-491a-8a78-a862ff7ba810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5e886a3-7b19-442f-98e2-3e813256f55c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2f17700-0d3a-468e-8814-25733818a8a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af6d0187-4fe2-4056-941f-c2d0b7af1397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6274aa7b-1030-4c9e-b944-5b6e8a8f83b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 717b6ad4-f711-4136-83b5-7a844d5e1746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdeb33d2-aec4-48d2-882e-70021f190ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef414d48-2158-4877-b67a-8b5b697b4cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b762338c-f5fd-414c-b30e-b736f4bc6818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f4e8f5d-9a74-423e-b0ed-48ba58472fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 524e92d2-572a-4b9e-92b2-0049aa493709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2139901-b635-43f6-946c-abd9d0eff046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aec79ef-13c3-4745-9e6e-6749989b7f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf748117-4ff2-4729-8e1b-841940fd0d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04849965-92d4-4b83-8a02-bbc85ed89f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3c4855c-53d4-4558-9313-1cc13f80c1a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a5e35a4-86df-4aae-9d13-a0d7ee993c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69cb5b54-c66f-4dbb-a69d-d282fb05f2e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09c11f5c-d582-4e24-b0a6-d621036f69a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba695c4e-57c2-49ef-aa2e-0aef71968948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59d40db8-9472-4018-9d09-64baa387f1e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98ee8dc4-1a77-4664-88d8-3647b4cfdbc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 946d1971-c3a8-4689-aba0-7d088c7ded06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02b41e9a-0148-4a5e-a91d-8319274919c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ad1d2f2-afd5-4630-ac1f-b6a025f3ce11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af7d7bc1-e6a0-40c8-b57e-ff58ca4cfae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 928b830d-7b23-4ff8-b814-12558499530d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a7d9c0b-2fc2-4941-8d42-5c2439734009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ad85f42-16a9-4931-9b7e-5ac83eaeb3bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d48092e6-9ae5-4bbc-9298-59b8aad34ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d684268-b1a5-4781-a277-f0dfeebeab93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6422d704-b48e-4c40-b17f-54bdd42558c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41c17537-8db7-46f4-9d16-c8f4cdc9a50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e21becb-35a1-4c81-9c04-502d348129b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c243023c-abec-4e3b-8508-6ceea83f188d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3170eb30-602d-40b7-ba49-95e21788b27b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 680d3470-925c-421c-ae02-3255ea83ef0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a255783-5f3f-49d5-a058-e2b6abc2ade3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 507e07c9-313a-4a95-88e6-9f0af00845cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6d2217e-d80c-472e-8b51-45fb79b2843e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08cfb40e-ae88-4961-b991-a266a088c119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20b26a7a-e29b-43f1-b736-bd686c84e015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4b94d92-4844-446d-9c65-e26ebfbca9c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 650859ce-40da-4853-b42e-0b8377782043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c854b6e-c4bf-4b6d-a330-3ba3fd135882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cfe94e6-6928-4b2c-8194-e7f006e361de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 873c7768-a068-4146-832f-b3093fe21515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c84a750-d4f5-43c7-8af5-9dfbe869fcdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 226705fc-a972-451e-80bf-7338734f3521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f3a232b-26ea-4a42-8221-4183c83745d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc1ae705-558a-4d0e-9a9f-47acde3ac576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99fc75f1-cff0-4fe7-a774-796a2b015252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03f73026-a934-4843-8dd4-c3e25a1f6fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 052d5f33-492f-4ad1-9e4a-ad76154f1740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e270f5e-53a7-40e4-9b4a-6d843d01bde3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c00bc5b3-dbdb-4ee2-8097-c2e100762a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1146c557-9ceb-4e13-a8be-c4ab80297b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84bef001-8ac1-4661-8d21-4577e2f87abe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb377393-d889-4905-be28-94fceceb6db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 630327e5-21f7-40d2-bd37-d59f54b4bce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5f83711-1408-45df-9419-644019f63ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ded78bad-1347-4757-a24d-82acb58325f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fe46759-e9e8-4d4d-a04c-5c1ff16514e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05761661-0068-4161-97b5-30039abcc29e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_84
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_84
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_84/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_84/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_84/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_84/test_labels.txt

📊 Raw data loaded:
   Train: X=(2020, 24), y=(2020,)
   Test:  X=(506, 24), y=(506,)

⚠️  Limiting training data: 2020 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  497 samples, 5 features
✅ Client client_84 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3074, val=0.1046 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1021, val=0.0997 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0838, val=0.0873 (↓), lr=0.001000
   • Epoch   4/100: train=0.0816, val=0.0887, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0818, val=0.0880, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0803, val=0.0874, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 1 Summary - Client client_84
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0014
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0043
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2410, R²: 0.0004

============================================================
🔄 Round 3 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0825 (↓), lr=0.000250
   • Epoch   2/100: train=0.0805, val=0.0825, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0803, val=0.0823, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0800, val=0.0823, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0798, val=0.0822, patience=4/15, lr=0.000250
   ✓ Epoch  11/100: train=0.0780, val=0.0813 (↓), lr=0.000250
   • Epoch  21/100: train=0.0736, val=0.0786, patience=1/15, lr=0.000250
   • Epoch  31/100: train=0.0711, val=0.0762, patience=2/15, lr=0.000250
   • Epoch  41/100: train=0.0694, val=0.0746, patience=1/15, lr=0.000250
   ✓ Epoch  51/100: train=0.0679, val=0.0741 (↓), lr=0.000250
   📉 Epoch 57: LR reduced 0.000250 → 0.000125
   • Epoch  61/100: train=0.0661, val=0.0741, patience=10/15, lr=0.000125
   📉 Epoch 65: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 3 Summary - Client client_84
   Epochs: 66/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0673, RMSE=0.2595, R²=0.1739
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.1060
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2382, R²: 0.0196

============================================================
🔄 Round 5 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0796 (↓), lr=0.000063
   • Epoch   2/100: train=0.0807, val=0.0798, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0806, val=0.0799, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0806, val=0.0799, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0805, val=0.0799, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0803, val=0.0799, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 5 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0182
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0113
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2377, R²: 0.0219

============================================================
🔄 Round 6 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0799 (↓), lr=0.000016
   • Epoch   2/100: train=0.0806, val=0.0799, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0806, val=0.0799, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0806, val=0.0799, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0805, val=0.0799, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0805, val=0.0800, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 6 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0230
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0141
============================================================


============================================================
🔄 Round 12 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0782 (↓), lr=0.000004
   • Epoch   2/100: train=0.0783, val=0.0782, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0783, val=0.0782, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0783, val=0.0781, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0783, val=0.0781, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0782, val=0.0781, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 12 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0405
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0522
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0750, RMSE: 0.2739, MAE: 0.2332, R²: 0.0472

============================================================
🔄 Round 14 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 14 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0409
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0521
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0750, RMSE: 0.2738, MAE: 0.2330, R²: 0.0481

============================================================
🔄 Round 15 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 15 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0499
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0237
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2329, R²: 0.0485

============================================================
🔄 Round 17 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 17 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0444
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0344
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2329, R²: 0.0485

📊 Round 17 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2329, R²: 0.0487

📊 Round 17 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2329, R²: 0.0488

============================================================
🔄 Round 23 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 23 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0464
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0328
============================================================


============================================================
🔄 Round 24 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 24 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0473
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0285
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2329, R²: 0.0488

============================================================
🔄 Round 29 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 29 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0417
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0522
============================================================


============================================================
🔄 Round 30 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 30 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0494
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0272
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2329, R²: 0.0488

============================================================
🔄 Round 32 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 32 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0453
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0337
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2329, R²: 0.0488

============================================================
🔄 Round 33 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 33 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0422
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0500
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2329, R²: 0.0488

============================================================
🔄 Round 36 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 36 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0455
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0405
============================================================


============================================================
🔄 Round 37 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 37 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0480
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0305
============================================================


============================================================
🔄 Round 38 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 38 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0463
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0383
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2329, R²: 0.0488

📊 Round 38 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2329, R²: 0.0488

📊 Round 38 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2329, R²: 0.0488

📊 Round 38 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2329, R²: 0.0489

📊 Round 38 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0489

📊 Round 38 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0489

============================================================
🔄 Round 53 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 53 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0546
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0068
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0489

============================================================
🔄 Round 55 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 55 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0489
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0211
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0489

📊 Round 55 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0489

============================================================
🔄 Round 59 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 59 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0466
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0340
============================================================


============================================================
🔄 Round 61 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 61 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0490
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0245
============================================================


============================================================
🔄 Round 62 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 62 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0449
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0439
============================================================


============================================================
🔄 Round 63 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 63 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0455
   Val:   Loss=0.0706, RMSE=0.2656, R²=0.0318
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0489

📊 Round 63 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0489

📊 Round 63 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0489

📊 Round 63 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0489

📊 Round 63 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0489

============================================================
🔄 Round 71 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 71 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0410
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0579
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0489

============================================================
🔄 Round 73 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 73 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0508
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0008
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0490

============================================================
🔄 Round 78 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 78 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0475
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0329
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0490

📊 Round 78 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0490

============================================================
🔄 Round 82 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 82 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0379
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0571
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0490

📊 Round 82 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0490

============================================================
🔄 Round 86 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 86 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0389
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0680
============================================================


============================================================
🔄 Round 88 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 88 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0448
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0326
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0490

============================================================
🔄 Round 89 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 89 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0499
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0234
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0490

📊 Round 89 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0490

📊 Round 89 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0490

📊 Round 89 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0490

📊 Round 89 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0490

============================================================
🔄 Round 100 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 100 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0492
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0179
============================================================


============================================================
🔄 Round 101 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 101 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0428
   Val:   Loss=0.0682, RMSE=0.2611, R²=0.0546
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0490

============================================================
🔄 Round 102 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 102 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0441
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0382
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0490

📊 Round 102 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

📊 Round 102 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

============================================================
🔄 Round 107 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 107 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0410
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0576
============================================================


============================================================
🔄 Round 108 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 108 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0450
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0444
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

============================================================
🔄 Round 111 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 111 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0422
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0560
============================================================


============================================================
🔄 Round 112 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 112 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0413
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0593
============================================================


============================================================
🔄 Round 114 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 114 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0455
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0424
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

📊 Round 114 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

============================================================
🔄 Round 116 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 116 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0380
   Val:   Loss=0.0708, RMSE=0.2662, R²=0.0688
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

============================================================
🔄 Round 121 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 121 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0493
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0097
============================================================


============================================================
🔄 Round 123 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 123 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0347
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0627
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2328, R²: 0.0491

============================================================
🔄 Round 126 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 126 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0420
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0514
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2328, R²: 0.0491

============================================================
🔄 Round 127 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 127 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0467
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0382
============================================================


============================================================
🔄 Round 128 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 128 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0516
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0153
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2328, R²: 0.0492

============================================================
🔄 Round 131 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 131 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0392
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0633
============================================================


============================================================
🔄 Round 132 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0668, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 132 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0423
   Val:   Loss=0.0668, RMSE=0.2585, R²=0.0577
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2328, R²: 0.0491

📊 Round 132 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2328, R²: 0.0491

============================================================
🔄 Round 135 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 135 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0461
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0318
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

📊 Round 135 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

============================================================
🔄 Round 140 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 140 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0409
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0513
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

============================================================
🔄 Round 141 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 141 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0452
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0435
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

📊 Round 141 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

============================================================
🔄 Round 143 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0630 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0630, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0630, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0630, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0630, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0630, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0630)

============================================================
📊 Round 143 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0410
   Val:   Loss=0.0630, RMSE=0.2510, R²=0.0625
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

============================================================
🔄 Round 145 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 145 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0481
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0309
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

============================================================
🔄 Round 146 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 146 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0462
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0389
============================================================


============================================================
🔄 Round 147 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 147 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0398
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0660
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

📊 Round 147 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

📊 Round 147 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2328, R²: 0.0491

============================================================
🔄 Round 154 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 154 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0442
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0475
============================================================


============================================================
🔄 Round 157 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 157 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0406
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0612
============================================================


============================================================
🔄 Round 159 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 159 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0447
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0453
============================================================


============================================================
🔄 Round 162 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 162 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0458
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0329
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2328, R²: 0.0491

============================================================
🔄 Round 163 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 163 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0456
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0422
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2328, R²: 0.0492

📊 Round 163 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2328, R²: 0.0492

============================================================
🔄 Round 165 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 165 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0423
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0398
============================================================


============================================================
🔄 Round 166 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 166 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0404
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0591
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2328, R²: 0.0492

============================================================
🔄 Round 167 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 167 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0493
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0265
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2328, R²: 0.0492

============================================================
🔄 Round 171 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 171 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0403
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0577
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2328, R²: 0.0492

============================================================
🔄 Round 174 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 174 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0452
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.0367
============================================================


============================================================
🔄 Round 175 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 175 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0516
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0173
============================================================


============================================================
🔄 Round 177 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 177 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0425
   Val:   Loss=0.0697, RMSE=0.2639, R²=0.0556
============================================================


============================================================
🔄 Round 179 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 179 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0419
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0570
============================================================


============================================================
🔄 Round 180 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 180 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0403
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0613
============================================================


============================================================
🔄 Round 181 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 181 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0452
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0441
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2328, R²: 0.0492

============================================================
🔄 Round 184 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 184 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0482
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0248
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2328, R²: 0.0492

📊 Round 184 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2328, R²: 0.0492

❌ Client client_84 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
