[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c96189cb-823f-49a6-8a57-f7472c61ee16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ad0070b-e7cb-425b-9d89-90eccd2f73e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be416fe1-9a3f-49ac-abf4-7e35ce7c2d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1f71cb3-24b4-4b30-b5d8-c70f6baf74b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44eaf8a1-91bd-4aec-b628-c37821ff8192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a486e08e-cb9b-40ff-aa7e-9fac01923ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e49610d-8e38-41ae-9244-a115ff32bb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c708d0b-af4b-4d0f-b232-3ff446ff19f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 929ad57e-7688-4753-9736-f4626b3596cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a3f29ec-0a2e-4bd6-94df-0b2f03239839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5bbb137-973d-4506-9bf9-c12ad203264f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d97cfad3-f321-488d-821c-7825f207907f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ae2548-a0a8-447a-ab35-f4f38bb04679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ae7a9c2-a0a7-4dc2-9fa9-3269c07463ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cbe7aad-5743-4064-a08d-96e4d0298082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8792bf21-06fa-4a7a-97e0-e8f5e7e014e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 023987ef-a8e7-4c44-95dc-aef53849be3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 494b3e66-f65e-40ca-98f9-5843ac2ece58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b07a3058-5359-4016-9a30-ff9ca3e08bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88f091e2-fe1f-4d04-b2dd-7191888ca39f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17614b3e-0bdd-4d11-b1f9-e62ec4012b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59160cdf-c2ff-4af1-a65d-6cc35a7535f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b954230a-898c-441c-bf15-7c461bcd426a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b73715ed-b9a4-4b10-ac6a-43de6c868c15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a283486a-ab4f-4669-a174-348674c7823b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b37b92db-6c3c-4aac-ad17-813bdf5f97a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d99e3e5-6d19-46b4-999e-248cab09cbb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c0c3534-65d1-4017-ae3a-fe8012ccad39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dc88df9-6665-40a9-acca-99d612ad9ff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5c12de5-aa36-4084-981a-f131d8665c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37c3b447-9cdd-423a-9a33-5dfea73d38ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf75a3f8-9d76-46d2-bb2b-81f4e3e90277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f352f0f4-8484-45c1-b11e-875d647c9ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8df4a15d-1e9f-424f-8d66-f76bbf0cc965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6935b69-46a6-4ff0-a86b-3e0bb926dd3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21e0d5d1-825c-4f8d-b4b7-6192532f1339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c8d1f62-b039-4ca3-9a96-53f7abc32d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a35c86fa-b857-44cf-8438-23af1356ffaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9d1842f-8ba2-4360-8238-d2bf3112ee5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9efe65fb-a30a-434a-aff7-6f25b8852bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4343bee1-3da5-4b53-b70f-b60d51bba4ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d36a806-22bf-445b-b977-c06f8d2464bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34571584-ef75-485b-bbcf-c35f9f1cc892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de80ce04-2747-498b-bdfb-f07b652bdaf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f5ecec1-f0cc-402f-b612-b17521ab105e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1942d1a-72e2-40e1-9c51-b349c9470bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60be6d33-be39-4e66-8602-843357a7bd53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8752ea5-cbdc-47de-af43-774a4b232225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce87fc10-ded3-478a-830c-57f4b4e61408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baa61d06-b437-4adc-a6a9-b8fe00b482a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51e8b24c-f6f6-4177-b450-acb0bb9d75e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4a5b8d9-b2c5-4ed4-87b6-8fc17187f195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2430b906-4629-4e17-9d9d-9f68661a4e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7b43a67-eb50-45ad-9cee-ba950b656988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 850bccb9-3c4a-4d30-944d-a1aefa31b46d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d296d035-85ed-4068-af18-a22a7c147195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be4e3f87-dc73-440a-ab0a-e47d99f014a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cbc49f4-cd01-4181-bf8e-a167c3d45e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe1e8092-e672-4bfd-8676-5c630d09a1e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57bcc50f-ccfd-45ad-a68d-ec85d1318d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aab8f42e-3789-4a61-87bd-f23a7b226148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d31ff92b-c54e-4304-b79e-7b9b615ffe35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b66d915e-e72d-4ecb-8e75-42e7dbed00ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d833efc1-eb64-4ad5-b486-b9535172f8a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e922bec2-6122-445e-85f4-829b977c61e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9457a0a9-855a-4d90-abf4-1f4300c02068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3931c76-9b30-4b39-96a4-175df5fafb72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29bdb916-aa10-45cb-8a67-eef737631458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaa11b89-095b-4e5c-ad40-d6f1c74d76a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bfa86a3-d594-4595-93d7-eca76603d4d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a7c0525-106d-4c94-9e65-bc9f3d953655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 655a29b5-db64-47c6-9a99-16a2795cc7b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b2ab0c-0e7f-4510-a9c6-0744af10b8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89bb97b9-7bea-41d9-916b-4ec818931339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48cd5eb5-4072-4fc4-a669-de3537f3bf6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 705e9b02-0d58-4adf-8dee-f6334e78e6d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15cf2a7e-878a-4358-a4a7-593644f2e56b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef475b38-d7bf-4022-9598-bf9104de2bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db6da4dc-1aa7-4691-8d82-6ff9373eb0d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2a25907-4f24-4d3a-bc63-0413d68076cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7213440-a2ec-4319-8bb9-df0dda17dffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70ada965-e904-45fa-b326-92e3267fa01d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fab1e83-3368-4fe4-a64b-7ab7499c2c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 990c05a8-e548-4400-9951-dc907f3221d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49b06ef0-c68c-47de-9f01-39bfcc4964f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f32c1e4-0258-4910-8911-dbba6b763fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 582eb064-1742-4095-b878-359ce37dcb09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3f840cc-1d08-4772-b0ad-ac3d4286a013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31201665-458d-49ce-9fb2-bd17b21e4ce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17c75ef9-2a9d-4cf1-9840-5b3b8d52f223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45ac0084-9fa4-40aa-889b-7fd5d573a1da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a45010f-6f9d-4249-90d5-6bccada39664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3f9b95f-fa5e-45c0-a159-9bc053378c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 849ed421-fe5e-4721-80d6-fe4b3f26b619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83e7b6b9-1401-4423-ad18-3345d74e3e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf4f5b23-f72a-48fd-9fd3-835985b60bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f92f344f-30f4-4d28-a9e3-9276fa7e59c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a94cbb5c-3071-47b3-aea7-2b719b7f5390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44ccb610-b33d-4dfc-881a-1a4fdbb1b26c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34af84c9-1983-45e2-9b38-e1bb06a1471e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f1c8eb-5bb4-4354-a885-94f232886e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33d82099-4a99-4731-b859-6a05613d777b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 466a4987-fb5b-4b19-b72e-274db4ef61fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77a86c2d-5be3-4975-9c39-3fe9ffd9d024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adf98df6-3f7e-45f2-b902-97535b0d67bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b85c3dc7-ab6a-4821-8615-83ae00ae2cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d649ad8-c8b1-4916-9e99-94c9adfb0537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4887067b-ac06-4ca2-9f2f-e7bf186bbf1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac5366c0-f5e8-44c4-b391-b499c9427e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b011868-dbd4-487e-982a-b6eae581314d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ad8793d-1c01-4470-8b40-eacb204b8a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1059aea1-f453-4a49-8b8f-6a1238fb0ca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b38c2770-eb8b-4c69-bb1c-2f5682280490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32f5befe-686a-427b-abcb-ef668258221d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad612535-158c-4d74-86bd-9bb414933117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41ff3b51-51a8-4373-b0eb-1ed8939b2fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3080f6f5-4d81-4d08-90d9-6f2c5fd978c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d458fdd-2ce5-467a-9504-0ce4bb4a4fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca4dd660-e199-4cbd-b903-8c857236588f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff3d57a7-7f26-4510-a725-054a2f90e326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2581bc8-3f7c-49cc-9c9c-16cd7de788f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6db483bb-0da6-4e28-b13b-1007e4eaa3e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d5b9ebd-282e-48e0-b3b8-7511dad00fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40893fd4-11c4-4b03-8ee8-def2973d9663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7abf9f8-41b8-48b3-a2bc-8d27d5c40ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7a2c4dc-af06-4cc1-a354-b20564dc40ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae926c1e-4c2b-4c84-b4fb-7ef42215f645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a76c8611-1e8a-4477-a24c-6ece15007377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f062231c-4058-4395-9203-7506915d4599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9998f8b5-f4c1-4e5b-8f33-11a317cfdf33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb62c3ec-fdc4-41dd-924d-87b162600b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d66c1b40-b7f2-4274-bbeb-517d5c4feb30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a322c333-ed91-4378-92a2-43f5e0bb358f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 430b43c8-61ef-4736-b601-ad71161920e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0854751-2784-4e9f-be2c-4650bf7bb627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eccc6f2-2e9e-4d36-a88c-6980ce58982f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce9c4ff6-050f-4688-9c46-8f2b41d87dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38aa3cbf-252a-40c2-9115-b4c7db64886b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e122648f-1efb-418f-8998-3a0e3bf059a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12a3e7b1-5322-4f51-8e2f-adef1ed8bf16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b8b8b6f-06ca-4efe-b27f-40994200d55c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00bf5397-4a1b-4f6f-beae-b7195ab937d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d95c1893-e8d4-48d5-a539-a1ea105e296d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc155e39-2941-4a71-9d2a-157342e00557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b50e6ce9-672a-4e8d-8a51-030a0de14f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ecd3a79-6d52-4684-b758-0d2bf3d1f863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a2aed2b-0962-4549-a0e0-011412e6d435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8caf50ea-925b-4156-9af0-5b8c3203acc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc1f8456-f469-47a0-b029-1aa2dde45e6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0628ed72-323b-423b-99b0-2044ac75755d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 733ec536-1625-4661-a8bd-2508f1269810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c08acbb-533a-4d84-927b-6d9d1552e0da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06c0b802-cf92-45e5-bbf6-3b6213d020ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47d18969-60f6-480b-8cca-900e096fc00a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b6ab32a-d95e-4d2a-b7e3-70210c17c8a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b26eadbb-ff60-4d59-82a6-cf38e09868ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7b8a669-7831-4bc3-8151-88594d9653c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c465e7d-471a-4cc7-aa6d-d7dcdd0836b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30a86a44-3638-4181-a236-baf919a6842b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86aa8c5a-91ab-4dbb-a584-1d1ffd6dd61a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_85
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/test_labels.txt

📊 Raw data loaded:
   Train: X=(1160, 24), y=(1160,)
   Test:  X=(291, 24), y=(291,)

⚠️  Limiting training data: 1160 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  282 samples, 5 features
✅ Client client_85 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2469, R²: 0.0048

============================================================
🔄 Round 4 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0808 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0802, val=0.0796 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0797, val=0.0787 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0791, val=0.0780 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0784, val=0.0772 (↓), lr=0.001000
   ✓ Epoch  11/100: train=0.0726, val=0.0717 (↓), lr=0.001000
   📉 Epoch 17: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0657, val=0.0741, patience=10/15, lr=0.000500
   📉 Epoch 25: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 4 Summary - Client client_85
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0704, RMSE=0.2654, R²=0.1383
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.1330
============================================================


============================================================
🔄 Round 5 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0803 (↓), lr=0.000250
   • Epoch   2/100: train=0.0800, val=0.0803, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0797, val=0.0804, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0795, val=0.0804, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0792, val=0.0805, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0782, val=0.0807, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 5 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0263
   Val:   Loss=0.0803, RMSE=0.2835, R²=0.0133
============================================================


============================================================
🔄 Round 6 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0833 (↓), lr=0.000063
   • Epoch   2/100: train=0.0788, val=0.0831, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0787, val=0.0830, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0786, val=0.0830, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0786, val=0.0829, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.0783, val=0.0828 (↓), lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0780, val=0.0827, patience=10/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 6 Summary - Client client_85
   Epochs: 26/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0344
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0304
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2441, R²: 0.0266

============================================================
🔄 Round 8 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0905 (↓), lr=0.000008
   • Epoch   2/100: train=0.0759, val=0.0905, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0759, val=0.0904, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0758, val=0.0904, patience=3/15, lr=0.000008
   📉 Epoch 5: LR reduced 0.000008 → 0.000004
   • Epoch   5/100: train=0.0758, val=0.0904, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0756, val=0.0903, patience=10/15, lr=0.000004
   📉 Epoch 13: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 8 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0398
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0311
============================================================


============================================================
🔄 Round 9 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0767 (↓), lr=0.000002
   • Epoch   2/100: train=0.0792, val=0.0767, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0792, val=0.0767, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0792, val=0.0767, patience=3/15, lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   • Epoch   5/100: train=0.0792, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 9 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0390
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0405
============================================================


============================================================
🔄 Round 13 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 13 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0452
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0597
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2429, R²: 0.0347

============================================================
🔄 Round 14 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 14 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0482
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0303
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2427, R²: 0.0351

📊 Round 14 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2427, R²: 0.0353

📊 Round 14 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2427, R²: 0.0353

============================================================
🔄 Round 17 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 17 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0436
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0738
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2427, R²: 0.0353

📊 Round 17 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0356

============================================================
🔄 Round 21 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 21 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0470
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0481
============================================================


============================================================
🔄 Round 23 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 23 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0473
   Val:   Loss=0.0676, RMSE=0.2600, R²=0.0610
============================================================


============================================================
🔄 Round 24 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 24 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0521
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0410
============================================================


============================================================
🔄 Round 25 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 25 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0520
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0395
============================================================


============================================================
🔄 Round 26 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0618 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0618, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0618, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0618, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0618, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0618, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0618)

============================================================
📊 Round 26 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0409
   Val:   Loss=0.0618, RMSE=0.2486, R²=0.0796
============================================================


============================================================
🔄 Round 30 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 30 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0472
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0444
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0356

============================================================
🔄 Round 31 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 31 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0474
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0442
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0356

============================================================
🔄 Round 33 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 33 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0464
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0614
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0356

============================================================
🔄 Round 35 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 35 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0497
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0501
============================================================


============================================================
🔄 Round 36 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 36 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0478
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0436
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0356

📊 Round 36 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0356

============================================================
🔄 Round 41 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 41 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0450
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0613
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0356

============================================================
🔄 Round 42 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 42 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0524
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0376
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0356

📊 Round 42 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0357

📊 Round 42 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0357

============================================================
🔄 Round 47 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 47 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0515
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0387
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0357

============================================================
🔄 Round 50 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 50 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0470
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0569
============================================================


============================================================
🔄 Round 51 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 51 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0521
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0397
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0357

📊 Round 51 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0357

============================================================
🔄 Round 59 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 59 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0473
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0434
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0357

============================================================
🔄 Round 60 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 60 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0447
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0201
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0357

============================================================
🔄 Round 65 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 65 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0449
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0631
============================================================


============================================================
🔄 Round 66 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 66 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0453
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0660
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0357

============================================================
🔄 Round 69 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 69 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2769, R²=0.0449
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0297
============================================================


============================================================
🔄 Round 71 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 71 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0539
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0181
============================================================


============================================================
🔄 Round 72 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 72 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0565
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0256
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 73 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0651 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0651, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0651, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0651, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0651, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0651, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0651)

============================================================
📊 Round 73 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0483
   Val:   Loss=0.0651, RMSE=0.2551, R²=0.0500
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

📊 Round 73 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

📊 Round 73 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 78 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 78 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0484
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0554
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 79 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 79 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0480
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0420
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 80 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 80 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0508
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0463
============================================================


============================================================
🔄 Round 81 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 81 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0518
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0416
============================================================


============================================================
🔄 Round 83 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 83 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0503
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0477
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 84 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 84 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0482
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0510
============================================================


============================================================
🔄 Round 86 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 86 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0478
   Val:   Loss=0.0682, RMSE=0.2611, R²=0.0584
============================================================


============================================================
🔄 Round 89 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 89 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0511
   Val:   Loss=0.0727, RMSE=0.2695, R²=0.0441
============================================================


============================================================
🔄 Round 91 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 91 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0383
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0767
============================================================


============================================================
🔄 Round 93 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 93 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0519
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0420
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 95 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 95 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0507
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0471
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 98 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 98 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0505
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0470
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 99 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 99 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0517
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0418
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 100 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0651 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0651, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0651, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0651, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0651, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0651, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0651)

============================================================
📊 Round 100 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0514
   Val:   Loss=0.0651, RMSE=0.2551, R²=0.0276
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

📊 Round 100 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 103 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 103 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0480
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0522
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 104 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 104 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0497
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0499
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 106 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 106 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0509
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0459
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

📊 Round 106 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

📊 Round 106 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 110 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 110 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0508
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0462
============================================================


============================================================
🔄 Round 112 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 112 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0525
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0389
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

📊 Round 112 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

📊 Round 112 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

📊 Round 112 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

============================================================
🔄 Round 118 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 118 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0415
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0700
============================================================


============================================================
🔄 Round 120 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 120 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0508
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0131
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

============================================================
🔄 Round 121 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 121 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0495
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0453
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

📊 Round 121 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

📊 Round 121 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

📊 Round 121 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

============================================================
🔄 Round 125 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 125 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0441
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0728
============================================================


============================================================
🔄 Round 128 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 128 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0556
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0305
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

============================================================
🔄 Round 130 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 130 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0494
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.0535
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

============================================================
🔄 Round 133 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 133 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0484
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0559
============================================================


============================================================
🔄 Round 134 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 134 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0549
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0288
============================================================


============================================================
🔄 Round 135 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 135 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0534
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0357
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 139 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 139 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0528
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0353
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

============================================================
🔄 Round 142 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 142 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0548
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0244
============================================================


============================================================
🔄 Round 143 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 143 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0407
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0724
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

============================================================
🔄 Round 145 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 145 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0509
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0462
============================================================


============================================================
🔄 Round 147 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 147 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0494
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0511
============================================================


============================================================
🔄 Round 148 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 148 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0488
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0238
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 150 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 150 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0502
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0438
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 152 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 152 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0531
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0335
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 153 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 153 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0543
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0337
============================================================


============================================================
🔄 Round 156 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 156 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0529
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0284
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

📊 Round 156 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0358

============================================================
🔄 Round 158 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 158 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0493
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0408
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

============================================================
🔄 Round 160 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 160 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0553
   Val:   Loss=0.0815, RMSE=0.2856, R²=0.0091
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

============================================================
🔄 Round 164 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 164 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0510
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0401
============================================================


============================================================
🔄 Round 165 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 165 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0475
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0598
============================================================


============================================================
🔄 Round 166 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 166 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0449
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0674
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

============================================================
🔄 Round 168 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 168 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0503
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0486
============================================================


============================================================
🔄 Round 169 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 169 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0506
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0151
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

📊 Round 169 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0360

============================================================
🔄 Round 171 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 171 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0452
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0654
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0360

📊 Round 171 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

============================================================
🔄 Round 174 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 174 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0509
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0469
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0360

============================================================
🔄 Round 176 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 176 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0536
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0350
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0360

============================================================
🔄 Round 178 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 178 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0425
   Val:   Loss=0.0693, RMSE=0.2633, R²=0.0661
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0360

============================================================
🔄 Round 179 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 179 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0462
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0547
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0360

============================================================
🔄 Round 181 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 181 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0491
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0544
============================================================


============================================================
🔄 Round 182 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 182 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0517
   Val:   Loss=0.0685, RMSE=0.2618, R²=0.0430
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

============================================================
🔄 Round 184 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 184 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0452
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0464
============================================================


============================================================
🔄 Round 185 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 185 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0481
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0493
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

📊 Round 185 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

📊 Round 185 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2427, R²: 0.0359

❌ Client client_85 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
