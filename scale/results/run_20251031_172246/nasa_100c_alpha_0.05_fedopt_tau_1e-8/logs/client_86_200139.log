[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00ec99ed-4343-40d6-987f-998b9545bd03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1b73574-7a62-47fe-ab29-9815f7f55df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45517254-dfcf-43c9-98bc-81d842a6537a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa8fba05-ea25-4265-8947-f23ed1542187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b996af2d-3718-454c-a423-fe1ad3d0538f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14e8905d-64a6-4039-9bce-df6d7c0691f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5d2ff4f-0a77-45c1-ba72-3d199119bf5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5704e5ea-c7c1-46f4-b3bd-381ed779e6ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8492109d-c88a-424f-9c5d-b5822613ddcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd326b7-d25c-42e3-a41a-0d0d64be045f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ddd1057-c302-4786-8131-3c5ac030498a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7648de1-942e-4d6c-823a-f019942888f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d438f789-2bc8-4c27-ae5d-a9e76ab784ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa4fe715-8357-45f4-b227-bcedbabe1e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b9ec6b3-6cb9-4973-ac24-ce7a6c947237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 908de215-80ba-4fe3-81b3-0346912f1762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 927584d6-0bc4-41a3-898c-95724355062f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90de8763-5443-459a-b661-8338d8f716ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6c1a7b5-b3c1-4772-b21a-e4bcc4ec17b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce012ca5-9969-441d-92e9-eb10af2f9de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0a5b048-1f83-4acf-bd6a-41c775d28432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37a836aa-75a8-4304-a310-89919c6b4588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b067781-4fff-42cc-b1ec-9ef4c390a68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a029f13f-8dd2-450a-a850-cc5806c99691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f935a63d-06a3-4435-9222-9134f7bb450f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8edca2ce-8321-4122-b85d-7814d2061d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68403bc6-2c1c-40d9-9e76-835738acc1b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 994e2f72-3bad-4f8a-aaf6-ac49e9759e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b5a83f8-3e2d-494e-bbe0-e6af3b76c989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c9f2cf5-9f67-461f-b830-62c01b5e4673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 309bc7f2-d101-494c-9947-89cd2678ed30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1eb5848-695b-4515-9465-1ec305da60fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c409ca05-7558-4e54-9cfd-5a8dabb246a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd3bcf9e-11f0-4d09-854a-892d11d3d8ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 818442e7-c488-494f-8d60-3b34c5277010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea9a4315-d2b8-4da2-ace9-1832f8a8d411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c18bf6ae-04e8-4a66-b83c-8bfcd2b8d4a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43999795-471b-45b4-8b2a-ca61bccb35af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ed8ad05-987d-4dbd-8821-5d8ac18dcc0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beb5f35b-c15b-4b59-9854-6b08affb8ace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dd0de40-afbc-4439-8aa1-4cbfc0610c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed7af9ae-5577-48f3-ab01-c4d8b108fde4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04d68817-8037-4a8b-a4e5-f9486d68591d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5ca91a8-6aff-4b57-8c11-83e34ba38ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cf2caf8-4f37-4ffc-953d-0a68ec9397a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94714036-7141-4877-9775-a2ec2136a53a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98e3ba93-a427-42c0-8412-f0576dc7e4aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f916bf36-e974-4199-b29a-62d0c84d698a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2316a2b5-ad69-4441-aef5-a73b74011032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f284647a-d54d-44e7-ab1d-bf03a6da58cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 913a0df4-c04b-4972-8e71-9a9ac86e6725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f67de22c-939f-4bf7-b93c-cfdbeab3f948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d49372f-db06-4092-a0e9-0fe42cc9124e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09895f1b-73da-4fb2-af19-87ce59875720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c1405e8-9341-4b57-9f9d-e9b78128fbaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1d669fb-1dd2-4b62-876f-ea50c8b070ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 381a970b-7d4b-41b1-a476-2c497e5345bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c01d7b06-da1a-4fa0-8c69-a958c1bc3ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b1df0b0-a745-4ca5-becf-0df502935ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c8f4de4-035c-4cfa-b052-1efd361b6e56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aaada64-5cd0-48ab-a819-d32f72b6f253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce6f1404-106b-407d-9cdb-b050754cf1b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a90a5c19-07a3-472e-8b5c-fb8c569de37c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fbaf5c4-7ee5-4567-87bb-f503ccee323d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d856d4c3-d11e-4067-aa03-3dd50b738f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4c0cfad-2d51-44f6-93fd-9ad10d6534b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7119785a-1f2f-43f5-bb6e-33af86acdc2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcdd8005-1b28-4027-a05a-acdd0da8ec6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bba75307-578d-4c1f-8ad3-8c0f9a9b4e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bc3d5f6-a386-4c1f-a916-791f8527d8cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e92f1264-2f5d-447e-a34a-0406212ec9b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcaa3933-9026-4cb9-9f0e-ac2e8ac4305d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a83e3ace-551b-4868-9b23-37f319dfce1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e7eebf1-346b-4f60-a839-9dbb1ecb6197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a91310a8-a2e0-423e-86c0-a69ed0378b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf9fa6a8-0f23-49e3-91c0-52bd60f1bc04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67374cc2-e75b-48eb-a136-4a236dfe3b76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa355332-2718-4208-9ad7-59b5f5bd9164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12c75d1d-3721-4bb0-b040-91c285668277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e452a372-fdd9-4684-89b6-0d31ea399c2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32996ade-dfe8-4c4b-9c0f-9fae73d25f3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4923b00-e499-4ba5-98aa-a46f60402a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1033ac73-196d-4042-a02e-353a25c2ebd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a424b7b5-2196-43d3-8d1b-b4be6c6ba5dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e21b775-c644-4fd4-a6f5-a60d1ac2a143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9789bc89-dd95-499e-9205-47782fbcc36e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a491f486-8dfb-45c7-b2b9-3110ac3883e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0de17c6-962f-4a59-a817-b3ac087c9e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8787146e-2278-4ce0-913a-cd9ce761db96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b009648d-24d8-4540-842a-ea5e53740fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 284480bd-5c6a-4598-9146-dfed5cfd0c4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2008876f-4439-49d2-8db3-007c59926124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d674e623-fd19-457c-8383-f68df865ab1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e04539a-93c4-4036-a47b-3c4e8cb01a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5caa762-f5aa-4a69-a91c-cbc735cae31b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 349f4e62-5ccf-4d91-af8e-95dae09dcc82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0508f679-7834-4ece-8ce7-282d6b3d5493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38b1583c-2d38-46f4-ad82-2fc4536b29a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b47bbc5e-dc38-4b33-bad4-3551db234660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73ef24c7-b815-49ae-95c0-ac48282eba64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 804a7e75-4d1c-4d78-b5f1-fa7a46bf56be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0f2c89f-2d39-4d9d-92ea-84c45c5d51d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e73c6f6-7ab3-41c0-9f4c-2bea08447733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35d375df-d825-49a3-87bf-604c7e2211da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3bc09dd-7b7d-493f-a1c6-1fb79b455dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19bb77c3-8c52-4c67-9714-66611b40cf51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4629aa82-ff52-4635-b6b4-c6af5090da98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ae002cd-167b-4d7d-9167-04908f2449e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abf698d5-b0b3-4c2a-ade1-a838b410e820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2025194d-d839-4b58-bd44-451aee8038ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ff82e50-3206-4587-a5f4-902ed1cb65fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc9866ec-2c58-4132-bcab-dd22f3bece84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f45e7fc-651a-4557-8737-3d9acad85e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ef891a7-c21d-4799-9682-7e9ce9d89d1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aac465e-c6a2-4363-ad32-70db37839f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2551dca9-5bcc-4957-bc88-7e0e8865f1fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a060f19-da47-4ad0-8133-1b23e536652a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0317b99-1697-4c6a-b7ee-33b5a2bcb2f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a52d9d9-82ce-47bc-af6f-46c2f95e4987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1411f8b2-068c-48b5-95cd-d3eb61e4b6f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e29fd3c-e245-4c5d-9fed-665186acb0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be734f00-4646-477e-b774-7754aeda2fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2a13fd1-490f-45af-bc89-0437e19c6a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38081429-3430-4f4f-b0c0-978bf956e158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0edccb33-5a99-44db-a934-777f0cea9d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6763c0ba-51dc-4b22-b942-1a5012e542f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31746a52-f5e5-4acf-a702-275e98d12749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fabbc03e-010b-47ed-8cf6-e597783a45fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9906e216-b637-4635-9b66-8b3f3bb8942d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0bf3341-e147-467a-b749-1f9d5a9cc89a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7bd19cc-3ec0-4f8c-9f30-335d15ce8c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d608981f-1fbe-476d-9e22-58dc4da2c603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be428889-5f21-4d2d-a71d-9c57ad182e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12c6681a-0cec-46fd-a52a-bf9b73b16b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63face01-4c2f-4ec8-b9a2-00a3da194b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 394c044c-3ac0-41f6-84cc-1b0d8637546f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2df00239-47f7-4961-bc67-af0b40a3efd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fbe6099-50d8-45ac-9539-d93a93e17051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cef1efd-17cd-4a88-ba42-81dd5ca9ed63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68e3a055-f670-4b1f-9637-7bc15c3dabf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f7cec50-4432-4663-a215-57ac8bc3aec6
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_86
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/test_labels.txt

📊 Raw data loaded:
   Train: X=(698, 24), y=(698,)
   Test:  X=(175, 24), y=(175,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 689 samples, 5 features
   Test:  166 samples, 5 features
✅ Client client_86 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2555, R²: -0.0342

📊 Round 0 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2554, R²: -0.0229

============================================================
🔄 Round 6 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0812 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0882, val=0.0774 (↓), lr=0.001000
   • Epoch   3/100: train=0.0865, val=0.0774, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0855, val=0.0776, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0854, val=0.0774, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0826, val=0.0787, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 6 Summary - Client client_86
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0005
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0062
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2555, R²: -0.0251

📊 Round 6 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2558, R²: -0.0275

============================================================
🔄 Round 8 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0793 (↓), lr=0.000250
   • Epoch   2/100: train=0.0839, val=0.0795, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0836, val=0.0798, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0833, val=0.0800, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0830, val=0.0801, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0821, val=0.0805, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 8 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0094
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0015
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2564, R²: -0.0329

============================================================
🔄 Round 11 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0851 (↓), lr=0.000063
   • Epoch   2/100: train=0.0848, val=0.0850, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0846, val=0.0850, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0845, val=0.0850, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0844, val=0.0850, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0840, val=0.0851, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 11 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0181
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0042
============================================================


============================================================
🔄 Round 12 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0896 (↓), lr=0.000016
   • Epoch   2/100: train=0.0831, val=0.0897, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0829, val=0.0899, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0828, val=0.0901, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0827, val=0.0902, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0825, val=0.0905, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 12 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0163
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0255
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2567, R²: -0.0326

📊 Round 12 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0339

📊 Round 12 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0340

============================================================
🔄 Round 19 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0806 (↓), lr=0.000004
   • Epoch   2/100: train=0.0880, val=0.0805, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0880, val=0.0804, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0879, val=0.0804, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0879, val=0.0804, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0878, val=0.0802, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 19 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0159
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0313
============================================================


============================================================
🔄 Round 20 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 20 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0207
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0115
============================================================


============================================================
🔄 Round 22 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 22 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0179
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0238
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

📊 Round 22 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

============================================================
🔄 Round 25 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 25 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0215
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0118
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0337

📊 Round 25 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0337

============================================================
🔄 Round 32 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 32 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0200
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0140
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0338

============================================================
🔄 Round 33 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 33 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0185
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0233
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0337

📊 Round 33 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0338

📊 Round 33 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

📊 Round 33 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

============================================================
🔄 Round 38 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 38 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0197
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0200
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

📊 Round 38 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

📊 Round 38 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0337

============================================================
🔄 Round 44 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 44 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0096
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0638
============================================================


============================================================
🔄 Round 47 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 47 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0129
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0474
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

============================================================
🔄 Round 48 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 48 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0228
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0074
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

📊 Round 48 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0337

============================================================
🔄 Round 53 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 53 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0204
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0250
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

============================================================
🔄 Round 55 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 55 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0136
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0423
============================================================


============================================================
🔄 Round 56 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 56 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0206
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0218
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

============================================================
🔄 Round 59 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 59 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0256
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0061
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

============================================================
🔄 Round 60 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 60 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0123
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0490
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

============================================================
🔄 Round 61 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 61 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0081
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0579
============================================================


============================================================
🔄 Round 63 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 63 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0177
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0318
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

📊 Round 63 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

📊 Round 63 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

============================================================
🔄 Round 66 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 66 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0183
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0270
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

============================================================
🔄 Round 68 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 68 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0214
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0088
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

📊 Round 68 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

📊 Round 68 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

============================================================
🔄 Round 72 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 72 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0202
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0278
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0337

📊 Round 72 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0337

============================================================
🔄 Round 79 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 79 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0225
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0061
============================================================


============================================================
🔄 Round 84 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 84 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0264
   Val:   Loss=0.0915, RMSE=0.3026, R²=0.0003
============================================================


============================================================
🔄 Round 85 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 85 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0156
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0340
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

============================================================
🔄 Round 87 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 87 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0152
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0478
============================================================


============================================================
🔄 Round 88 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 88 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0188
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0414
============================================================


============================================================
🔄 Round 91 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 91 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0298
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0119
============================================================


============================================================
🔄 Round 96 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 96 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0168
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0290
============================================================


============================================================
🔄 Round 97 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 97 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0228
   Val:   Loss=0.0952, RMSE=0.3085, R²=-0.0105
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0338

============================================================
🔄 Round 101 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 101 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0187
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0381
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

📊 Round 101 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

📊 Round 101 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

📊 Round 101 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

============================================================
🔄 Round 106 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 106 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0190
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0257
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

📊 Round 106 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

📊 Round 106 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

📊 Round 106 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

============================================================
🔄 Round 112 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 112 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0177
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0519
============================================================


============================================================
🔄 Round 114 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 114 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0079
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0713
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

============================================================
🔄 Round 116 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 116 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0131
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0481
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

📊 Round 116 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

📊 Round 116 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0339

📊 Round 116 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0339

📊 Round 116 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0339

============================================================
🔄 Round 122 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 122 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0231
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0055
============================================================


============================================================
🔄 Round 123 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 123 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0143
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0401
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0339

📊 Round 123 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0340

============================================================
🔄 Round 129 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 129 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0258
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0095
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0339

============================================================
🔄 Round 132 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 132 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0248
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0002
============================================================


============================================================
🔄 Round 136 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 136 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0232
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0065
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

============================================================
🔄 Round 137 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 137 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0166
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0364
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

============================================================
🔄 Round 139 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 139 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0227
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0074
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

============================================================
🔄 Round 141 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 141 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0195
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0211
============================================================


============================================================
🔄 Round 142 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 142 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0142
   Val:   Loss=0.0773, RMSE=0.2779, R²=-0.0429
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0338

============================================================
🔄 Round 144 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 144 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0236
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0065
============================================================


============================================================
🔄 Round 145 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 145 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0132
   Val:   Loss=0.0975, RMSE=0.3123, R²=-0.0479
============================================================


============================================================
🔄 Round 150 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 150 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0183
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0259
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0337

📊 Round 150 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0337

📊 Round 150 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0337

============================================================
🔄 Round 153 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 153 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0260
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0064
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0337

📊 Round 153 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0337

📊 Round 153 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0336

============================================================
🔄 Round 159 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 159 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0150
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0571
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2569, R²: -0.0337

============================================================
🔄 Round 160 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 160 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0178
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0566
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

📊 Round 160 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

============================================================
🔄 Round 165 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 165 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0208
   Val:   Loss=0.0981, RMSE=0.3132, R²=-0.0158
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0337

📊 Round 165 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0337

📊 Round 165 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0337

============================================================
🔄 Round 171 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 171 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0103
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0641
============================================================


============================================================
🔄 Round 174 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 174 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0253
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0524
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0337

============================================================
🔄 Round 175 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 175 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0218
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0207
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0337

============================================================
🔄 Round 176 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 176 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0186
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0373
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

📊 Round 176 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

============================================================
🔄 Round 179 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 179 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0246
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0150
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

============================================================
🔄 Round 180 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 180 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0220
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0169
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

📊 Round 180 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

============================================================
🔄 Round 185 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 185 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0080
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0816
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

============================================================
🔄 Round 189 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 189 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0106
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0577
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2568, R²: -0.0336

❌ Client client_86 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
