[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09f30d2f-2146-4ae1-b1b8-211f35393e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df7c5095-db21-4367-b637-e0db73306b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a22de3b-4c0b-4a6c-9041-57ebda0fa17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dee76be-f3a1-45dd-80db-a98259060961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d073a72-5fb3-4f23-945c-50c7d1326629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82d2286e-0ad9-49c9-91d3-f1c8a11a604f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4af2c0c4-b456-476f-8c56-7644d3388366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c0de27-6651-4a67-83a7-794759e39d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19596511-f8c6-42a7-ac31-a5f48777cc96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf5515d7-88c0-4416-8d54-42888e3860b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c002c767-fec2-4454-934e-10953fbc6b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32d461dd-9f6f-48bf-8368-64c2fb33b32f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 404b9760-1b32-4354-9b37-4cc680dc46cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5895d192-0896-46f8-88ad-09821a148971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d48c3cbf-a0bf-4d02-b601-139419c1c391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a7e79b4-8fc4-4067-be07-3ee8d1152735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7f75527-c020-4231-bbc0-ed64b76ecc5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0649664-59b9-4e42-b54e-3e1acde10058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c00adcf-db98-4f49-bf14-b133ae71c477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53f43849-d4e7-42b0-9af3-aa6fb9e9493a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a780c7ad-dd18-4136-b3a4-d7873b5e310b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc76ab89-21e9-4a8c-a831-3d393c69f3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2237ddc-7e78-429c-96f0-34143ab94d0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50695d42-f462-4cc1-a845-cae31f2206fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2fa3fb3-0e21-40bf-9010-4aeffb96d153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 824d04df-ab01-4136-949a-a2265676e580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8918bc3-8eac-4695-b783-69b3c64e4020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 979b01fc-34e3-4d73-944f-e41350f55490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 230bd3ab-cfec-40ef-94c0-caecf94fc6dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8368f21-7c99-4cb2-8c1e-6f21a46cffa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95217436-ecc3-4ecb-9626-edadc6a0ca39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b35b987-3ff5-454d-81dc-ee1963e462a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f194ff14-9792-42db-b1e3-78cf20c5b87d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 869bb29e-74d8-4949-8e01-94cb475b6be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c80c92df-df23-4237-9c0c-eec97e963bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d792d998-86c1-4670-8b41-1f74cb685e3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5efaf45-cfa4-4b81-8f8b-3c41bad27ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee3d9a26-8ba9-4dd4-917b-05fdaa287b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2127920a-8481-4906-b4a1-16ec9bf4d149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48b1fe60-7a9c-4bd5-929a-4daabe972ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99a18d01-c342-4aab-90fb-c3016b4ac895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c3982de-b5cf-4d71-95a2-bb352b7cbb33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f582940d-7eef-4b32-81c9-3ed60850a1ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1447487b-6afe-47cd-b2f1-0a537e1208ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 880932de-f459-4fc7-9484-2cab156a410c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e8e14fa-da53-4870-9400-b6716ea51671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95a56aff-f69f-427c-83eb-83246d33dcea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2378f52-bec7-4cf8-8cee-a00f62947110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bea521ed-a27d-4643-9ec5-5a4dcc76032a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19dd366e-86ce-4a29-97d2-4b0154790e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fae09a6-cfab-4073-a1bb-f1f11bdf89d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b161c06b-5a11-40ab-917c-f90b69f1ab95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69978ba1-a01a-47dc-99cc-9e84a3d4b768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e5b0d7d-8d4b-4be0-ae51-6fe8be12e9f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b79e519b-dace-4687-a94f-56b67170df74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b50b4e6-206c-4449-b2c2-9eb52d1a0cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7afe8cb-b075-447c-8c4e-cd7290ddd050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab4e46ce-87e9-4813-bf8d-37ae74a1275c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2919756b-ad3c-41a6-a0ab-dcf28de676a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f631acb0-adf6-42ef-b2c8-f356aff85284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3105e3b2-0b4c-4ffe-b41d-eb66907d306b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa8471f5-d540-4501-9ec0-9a109bd7cf04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06083f31-e5e8-479d-a0ab-0df9627eee57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce89cefa-7946-466b-a438-c74928e54c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80421b6e-debb-47ec-92ab-861efe12a1ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8286262-cab9-46a5-bbf7-a5ca7e803ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 741274f6-66ee-474e-88a7-6e7fcd091411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fb29210-6b03-46fe-97fc-6d0981c4dff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc601207-a3ee-4f22-a8b4-0808044a4506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce2d09c9-b155-44c2-93cf-5487ab006c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d087e79-79b3-4e9b-93c1-5e30fb29d723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bea7d2c-4f33-4b77-9489-efd3c54cc36d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c432cdd-7052-4adf-b08e-b34fc4da0e4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53f6b50b-3256-4a87-9e34-ba6513c3cc1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a5c404c-c9a6-4e16-a56e-198075cddb66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c573d75-716b-45b1-a3f1-67863db41630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8b258f4-c0bc-43d6-9c5b-12c24ac93908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53a2b8e5-af54-47ac-ac14-0431dc281767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b35595e0-9f4f-4e65-a318-e59751998359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dde8680-5778-4a2f-9971-1c0648dac48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b86bb706-2f73-41b4-9d2e-46e559fc4973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb2385e-71ae-4e2f-bd53-fa276da950a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0758fcc6-1d4d-4130-9250-936bd96bed60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84eca529-d844-4c95-bbe4-4cd244c08fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba7c8172-99ba-4b66-9f0a-655170750b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8add2088-9f6a-4d25-9be1-1de5f7995beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaefd2d4-cb67-440d-8ba7-3ead0bcec4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 649c7312-5fbd-45cd-b0ef-e509eacf2c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e1ed9af-0644-447d-ad60-b840ca2e0f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d057577-a4db-4f69-a02f-f1a0723cbb19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72b12ada-3ef1-4e68-b244-826d6ab0c831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a945e92-483b-4e24-a291-51740d184af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d55b5ce-33dd-432e-9741-8be87b38ae8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b4909dd-c09f-4b9f-921b-333d698fb895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38cba77c-f16c-4949-bad1-a3455b03dcbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d12437d5-1973-4b67-af49-86b5385367d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fbd68ae-54d6-4c9d-b680-26d98cc9c3d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a9a25c4-3d18-4066-a74b-9ada6e7f18a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af89c3d5-b2a6-498c-8968-fa8963465ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9179ed9-8bbf-421a-9d86-ee7d0d8e0942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3baef09c-8e7c-4916-a446-85c7ba26ad09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e786bf0-1cde-4b18-9ea9-4194fafc85dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b93e0c7-b8c5-45e7-9257-2c1036456436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d01edbc-3087-4ae5-8ff9-65d2d78ffc1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf90a26-7b96-454d-8b31-08d6dbaef635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50cac896-54ee-4bc8-b331-f0d15f8b6096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7af0113d-4640-47f2-8a69-0a2755e4049f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c71c546-d278-4d50-9613-bbaf82a20af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97b92718-750a-43cc-a4ea-99fd584466b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5afcfdbd-c51e-4f8c-8e37-6163ccb805a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9558d647-c372-4aca-9dd4-58f50fb0ee5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2f7e049-ba59-42fd-adf5-74608e3a66be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3412eb3b-a747-458e-a014-aadc2a5d1e10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9b1861e-efce-42f9-a05c-fce412c022b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c625180e-82fe-4bcf-ba59-3b2038a8504d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0bc10ce-54a1-44d6-9c77-a094c6628b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de5cde27-24ae-4d00-989c-c8cfe39927c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d593da4-7fe1-4e5e-8306-abd7a7ee8940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aef138e7-06ef-4c81-a305-5694e646699f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df8b2ccd-3d78-4cb9-b5cb-c9749967cd17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46138fca-c357-4828-a166-7962469bf48b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc417c42-f20e-4bd9-8370-4f8c4d434f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0936a3dc-8257-4b65-b1a1-2c9cd43c42af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 855a1b8e-fcf5-401e-8dec-4a75e12c0254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5fcb62b-a4c8-4ff2-9fc6-134e623cae33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3153a32f-3841-4848-9432-66bb5dae1ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f86cb098-8583-4d21-a62b-a0ba76a5ee48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f317781-f742-487a-bf54-e66954d6a821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac2c9745-a7e0-499e-8ce5-8728bdcb2bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf7f01c2-8d48-4230-9ef0-11ea5994f894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12576719-dc9f-4f9f-9ea3-350e1a7ba9c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a279fc20-1175-4952-a9da-b3f3a8d53c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32cf91d1-53e9-42eb-9428-d8f66d4ebab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c5dd16c-4108-48d0-9cc8-796d4a989aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb65dc47-2912-4616-8215-84a05a15d129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 465fecd8-3a09-4694-9af0-0059d0ae8468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e62d506-6bbc-4c03-9fec-f5ddbb0ae00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16fa03e8-336a-4023-8a04-499e55335f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 508401a0-2547-42fa-8b06-d1811624f601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b5888cd-784b-45f1-9229-f8d90db22dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afbb3189-916e-4a49-8b0b-3b2604061a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 306fb700-953e-4699-a8bc-a97cb53404aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fef6e842-6d4a-47db-8fee-db3c3a687fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e908d179-8099-4289-bd1f-fe43a7bf0252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89446d90-eaa3-4b28-8df0-bad9fd063cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8aa0afd-0968-45ce-9e30-b40b265adfa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04202012-13e3-4b31-9f25-3e8d7e07f457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f6ba1f7-0b70-49ed-8c71-a672a11a2633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 731688ea-39c1-4e53-9f7d-8b27d64fcb62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b63cd961-2f4f-4067-aa09-885b2dc02443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 669c8f77-f58f-4ed2-82d7-ede011f90f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 206a31ab-0696-4c8b-b5d1-d7b09a240c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ce70973-49e5-4533-a309-f878deea3503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d60d78e1-73d2-4422-9f27-57626d3fccd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6f812a8-d4d2-4626-9ada-5afba1fb591d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcb43ddc-84ee-4131-8f0d-f8d952581599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c89b616a-8750-4de1-a784-3713ae077bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41f9c2e0-f24c-40e0-881a-366eb05704cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca7e5f62-c83a-48e3-9056-e7ee9398d7fb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_87
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/test_labels.txt

📊 Raw data loaded:
   Train: X=(1701, 24), y=(1701,)
   Test:  X=(426, 24), y=(426,)

⚠️  Limiting training data: 1701 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  417 samples, 5 features
✅ Client client_87 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0802 (↓), lr=0.001000
   • Epoch   2/100: train=0.0822, val=0.0808, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0820, val=0.0810, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0818, val=0.0810, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0817, val=0.0811, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0806, val=0.0822, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 2 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0051
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0023
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2485, R²: 0.0063

============================================================
🔄 Round 3 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0849 (↓), lr=0.000250
   • Epoch   2/100: train=0.0805, val=0.0849, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0803, val=0.0850, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0802, val=0.0850, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0802, val=0.0851, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0798, val=0.0853, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 3 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0021
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0038
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2479, R²: 0.0106

📊 Round 3 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2471, R²: 0.0165

============================================================
🔄 Round 8 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0818 (↓), lr=0.000063
   • Epoch   2/100: train=0.0808, val=0.0819, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0807, val=0.0821, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0806, val=0.0822, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0805, val=0.0824, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0802, val=0.0830, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 8 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0104
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0032
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2471, R²: 0.0162

============================================================
🔄 Round 9 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0768 (↓), lr=0.000016
   • Epoch   2/100: train=0.0821, val=0.0773, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0818, val=0.0778, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0817, val=0.0781, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0816, val=0.0784, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0814, val=0.0790, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 9 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0048
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0162
============================================================


============================================================
🔄 Round 10 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0866 (↓), lr=0.000004
   • Epoch   2/100: train=0.0800, val=0.0865, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0799, val=0.0865, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0799, val=0.0865, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0799, val=0.0865, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0799, val=0.0864, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 10 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0038
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0161
============================================================


============================================================
🔄 Round 11 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 11 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0090
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0060
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2467, R²: 0.0202

📊 Round 11 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2466, R²: 0.0206

============================================================
🔄 Round 13 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 13 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0097
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0241
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2466, R²: 0.0207

============================================================
🔄 Round 14 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 14 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0024
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0127
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 19 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 19 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0086
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0220
============================================================


============================================================
🔄 Round 20 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 20 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0084
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0031
============================================================


============================================================
🔄 Round 21 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 21 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0019
   Val:   Loss=0.0699, RMSE=0.2643, R²=0.0011
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 21 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 25 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 25 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0049
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0149
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 25 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 27 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 27 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0118
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0133
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 29 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 29 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0049
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0171
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 29 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 29 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 36 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 36 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0094
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0014
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 36 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 41 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 41 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0020
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0165
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 41 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 43 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 43 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0136
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0375
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 44 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 44 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0054
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0051
============================================================


============================================================
🔄 Round 45 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 45 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0042
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0037
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 45 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 45 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 45 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 51 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 51 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0077
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0013
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 52 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 52 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0030
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0270
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 57 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 57 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0105
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0060
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 59 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 59 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0113
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0438
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

============================================================
🔄 Round 60 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 60 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0145
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0203
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

📊 Round 60 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 66 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 66 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0114
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0200
============================================================


============================================================
🔄 Round 67 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 67 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0043
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0229
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 68 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 68 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0096
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0030
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 69 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 69 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0041
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0123
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 71 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 71 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0039
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0243
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 75 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 75 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0137
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0198
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 75 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

📊 Round 75 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

============================================================
🔄 Round 80 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 80 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0084
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0045
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2465, R²: 0.0216

============================================================
🔄 Round 81 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 81 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0078
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0033
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2465, R²: 0.0216

📊 Round 81 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2465, R²: 0.0216

============================================================
🔄 Round 84 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 84 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0038
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0201
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2465, R²: 0.0216

📊 Round 84 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 88 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 88 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0131
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0324
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

📊 Round 88 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

📊 Round 88 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 95 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 95 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0043
   Val:   Loss=0.0939, RMSE=0.3064, R²=0.0115
============================================================


============================================================
🔄 Round 96 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 96 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0065
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0114
============================================================


============================================================
🔄 Round 97 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 97 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0109
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0149
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 100 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 100 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0076
   Val:   Loss=0.0671, RMSE=0.2590, R²=-0.0063
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 101 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 101 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0002
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0353
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 102 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 102 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0103
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0054
============================================================


============================================================
🔄 Round 103 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 103 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0126
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0244
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 106 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 106 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0085
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0027
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 106 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

📊 Round 106 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

============================================================
🔄 Round 110 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 110 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0059
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0121
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

============================================================
🔄 Round 112 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 112 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0033
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0273
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

📊 Round 112 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

📊 Round 112 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

📊 Round 112 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

============================================================
🔄 Round 117 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 117 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0021
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0216
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

📊 Round 117 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 117 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

============================================================
🔄 Round 125 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 125 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0089
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0233
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

============================================================
🔄 Round 126 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 126 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0073
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0003
============================================================


============================================================
🔄 Round 127 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 127 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0055
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0163
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

============================================================
🔄 Round 128 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 128 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0111
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0055
============================================================


============================================================
🔄 Round 129 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 129 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0085
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0037
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

📊 Round 129 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

📊 Round 129 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

============================================================
🔄 Round 132 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 132 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0102
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0183
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

============================================================
🔄 Round 133 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 133 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0060
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0081
============================================================


============================================================
🔄 Round 134 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 134 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0060
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0057
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 138 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 138 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0081
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0038
============================================================


============================================================
🔄 Round 139 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 139 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0060
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0049
============================================================


============================================================
🔄 Round 143 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 143 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0035
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0239
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 143 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 147 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 147 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0006
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0269
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 147 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 147 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 147 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 156 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 156 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0099
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0244
============================================================


============================================================
🔄 Round 157 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 157 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0044
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0209
============================================================


============================================================
🔄 Round 158 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 158 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0081
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0029
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 159 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 159 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0028
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0201
============================================================


============================================================
🔄 Round 162 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 162 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0060
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0038
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

📊 Round 162 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 169 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 169 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0077
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0063
============================================================


============================================================
🔄 Round 173 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 173 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0104
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0223
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

============================================================
🔄 Round 174 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 174 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0102
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0036
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0216

============================================================
🔄 Round 177 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 177 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0091
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0016
============================================================


============================================================
🔄 Round 178 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 178 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0097
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0099
============================================================


============================================================
🔄 Round 179 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 179 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0096
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0341
============================================================


============================================================
🔄 Round 180 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 180 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0101
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0038
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 181 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 181 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0074
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0007
============================================================


============================================================
🔄 Round 183 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 183 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0065
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0110
============================================================


============================================================
🔄 Round 184 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 184 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0158
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0411
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 186 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 186 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0073
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0019
============================================================


============================================================
🔄 Round 187 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 187 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0101
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0024
============================================================


============================================================
🔄 Round 188 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 188 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0122
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0172
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

============================================================
🔄 Round 189 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 189 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0064
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0116
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0215

❌ Client client_87 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
