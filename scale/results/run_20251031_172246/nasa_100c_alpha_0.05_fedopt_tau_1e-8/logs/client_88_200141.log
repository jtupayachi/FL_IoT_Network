[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fc56162-35ca-4d76-a9f6-dcfa28db4540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 924acdb7-9328-4d75-843a-98ca21405de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a649ea5-4c67-480d-8250-561d4771e1ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31819ad8-9347-4ff2-bad6-121498f6ed0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e47d047-6197-45e0-9379-a80525e15837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 135cc1a9-3a67-4e5e-94a0-a2bde66e3ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bc85114-2374-468b-a902-0511f939985d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0579309-b047-4636-a699-a5e86ea06a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a00dea0f-e3ab-44b5-b64d-0d39c8d33c9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec85c40-c73f-468d-a02e-4526d627438a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b8b30d1-a040-4236-9b30-f6e0850b6143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 234140dd-e29c-4281-8ff7-51f16bed2c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c817e23-d424-49b6-9304-ce35b16df82f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc37743-9ca8-4a24-a9a4-39edc721c019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b7a7113-5a7c-4a41-b2d4-44eba1008427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7abb0e21-9cf4-4b36-984e-e04e99b55834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9c2dc5c-827a-4a0b-9f19-01c32e4c2715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a4b9d6c-85ef-4c78-80ce-90a339736394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1895b105-ca2d-439e-b84f-0dd7bdf012af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b32fc6e-b903-4b58-a16e-a44cf915b912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1202a51-89c6-495f-bf03-40ea4e985d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6d7dd95-70d5-4795-a75f-71ca5e7c5b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5e7b632-bf82-4ba6-9651-55f01642a3a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f03848e-301a-4bd4-8514-b9e57a73ab68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd502fee-b269-4014-8c1a-5825ff41862d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd12d179-95bf-40b3-bd95-c25a8cd42426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d5fff28-746d-4398-b2fc-47c7fa15367a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a26fa89-8fdd-4689-a824-0c5ab81e5c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e046db5-880c-4a97-9cc0-6289328b190c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a858586-6a1e-4b6d-9437-98b7587b1b17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b5f40b5-c04a-42b1-a27f-8baec0745c56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c14880be-4d30-43b3-add3-32ef3fe3ece2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 150547b4-6cea-4b67-8438-2827d16d7116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04e61e74-0a1a-4dca-9b8b-2829a4a05d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67f7114b-64fc-4d45-b33f-03b2821b6824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 153a174b-09bb-48cd-ad7e-99b29a4c9088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c798ff0c-ec5b-4fff-87ff-cf99da0e4c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 597ed8bb-a67c-490c-9085-d7e4607d92ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 730c110c-36b2-4034-9bdd-06ce3aa161ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13939f61-1306-4f39-bdae-5e074eb87f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6abee323-ca11-4ccb-966c-4422a96b589e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5687e766-7eb7-497b-90d7-61ffabf1879a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a975a28a-022c-4091-9d80-e7ec10f80ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a9c1ffd-3731-4568-83fa-3325b254933d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8558a9b4-d7ea-430c-ade3-7aed5001c0ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7b4d210-9414-4f97-9890-b366cb61ad64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b4d2463-ae0d-4ade-9cda-7437808c8528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89c0dc93-2d33-4e96-8841-e92eaf063b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eabb7391-b351-4683-8904-c693bf6216ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14034ded-3282-4e6b-9852-3ab9897094f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8a8ce34-63d1-4536-9274-e3744a3a250c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e964446e-2897-42ff-bd42-211090075e4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e83e086-28b9-4265-9e00-d2c8ca96eb23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f450265-1938-4f4a-9070-dcd340c65489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fed5b1d-3704-4b42-9c8c-570bbd8f87cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e88b958b-88b2-450d-93a0-485b2e635e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 976944d3-c4a2-4c96-be86-fff390552f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77e9ccbd-45ff-4fdd-b740-0f779585334d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42cddbbd-7a55-4f06-94e5-3dd1b29469a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6012322-8dde-42d1-b23d-bb20e9e66100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ba03f29-9075-47db-b9fc-f786acafba1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22c7d81b-d9e1-4c7d-9a34-68c4b6b56c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62a98fb5-f1d5-4892-b702-2baa4390d113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 998cac83-cf5d-4085-880a-aab58da3880d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7dee94c-2521-4241-a606-009de8508675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f25ece42-f7f3-46a8-9e49-7f00ce6d672a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 658e6f9c-03d2-4ec8-b7e7-b5ad58577436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d8127ef-9ea4-4c5c-856c-a961bce70fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3b9e01a-5837-44f4-8e49-6ecabe0f21bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7adc104-72ec-426d-b578-a7538e19745a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70b1b0d0-12ed-49d6-950c-110e56ece36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bc6f9dd-8e8c-4975-ae30-adcfd4a6b171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bab7b5a8-7585-499e-a149-833d06e4ca4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a38d4e54-5421-44ac-9cc8-00f833db32c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00aafbac-4753-48bf-b86e-534fbe3c25aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 543e3a6a-89ce-40a3-ab7e-3b5839722751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58f439f2-afdf-44ff-b58a-b8c7cf969ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fe0a1bb-4223-4383-b657-f5fed0a9348d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 127cadee-7fe5-42c9-bcd0-98a7b0daaee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 489f5ccf-fbec-4c5a-9c02-fca49827b26f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3756c41-1db4-4270-984e-34bd0397307e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 081a1c6f-1c7b-40b4-8523-4ef53b4430b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44999f6b-ce5d-404b-85d1-f33df71ade87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b9d8a76-587d-4a7f-b454-a315e0b47454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d7d5f4e-d45d-4460-9ff3-fd4d48bd66cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6225b4be-2ade-4035-8b4f-d958cebd343e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05848df7-1b1b-4c1e-8ff9-feee9ae1af79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ab62afd-19cd-4ac5-8317-f6580e3555b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5fd3a5e-08a7-4bc3-89d9-b110848a2373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87f4cd23-c90e-4a25-aaff-60543c5f98e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b5ada91-0856-40c3-9089-4811823ef810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61489015-cdb7-40c1-98d2-8428def684bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0b19cf3-86dc-42ec-9a5b-f430e923c7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd4f4c29-dfbc-455e-ab41-8a761ef9ddff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1aaaf78-b47e-481c-8f6c-226e173d55e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98ccdba5-12b7-4e8d-8226-44495ae23d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fc39d28-3863-4d8c-8439-86658aa95421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df320ddc-947f-4184-b54e-8923c16518f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b934593-bd0f-46b3-9cf0-4fa54e587b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e385eee0-12a0-42d7-9547-a5c35db28b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdc4235c-d3f3-47ac-a606-7c14993f70a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af416fa1-469b-46fb-b556-41901cb84644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0e75ff8-897f-4358-94c1-909bde111122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7c94f8a-bd51-4f26-873a-42c70d5bf946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6625a018-0bd2-4665-834d-4762908ee9cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a5e8f2a-dceb-479f-8c9a-96f6b166cca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 428b5982-f5d6-4283-9eaf-bc1df1bf1f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0620846-16d8-4a68-925d-927bd55a52cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 592de785-c0a9-49cb-bcdd-217c11e62b6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91a5d10c-e595-45e8-92b2-4662f5959cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 101c7f6d-e97d-476b-a324-a96f4db3b246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec213fe8-414e-4001-832e-b490eb266c59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a969cb4-f84e-45a9-b407-b8b6578b5419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e523a0cf-93f3-48b5-87e9-eac857d9788a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9a0a09b-3a15-467c-857c-012a938097d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2007da33-1d3f-4b2c-b376-1ecb76151ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a25d734e-9fca-4013-b2fa-d0a26e2fb4bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc9c00a8-2142-4835-99e1-9759ead4b539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce82b8b9-ed18-45aa-b00a-72e576f98759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d0e011e-0e7a-4f4d-8c9e-28f754dbf999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c65c0f7b-39c0-4ee2-9c28-933027b9b038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12bbe492-351c-4f6f-aaa1-a30e362c594e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1983857b-e141-4c89-b54a-7f2b0edec11a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f702948d-e506-471f-81d9-e90982216fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aa11f17-611f-4bdc-b7ae-ae00815e9a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa48b271-1fe5-4b8d-ad99-85968cc1c4f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bf13526-7f7d-4b39-b0d5-9b97c5df464d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 249494ad-6776-4431-8736-27903b694175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ce4b7e0-91f7-43d0-ab9f-195526c154f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c0f3981-d019-4e9a-9c92-931a43cf6745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab44bf8e-e2ed-4427-b93e-12f1211b66f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcdfde7c-5555-4213-b8b0-0c4b20ff2c25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a31a2f96-8f31-4daa-ac6e-35919930e4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f39ab5d-454a-41f9-981f-5b53e4d23e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5934aef-192b-4ebd-883b-5f585c0b0712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e807779f-a650-4c47-93a8-64fa4585fc09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12e5b901-d3c6-49f3-b643-818afafad420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab8ba54a-6c53-487d-9ddc-291cd37c6000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cb0aa9a-473e-4791-9a31-6fa0ee3655fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a89ebb59-e20c-4222-99f7-ed79ad38abd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b86b6522-8bd0-4cb6-8960-95eee3db2b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45a9eea9-cb2e-4cbd-a134-c41b5d25e42a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f99e974d-64d4-417d-903f-d8bf96abdb9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe693bc8-6fc6-4a38-853d-f45c113cbc51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe7ee7e5-55fb-4963-bd97-0347aff9723a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9140d2cd-73cc-4eb4-af2f-951068f4ca15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2d0d54c-1052-44e6-967d-ee0d08c76181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c411f04-efd2-44b8-adf3-6197938f00da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b3627da-7aa6-4579-a342-dbc9ddfa4035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41a33204-bf9c-4985-a6be-2562b63763b7
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_88
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_88
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_88/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_88/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_88/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_88/test_labels.txt

📊 Raw data loaded:
   Train: X=(1537, 24), y=(1537,)
   Test:  X=(385, 24), y=(385,)

⚠️  Limiting training data: 1537 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  376 samples, 5 features
✅ Client client_88 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2572, R²: -0.0152

============================================================
🔄 Round 6 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0714 (↓), lr=0.001000
   • Epoch   2/100: train=0.0839, val=0.0733, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0839, val=0.0728, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0835, val=0.0730, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0832, val=0.0728, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0814, val=0.0732, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 6 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0061
   Val:   Loss=0.0714, RMSE=0.2672, R²=-0.0304
============================================================


============================================================
🔄 Round 7 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0819 (↓), lr=0.000250
   • Epoch   2/100: train=0.0822, val=0.0816, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0820, val=0.0815, patience=2/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0817, val=0.0814 (↓), lr=0.000250
   • Epoch   5/100: train=0.0816, val=0.0813, patience=1/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0810, val=0.0811, patience=7/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 7 Summary - Client client_88
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0014
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0107
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2575, R²: -0.0196

============================================================
🔄 Round 12 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0814 (↓), lr=0.000063
   • Epoch   2/100: train=0.0833, val=0.0813, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0831, val=0.0812, patience=2/15, lr=0.000063
   📉 Epoch 4: LR reduced 0.000063 → 0.000031
   • Epoch   4/100: train=0.0828, val=0.0812, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0827, val=0.0812, patience=4/15, lr=0.000031
   • Epoch  11/100: train=0.0822, val=0.0811, patience=10/15, lr=0.000031
   📉 Epoch 12: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 12 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0152
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0166
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2571, R²: -0.0194

============================================================
🔄 Round 17 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0852 (↓), lr=0.000016
   • Epoch   2/100: train=0.0825, val=0.0852, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0824, val=0.0852, patience=2/15, lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   • Epoch   4/100: train=0.0823, val=0.0852, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0822, val=0.0852, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0820, val=0.0853, patience=10/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 17 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0232
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0041
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2571, R²: -0.0193

📊 Round 17 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 21 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0820 (↓), lr=0.000004
   • Epoch   2/100: train=0.0837, val=0.0820, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0837, val=0.0820, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0836, val=0.0820, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0836, val=0.0820, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0835, val=0.0819, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 21 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0222
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0129
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 22 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 22 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0257
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0035
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 23 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 23 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0206
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0302
============================================================


============================================================
🔄 Round 24 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 24 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0150
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0656
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

📊 Round 24 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

📊 Round 24 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 28 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 28 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0239
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0113
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

============================================================
🔄 Round 35 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 35 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0242
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0121
============================================================


============================================================
🔄 Round 36 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 36 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0250
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0032
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

📊 Round 36 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 39 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 39 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0198
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0291
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

============================================================
🔄 Round 40 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 40 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0178
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0626
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

============================================================
🔄 Round 41 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 41 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0226
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0145
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

============================================================
🔄 Round 43 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 43 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0263
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0180
============================================================


============================================================
🔄 Round 45 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 45 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0208
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0190
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0190

============================================================
🔄 Round 47 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 47 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0236
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0066
============================================================


============================================================
🔄 Round 48 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 48 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0220
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0244
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

📊 Round 48 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

============================================================
🔄 Round 56 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 56 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0206
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0270
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0190

📊 Round 56 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0190

📊 Round 56 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0190

============================================================
🔄 Round 59 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 59 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0188
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0277
============================================================


============================================================
🔄 Round 60 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 60 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0187
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0309
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0190

============================================================
🔄 Round 61 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 61 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0158
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0413
============================================================


============================================================
🔄 Round 62 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 62 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0181
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0288
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

============================================================
🔄 Round 66 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 66 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0178
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0383
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

============================================================
🔄 Round 67 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 67 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0193
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0286
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

📊 Round 67 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

📊 Round 67 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0190

============================================================
🔄 Round 73 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 73 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0232
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0104
============================================================


============================================================
🔄 Round 76 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 76 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0262
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0029
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0190

📊 Round 76 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0190

📊 Round 76 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0190

📊 Round 76 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0190

📊 Round 76 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0190

============================================================
🔄 Round 82 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0982 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0982, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0982, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0982, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0982)

============================================================
📊 Round 82 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0167
   Val:   Loss=0.0982, RMSE=0.3134, R²=-0.0327
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0190

============================================================
🔄 Round 86 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 86 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0197
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0278
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 87 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 87 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0223
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0421
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 88 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0981, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0981, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 88 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0163
   Val:   Loss=0.0981, RMSE=0.3133, R²=-0.0391
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

============================================================
🔄 Round 90 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 90 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0182
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0339
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

📊 Round 90 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

============================================================
🔄 Round 95 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 95 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0201
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0221
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

============================================================
🔄 Round 96 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 96 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0165
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0440
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0191

📊 Round 96 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 100 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 100 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0179
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0308
============================================================


============================================================
🔄 Round 102 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 102 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0195
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0334
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 103 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 103 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0227
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0430
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 104 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 104 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0191
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0277
============================================================


============================================================
🔄 Round 105 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 105 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0171
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0410
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 106 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 106 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0181
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0303
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

📊 Round 106 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 111 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 111 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0183
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0314
============================================================


============================================================
🔄 Round 112 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 112 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0215
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0260
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 114 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 114 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0129
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0529
============================================================


============================================================
🔄 Round 115 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 115 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0200
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0239
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

📊 Round 115 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 117 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 117 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0246
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0246
============================================================


============================================================
🔄 Round 118 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 118 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0243
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0038
============================================================


============================================================
🔄 Round 119 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 119 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0319
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0104
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 120 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 120 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0169
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0417
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 122 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 122 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0193
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0249
============================================================


============================================================
🔄 Round 123 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 123 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0228
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0122
============================================================


============================================================
🔄 Round 124 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 124 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0222
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0238
============================================================


============================================================
🔄 Round 126 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 126 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0195
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0249
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

📊 Round 126 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 129 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 129 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0225
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0205
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0192

============================================================
🔄 Round 131 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 131 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0176
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0627
============================================================


============================================================
🔄 Round 133 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 133 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0209
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0217
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0194

============================================================
🔄 Round 136 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 136 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0186
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0271
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2571, R²: -0.0194

📊 Round 136 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0194

📊 Round 136 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0194

============================================================
🔄 Round 149 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 149 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0194
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0365
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0195

📊 Round 149 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0195

============================================================
🔄 Round 152 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 152 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0175
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0311
============================================================


============================================================
🔄 Round 158 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 158 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0215
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0158
============================================================


============================================================
🔄 Round 159 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 159 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0244
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0097
============================================================


============================================================
🔄 Round 161 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 161 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0165
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0440
============================================================


============================================================
🔄 Round 162 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 162 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0245
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0105
============================================================


============================================================
🔄 Round 164 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 164 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0206
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0277
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0194

📊 Round 164 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2571, R²: -0.0194

============================================================
🔄 Round 166 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 166 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0220
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0171
============================================================


============================================================
🔄 Round 167 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 167 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0179
   Val:   Loss=0.0943, RMSE=0.3070, R²=-0.0292
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0193

============================================================
🔄 Round 171 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 171 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0208
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0185
============================================================


============================================================
🔄 Round 173 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 173 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0217
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0157
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0193

============================================================
🔄 Round 175 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 175 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0213
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0197
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0193

============================================================
🔄 Round 177 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 177 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0180
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0309
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0194

============================================================
🔄 Round 180 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 180 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0184
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0381
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0195

============================================================
🔄 Round 182 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 182 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0207
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0192
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0195

============================================================
🔄 Round 183 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 183 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0174
   Val:   Loss=0.0831, RMSE=0.2884, R²=-0.0480
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0195

============================================================
🔄 Round 184 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 184 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0129
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0782
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0195

============================================================
🔄 Round 185 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 185 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0210
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0226
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0195

📊 Round 185 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0195

📊 Round 185 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0195

📊 Round 185 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0195

📊 Round 185 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2571, R²: -0.0194

❌ Client client_88 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
