[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cdcaa9e-7123-4c57-bf5c-f7ea8591172a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f55d5cf-49f7-4265-8eb7-cbb8e8502735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ba3a20a-7a5a-4d19-810a-69aaa26974f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba373800-063d-41f3-97b2-e8990b71163f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8241a2b-3356-4a35-afef-edd81787f518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5ca80ab-c103-4145-8a43-942eae17fde2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80207a80-2901-42c1-a2a5-6a5429543ae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d26e5288-6088-4377-8257-59bedc745b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf9d0dd-c766-4c55-ab4f-59476161e49e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4e4de75-2416-4f48-9a9c-dcead9c4a5f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0ec1755-15f7-4673-abb0-3fc09b063a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ff47db4-4c96-4f50-896e-c14281c30236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 280139c7-8cbd-4a08-8a8e-81b35e263bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fee57711-adb5-4c7f-8027-0de5e3fbda11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c801be27-611c-4bba-977d-c321dfcb16ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8f4bb66-5d46-4f6e-9f37-0b344a495b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e695e0df-1c66-4767-9e64-85e0c64e368a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3a6ded9-4a4f-451e-8167-a08bca0eba3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2387a4c8-fc5d-4d32-867d-4c4e0f4e65b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5d9c908-1c3d-43ac-9beb-73793b957002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe3c32ec-fb30-4521-bf44-355de5600fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d6d0fd1-c4e3-49fc-ab03-3699c3192c59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29cff9a4-4848-4dbd-bf0f-f103943a9bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a33ea984-2857-49cf-8768-5b4b9d418312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 895ced20-e800-401e-9a31-02022b1b7063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8307e85-e7f2-4ca1-96cb-139a51b22915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f3369c1-9032-4f85-93af-591c363735cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70ebf45f-7ec8-4f52-a416-81f962ff1f7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c1db271-6f49-49e5-80da-ce50159f5ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcc1bb02-4e92-4767-8b8e-d51be8a94a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b42cc1f4-3310-4396-b160-f20d8f315704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a711aa7-064e-4464-95e3-f78e702e2386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64882689-1a1c-4fbd-984c-7710b4e6460e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25000f3b-20d6-479f-b3dd-5a965f1718ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e3c48d3-ae8d-4cfd-9531-4878f9cb386c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd03241-5e10-4955-8865-2cddf49ff517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f309d739-884f-4594-946b-a6585b0066d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a18c8c00-24c0-4f09-b06f-08a09cf0c693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d483c32-7622-4934-b1d2-6c3a57922c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca1b1b6c-3860-4567-b8b5-d42382edb597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4019a4fa-02e7-421e-948d-b27f2cee89fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b94ce249-bf65-4c03-b0da-05f340375632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83fefbfd-98fb-4696-a733-24245bfc4447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67156ac2-0923-4c8b-974c-f61dba0cac86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45905a71-8640-4cda-96f5-d335bc4276b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abd702d5-ee8e-4e57-a615-a6a78bbb5cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaf54bab-9e41-45d6-938c-b401180d7e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52fbdd21-1666-415c-b79d-2896534cb89c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e975b24-a6dd-4f75-a3bd-74df19dee11a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2b9e1b8-1236-473e-a10b-98703454fe38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e270194-f0bd-4e9a-8e73-d9b4c8987052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b5d643d-a9df-453f-8efd-f251cc8f62dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf936739-a46f-4b88-924a-d815f4f2307b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89058399-66a6-4599-a044-4bc6f27b2f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61df3800-b2a0-4575-ac26-c8c69aca0e45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8efd0d29-33dd-4f00-ab83-324b4c42154c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e347f20-622e-4c11-a1d5-02e33330833c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 907c3108-a88e-413b-98b6-3ea6bee49721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fac7710-2a65-4282-acf4-93e0c4d3800b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45ba303e-da7c-4994-893d-8c2934bf32ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb6c1723-6439-425e-a839-a2525f8c9720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b021791-dc3c-4498-9aee-ffe7414f3263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aff4f92-e1ce-46ae-80e7-90b3297c8982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e0afc2a-5ef9-4357-8114-a25f394041e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f2d1838-4c97-4dec-81fd-8c53a74b78d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75a56ee4-b744-4143-8120-043a8a522972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91f51722-9517-40eb-adce-c28bcda28abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dabcc84b-3048-40ad-9de2-5f5b5bd846cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ffe1922-5579-489a-a0dc-2aba6d450915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c551212-ab02-4fc7-8606-437f6d336c1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ad71c11-45d1-43fb-bf36-c980fba62db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7be770da-d7b4-484f-ba36-49e694cde032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 778f06c6-805a-490d-baaf-9a6780bca640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6582a7f2-bf8c-499b-8cbf-16dc8d904afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d81d80de-8e43-4f01-b725-676af86f9060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3a55117-2410-4e08-b7fd-fb135b4a4127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68aa852b-bcfe-4556-8af5-4b2ac3ec71c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c0b909e-fc6e-480d-8544-b0e87658ad4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 255dcbaf-43e8-4076-80bc-ab6493508da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 287a2231-f0e6-448a-86d9-1a20eca5540a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 809fb8c0-53e3-4e46-9f27-1a356bc54d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 203980b1-ef19-4648-a48a-13b74161bfbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e2af009-bded-4a89-b543-8b6c2e914a26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc2d3026-be00-4efc-855d-f86d2d3e6c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03f82c21-786e-4b7a-9be5-4aa156272fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 552c34e7-e9d5-48c7-beb1-1e2f13eb5752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c1f9c99-ecaf-4c82-878c-5c014c3ab943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3618da51-64e4-4e33-b79d-03c5e95cbbd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46373971-ec82-41fb-ad75-ab8fcdc8692a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c7df59-d7c8-4433-ba0a-be2b0332f43b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4f6d633-3ec2-4251-974f-8902d7f4c57b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 928e1359-71ef-43bf-b52e-0c3f03637a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 172ade64-da95-4930-b5da-50bc06323466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cb5b070-66c9-4c34-9592-9cd37ee6284a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39b84464-0031-406f-b84d-ee9cc0f52194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4357243-8e09-4cc6-8c81-0ac5285ed16b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddc4af38-5035-454d-a740-4e0a80d077b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59812b0a-95a3-4fb0-a394-98a08e56bed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d21fc06-38f2-4547-b7b8-0f26905722aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45ef204a-e9c6-4157-93cd-ac18fa180b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c45d630-ccc9-49af-b96b-88113963d8d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89559d21-40ac-419c-9bc7-3e2697d661b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46431a16-c1c4-474c-886b-d1da0e6ba110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ee8bcbd-5b13-4fc8-af09-46789dc173e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5531aff-f93c-4c11-9a5e-f2287a5b7f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 350944ef-e3ed-4d8d-8f4e-038750353633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6df6bccf-f573-41d8-bcea-0ee17d56f25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c641dcf0-4db7-4c65-bc07-1e56933957d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b13352-3d31-47c2-8d3f-860e59794cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b9f7c3-0a2d-4e5b-8818-9eda1cacd81f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40fc06ca-77ef-4a25-bf89-f3f9507aa578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd20073e-51e3-460e-a157-eaca2e6ee629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2817f57a-9455-406e-aa40-f0a24b5eb9e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abc50718-4c33-46f7-8416-411cb271a16a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 061831cd-a84a-4345-b66f-9ac9ded26d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e22e6ab-b685-4500-9946-ec4c2fc2f04f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e7b5bff-2d71-4c2a-80ff-b69052d50bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58b40403-ce8d-43a5-914b-bb588c15bf36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95d29a48-cf35-4b58-95a4-a069222210bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message def51163-f771-48e3-8c92-90376a1e05c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78183d6f-5472-4e31-a39b-65ac568aee1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68549109-28b5-4a8c-959d-5009697027fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc6a5a83-15eb-4041-983b-776f4338afe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f30064a4-cb62-4973-ba0e-002cd47d4ef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6d8b03a-68b6-4207-8049-d80781aa1a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daae49cc-d470-4eaa-8c51-ff1919867229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2e54b3a-8aa1-42ff-8f62-4d8071c07e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5e5a462-1755-4f98-9ecf-b145a4288734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 505630c7-1fca-4f37-a174-fcea530a83d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 653fee06-daa9-4440-b268-7de177462438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0900dc68-454b-4e06-9e3c-1d1d490802ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d3e6eb4-6b50-4c3c-b6e1-8ae1c63231d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf4b1b5a-eab3-4fff-9f4e-ef9f2fef252c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84029a5c-bfc4-4e87-894f-cb86a3754000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5775d11a-53e8-48ec-ab25-dea2311fd9a6
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_89
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/test_labels.txt

📊 Raw data loaded:
   Train: X=(1393, 24), y=(1393,)
   Test:  X=(349, 24), y=(349,)

⚠️  Limiting training data: 1393 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  340 samples, 5 features
✅ Client client_89 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0743 (↓), lr=0.001000
   • Epoch   2/100: train=0.0868, val=0.0755, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0858, val=0.0749, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0854, val=0.0748, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0853, val=0.0748, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0839, val=0.0747, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 5 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0011
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0113
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2581, R²: -0.0030

============================================================
🔄 Round 6 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0919 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0804, val=0.0906 (↓), lr=0.000250
   • Epoch   3/100: train=0.0802, val=0.0907, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0801, val=0.0906, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0799, val=0.0907, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0795, val=0.0907, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 6 Summary - Client client_89
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0031
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0589
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2583, R²: -0.0043

============================================================
🔄 Round 9 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0836 (↓), lr=0.000063
   • Epoch   2/100: train=0.0829, val=0.0837, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0827, val=0.0837, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0826, val=0.0837, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0826, val=0.0836, patience=4/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0823, val=0.0835, patience=10/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 9 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0130
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0188
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2584, R²: -0.0080

📊 Round 9 Test Metrics:
   Loss: 0.0861, RMSE: 0.2933, MAE: 0.2584, R²: -0.0086

📊 Round 9 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2586, R²: -0.0100

============================================================
🔄 Round 14 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0820 (↓), lr=0.000016
   • Epoch   2/100: train=0.0842, val=0.0819, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0842, val=0.0819, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0841, val=0.0819, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0841, val=0.0819, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0839, val=0.0818, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 14 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0178
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0292
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0862, RMSE: 0.2937, MAE: 0.2586, R²: -0.0108

📊 Round 14 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0110

============================================================
🔄 Round 19 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0819 (↓), lr=0.000004
   • Epoch   2/100: train=0.0842, val=0.0820, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0842, val=0.0820, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0841, val=0.0820, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0841, val=0.0821, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0841, val=0.0822, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 19 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0191
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0514
============================================================


============================================================
🔄 Round 20 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 20 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0261
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0070
============================================================


============================================================
🔄 Round 21 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 21 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0269
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0493
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0113

============================================================
🔄 Round 25 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 25 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0251
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0135
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0113

📊 Round 25 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0113

============================================================
🔄 Round 30 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 30 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0193
   Val:   Loss=0.0965, RMSE=0.3106, R²=-0.0299
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0113

============================================================
🔄 Round 31 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 31 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0199
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0279
============================================================


============================================================
🔄 Round 32 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 32 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0239
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0110
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0113

📊 Round 32 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0113

============================================================
🔄 Round 35 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 35 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0158
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0442
============================================================


============================================================
🔄 Round 37 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 37 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0217
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0372
============================================================


============================================================
🔄 Round 39 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 39 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0227
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0154
============================================================


============================================================
🔄 Round 42 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 42 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0252
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0082
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0113

📊 Round 42 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0113

============================================================
🔄 Round 50 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 50 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0207
   Val:   Loss=0.0724, RMSE=0.2690, R²=-0.0241
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0113

============================================================
🔄 Round 52 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 52 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0245
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0079
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0114

============================================================
🔄 Round 56 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 56 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0253
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0453
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0114

============================================================
🔄 Round 58 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 58 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0309
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0319
============================================================


============================================================
🔄 Round 60 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 60 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0183
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0341
============================================================


============================================================
🔄 Round 63 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 63 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0199
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0255
============================================================


============================================================
🔄 Round 65 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 65 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0158
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0554
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0114

============================================================
🔄 Round 66 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 66 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0203
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0241
============================================================


============================================================
🔄 Round 67 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 67 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0243
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0094
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0114

============================================================
🔄 Round 68 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 68 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0233
   Val:   Loss=0.0673, RMSE=0.2593, R²=-0.0112
============================================================


============================================================
🔄 Round 69 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 69 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0223
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0222
============================================================


============================================================
🔄 Round 70 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 70 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0183
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0381
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0114

============================================================
🔄 Round 71 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 71 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0159
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0447
============================================================


============================================================
🔄 Round 72 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 72 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0223
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0159
============================================================


============================================================
🔄 Round 74 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 74 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0154
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0461
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

📊 Round 74 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

============================================================
🔄 Round 76 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 76 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0298
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0167
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

📊 Round 76 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

📊 Round 76 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

============================================================
🔄 Round 80 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 80 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0240
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0153
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

============================================================
🔄 Round 82 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 82 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0166
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0384
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0115

============================================================
🔄 Round 85 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 85 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0170
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0403
============================================================


============================================================
🔄 Round 86 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 86 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0205
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0229
============================================================


============================================================
🔄 Round 87 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 87 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0217
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0297
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2586, R²: -0.0114

📊 Round 87 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

============================================================
🔄 Round 90 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 90 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0229
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0413
============================================================


============================================================
🔄 Round 92 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 92 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0216
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0192
============================================================


============================================================
🔄 Round 94 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 94 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0191
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0289
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

📊 Round 94 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

📊 Round 94 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

📊 Round 94 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

📊 Round 94 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

============================================================
🔄 Round 103 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 103 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0173
   Val:   Loss=0.0962, RMSE=0.3101, R²=-0.0340
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0115

============================================================
🔄 Round 106 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 106 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0198
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0565
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

📊 Round 106 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0115

============================================================
🔄 Round 110 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 110 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0245
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0089
============================================================


============================================================
🔄 Round 111 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 111 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0218
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0217
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0115

============================================================
🔄 Round 112 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 112 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0247
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0099
============================================================


============================================================
🔄 Round 113 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 113 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0226
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0168
============================================================


============================================================
🔄 Round 117 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 117 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0191
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0440
============================================================


============================================================
🔄 Round 120 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 120 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0254
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0172
============================================================


============================================================
🔄 Round 121 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 121 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0208
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0330
============================================================


============================================================
🔄 Round 122 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 122 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0231
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0171
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0115

📊 Round 122 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2587, R²: -0.0115

============================================================
🔄 Round 127 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 127 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0271
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0103
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2587, R²: -0.0115

============================================================
🔄 Round 129 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 129 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0176
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0365
============================================================


============================================================
🔄 Round 131 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 131 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0201
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0281
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2587, R²: -0.0115

============================================================
🔄 Round 132 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 132 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0163
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0466
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

============================================================
🔄 Round 136 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 136 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0215
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0202
============================================================


============================================================
🔄 Round 137 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 137 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0177
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0409
============================================================


============================================================
🔄 Round 139 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 139 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0222
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0302
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0115

============================================================
🔄 Round 140 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0988, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 140 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0175
   Val:   Loss=0.0986, RMSE=0.3141, R²=-0.0550
============================================================


============================================================
🔄 Round 141 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 141 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0160
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0508
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0115

📊 Round 141 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0115

📊 Round 141 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

📊 Round 141 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

📊 Round 141 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

📊 Round 141 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

============================================================
🔄 Round 151 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 151 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0193
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0291
============================================================


============================================================
🔄 Round 153 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 153 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0208
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0222
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0115

📊 Round 153 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0114

============================================================
🔄 Round 157 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 157 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0220
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0182
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0115

============================================================
🔄 Round 162 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 162 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0250
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0185
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0115

============================================================
🔄 Round 163 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 163 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0273
   Val:   Loss=0.0879, RMSE=0.2966, R²=0.0012
============================================================


============================================================
🔄 Round 165 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 165 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0197
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0314
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2587, R²: -0.0115

============================================================
🔄 Round 167 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 167 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0159
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0488
============================================================


============================================================
🔄 Round 168 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 168 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0274
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0018
============================================================


============================================================
🔄 Round 172 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 172 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0216
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0189
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2587, R²: -0.0116

📊 Round 172 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2587, R²: -0.0116

============================================================
🔄 Round 176 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 176 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0155
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0470
============================================================


============================================================
🔄 Round 178 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 178 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0229
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0205
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2587, R²: -0.0115

============================================================
🔄 Round 180 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 180 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0213
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0357
============================================================


============================================================
🔄 Round 183 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 183 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0239
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0161
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0115

============================================================
🔄 Round 185 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 185 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0182
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0366
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2586, R²: -0.0115

============================================================
🔄 Round 186 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 186 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0210
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0213
============================================================


============================================================
🔄 Round 189 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 189 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0178
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0374
============================================================


❌ Client client_89 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
