[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc1cfdbd-4712-419e-84fb-d935f5ae2acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a656f2fa-6799-4051-8019-2ffd23f3a247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79119ecd-890b-48ea-aeec-6189dc02a489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6f26493-2865-4dfa-b33b-741dfae9691b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dac51da0-ae1c-41c2-819d-e9c218de70c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6ff0212-48a8-4491-97fe-3351735e4681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9040b32a-e2c4-4a09-8ef8-e55bfc7d01bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d05df8c-ede4-40b4-aa85-e2181eef7d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29891cdf-b8cc-4074-b625-edaa65f8ce48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dead438f-26bf-45bd-95e9-edde6195da24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a3b5214-bc6d-41da-9bc6-dda4651a3499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20efea67-903c-44dd-bd09-b5e1d04b367e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97dde4fd-c2d9-4494-a3a4-7d8a50e96fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d608557d-8975-47b4-8709-c9f1957a55ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9401071-a871-48b2-9c99-331d73faddbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdfb9885-8a19-490e-86e3-b5171a1dcac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f96a490-8a83-46f4-b2f6-5894f8f36186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ba3e553-9b0a-4a4a-80b5-47b7221ab894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e59df6c-0193-4a1c-bb53-42413b142f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de92ea84-718d-40a1-81ac-a7ffc438e688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d2963c4-c82b-448b-8e14-4ab6266145df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4354c34f-b212-46a9-9324-19b224e6c454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aefb6c8-6711-4153-8e52-e8cbda19e559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7056264-74fd-41b8-a279-5a2238a0f6db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ea58fde-0d8d-4c1c-ac36-b25d204b97e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80a5abb0-3cbc-453f-ab66-338bba33e943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80e16939-7531-4ae1-8b9a-1a1e14cc142b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ff78b1a-96f7-4723-9667-1be630338dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0940979-6e22-4444-b0a4-409fffe58ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a21ad6f3-0f34-4a89-a6b2-1a0f3f631db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5960d63e-a072-4cb2-9854-c8ae38ec6929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b92918e8-b33b-4a87-9b20-2882e56fe309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f242c3f7-e084-4e6e-b412-837bb8b13c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7d47a6b-af17-4c3f-8332-567a2eba6d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15109adb-93c7-4d8b-9f0b-cb848059cc82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c45bdaa8-036d-4bbd-b2d1-79488410ed32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7cb93ae-43f7-4b37-96d5-9a35839e0f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3b772e6-36e7-4ecc-9e36-c066043bc125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d72f40c1-72f9-445e-9e5b-8c8c902a18ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da75af5e-d892-4c45-8ee5-9b9b130117b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feb31448-d492-439e-9250-bd877db5b1d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5df8268a-3a5c-4da2-a61f-45e32ee90fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2bf8371-b13d-4f41-82d4-a707f96db803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfeae3a8-e648-443d-83fc-e36e08a3f655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2594b61-cf52-4bd8-9080-0f8f2053a3e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94420c17-92fe-4804-bb38-fe4f232a3e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65994b02-2ef0-4878-82ee-adf923799321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dba3e5f-decb-49f6-8ef9-13b96ed9b158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5025898d-0404-4e6d-be08-d791cb27d6df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e3da140-9139-4003-b083-87f082a20ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa0e474b-5836-4795-a2f1-7db0cd5f1f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32c56898-224c-45aa-8aa7-73eb909db07e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7100b600-a4dc-4ca8-9377-fd444d4b003a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51b05f29-a433-4e43-89a9-c3614559cde9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7d61b7d-8838-4145-b46c-43eb7fd48ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db4798a7-0498-4e5a-a673-eb8f245e7a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa746a4e-e54b-43fb-976b-a16ffceb5653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a149c9f9-228b-4e0f-934c-8be0b136db7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f655ed8-2432-43ce-ba82-8b995932a5ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6771f79a-8f5c-4836-95b1-3a266b46a90f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca4a3a5e-a2ae-4ba8-a5af-05d1c86c6d58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da433f25-a02c-4c93-a74a-18e61a9f4c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8660ff0b-3500-4213-b913-d66dda2fa479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a1292b3-1f4f-4b27-b0cb-bce100a4b97b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31861d42-8d3c-4689-bffd-9e9416f2cee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 847e2132-617e-401c-8e1f-54b53f0705ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b64a9405-8598-40f4-a088-15f43733f445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2455584-76d8-444a-8d5d-c5933dce3182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 058e0044-e8ed-4546-bddf-c7d3c0f43265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fad733d2-9751-453e-9208-4110de27dfc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abcb73f2-6768-4a54-b789-5da968498865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ab65743-ce3b-4173-a43e-f0b4f9cb37d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0ad3fe6-eb70-469f-8c14-a6c353d363da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 643539a6-7b5a-4b70-9940-2cfbb6e5d4d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52921d19-bda6-47c7-931a-f3275da71fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 186c54de-b229-469e-879a-a81dc21d438b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6755b8a6-287b-402b-93cd-64ca918882ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9538cab-b363-4b62-b779-51f066294eb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e5a2148-d0e7-47fb-b73a-402269b0ba06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9f123da-509d-4329-9a9c-6cd27417d9f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 585ca378-718c-43b4-a58f-9cd5f477ac52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbd53859-96b9-49db-a007-34076107b9d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60596fe7-1f4e-43f9-86d0-b9dee2318864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e209cad1-bb83-4637-b321-8f9e74228098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d385d723-8a4a-4802-9a52-eee69d54c77a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 410edca2-c3a9-44f0-afd7-1e5976173b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01c6af25-a1ce-4b8c-91f4-676f39a3f8aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc17839e-ab61-4407-a757-d1da8b820c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25eca427-65a0-4d1a-ac7b-372ec64f2155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad6324fe-9551-43aa-9643-b45fa16bc6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4049bc2-060c-4b13-a9ab-8d94b1c9d0c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c80d4e13-e937-4e7d-87b4-0c5157f1f0b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3500349-142d-42eb-8397-3c8f12fb18af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bbb7d8e-9731-483f-a0a3-c5b005071ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87120999-106b-45d1-87ff-487838a74e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19a26e3a-f769-4073-9367-96165e8ac787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eee27d11-c160-48ee-993d-622ca3be835b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06595d3e-5bbc-4451-aabb-35e2b400e934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71c9df90-72d7-4c28-8c2d-af388083dae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a73467fd-598d-4e49-9d3e-4d0f0f09e8b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e2fd900-0915-4e3f-a8ce-554b5edb1185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64df0fe1-3337-4bc8-8c62-37ca135a84d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fef2f50-bda5-421e-a558-882a162d89f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 211d9f03-8b02-4072-ae26-dbc4904d2601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79a6a5f5-91bb-4f07-8ef6-0d35b961fce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b9fc2a-b96d-42fa-9865-73c0187810ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b4c4798-f313-49e9-a917-c7a018cbe051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a703232-6b83-45cf-a9dd-3207e9738a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae85aa53-cebf-46a4-b089-a6da66f84efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 953a8f1a-fbb7-4f87-b888-e5dfa3f25e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a0bdd70-abb9-4ef2-a709-6ed1b1825b94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8bba528-6b3d-438f-8c1d-e324b525508f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20bc42d7-2108-4417-a914-3c7de1c16d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 002bb799-68a2-48db-aa21-671d133642a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a904bff8-4959-49d8-bb07-83656eb34b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be412786-4678-41b5-a56b-d307a9aad262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33637479-5450-47d8-92b2-db7dc96c7f7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4e2a9ce-e1be-43b4-9924-b52a24163401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17ee6e64-e573-4aea-99b9-c7594e343564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5aae8ac-bc81-4d6e-9e0c-ff5f6327800f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39542283-ece9-47e2-bbf5-d898a589d8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 773f70a6-58a8-4fb0-9fe9-2b3988f5dfcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bda09554-579a-4a48-bfe6-4332480f1b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c8efb39-6c1f-40e1-8236-98f9725c93a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8908d1c-a352-4ff6-8eb7-9a005c589f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92ebc311-b09e-41b0-ae53-f219d4e46e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caaebcdb-c9a2-4f87-af35-d6930964fdc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 734f9434-1223-4d17-a4b1-85dc3a4287dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cea8fd3d-f103-42a7-b3fe-e2a1bd34eaa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57f0d641-61fb-48ce-b03f-6a9c6d84a451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08868e93-0ca2-4583-becb-e1455f51006b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 689c1df8-8d24-45a0-9fd4-e4a887b1e513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4fbd187-baf4-4f06-adf4-c1a2493ea93f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 637fd619-807a-421d-b653-e9002aff9786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da0116aa-0a50-499c-9996-1b27a1b0b93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2efde870-a06e-48bb-854c-a60c3fac9e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dba1ea3e-93fc-4a9b-89a3-517ed58291cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb988a3a-06d1-417a-9ff7-01d0b118f802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 963eeae6-d7c3-4bc6-9e7d-c88eefb52ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f81c64a8-5e14-4bdb-85d1-8603e7344dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43bf1f8b-caa7-4460-9caf-853fa26ce4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 571cc67c-01af-4072-8db3-137378651325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99bdee84-8bfe-4078-adb3-04758a22d685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb224fa2-da37-45e3-a693-7d13182bd1ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e022719d-b984-435f-8477-8de32114866f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6193e7e7-4407-4138-aac9-8327d35373ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9bacb4b-8987-4637-8c24-bd63a9cf6f2c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_8
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_8
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_8/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_8/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_8/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_8/test_labels.txt

📊 Raw data loaded:
   Train: X=(1156, 24), y=(1156,)
   Test:  X=(290, 24), y=(290,)

⚠️  Limiting training data: 1156 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  281 samples, 5 features
✅ Client client_8 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2575, R²: -0.0044

============================================================
🔄 Round 2 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0780 (↓), lr=0.001000
   • Epoch   2/100: train=0.0829, val=0.0782, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0841, val=0.0761 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0840, val=0.0751 (↓), lr=0.001000
   • Epoch   5/100: train=0.0832, val=0.0750, patience=1/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0818, val=0.0749, patience=7/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 2 Summary - Client client_8
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0096
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0042
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2562, R²: 0.0048

============================================================
🔄 Round 5 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0845 (↓), lr=0.000500
   • Epoch   2/100: train=0.0793, val=0.0845, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0790, val=0.0845, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0786, val=0.0845, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0784, val=0.0844, patience=4/15, lr=0.000500
   📉 Epoch 6: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0769, val=0.0845, patience=10/15, lr=0.000250
   📉 Epoch 14: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 5 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0166
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0040
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2549, R²: 0.0123

📊 Round 5 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2549, R²: 0.0147

📊 Round 5 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2541, R²: 0.0196

📊 Round 5 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2541, R²: 0.0213

📊 Round 5 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2539, R²: 0.0230

============================================================
🔄 Round 14 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0736 (↓), lr=0.000125
   • Epoch   2/100: train=0.0802, val=0.0736, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0800, val=0.0736, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0798, val=0.0735, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0797, val=0.0734, patience=4/15, lr=0.000125
   • Epoch  11/100: train=0.0790, val=0.0730, patience=1/15, lr=0.000125
   • Epoch  21/100: train=0.0781, val=0.0725, patience=2/15, lr=0.000125
   • Epoch  31/100: train=0.0772, val=0.0719, patience=3/15, lr=0.000125
   • Epoch  41/100: train=0.0764, val=0.0714, patience=3/15, lr=0.000125
   ✓ Epoch  51/100: train=0.0756, val=0.0711 (↓), lr=0.000125
   • Epoch  61/100: train=0.0747, val=0.0709, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 14 Summary - Client client_8
   Epochs: 66/100 (early stopped)
   LR: 0.000125 → 0.000125 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0849
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0651
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2537, R²: 0.0243

============================================================
🔄 Round 18 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0862 (↓), lr=0.000125
   • Epoch   2/100: train=0.0771, val=0.0861, patience=1/15, lr=0.000125
   📉 Epoch 3: LR reduced 0.000125 → 0.000063
   • Epoch   3/100: train=0.0770, val=0.0861, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0769, val=0.0860, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0768, val=0.0860, patience=4/15, lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0765, val=0.0859, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 18 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0229
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0377
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

📊 Round 18 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 20 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0752 (↓), lr=0.000031
   • Epoch   2/100: train=0.0797, val=0.0759, patience=1/15, lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   • Epoch   3/100: train=0.0794, val=0.0765, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0793, val=0.0767, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0793, val=0.0769, patience=4/15, lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0791, val=0.0774, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 20 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0238
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0010
============================================================


============================================================
🔄 Round 22 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0840 (↓), lr=0.000008
   • Epoch   2/100: train=0.0778, val=0.0840, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   • Epoch   3/100: train=0.0778, val=0.0840, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0777, val=0.0840, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0777, val=0.0840, patience=4/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0777, val=0.0840, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 22 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0285
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0102
============================================================


============================================================
🔄 Round 23 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0832 (↓), lr=0.000002
   • Epoch   2/100: train=0.0782, val=0.0832, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0782, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 23 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0282
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0027
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

📊 Round 23 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 25 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 25 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0195
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0036
============================================================


============================================================
🔄 Round 27 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 27 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0273
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0145
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 28 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 28 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0229
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0227
============================================================


============================================================
🔄 Round 29 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 29 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0251
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0227
============================================================


============================================================
🔄 Round 30 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 30 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0196
   Val:   Loss=0.0700, RMSE=0.2646, R²=0.0451
============================================================


============================================================
🔄 Round 31 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 31 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0263
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0161
============================================================


============================================================
🔄 Round 34 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 34 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0228
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0269
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

📊 Round 34 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

📊 Round 34 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 40 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 40 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0236
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0094
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 42 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 42 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0195
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0402
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 43 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 43 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0246
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0242
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 46 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 46 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0232
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0303
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

📊 Round 46 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

📊 Round 46 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 50 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 50 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0237
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0284
============================================================


============================================================
🔄 Round 51 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 51 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0247
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0046
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 55 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 55 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0302
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0049
============================================================


============================================================
🔄 Round 56 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 56 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0267
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0157
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 57 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 57 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0225
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0319
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 59 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 59 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0234
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0288
============================================================


============================================================
🔄 Round 60 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 60 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0227
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0318
============================================================


============================================================
🔄 Round 62 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 62 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0297
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0030
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 63 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 63 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0225
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0274
============================================================


============================================================
🔄 Round 64 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 64 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0224
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0253
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 66 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 66 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0265
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0150
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 69 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 69 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0285
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0094
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 70 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 70 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0266
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0160
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 76 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 76 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0252
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0221
============================================================


============================================================
🔄 Round 80 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 80 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0239
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0266
============================================================


============================================================
🔄 Round 83 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 83 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0242
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0223
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 87 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 87 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0245
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0205
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 88 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 88 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0218
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0336
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

📊 Round 88 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 90 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 90 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0210
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0367
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 91 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 91 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0261
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0186
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 92 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 92 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0244
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0114
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 94 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 94 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0228
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0264
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 95 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 95 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0274
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0071
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 103 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 103 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0226
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0274
============================================================


============================================================
🔄 Round 105 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 105 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0250
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0225
============================================================


============================================================
🔄 Round 106 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 106 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0218
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0261
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 107 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 107 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0231
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0310
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 108 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 108 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0211
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0338
============================================================


============================================================
🔄 Round 109 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 109 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0199
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0216
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 110 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 110 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0218
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0261
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

📊 Round 110 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

============================================================
🔄 Round 113 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 113 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0206
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0418
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

📊 Round 113 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0241

📊 Round 113 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 122 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 122 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0292
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0054
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 126 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 126 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0295
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0033
============================================================


============================================================
🔄 Round 128 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 128 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2812, R²=0.0214
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0374
============================================================


============================================================
🔄 Round 129 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 129 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0236
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0238
============================================================


============================================================
🔄 Round 130 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 130 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0258
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0159
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

📊 Round 130 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

📊 Round 130 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

📊 Round 130 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

📊 Round 130 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 141 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 141 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0247
   Val:   Loss=0.0704, RMSE=0.2654, R²=0.0242
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 142 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 142 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0205
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0398
============================================================


============================================================
🔄 Round 144 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 144 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0245
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0251
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

📊 Round 144 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 146 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0612 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0612, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0612, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0612, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0612, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0612, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0612)

============================================================
📊 Round 146 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0216
   Val:   Loss=0.0612, RMSE=0.2475, R²=0.0292
============================================================


============================================================
🔄 Round 148 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 148 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0249
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0213
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 149 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 149 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0235
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0231
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 150 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 150 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0269
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0159
============================================================


============================================================
🔄 Round 152 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 152 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0175
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0513
============================================================


============================================================
🔄 Round 153 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 153 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0207
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0347
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 154 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 154 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0206
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0362
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

📊 Round 154 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 158 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 158 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0288
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0506
============================================================


============================================================
🔄 Round 161 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 161 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0244
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0252
============================================================


============================================================
🔄 Round 162 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 162 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0212
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0335
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 163 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 163 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0291
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0068
============================================================


============================================================
🔄 Round 166 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 166 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0277
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0123
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 167 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 167 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0186
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0433
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

📊 Round 167 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

📊 Round 167 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 175 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 175 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0287
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0061
============================================================


============================================================
🔄 Round 177 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 177 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0265
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0132
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 180 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 180 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0265
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0169
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2538, R²: 0.0242

📊 Round 180 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 183 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 183 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0207
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0393
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2538, R²: 0.0242

📊 Round 183 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2538, R²: 0.0242

📊 Round 183 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2538, R²: 0.0242

============================================================
🔄 Round 189 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 189 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0234
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0282
============================================================


❌ Client client_8 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
