[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 610af191-fe34-4183-a551-8d0fa9dbae98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37b81211-ba87-45dd-8dec-858cb8df7323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a37a985-83df-45f8-ab62-d37f2c84c42d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7a03bc9-9823-44fc-b66b-0a70d267a614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cacfd5d3-e7fc-4bf2-83e5-a2fefdc9a73c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98a1e0a4-8c8d-4ff8-9a9f-0d5b7cb833ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2c11925-16da-4ee4-93a2-f043639ee00f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 400a9308-f778-4d2b-af70-09e1397b7605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1213915d-7ea3-4b02-bc86-b8adcde2ab8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea2d2de3-2c1c-42a8-bab0-aedc7c43b78c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98b5fae0-5d16-4b11-a266-6db77aa70d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28da5abb-7f73-4f4f-a7e6-dffe929e5905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8012681-c0bc-4e08-840d-32be90b91d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e11107ae-d4cf-4250-b35b-f74e4dbab70c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42542c90-b278-40f1-a55f-ffd85b1cd82f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dac07df0-f37a-45a5-bb66-cd43791c9aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64354c81-0417-4f5f-a93b-5dd4623f6ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7f1176b-f3ab-41a6-ad09-bf58ed9230dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 118e5809-94f1-4007-aa92-b9ca12a8fc53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c25ad0b-c0db-4874-9df4-7b5669be030c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 474946b0-f722-4bf1-8ee1-44ba043e5c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bddd19a-2e36-4378-9cd6-77fde25442c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49e4a17a-b666-4877-9458-b7521eb6175b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64ac657c-d8dc-41a7-9e6c-3365efb3a307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27f4763b-b297-44ef-92bb-8f0333759a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5c8f4e8-cd40-425d-ae85-152029ee1fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf532eda-f8ff-4a4a-b0b4-8705490bd1b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cd14a1f-9968-42c6-b38c-216460c63a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ecad174-9db5-43ad-9eec-ddcbb776f9ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72ac1ae1-dbd6-47d1-9ea7-18ef454b0663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfdffe97-ceeb-4e70-869a-cdb253903b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91c3ec1f-8c05-4a13-9074-806f63f17cc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2090741-022d-4e43-9446-26eb23e8ac4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdde628b-0e13-442e-807c-549533cf53b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c2f90f9-b811-4300-91f8-cbf699d80c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1b3b6f2-615f-42c8-9106-2b605d979d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 751376cd-222a-4e7a-9d98-037b3e593a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5da42e4f-1b55-48d4-9588-8fdd44c46c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c6e53eb-0feb-4cf0-8692-141aea682d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 771ef00c-f3bf-4c0f-82f3-7efa85671d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93390fee-757a-4e24-aaa5-54fbb5869d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4c89a1a-ae8e-4d4f-9f38-061002fc5bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9b798bb-c4d0-4139-a4e0-6e85f5da10fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 013c5948-1d3a-4c53-9245-9cdb122ecca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fe2767d-1d98-462c-afcf-722267b5cdc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9acc754a-af60-484e-99c7-fe83bed60d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db31e79b-e8fe-4a68-9a9b-2f77fd2a7135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15d46691-7766-48c3-b1c3-914d70aa6902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b619daba-d8bc-4d8b-a58a-e0cd98e75c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e9a37c0-3105-4e50-83e7-76ba068ad018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3bb53c9-81a1-4472-a8b2-6b3183d8dcc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 497cf41d-4e1e-4a0e-93d0-d148733fad36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fcd2276-06b6-4c83-bb3d-098b6b232caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b80ed934-c6af-4c41-88e3-7dbf8dad1a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eecc2a3-5980-4e81-b720-1a6c12128e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdd37bed-84b5-43ba-829a-b87add920fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c8ef1c2-7a1e-4928-9f31-c167b05e1ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f0a4aae-1848-4147-b8fe-d104c57af135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08b5c5d5-991c-441d-b564-cf559a3378cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83367732-864d-4f57-91d7-c6b12e00a718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aa7e7dc-87cc-4cae-9b6f-712b163dd631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d80dfc01-8d32-4169-a387-6951698f3e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 130bc4c0-e04d-4ff0-bfcb-e91aa0870c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4aeb43f-6f7a-4d15-8492-141bbd8018f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0f6d8d7-5928-443d-844a-4605b37cf6d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f9da3e7-213a-416b-aa65-ea16bb607881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43706fcc-1746-4215-ad17-63259d2ec43d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98cf4a9f-1b35-4735-8909-c925c097d8c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef7a017f-51e9-46ab-9d9f-da8b9cb93506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da5597b6-eeab-45da-9fa0-a43b1d5382b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f814452-a00d-46eb-b191-e0551d135c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 025e0e3d-dab2-4ec1-81b4-40672bc5ae65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e886fc2a-110e-4178-8584-79375163d4b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d955f2f-6026-45aa-8745-4eb2340761b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93f92846-eb42-48ac-a11c-5a749ba72305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 077be1b7-50af-4b13-b9f0-172ac26873c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0af897ff-23bb-4942-a0a7-4eccca0499de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d6f45bc-ad51-4dad-81a6-0f7b6bc902c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a7014f3-7db9-4944-a161-7475368de9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c41d189c-5903-4a2a-9da2-f895ef7d5a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b9bedf4-7c3f-4616-aceb-76ecfebdf1f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5bb70c1-4229-4759-b8ca-dbea4ca8d568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac96f24-4713-47de-a364-29eacf06afd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d169e965-7e59-4c17-a634-199c3560d37d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94b76ea4-3161-4f47-b6a7-6fe6152c817a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f98851f-8abe-4cde-92b8-f700f358f0bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27fa9d10-694e-47bb-ac49-563866ed0bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eca0c116-5d26-4fa1-8a5f-f2f1fe7d512a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfefa58e-cda0-4d7e-81f1-8eda3528c6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e18ec5-a2cf-44c2-97ce-544ff7d738ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4703d910-afbe-49bc-80ed-91ec4b541da7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bf057bf-d803-4b8a-a8c0-ac7edadb63ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b96bd670-0a9c-4818-be28-19ae2cc73994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34bd0d0a-95f0-478b-9e83-2e4ff69d09a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aee1d4d-63cb-4c6c-b310-cc3a0cb9827c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1547f9b2-283d-4e15-a3ce-6e798a47dc95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe4c4d1-8c1a-415a-8faa-ff8fafa35e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 682e551a-1ee2-4a09-a831-6fd2ac67d6e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 973631fa-112a-45d3-906c-8e6577fd5825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae0c7b2d-1ccb-476b-ac74-da0a54543517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b830ff1d-d212-4689-8f5b-ae4c9ac8dedc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ab2c491-08dc-46ea-bb4c-e21282eb3ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b5e6a90-20b5-426d-a18f-d7c2a10d67ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4da565da-d2ee-47c1-922e-e89ffc2c0fa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c566c43b-d861-4a2c-b6ba-9b3a21ece4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5724a42-4bd8-4a47-a901-32d1e6b77075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dfaa4c2-8a16-403e-b916-2a6f300a2df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90100c7d-3984-4ff8-8880-d76a642e946d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f86e638b-f25c-4fc6-8694-2ef5831406dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e756e155-7641-4915-94f0-6c5016a6d803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03f5ab34-aaac-4cf4-8113-209e4dc5f955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c17e983-d4d3-485c-bb9b-6ecebeb26a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfe9bc86-d3e5-41bd-8c38-90c4cbc3043d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a81bf3d-18f2-462f-ad42-0e764252f902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6f889e7-5746-4f27-9490-b9b7bff05c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcdedf30-7285-4282-b617-2bceea8d4982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de393d4d-0c11-447b-aca4-ccbc320fc0e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2f25721-f3a2-4869-991d-5be99ef1a55f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4538fba6-b506-48e0-82e6-8365dcb2a6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98549036-499e-4581-84a4-da397d06df5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68d7e69b-4071-4caa-8d56-3c9571197d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5ad9416-7f57-4e8c-93ea-3863a22a1d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10c753b6-4a06-482e-a082-242a2505a944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caf0f439-ce41-4a74-bdfe-063bd5e2eab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbaf13f4-7258-47e2-ae4d-26411f79532f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22f21e2d-f826-4dfc-aed8-95ab90b67a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message decc9f18-cced-4cd5-94dd-f3315e83ecef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb278b19-2201-4571-b855-16e5ae422d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bca2b16a-1281-4cb9-9bcd-4faaccaa5371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8ebaed3-be21-4a5d-87c8-edf503ffbb5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 594ac754-0db2-4719-8315-696a589f8b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83ed135c-b442-4794-ada9-cb36508f81ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8792ce0-16a2-4b78-8bfb-615f39f64c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd2c792d-e086-45cd-b0d4-9c69c539e239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35c327be-6c60-4017-b7f4-ceb68af9cd7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24996016-432a-4d16-895b-9dc7aeb32edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef9560a8-287c-488d-bb50-5a7ccf9f7354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b7a9f14-718b-4b97-8083-ebd5d3f4a3a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40066bb0-2046-447e-98b8-0d4fd6123a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f14442c-c13f-431f-8d3b-473fe31ac1dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11bbcf4e-6bb1-4352-9a5a-e2ca04541b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9664b875-be59-44ff-9a42-76c845f7179a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05a3ec7d-f766-49e3-8218-4e218fa94767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 290b6e52-887d-48b1-94f5-c03685f9d925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd7260b4-27d3-4c11-8b88-ae10611e1276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47189405-8f57-434d-bb2e-d389a980f7dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32d613de-4ac7-44e1-9bc7-8246df71ebd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82c63400-99e5-4881-b1cf-b82c30c02921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1e8139a-8891-4d5a-8a9f-facc8b4dc4ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e5605f4-4da2-4739-be38-6b0720f33bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17fefb5a-8a08-489f-9d40-565955e1a86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5bea136-4058-4fa8-93cc-e3e85cdb04af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 841c1f9d-8f5e-4f47-87b7-0bff0c512b2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecb9db1e-ad8b-495c-bbad-b50eeee26ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22e92248-90df-4e0a-9d83-5f4097cfe9ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cc280cc-3f7d-4bd8-9ae1-be7be55bcae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 174c4afa-acb5-4044-a903-082d7b8e8426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49bb1fa1-35d4-408a-bb4c-890b5d9c1944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e159e97e-8da3-42d0-a7a9-e32047df821e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 158ebacf-497c-4bab-8ada-2a9a3f8abdc1
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_90
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_90
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_90/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_90/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_90/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_90/test_labels.txt

📊 Raw data loaded:
   Train: X=(2056, 24), y=(2056,)
   Test:  X=(514, 24), y=(514,)

⚠️  Limiting training data: 2056 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  505 samples, 5 features
✅ Client client_90 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0721 (↓), lr=0.001000
   • Epoch   2/100: train=0.0903, val=0.0753, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0894, val=0.0744, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0881, val=0.0734, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0878, val=0.0736, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0849, val=0.0734, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 3 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0150
   Val:   Loss=0.0721, RMSE=0.2686, R²=-0.0062
============================================================


============================================================
🔄 Round 6 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0795 (↓), lr=0.000250
   • Epoch   2/100: train=0.0844, val=0.0797, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0842, val=0.0796, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0840, val=0.0796, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0838, val=0.0797, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0828, val=0.0798, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 6 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0241
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0083
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2439, R²: 0.0125

============================================================
🔄 Round 7 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0785 (↓), lr=0.000063
   • Epoch   2/100: train=0.0847, val=0.0782, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0846, val=0.0781, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0846, val=0.0781, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0845, val=0.0781, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0842, val=0.0782, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 7 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0239
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0002
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2434, R²: 0.0136

============================================================
🔄 Round 9 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0881 (↓), lr=0.000016
   • Epoch   2/100: train=0.0814, val=0.0883, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0812, val=0.0885, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0811, val=0.0886, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0810, val=0.0888, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0809, val=0.0890, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 9 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0217
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0440
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2428, R²: 0.0168

📊 Round 9 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2426, R²: 0.0181

============================================================
🔄 Round 12 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0878 (↓), lr=0.000004
   • Epoch   2/100: train=0.0812, val=0.0877, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0812, val=0.0877, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0812, val=0.0877, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0812, val=0.0876, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0811, val=0.0876, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 12 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0331
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0276
============================================================


============================================================
🔄 Round 13 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 13 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0290
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0418
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2425, R²: 0.0184

============================================================
🔄 Round 15 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 15 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0230
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0643
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2424, R²: 0.0182

============================================================
🔄 Round 17 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 17 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0273
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0498
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2424, R²: 0.0182

📊 Round 17 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2424, R²: 0.0183

============================================================
🔄 Round 20 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 20 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0284
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0465
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2424, R²: 0.0184

📊 Round 20 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2424, R²: 0.0185

============================================================
🔄 Round 24 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 24 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0240
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0653
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2424, R²: 0.0184

📊 Round 24 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2424, R²: 0.0185

📊 Round 24 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2424, R²: 0.0185

============================================================
🔄 Round 27 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 27 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0363
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0169
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

📊 Round 27 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

📊 Round 27 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

============================================================
🔄 Round 34 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 34 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0293
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0434
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

============================================================
🔄 Round 35 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 35 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0322
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0355
============================================================


============================================================
🔄 Round 36 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 36 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0339
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0270
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

============================================================
🔄 Round 37 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 37 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0350
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0239
============================================================


============================================================
🔄 Round 38 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 38 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0332
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0216
============================================================


============================================================
🔄 Round 39 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 39 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0359
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0204
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

📊 Round 39 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

============================================================
🔄 Round 41 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 41 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0360
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0145
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

📊 Round 41 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

============================================================
🔄 Round 44 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 44 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0391
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0149
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

📊 Round 44 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 48 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 48 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0360
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0053
============================================================


============================================================
🔄 Round 51 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 51 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0373
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0107
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

============================================================
🔄 Round 52 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 52 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0354
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0235
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

============================================================
🔄 Round 53 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 53 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0316
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0393
============================================================


============================================================
🔄 Round 55 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 55 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0293
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0474
============================================================


============================================================
🔄 Round 56 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 56 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0345
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0243
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 58 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 58 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0342
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0254
============================================================


============================================================
🔄 Round 60 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 60 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0301
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0386
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

📊 Round 60 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

📊 Round 60 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

📊 Round 60 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 66 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 66 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0296
   Val:   Loss=0.0920, RMSE=0.3034, R²=0.0361
============================================================


============================================================
🔄 Round 67 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 67 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0317
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0333
============================================================


============================================================
🔄 Round 68 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 68 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0333
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0322
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 72 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 72 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0279
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0489
============================================================


============================================================
🔄 Round 73 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 73 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0390
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0053
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 74 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 74 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0308
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0061
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 75 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 75 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0370
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0167
============================================================


============================================================
🔄 Round 77 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 77 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0328
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0071
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 79 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 79 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0309
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0413
============================================================


============================================================
🔄 Round 80 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 80 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0312
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0407
============================================================


============================================================
🔄 Round 82 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 82 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0402
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0149
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 85 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 85 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0317
   Val:   Loss=0.0827, RMSE=0.2877, R²=0.0381
============================================================


============================================================
🔄 Round 89 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 89 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0281
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0531
============================================================


============================================================
🔄 Round 90 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 90 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0275
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0508
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 91 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 91 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0320
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0376
============================================================


============================================================
🔄 Round 92 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 92 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0338
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0149
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

📊 Round 92 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

📊 Round 92 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 99 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 99 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0269
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0580
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 100 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 100 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0361
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0152
============================================================


============================================================
🔄 Round 101 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 101 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0365
   Val:   Loss=0.0861, RMSE=0.2933, R²=0.0068
============================================================


============================================================
🔄 Round 103 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 103 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0401
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0091
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 105 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 105 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0297
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0410
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 106 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 106 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0294
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0419
============================================================


============================================================
🔄 Round 107 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 107 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0309
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0367
============================================================


============================================================
🔄 Round 112 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 112 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0331
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0327
============================================================


============================================================
🔄 Round 113 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 113 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0381
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0117
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 115 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 115 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0347
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0267
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 116 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 116 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0352
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0251
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

📊 Round 116 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

📊 Round 116 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

📊 Round 116 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 120 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 120 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0367
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0160
============================================================


============================================================
🔄 Round 121 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 121 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0338
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0301
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

============================================================
🔄 Round 125 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.1005 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.1005, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.1005, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.1005, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.1005, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.1005, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1005)

============================================================
📊 Round 125 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0379
   Val:   Loss=0.1005, RMSE=0.3171, R²=0.0163
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

============================================================
🔄 Round 127 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 127 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0353
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0244
============================================================


============================================================
🔄 Round 129 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 129 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0297
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0433
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

============================================================
🔄 Round 131 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 131 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0336
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0311
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

📊 Round 131 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

📊 Round 131 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0185

============================================================
🔄 Round 136 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 136 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0352
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0162
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

📊 Round 136 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 142 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 142 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0334
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0292
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 145 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 145 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0299
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0227
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 148 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 148 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0216
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0708
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

📊 Round 148 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 152 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 152 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0367
   Val:   Loss=0.0945, RMSE=0.3073, R²=0.0166
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

📊 Round 152 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 154 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 154 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0344
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.0258
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

📊 Round 154 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

📊 Round 154 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 158 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 158 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0331
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0305
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 159 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 159 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0358
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0179
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 160 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 160 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0281
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0546
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 161 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 161 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0317
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0383
============================================================


============================================================
🔄 Round 162 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 162 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0314
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0405
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

============================================================
🔄 Round 166 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 166 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0354
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0243
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0187

============================================================
🔄 Round 168 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 168 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0319
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0310
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0187

============================================================
🔄 Round 169 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 169 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0392
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0079
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0187

============================================================
🔄 Round 170 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 170 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0324
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0362
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0187

============================================================
🔄 Round 172 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 172 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0234
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0238
============================================================


============================================================
🔄 Round 174 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 174 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0357
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0212
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0187

============================================================
🔄 Round 179 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 179 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0376
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0023
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0187

📊 Round 179 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0186

📊 Round 179 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0187

============================================================
🔄 Round 184 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 184 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0353
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0220
============================================================


============================================================
🔄 Round 187 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 187 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0328
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0302
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: 0.0187

============================================================
🔄 Round 190 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 190 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0324
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0182
============================================================


❌ Client client_90 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
