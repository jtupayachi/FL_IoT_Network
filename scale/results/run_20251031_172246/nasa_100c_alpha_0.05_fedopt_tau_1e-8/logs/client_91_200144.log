[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78a07b62-c9d0-4c6a-9926-9402ea32ea4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58235831-33c6-448b-9e44-7be87a2e908a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e9087bc-607e-4a13-b2ac-d61de27b06ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 060221a7-4d2e-4e1a-9267-460f2aab77d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6754446-4865-43ef-b23f-779504c6910b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ba8232c-f257-47c9-8f84-4d62c9422ace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b4ab788-f16d-402d-919c-a9d995b52d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 311dff52-5618-4c40-a09c-485b1443d410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b70e3cf-d9f1-46ab-af6b-1785475b314e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0fc9888-c52f-484e-a08e-bc6783bdc2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5272c948-3a02-4a63-a3c3-771c90bce40c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd773941-d202-416a-a3e0-6d2612bcb081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77b1b711-4c08-43ac-bd06-756b34c229ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1f12b33-61b6-4b29-a6fb-23e0ae1f524c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97089ace-90f4-45d9-b8cf-98251631afd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aa8eb49-7218-4125-aac8-5e9bd5656f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23669f80-1a83-44ea-936f-2797dffeb614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e497cee7-6627-4e0f-9329-ddfbd526417e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84e110c0-10aa-4670-8019-d2dc0db46f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79b3308d-daf8-43aa-ba59-37a30d453701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03dc39f1-ff4e-4d67-be10-ad7932695232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92e9de29-1bba-4159-b133-913845150f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f616a33-9aaa-456e-bfa2-cd5337e6adb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dcf7633-947f-4444-89eb-ecf01034d40e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df216db7-718b-4e98-bfde-6a8ce0fe4c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48dd42fa-b4c9-4df7-84ff-9fbf225e36bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c48ea60a-a934-419a-8ad4-c63446efc80d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d54ffc5a-bdb1-42d0-9edc-f5f2bc236a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a2a4848-d50c-43a4-ace1-c8a48ba23414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc3b894b-8c05-4bf8-8ee5-5e14f49a2503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14f78141-30ee-4772-981d-8bf963fca3fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a52ee81-f6b1-430c-8ed8-19e040de68e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 781848dc-e633-45bf-90c9-72be5f5e194b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8270b26-628e-4f97-95a9-491d7e2c3ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6122d1a3-d20d-423a-bafe-af31ae7994ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2ee88f7-b333-45eb-9921-c662d2967d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 361d850d-0838-4369-8f90-0175c956fb7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a24b9ed9-519f-4c70-955d-fd7b67a1fb3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afdfa12b-9289-44b6-b2d3-0023da77e25c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c2aaa1a-2019-49ef-8c0a-00f85d23ab7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b391819f-8e91-4c29-944f-75a8d878f7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c22e7821-ce77-487a-96b1-45ea34902aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 372e760e-2789-4177-8cdc-9c3ff2d5628a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47cc4d4f-0d43-4d2e-9aaf-8bfe95fb48f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32e58cc3-eeba-4a54-a83f-81e0c5b76bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fe9b7f3-d1fb-48df-9e8c-7399f8447be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c340f57-02cf-4a89-9ecc-a10e1946c930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5fa0d93-730b-49f2-bf00-fc3cf3d0a81f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84916823-293f-4f53-8ef6-01e6e27d4200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baf707c2-e951-4349-ac8c-e03afa1c8b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5995a576-3242-4c57-a024-392a80598523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26fab21f-c380-4ca8-a79a-f96e19e1f430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de71dffc-befb-4574-984d-e468b075dd43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cab9b44-b9ac-4ecb-8955-a7bd939b52f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0d7f0ee-bd94-42e4-aa5f-12d7b650b4d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30cfae70-91c2-4172-993b-ad615e32556d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deafa59d-facc-4329-850d-1f852b9ac6ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98af8fe8-ada9-4220-9169-43ac7f0bb186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fac0f314-e6a2-4f8b-be98-8a53806c2dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5b10d89-ef3e-4a8b-86fb-f8cdfe5aab37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26c8115a-98d6-41a7-99e5-6d95745fae4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edb6f81f-1ab8-410c-a84e-38cbe41d226a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ac19d62-e3ef-4eba-a69e-f83a7e2e9897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 699922b9-9f11-44fa-8aac-cd674225371a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8b717fc-973e-439a-8393-5a04e30bb05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a520a744-e3c7-4afd-be76-13dec4f7cf5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8286a0bd-29b5-4cb6-9c5b-60f88a88ea95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98d4c16d-5aa2-4db8-a060-6cc662e5e2ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20f9baf8-05b5-44c9-b4fe-405d3e691ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deeed940-b310-44ff-b139-a377d431d3c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b7d124f-a4f9-47a5-9c1b-dc7e790a13bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77e3b349-be0a-44ef-ab49-862ebb7638b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd1c20a7-35c8-4a5a-8fd8-e6125036ed75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b37d715-ef62-4b64-8d71-ed63179a6656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb87cbf4-77ed-4917-9c11-b898c21c0f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09e3ae8f-7e8e-49af-990e-2dacf1d33a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 868215f9-2e73-42f3-bd2f-79465a4842c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9297689c-0e80-440f-baa2-ea53a718435e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a272e5-bcaf-4b56-b726-a701a0b6f113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22f498b5-1827-47c9-9418-2c968960b5cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9057814-2cd6-4839-82d4-cc11ba66b143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66885ddc-200d-4de9-994d-b47c90f2695c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41fb1bea-8a56-4cd1-964f-fcd4034a0f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34b030fe-efd4-4e45-b24f-1b06f6f51d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb825d3c-cd72-4859-8fed-7c4bdb43de5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae90031d-ab25-4b18-956d-4f0036299a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ec71abd-2c70-4a99-a7b1-fffc4aafbe33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd9ef764-02a3-4158-b918-ca9ec07f1599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53ec8814-cf41-400a-aa84-cd15c9e428dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4347802c-7c9b-4203-b24a-d142fbfab84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf0a82a8-2203-45bc-a34c-0cb91fcab1fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5aebc20-8ad3-4cb7-93f4-cd4814f369f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68263fa5-b554-4305-87b8-2a1e4c532efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12695613-535c-4de6-a091-6d3fab56c67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f86a53c-5a3e-4ec9-8a0a-f0ab9b33f2f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52d6691b-279e-45a4-bf45-b3aa5243deb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b58188c2-5924-4801-b82c-4895ff51eb28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4987ff16-6b77-4568-99bb-25e83864aaea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb1e31a2-7530-4dd5-9e29-44ecf4655ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fc319d5-a560-40fc-a398-62d61986653b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32fb5cb2-6ff8-49c3-9f75-fd5cd50f1648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41d51bd3-973d-4f8d-93df-91de65d26af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 008d2cab-f3ba-46b7-873e-3a806f1f967b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceb6c4e3-b47b-4e0f-93dd-d0b0cd894eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4d9208c-b933-458d-8d07-8b8a6e2e96fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77408c1e-1b6f-4663-b9e3-1e48196ddacb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad309cc2-28c9-43b4-9d1c-d634ed2ca0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7988c32-e276-4263-a38c-23e90117063e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e3703d2-2acd-40f5-8799-e11b6e84f2d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3945d7e2-b713-4ee8-9214-d5589aef2996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f801fc70-e232-4fbe-a693-1e34d24d501c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86f8be84-d4d8-4178-bb3d-da7ac4a46f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90981779-a918-402b-9b23-deea42e86e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc1e971a-4f45-4264-9c81-b4a5832810cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0e71ba6-51fd-48bd-9237-32f9ec0c3806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c50b0715-b161-4859-8b24-8d0c64675e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb13aa3a-b741-4470-a527-7bc254527bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66590e61-daac-4d10-8829-84dcc430cfbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d47db393-e55e-4c66-995c-e403b5366891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cfe3e91-bc5b-47d8-a818-77c87eb44f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5cfeebd-58b9-49de-a7d9-23fc77797646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1012840-a3c5-4635-8d33-34321d952ff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81fab670-ff79-4ce9-b712-217af0e3e0ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dff889e3-41fc-4d12-ad09-4c5c99abd248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d29faa44-60da-4e8c-9c23-ee1dd561593f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6151870-ddff-4f2a-bb2a-ffef9dc85b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17f54412-f8eb-4bd5-8864-ca84b547ff03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bf78e47-fcb0-45b4-86d9-d5ff6b770e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 953bd95b-2928-4faa-8851-23c3fda8d89a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71df53f8-6cf2-49f7-866d-d05fda8e0c56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07b283ad-6aa8-4e9f-8335-0f88d097c7f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d576e39-6e04-45b2-955c-2948f2359b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 630db7e0-d2e5-4478-8980-c9c7268d8c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70cf7616-107d-4129-9145-d1466da44414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22a8ae2f-b9ab-4941-b9ee-e18da780761f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 127bcca2-6568-4021-b19d-cbb03eb8cf0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 697cf531-8823-4c8e-9d34-ae70fb252c2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a64295c0-b759-4e46-a8ce-4fa63e9db27e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c09fc6-6d83-49b6-9546-03f13b22e0c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de232d2-360d-4a13-bd42-02b6403461be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad42922e-79d5-4d74-8ef4-8595c454444a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f88e329f-c243-4b80-85ab-da071bbfccad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35e8e240-e60d-4a0f-99d0-cbe16140eef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fb7b6ed-e8f1-4bd0-a66e-762eced54505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c47f365-2598-40fb-ba7b-0661f0dcdbce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 701effec-8f7f-4f5f-bfd3-062c72bbc07e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df68cae7-1a0b-48e5-b349-eb2df4cfa090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47047727-bafa-4135-985e-af167bb7b572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9628a534-5f12-4c8f-b752-1b9e9929ddfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a3f34f4-00d1-4da5-b4bc-b565c4ace5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85798e08-d111-409c-a0a2-d8977ff05520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fc256b9-ffe7-4de0-aba8-ed104579ef0b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_91
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/test_labels.txt

📊 Raw data loaded:
   Train: X=(563, 24), y=(563,)
   Test:  X=(141, 24), y=(141,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 554 samples, 5 features
   Test:  132 samples, 5 features
✅ Client client_91 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 4 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0801 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0877, val=0.0795 (↓), lr=0.001000
   • Epoch   3/100: train=0.0846, val=0.0798, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0850, val=0.0800, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0844, val=0.0801, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0825, val=0.0815, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 4 Summary - Client client_91
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0215
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0024
============================================================


============================================================
🔄 Round 5 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0880 (↓), lr=0.000250
   • Epoch   2/100: train=0.0831, val=0.0876, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0826, val=0.0878, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0822, val=0.0883, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0819, val=0.0886, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0808, val=0.0891, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 5 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0148
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0326
============================================================


============================================================
🔄 Round 6 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0869 (↓), lr=0.000063
   • Epoch   2/100: train=0.0833, val=0.0869, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0833, val=0.0868, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0832, val=0.0867, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0831, val=0.0866, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0827, val=0.0862, patience=4/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0825, val=0.0860, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 6 Summary - Client client_91
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0181
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0149
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2403, R²: 0.0136

📊 Round 6 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2402, R²: 0.0147

============================================================
🔄 Round 9 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0729 (↓), lr=0.000016
   • Epoch   2/100: train=0.0858, val=0.0729, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0858, val=0.0729, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0857, val=0.0729, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0856, val=0.0729, patience=4/15, lr=0.000016
   📉 Epoch 10: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0852, val=0.0730, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 9 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000008 (1 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0192
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.0108
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2398, R²: 0.0189

============================================================
🔄 Round 10 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0855 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   • Epoch   2/100: train=0.0827, val=0.0855, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0826, val=0.0855, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0826, val=0.0856, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0826, val=0.0856, patience=4/15, lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0825, val=0.0857, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 10 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0239
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0133
============================================================


============================================================
🔄 Round 11 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0895 (↓), lr=0.000002
   📉 Epoch 2: LR reduced 0.000002 → 0.000001
   • Epoch   2/100: train=0.0817, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 11 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0218
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0018
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2397, R²: 0.0203

📊 Round 11 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2397, R²: 0.0205

============================================================
🔄 Round 14 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 14 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0236
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0043
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2397, R²: 0.0205

============================================================
🔄 Round 15 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 15 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0164
   Val:   Loss=0.0954, RMSE=0.3088, R²=0.0315
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2396, R²: 0.0212

📊 Round 15 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2396, R²: 0.0212

============================================================
🔄 Round 19 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 19 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0189
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0235
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0217

============================================================
🔄 Round 23 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 23 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0231
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0013
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0217

============================================================
🔄 Round 25 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 25 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0211
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0184
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0217

📊 Round 25 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0217

📊 Round 25 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0218

📊 Round 25 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0218

📊 Round 25 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0217

============================================================
🔄 Round 31 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 31 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0213
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0068
============================================================


============================================================
🔄 Round 33 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 33 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0199
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0218
============================================================


============================================================
🔄 Round 34 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 34 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0218
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0124
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0218

📊 Round 34 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0217

📊 Round 34 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0218

============================================================
🔄 Round 43 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 43 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0183
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0210
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0218

============================================================
🔄 Round 49 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 49 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0201
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0142
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0218

============================================================
🔄 Round 50 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 50 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0164
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0312
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0219

============================================================
🔄 Round 51 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 51 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0213
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0143
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0219

📊 Round 51 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0219

============================================================
🔄 Round 54 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 54 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0234
   Val:   Loss=0.0766, RMSE=0.2769, R²=0.0070
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0219

📊 Round 54 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0219

📊 Round 54 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0219

============================================================
🔄 Round 59 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 59 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0223
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0030
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0219

============================================================
🔄 Round 61 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 61 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0197
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0233
============================================================


============================================================
🔄 Round 62 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 62 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0221
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0146
============================================================


============================================================
🔄 Round 63 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 63 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0221
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0138
============================================================


============================================================
🔄 Round 64 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 64 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0174
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0350
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0219

============================================================
🔄 Round 66 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 66 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0155
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0245
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0219

📊 Round 66 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0219

📊 Round 66 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0219

============================================================
🔄 Round 70 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 70 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0206
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0205
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0219

============================================================
🔄 Round 73 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 73 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0219
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0144
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0219

============================================================
🔄 Round 74 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 74 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0209
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0145
============================================================


============================================================
🔄 Round 76 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 76 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0184
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0088
============================================================


============================================================
🔄 Round 77 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 77 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0234
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0069
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

📊 Round 77 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

📊 Round 77 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

📊 Round 77 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0221

============================================================
🔄 Round 85 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 85 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0200
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0187
============================================================


============================================================
🔄 Round 86 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 86 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0245
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0019
============================================================


============================================================
🔄 Round 87 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 87 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0201
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0213
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0219

📊 Round 87 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

============================================================
🔄 Round 91 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 91 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0204
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0207
============================================================


============================================================
🔄 Round 92 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 92 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0202
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0130
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

============================================================
🔄 Round 93 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 93 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0149
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0245
============================================================


============================================================
🔄 Round 94 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 94 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0224
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0128
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

📊 Round 94 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

============================================================
🔄 Round 97 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 97 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0206
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0190
============================================================


============================================================
🔄 Round 98 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 98 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0190
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0266
============================================================


============================================================
🔄 Round 99 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 99 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0216
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0088
============================================================


============================================================
🔄 Round 100 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 100 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0199
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0232
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

============================================================
🔄 Round 101 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 101 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0205
   Val:   Loss=0.0794, RMSE=0.2819, R²=0.0152
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

============================================================
🔄 Round 104 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 104 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0164
   Val:   Loss=0.0952, RMSE=0.3085, R²=0.0235
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

============================================================
🔄 Round 110 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 110 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0215
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0031
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0221

📊 Round 110 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0221

============================================================
🔄 Round 117 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 117 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0208
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0207
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0221

============================================================
🔄 Round 118 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 118 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0222
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0008
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0221

📊 Round 118 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0221

============================================================
🔄 Round 121 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 121 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0235
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0077
============================================================


============================================================
🔄 Round 123 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 123 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0232
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0038
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0221

📊 Round 123 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0221

============================================================
🔄 Round 129 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 129 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0254
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0019
============================================================


============================================================
🔄 Round 132 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 132 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0193
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0255
============================================================


============================================================
🔄 Round 134 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 134 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0220
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0114
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

============================================================
🔄 Round 137 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 137 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0167
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0301
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

📊 Round 137 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

📊 Round 137 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0221

📊 Round 137 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0221

============================================================
🔄 Round 143 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 143 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0185
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0302
============================================================


============================================================
🔄 Round 144 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 144 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0222
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0060
============================================================


============================================================
🔄 Round 147 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 147 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0185
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0287
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

============================================================
🔄 Round 149 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 149 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0223
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0107
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

============================================================
🔄 Round 151 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 151 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0199
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0239
============================================================


============================================================
🔄 Round 152 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 152 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0163
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0299
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

============================================================
🔄 Round 153 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 153 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0207
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0044
============================================================


============================================================
🔄 Round 154 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 154 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0195
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0255
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

============================================================
🔄 Round 155 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 155 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0211
   Val:   Loss=0.0903, RMSE=0.3004, R²=0.0192
============================================================


============================================================
🔄 Round 156 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 156 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0249
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0024
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0220

============================================================
🔄 Round 157 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 157 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0219
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0119
============================================================


============================================================
🔄 Round 158 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 158 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0196
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0253
============================================================


============================================================
🔄 Round 159 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 159 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0217
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0141
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0221

============================================================
🔄 Round 160 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 160 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0217
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0144
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0221

============================================================
🔄 Round 162 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 162 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0177
   Val:   Loss=0.0957, RMSE=0.3094, R²=0.0301
============================================================


============================================================
🔄 Round 163 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 163 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0236
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0047
============================================================


============================================================
🔄 Round 164 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 164 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0187
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0272
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0221

📊 Round 164 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0221

============================================================
🔄 Round 167 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 167 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0177
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0344
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0222

============================================================
🔄 Round 168 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 168 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0152
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0307
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0222

============================================================
🔄 Round 173 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 173 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0207
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0181
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0222

📊 Round 173 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0222

============================================================
🔄 Round 178 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 178 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0242
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0212
============================================================


============================================================
🔄 Round 180 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 180 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0205
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0120
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0221

📊 Round 180 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2395, R²: 0.0221

============================================================
🔄 Round 182 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 182 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0243
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0014
============================================================


============================================================
🔄 Round 184 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 184 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0216
   Val:   Loss=0.0937, RMSE=0.3060, R²=0.0177
============================================================


============================================================
🔄 Round 185 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 185 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0216
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0073
============================================================


============================================================
🔄 Round 187 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 187 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0204
   Val:   Loss=0.0979, RMSE=0.3128, R²=0.0215
============================================================


============================================================
🔄 Round 188 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 188 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0178
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0325
============================================================


============================================================
🔄 Round 189 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 189 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0169
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0349
============================================================


❌ Client client_91 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
