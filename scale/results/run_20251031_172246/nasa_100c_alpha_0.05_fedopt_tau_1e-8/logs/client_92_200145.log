[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ec0898d-b4c8-4b69-9140-3eb2fc0015ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message babbdd6c-07bf-49e7-9cc1-ba23ed874ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c045caff-7055-42c7-a2dd-9339ca00741c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d996e7-7ef1-4913-a618-0b885db08c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f00a1a9-d81c-4b60-9945-5f8e1e38f730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeb18557-32c6-4271-bab4-489fe842a2a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d11aa3b8-7b63-47ac-a921-955043ad4073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1f154f1-cf26-4949-912d-a07cf6cfad9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46d5f221-5106-4341-b622-1eff58e67720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c073555-ee4e-4819-8cd0-51398b2dc3c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b328888-739a-47d6-ac5a-09bddc9e0ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ff67b01-2dd5-49f7-8639-a661509f4073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b31ed7b1-6a45-4c9c-b728-89bfa2c9a5f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be0f9d37-8ae3-4be9-b7f0-07b4a951dd39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b39069b-f099-46dc-86c3-6aeb434fc9d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c84d4b59-65f7-46be-94f5-a3c5b52dfb3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be13dcd0-e24f-48f4-9440-3d9464abe369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a08476f-70c7-403d-8dc9-616cd73043f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e34d63e-f440-4eca-b923-d7a4692ff344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 262591bb-86a8-47cd-adc5-4d7eaf3d82e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6644690-fe2e-489c-b18f-cd1d024b65ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 604f5ee1-de48-46c4-ac3e-6893b0bb1baf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94a5d117-6bb5-452f-a54f-d978221b97f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 689b7b68-bc99-4c77-9b72-ae01912ffd5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e1a71d0-406e-4846-bf30-8caafab55fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da114bb1-753a-4433-8c36-440f75e63bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f1afd71-464b-4c5f-97bc-9070e8360692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba7578b1-c86f-4a64-9cde-f83fbdc4fa14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb0dee22-1e4d-4795-9ae7-35d2b5edacc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa3947ff-5f67-45cd-8775-1141d2758359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95c540ab-d7f5-460c-9f74-2620ccf5eb92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3503cdb-85a4-4395-b162-185e03075a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e589cef1-b038-4157-960b-4ea056e65e94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d8dc39f-ecc4-4a29-af34-0f7d7ffc0dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2583f23-a051-4a97-89a7-f34435d1e9b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09388951-272f-4306-a5bc-124c9a63e2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41a277ba-7048-425e-b7c5-4c2004e71d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5967113-ab6e-43a2-87c2-64906ea83264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7a13921-d534-4295-82a6-4414057f3a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d307358-1e56-4e56-9aa5-d865c5963460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8fcec55-3bf9-4bad-a205-c0ff6638d8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d20d2e0-4f79-4d5a-8804-31cde3f142ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 283e71b3-9746-4159-a2da-9b1800087ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22a7bd45-689c-4bf7-8a64-7e408dfcbb44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c084cf1-1446-4824-85c1-38972aa6e267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 767c1e3c-a841-4410-af06-1c498bf01748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b29a18c-6419-426e-bc83-3fc2e7b9645f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d6a6921-c16c-4ca7-a4ac-5a9b2523bee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97261ec5-6f98-4e45-9e4e-47809f551eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a06db177-4ac5-4601-af57-e569ce43953c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea8011f2-987b-490e-b9a8-9af8fccdfa45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89094c3d-42de-4736-a2e6-9f79e3d19d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0aff1ae-6520-43ee-abc6-f1f37ae9aabe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8b9dc20-d557-4fe4-ba32-d29d1df3e396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9989b8bc-7ddb-4ffc-ab2f-be6543f1b7f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51f18daf-c18e-4743-92af-a841f567eec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e62e61de-4951-4b55-b5d9-6d441ece61f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 112f12f9-dc98-4725-886a-c627e0ec0d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 250dbbb0-4216-4b77-82be-7d79e50e555a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e23a530b-8046-4772-8ba9-d4f578ebd8eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 712f1c3d-3cb8-41ad-8c6f-f3fcd83069ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e32efe2d-be32-42f6-8ab2-ad8db679f4d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31487c92-2162-4796-a58e-6081afca32e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80c38b84-b7f2-4614-9eeb-a6038e03d9b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7400515-3bfa-4320-b413-0994eb3db36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 059c7b5e-f049-435b-aa9a-7cc11f3ddde8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 779431a0-389f-48f7-bba8-f220f93d122e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5943870c-794a-48bc-913f-b422e57de790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5f44871-05e1-48ea-adea-870987cc16d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 983a7c7b-cb23-4abe-abc2-db0480f3ddc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c16abb35-863b-4c6e-b7b8-f27eac6749e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06f5e0bd-8b45-4645-9b5c-a66bc2c1fad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce99888c-0d0f-461b-b1b3-ffc836fb2c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3093012d-f8e3-46d0-aa3a-b57bfcdc926a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc66abfd-8a5c-4705-b6ef-56ae95102921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 975856db-0d99-4a3c-b15a-0f426cc2c3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d21a0393-3841-453a-ad9d-d39df74c1062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f65ea56-d00a-43ac-ae2e-5f469b7c4809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76109b15-0ad2-47f4-8798-2477850e2eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2251504a-4d48-43e8-a59a-b5863cf76109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c5c83db-96ff-45a0-ab4c-3912bdda840e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c866afa-8e12-4e79-af8c-4bdba875d76c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cbefea2-7195-4d1b-a49b-1a215af72bed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 866a8099-6c0c-4337-9026-e99e7b494d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46deeafc-58e6-48fa-9973-9d3ade04a3bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 412b950d-50a2-4183-97c5-38f3baa82257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a083e0e2-2f84-41a7-aef7-bc8326d688de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7424df3c-d075-48f7-8b9a-28ae7593ee28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a33cabdf-a289-4f55-862b-8fba91efc944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f66bd1d-ae98-44cc-9e88-72a59e6c304c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfc12377-13f6-4cf8-a58d-c4310bb43468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d02a92ce-b356-49e3-aaab-ea93294c4bdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 089de706-f2c4-4a51-b0fb-96f67517c8f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d52db85-2bc7-4127-8201-ab17e532507c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b709984-3699-4619-9ce0-f6a80bc5ce40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c14afce-347b-49c0-8b30-ae9e36caa821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fcce25a-cce2-4310-bdaf-32cb20d7cc84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 682ff844-6c0d-4506-9b63-c7ef80db41d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 644d4c7a-f099-483c-ae2a-e6af8a3722fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73b25db4-8d52-4dee-b484-9685132f7091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ff6d36c-bc56-4333-936b-0a6f7c9167fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 872b7eb7-cd68-463c-924b-6bd018f43745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42051b17-b6e3-4965-8d76-ff395eb9a255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09d8d74d-9ce5-41cc-857d-e26fe1101e56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7372c4d6-2479-4a50-8795-1f400bd26a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2869181-13a1-4105-8ff5-452724ed316f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaa97525-32e5-4f17-a9d8-12fb60802e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53df5056-e464-4f07-b396-2e7e1f47355a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64aa0e4a-54ae-4dda-ad1c-b2303084a72d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8a814f4-4012-471c-988d-126f68a6bbfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17113dba-8544-47f2-a415-2b48b3c77502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bce7e489-f4e9-4ef1-8929-f23ab84620ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cc48407-ad7d-426f-88f5-3d7669fb33cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00f10ad8-daca-4f4c-adc9-207227eb1109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a4a10ff-7b3b-48fb-a2d9-aea62b7b79e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de791a8a-ca62-4f3e-a551-e5dcfcb812de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6da1a92e-259a-407a-9319-616afffc874d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84c7f82b-b022-4b28-a8cb-a54ec72c18c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96dec160-93f4-418e-8ec2-7879afa7119e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb492a22-e55f-4c3d-a010-0d8c05aa3c2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84d646c7-d607-40b8-a344-7adbd2dd85d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3a2e72f-fabc-4bb5-9772-45710b8bd7ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34f30547-67f3-48d8-bdeb-3771548a4c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dd56019-98c6-4c66-b5a1-0b545c576e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0984fee-9df0-4a23-94e2-9eefde073112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d81b13d1-7430-4480-a9bb-9464810b87c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da194df7-03ba-474e-be82-dbd2400b5efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32da7879-e940-435e-acae-9b34e863c2c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 102b38ae-fa4f-4361-908b-8ef330f7446c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7ac518a-0c84-4e9f-aaa1-ab51f14db4fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 636dbee3-3d6f-4960-8076-374237615f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b6998c6-b121-4aa9-a852-c3384db589db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d47104a-e726-4f66-a87f-8aade99ca6ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d630795-f1c3-41cf-9121-b2b8013d7b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b77c31d7-d439-4425-a105-14341c18aafc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba1b8608-bff9-4c9c-9f22-f101c1c6a2ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7bf36c2-f425-4f47-ba7c-be8578f654f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f113a0a-6d35-4e76-95e8-a1e471ed0096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f02f6204-2d69-421c-8749-8ff7b812c8be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 859dfdc0-0a0f-48d8-8ec5-0049cb6c6ccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bbbc209-8cb4-4377-8561-05b525a4006c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19991842-0e06-4e97-a293-fed56b32ecb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f99a1c35-b7bb-42e1-9122-0f4bd2726437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1291daff-e115-40c9-b8b0-fd9cba3c7a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fff7e69b-6f27-4414-89f9-58faafc93d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bf61b70-7238-4eb2-bb9a-a93960b9cff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9def73f-4747-4348-bc66-535d025b1717
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_92
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/test_labels.txt

📊 Raw data loaded:
   Train: X=(1170, 24), y=(1170,)
   Test:  X=(293, 24), y=(293,)

⚠️  Limiting training data: 1170 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  284 samples, 5 features
✅ Client client_92 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2452, R²: -0.0055

============================================================
🔄 Round 2 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0852 (↓), lr=0.001000
   • Epoch   2/100: train=0.0833, val=0.0851, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0834, val=0.0855, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0831, val=0.0856, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0827, val=0.0855, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0811, val=0.0851, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 2 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0037
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0033
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2445, R²: 0.0001

📊 Round 2 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2445, R²: 0.0003

============================================================
🔄 Round 8 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0855 (↓), lr=0.000250
   • Epoch   2/100: train=0.0824, val=0.0852, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0817, val=0.0854, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0814, val=0.0856, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0812, val=0.0855, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0803, val=0.0854, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 8 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0114
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0153
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2442, R²: 0.0017

============================================================
🔄 Round 11 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0823 (↓), lr=0.000063
   • Epoch   2/100: train=0.0827, val=0.0821, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0826, val=0.0819, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0825, val=0.0818, patience=3/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0824, val=0.0817 (↓), lr=0.000063
   ✓ Epoch  11/100: train=0.0820, val=0.0812 (↓), lr=0.000063
   • Epoch  21/100: train=0.0815, val=0.0803, patience=3/15, lr=0.000063
   • Epoch  31/100: train=0.0811, val=0.0798, patience=6/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 11 Summary - Client client_92
   Epochs: 40/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0216
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0363
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2441, R²: 0.0023

============================================================
🔄 Round 14 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0868 (↓), lr=0.000063
   • Epoch   2/100: train=0.0815, val=0.0866, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0814, val=0.0864, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0813, val=0.0863, patience=3/15, lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   ✓ Epoch   5/100: train=0.0812, val=0.0862 (↓), lr=0.000031
   • Epoch  11/100: train=0.0809, val=0.0858, patience=6/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016
   📉 Epoch 21: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0807, val=0.0855, patience=5/15, lr=0.000008
   📉 Epoch 29: LR reduced 0.000008 → 0.000004
   • Epoch  31/100: train=0.0806, val=0.0854, patience=15/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 14 Summary - Client client_92
   Epochs: 31/100 (early stopped)
   LR: 0.000063 → 0.000004 (4 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0168
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0174
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2439, R²: 0.0029

============================================================
🔄 Round 16 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0835 (↓), lr=0.000004
   • Epoch   2/100: train=0.0824, val=0.0835, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0824, val=0.0835, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0824, val=0.0835, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0824, val=0.0836, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0823, val=0.0836, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 16 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0095
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0083
============================================================


============================================================
🔄 Round 17 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 17 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0068
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0050
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 17 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 23 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 23 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0108
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0125
============================================================


============================================================
🔄 Round 24 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 24 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0021
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0240
============================================================


============================================================
🔄 Round 25 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 25 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0035
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0202
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 26 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 26 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0091
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0021
============================================================


============================================================
🔄 Round 29 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 29 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0000
   Val:   Loss=0.0673, RMSE=0.2594, R²=0.0252
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 29 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 29 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 33 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 33 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0047
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0143
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 35 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 35 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0068
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.0048
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 36 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 36 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0079
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0003
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 42 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 42 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0052
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0127
============================================================


============================================================
🔄 Round 44 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 44 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0084
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0065
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 46 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 46 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0083
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0001
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 46 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 46 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 46 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 55 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 55 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0080
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0017
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 56 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 56 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0113
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0139
============================================================


============================================================
🔄 Round 57 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 57 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0076
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0036
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 59 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 59 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0090
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0200
============================================================


============================================================
🔄 Round 61 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 61 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0105
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0115
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 66 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 66 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0077
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0017
============================================================


============================================================
🔄 Round 67 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 67 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0062
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0044
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 68 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 68 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0086
   Val:   Loss=0.0973, RMSE=0.3119, R²=0.0008
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 68 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 73 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 73 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0092
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0050
============================================================


============================================================
🔄 Round 74 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 74 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0024
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0214
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 74 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 76 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 76 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0071
   Val:   Loss=0.0979, RMSE=0.3129, R²=0.0030
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 77 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 77 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0052
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0134
============================================================


============================================================
🔄 Round 79 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 79 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0056
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0109
============================================================


============================================================
🔄 Round 80 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 80 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0058
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0051
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 80 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 82 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 82 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0077
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0018
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 82 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 90 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 90 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0021
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0254
============================================================


============================================================
🔄 Round 91 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 91 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0036
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0120
============================================================


============================================================
🔄 Round 92 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 92 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0039
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0228
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 93 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 93 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0074
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0045
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 95 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 95 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0067
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0066
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 96 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 96 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0054
   Val:   Loss=0.0729, RMSE=0.2701, R²=-0.0146
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 96 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 96 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 104 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 104 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0094
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0049
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 105 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 105 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0048
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0112
============================================================


============================================================
🔄 Round 107 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 107 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0100
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0114
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 107 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 111 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 111 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0055
   Val:   Loss=0.0903, RMSE=0.3004, R²=0.0114
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 115 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 115 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0040
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0196
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 117 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 117 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0055
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0060
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 117 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 123 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 123 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0051
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0063
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 126 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 126 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0079
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0077
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 126 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 130 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0669 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0669, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0669, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0669, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0669, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0669)

============================================================
📊 Round 130 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0044
   Val:   Loss=0.0669, RMSE=0.2587, R²=0.0182
============================================================


============================================================
🔄 Round 135 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 135 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0114
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0142
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 135 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 135 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 141 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 141 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0088
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0022
============================================================


============================================================
🔄 Round 143 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 143 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0101
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0117
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 145 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 145 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0090
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0024
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 146 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 146 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0052
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0120
============================================================


============================================================
🔄 Round 149 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 149 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0098
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0062
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 150 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 150 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0040
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0174
============================================================


============================================================
🔄 Round 151 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 151 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0059
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0015
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 151 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 154 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 154 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0057
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0105
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 155 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 155 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0065
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0079
============================================================


============================================================
🔄 Round 156 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 156 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0100
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0108
============================================================


============================================================
🔄 Round 157 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 157 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0064
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0000
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 159 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 159 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0059
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0096
============================================================


============================================================
🔄 Round 163 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 163 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0036
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0160
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 164 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 164 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0057
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0089
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 166 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 166 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0091
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0019
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 166 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 168 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 168 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0020
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0046
============================================================


============================================================
🔄 Round 169 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 169 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0073
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.0001
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 173 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 173 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0100
   Val:   Loss=0.0704, RMSE=0.2654, R²=-0.0111
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 175 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 175 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0071
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0021
============================================================


============================================================
🔄 Round 176 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 176 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0040
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0168
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 176 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 179 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 179 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0043
   Val:   Loss=0.0955, RMSE=0.3090, R²=0.0067
============================================================


============================================================
🔄 Round 180 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 180 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0066
   Val:   Loss=0.0752, RMSE=0.2741, R²=-0.0083
============================================================


============================================================
🔄 Round 182 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 182 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0073
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0024
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

📊 Round 182 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 185 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 185 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0056
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0095
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 186 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 186 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0022
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0193
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: 0.0031

============================================================
🔄 Round 188 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 188 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0075
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0018
============================================================


============================================================
🔄 Round 189 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 189 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0156
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0442
============================================================


============================================================
🔄 Round 190 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 190 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0047
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0155
============================================================


❌ Client client_92 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
