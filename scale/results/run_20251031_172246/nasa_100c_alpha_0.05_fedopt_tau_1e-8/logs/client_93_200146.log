[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 410461d0-90b5-4659-aa43-643eecf81ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55898b74-510f-4b57-9920-4cdc38515363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fff480ed-94ec-446b-8377-b3b1c452a726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f84facdb-9658-4146-a69b-81fd5cc5656b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0739b634-22b2-4ec5-af97-ea9dce3d6578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c661ba5d-5b67-4ec8-9d54-bb6610bf129e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6309c1ce-525f-412e-8bb4-420f9b8607a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 606810bf-8262-496d-8c91-c2cb4edbe0bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a430ccb-b132-4f49-9949-c143d0542306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddda3050-4ebf-4baa-9a55-9cb493943a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f529a2c1-6cb8-49a9-9696-e19b76659814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6932d24-8a33-46a8-8234-4b2b8c73daea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeccb406-87ae-464f-8050-8194974e43f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c97805b-6474-4452-9bc6-52cd2ef88f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e97b31b-c5c4-40fd-87ed-18a76e210d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e1c37f5-9ed6-4cb2-af43-e3192f4372a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b36cea3-c1f0-4751-ae4a-b76d2a78819e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1246cc5-e300-48c9-8f32-1934f398bfec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b35e7a9-6ff2-4f55-a614-2ffd93517583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72147757-7582-48cb-b4a4-085f054afe81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a472a6fc-91ee-422d-82f3-fd3f83853356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad93e12-0885-4fe4-9371-8951ee0c0e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13b2d7aa-ceef-4fcb-8316-d2977d3843e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7df84c7-229a-49be-83a1-89503786a6dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0adda626-0c44-4dcd-91e2-591970da6d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80cd96db-9c83-4e76-87af-b0472cdeeef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 251a7dc0-fc32-44e5-84e2-55353b87b8d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61309234-1db9-4bac-804d-3c08c9cdb753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc0955f8-ab97-4423-95fa-4f84b0bec738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4767e872-7878-43e1-a81f-f3146c4acdaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d427411-d4b6-4587-931d-9137e545d009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a17d968e-f45d-45db-b6db-0fc9a3988ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18b0cbd3-73b2-4860-8498-a83da0bf80f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9105ca25-4e4e-4475-bb7a-f7eca011d18d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebfce363-13ca-4615-8d8a-ea752ba4403e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c127f901-bd5f-4539-ba4a-a4236605f989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4823d2e-c86b-4e57-a1ec-99b15548e27d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee406cf6-e054-4a3d-b81e-d0a39ba2cd29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8588859f-ad86-4a7a-ab63-7f0007bb8a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b7c851d-cc63-48d2-8966-788166cda71d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dd5f047-3ae1-4d8d-8495-7fcc694c9f50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90f33382-5629-4072-b3ca-cbdadc6ea3b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a975a343-8fad-4a2e-a749-90c98920de6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cca0861-decf-44a8-92e9-bb71b30b879e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b87411d0-fd0b-4b75-bb85-456d8ea0a5a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 026d6bbe-6a57-4cdf-b8a5-af4368a7a940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fab7ada7-080b-4647-b4e1-2b00207fd28d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40335272-9866-4ae4-a38f-8a2ae2c5095b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ed9ad1e-223a-406b-9899-9b57f1d5f6bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71cf82a8-40dd-4d9f-b5b8-1ef26d335623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43c2d708-2599-4335-be80-e9c093260cca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 032eb129-e5d8-452f-8374-2e8934595c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 853579ac-faeb-4743-a69d-bf5ae0ceebde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03a6f2a9-0bcb-4adc-a50f-054f3e672bbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a23ead53-0e38-4cfe-bdf6-34a75ad93ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38bd7958-d21d-445a-9bd4-bc1f2f86465e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41dbe326-d0c1-4684-a576-86e5ff1e8b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95d312d3-da9a-42fe-9b10-8897e6f378fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7d2b596-98d8-451a-ac8d-4215f50eb459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3b11f95-6846-4c5a-96df-e9e4ddb6297b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b7ed4ef-e971-420e-862f-50a98b49a0cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8212e67-5f41-48e1-8e0a-9a963a9900a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c469aebd-ee42-41f5-b455-921c5e41c650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24efcd5e-bd80-4701-8155-ab10f7cffc86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aee7771e-c3c9-42da-9340-e726d12fdf73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d97e113-257f-4fd6-bbe1-15ef1fa52e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37fedc40-b39c-4b0a-90ba-013b99977665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d10ccd6c-d501-457c-bd3e-2216c9abb7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 252eef04-8472-4a4a-a8d8-c05bcdcc41eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3df8122c-1886-40a5-b9e5-f6847ff1a7a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b6cfb6f-d8d1-48be-97ff-89ae1ba4a10b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 125762ad-d0e1-4d65-8575-38c7d1028351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48851fbb-532d-4f63-9623-4529196b3b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18c83161-1f35-4f81-93aa-e22b79f6202a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c9f9e12-ac85-4a87-978c-ca1e1225508f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d411e035-c25b-4a56-98dd-2a6b80a1078e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 144a0d0c-dbab-4766-97fa-052dd50f9a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15cecc74-debe-420e-9c34-f2870b04c882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7c7cc00-18df-4253-9a46-6f3fe874eb2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd92062c-2e0a-49a2-9dcb-5786d57394db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9512c635-f6d9-4a99-a010-d9ffc9008c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdebf185-c254-45de-b241-ed88d7bc26a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa4f1ba-cdf7-4085-9cba-037a76e5a141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5984a29-9712-4d4a-a070-2b8eec326dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14178403-e9ac-4e1b-b0b1-6b66e2cf9328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70a45076-7a75-41f3-b03e-a2927df8c3a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 306ffb0a-a4fe-41ef-87a6-f365b9a4c1f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37dcf470-b53a-4434-8ccb-a51e2631aa84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a5a460a-889a-456e-af52-89e53a2634b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97679f5f-5ea1-4a37-8b06-e21b57ec85dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b3e7b14-41cb-44f2-8a5c-d3ed38c24725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59817133-ca81-464f-abdf-dc88ada7648e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 697d5ce1-d034-4586-8661-bb2989128ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bab4f931-c778-4a2f-84f7-4b16181e3aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7ff3813-570d-4282-9050-8696d55cfb3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dd997f5-29b1-4478-8826-16fec71f72ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4101c815-49cd-49f9-8fd7-f3afa6f33108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75358d37-c28b-41f9-b5f5-da21dbe95833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8ac61a6-aaa9-4d73-bb6c-cffb4c9083a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b242bce-772f-4a88-845a-0b070eec8b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a947342c-80b4-4b07-90b9-7fca1ee6b752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4eb311a-e2d0-4ea8-beaf-e8e1c25d3324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca814de9-63ec-43e0-adc7-826628a37fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc51811c-907d-48d5-abc0-b16fc54a7665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4768597e-aad5-4f1a-b852-81e64121341e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cb9ffa6-ece7-476a-a71e-a6002bb378af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ee8c166-49ec-4667-aee2-b0118f28cc2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52b38513-9fca-4dfd-9d75-a8ee7bccf3de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab785477-4687-4e0a-b1af-5dfd5af6515e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d4c967c-5485-49f9-85b2-0016830ea472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55a2dabe-c9bb-449a-8372-36a0cb6388d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b77f2a31-953c-4ca6-990f-7f50bc8878e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d6d089a-ffdb-4d5c-93f5-7cdbf3ebf413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbbf0e2f-25c7-4ae8-ba46-2fcd059f1bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24b97f03-42a3-4b24-bed9-eb6d7998cd4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d1b8bd2-4650-4097-81f0-a9d8861f7116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 821cdf21-b287-4d24-8e0b-63b5c0280008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a76a9463-8bf8-4fec-8b0f-a86e6fc54638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90f33186-0592-4935-8338-1dc2bef4af41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 939f5830-b28a-425f-9b36-872fedd7b3dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84be9693-a5a6-4508-803b-43f21b024dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81df0cff-1a2e-4387-b6ab-f41533eb1196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0b2fc8b-8d94-4369-85fe-827d4bc7e6e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c88d5a11-99f2-4cb0-a109-63ffc6e1df63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b024db8-5e5c-4c8e-b545-d63b7d661578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8476ea67-0852-4e53-bcfb-424d02de6633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea320dd5-3eb4-46f7-a7f2-7af5cde9ac55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56476249-7cff-41eb-8e16-3bf873c3a34b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a41b8d5-de6b-47f1-ad3b-6ec43c62e20d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09a02d8d-6d05-4639-81b9-75bd8b29fd9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 988713ff-a4da-4160-8d68-57f93190f972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0cf76be-81cf-4dc2-8f27-1d9b252bbf52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dcf6dab-9afb-4b2c-b173-6561f198212c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbb5aa30-7605-46ef-a22c-de9b3f2366d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21fe8cd8-fde2-436b-ab94-4649979a0c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d7c12cb-e685-45bb-a35a-ad696e3f3904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d602facc-5340-4134-be02-a0ed156a17eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c836a05-e4a4-47f3-91f6-7b4b6cf7cc0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c6c174f-d4c3-4912-b7fd-d96c26bc4596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f18ac0d1-cc35-4f24-8fc8-a9b84678871f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f5162e6-010d-4064-8fc9-046fa026e5c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c77a1b86-5816-49b4-9386-525a13d1d3ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a18e8ddb-9a7c-41db-bf21-5d9314aa887d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d83397cb-32a0-4b74-bb5a-f015723c2622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 485216a1-5aca-4a09-a1b9-ecffe4373905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eafcb9cb-47c5-4d2d-8935-25b33e4a1a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df106754-3d6d-4b89-a17f-0d04d440dd33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16454534-1c7d-4000-9ed6-d24b6b649fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62702f85-8291-4b5d-99d9-ca7098bdbd44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb5be9c2-267e-4b39-8712-731fe6f19c59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2a47cac-c7e4-4326-959f-3a63090d11bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 148eeebf-d7f6-46d6-a61c-3557bb8026f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 485b3752-c855-449c-bc20-6c6944e46516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3b305f0-799d-4642-bd56-118dceb47c9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b5682ad-dce0-4aaa-858f-b5037a281516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f8d9bf5-8fc2-4004-83c9-410a1548a164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66778247-63a7-4fb3-baa9-adcf6f9aaaeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e2f2b72-9ec8-4eea-bd5a-b1ecac412573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef5defaa-f65f-4d13-a6f4-d9e18b28b78b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcfac38e-9e21-467e-a272-52bbc59a7013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62385f28-2f65-41b5-add7-c4b1643e33d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d769dd5f-2686-4af4-a44d-d402d363861b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa7ba178-4a7b-49bc-9f6f-f5f23f99f6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aecc03a-9cfa-4977-b5d4-ec11c349679c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_93
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/test_labels.txt

📊 Raw data loaded:
   Train: X=(815, 24), y=(815,)
   Test:  X=(204, 24), y=(204,)

⚠️  Limiting training data: 815 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  195 samples, 5 features
✅ Client client_93 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0794, RMSE: 0.2819, MAE: 0.2463, R²: 0.0015

============================================================
🔄 Round 2 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0899 (↓), lr=0.001000
   • Epoch   2/100: train=0.0853, val=0.0901, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0876, val=0.0875 (↓), lr=0.001000
   • Epoch   4/100: train=0.0867, val=0.0883, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0849, val=0.0877, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0837, val=0.0879, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 2 Summary - Client client_93
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0014
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0042
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2474, R²: -0.0068

📊 Round 2 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2480, R²: -0.0125

📊 Round 2 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2487, R²: -0.0176

============================================================
🔄 Round 7 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0956 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0836, val=0.0951 (↓), lr=0.000250
   • Epoch   3/100: train=0.0830, val=0.0953, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0829, val=0.0954, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0828, val=0.0954, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0821, val=0.0953, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 7 Summary - Client client_93
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0043
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0156
============================================================


============================================================
🔄 Round 8 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0835 (↓), lr=0.000063
   • Epoch   2/100: train=0.0860, val=0.0834, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0857, val=0.0836, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0856, val=0.0837, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0855, val=0.0838, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0852, val=0.0842, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 8 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0130
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0238
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2491, R²: -0.0249

============================================================
🔄 Round 14 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0912 (↓), lr=0.000016
   • Epoch   2/100: train=0.0856, val=0.0910, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0854, val=0.0908, patience=2/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0853, val=0.0907 (↓), lr=0.000016
   • Epoch   5/100: train=0.0853, val=0.0906, patience=1/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0849, val=0.0902, patience=7/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 14 Summary - Client client_93
   Epochs: 19/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0194
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0245
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2501, R²: -0.0306

============================================================
🔄 Round 15 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0805 (↓), lr=0.000004
   • Epoch   2/100: train=0.0884, val=0.0804, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0883, val=0.0804, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0883, val=0.0803, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0882, val=0.0803, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0880, val=0.0802, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 15 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0281
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0278
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 16 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0961 (↓), lr=0.000004
   • Epoch   2/100: train=0.0847, val=0.0960, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0847, val=0.0960, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0846, val=0.0960, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0846, val=0.0960, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0844, val=0.0959, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 16 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0261
   Val:   Loss=0.0961, RMSE=0.3099, R²=-0.0462
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 16 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 16 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 16 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 16 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 25 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 25 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0306
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0229
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 25 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 27 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 27 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0311
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0204
============================================================


============================================================
🔄 Round 28 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 28 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0277
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0424
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 28 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 28 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 31 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 31 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0256
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0632
============================================================


============================================================
🔄 Round 33 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 33 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0266
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0401
============================================================


============================================================
🔄 Round 35 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 35 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0327
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0152
============================================================


============================================================
🔄 Round 37 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 37 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.0296
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0265
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 40 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 40 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0324
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0263
============================================================


============================================================
🔄 Round 41 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 41 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0310
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0257
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 41 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 41 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 46 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 46 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0345
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0143
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 46 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 46 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 53 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 53 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0293
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0406
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 55 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 55 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0285
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0329
============================================================


============================================================
🔄 Round 56 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 56 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0331
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0149
============================================================


============================================================
🔄 Round 58 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 58 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0274
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0354
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 59 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 59 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0305
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0271
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 59 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 63 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 63 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0283
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0331
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 63 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 66 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 66 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0315
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0176
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 69 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 69 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0347
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0077
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 73 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 73 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0303
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0425
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 74 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 74 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0288
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0302
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 76 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 76 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0356
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0311
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 76 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 76 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 81 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 81 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0273
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0357
============================================================


============================================================
🔄 Round 83 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 83 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0371
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0035
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 83 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 85 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 85 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0326
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0167
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 85 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 85 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 85 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 85 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

============================================================
🔄 Round 94 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 94 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0354
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0257
============================================================


============================================================
🔄 Round 96 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 96 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0259
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0425
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 96 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 98 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 98 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2933, R²=-0.0338
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0110
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 98 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 101 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 101 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0242
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0513
============================================================


============================================================
🔄 Round 102 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 102 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0315
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0190
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 102 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 102 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 109 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 109 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0356
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0106
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 109 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 109 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 114 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 114 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0261
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0399
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 114 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 119 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 119 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0308
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0361
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 121 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 121 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0295
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0346
============================================================


============================================================
🔄 Round 123 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 123 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0274
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0354
============================================================


============================================================
🔄 Round 124 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 124 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0329
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0377
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 126 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 126 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0224
   Val:   Loss=0.0964, RMSE=0.3106, R²=-0.0937
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 126 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 126 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 130 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 130 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0299
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0305
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 131 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 131 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0362
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0038
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 133 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 133 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0311
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0208
============================================================


============================================================
🔄 Round 135 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 135 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0263
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0519
============================================================


============================================================
🔄 Round 138 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 138 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0298
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0291
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 141 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 141 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0257
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0427
============================================================


============================================================
🔄 Round 142 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 142 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.2999, R²=-0.0323
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0271
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 142 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 146 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 146 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0299
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0251
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 146 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 149 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 149 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0281
   Val:   Loss=0.0964, RMSE=0.3104, R²=-0.0418
============================================================


============================================================
🔄 Round 150 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 150 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0288
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0331
============================================================


============================================================
🔄 Round 151 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 151 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0221
   Val:   Loss=0.0963, RMSE=0.3104, R²=-0.0555
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 152 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 152 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0273
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0375
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 153 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 153 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0295
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0272
============================================================


============================================================
🔄 Round 155 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 155 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0289
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0323
============================================================


============================================================
🔄 Round 156 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0991 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0992, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0993, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0991)

============================================================
📊 Round 156 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0362
   Val:   Loss=0.0991, RMSE=0.3149, R²=-0.0386
============================================================


============================================================
🔄 Round 157 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.1020 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.1020, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.1020, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.1020, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.1020, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.1019, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1020)

============================================================
📊 Round 157 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0289
   Val:   Loss=0.1020, RMSE=0.3194, R²=-0.0297
============================================================


============================================================
🔄 Round 158 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 158 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0303
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0326
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 158 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 158 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 161 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 161 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0345
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0170
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 162 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 162 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0327
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0210
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 162 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 165 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0989, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 165 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0274
   Val:   Loss=0.0989, RMSE=0.3145, R²=-0.0371
============================================================


============================================================
🔄 Round 166 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 166 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0260
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0421
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 167 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 167 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0266
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0433
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 167 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 171 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 171 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0258
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0653
============================================================


============================================================
🔄 Round 172 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 172 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0253
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0449
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 173 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 173 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0312
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0263
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 175 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 175 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0223
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0590
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 179 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 179 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0326
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0147
============================================================


============================================================
🔄 Round 181 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 181 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0365
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0029
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0309

📊 Round 181 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 183 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 183 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0223
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0603
============================================================


============================================================
🔄 Round 185 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 185 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0263
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0414
============================================================


============================================================
🔄 Round 186 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 186 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0269
   Val:   Loss=0.0957, RMSE=0.3093, R²=-0.0377
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

📊 Round 186 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 188 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 188 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0245
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0500
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 189 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 189 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0298
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0323
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2501, R²: -0.0310

============================================================
🔄 Round 190 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 190 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0284
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0321
============================================================


❌ Client client_93 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
