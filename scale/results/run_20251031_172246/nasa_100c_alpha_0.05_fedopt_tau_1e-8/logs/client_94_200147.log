[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecefcfa3-95b3-4c35-ac37-6df1da798b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbe7cf87-b4a2-4a0e-8ba7-012315914307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1095bd62-cd4c-46f8-88c9-61c445fd67be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b28e19ae-9890-4209-8e3c-2f5ba93e75c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa9a3370-bfb1-4572-ad67-f446ca7ed6b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b703274b-5699-4efd-a084-b9020a3416fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24e03398-4627-49bb-baaa-402723eee470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ba0f90b-bef6-45bf-a574-a6041a21f6a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2a4ae20-9389-4d2f-97e0-60f6f3ecd9ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 769da187-d309-4edc-93c4-9a74e6fd2167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87b8c68a-2482-4321-a0c6-b0b9ebece2a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a114c5b-0eb9-4f0c-92e3-a08f467a2118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ea4ea8b-caa1-42a7-9014-716f42a87d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 960e8570-37ed-463d-ace7-83d11b04b938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0757fb8b-38e7-4ff0-b89a-dfa812f0986a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e446264-4c1d-4100-9b9f-52a4bd578ddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb106009-6728-4417-b043-302e29d9c6be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11cb3784-c26a-4b1a-814f-077650e40747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d60a632a-ae3e-4a1d-9d89-d4fb52666839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05bf0566-1cf5-4460-b1c2-16f9fb13e114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbfe8752-163e-457c-abbe-d14a59330e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e7eead8-27fb-45ec-9c71-976cb26a176e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b7dba1e-500e-4115-99b4-913a4922280b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4950b2d-e030-4e4e-881c-ca3134f42f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39784cea-d30f-4d8b-8023-33e68cf1b06c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de382b9f-894f-4151-a9b0-badfd9934d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58fb3428-1eea-41f2-8034-4f399e3d1093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cbf214e-27e2-4f8c-b7ab-f7d00c2b2fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cfe6a4e-aee4-4cd7-9e56-d64efb7dfc22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa7f9a9c-d835-480b-ad24-7d81262eab31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffcf2acb-86dd-457c-8cd1-ae3c02debb3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9d32d11-6f26-4681-9cd2-a16d9f3cfd92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 736447c9-0b8f-47fc-be09-a149a2fd8e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20dc0531-139d-499a-883d-dd782e006a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57731b56-1a7c-455c-86a3-63c4e055a7fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8135f52-d4a0-4d41-81ec-a3a76939b093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08b42cd8-0871-417f-8b78-63de6defe8ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23b77753-94d2-4f35-8fd9-1edcbc11cbb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b299520-9955-4315-8d4b-1197200d2280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8e2ac4d-5311-4a6c-bc6e-c99d250a7b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffd2d3bb-6ef1-4fc4-9fcd-17325a27f670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48502f47-ed47-49d3-9e18-ec27dc1141be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb0bcfbb-4e28-44a0-b73f-bdca7c48f1ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6867ac11-2062-45f8-9b9e-c6cf9ff98000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7faa14e8-d1b0-403c-a336-eeb49b2ba3a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7519d0df-725d-402e-8405-99f7d043bb17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a11aafe0-4d8d-4702-b990-0034a2f05791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c89c09d-31ac-4a3b-ab2a-49a7b9a77769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 454d6a29-bf37-42c7-aa2e-8b336ac1b9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 233dd5ce-dca2-464d-8a37-bcbbd4d0d567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa4d0f9f-36f4-4283-8340-b114482ed627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ece76b0-136f-4c8e-96f7-7e8834684246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6c747e9-c5ad-4f27-a4e7-8f6609481058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62c7051a-efc7-4653-a565-2700e08a03ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0da5c37-3a28-4967-b4bc-8b87cb63ebad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df6538da-2766-4b95-bca6-6d835c45ea5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5012ac3-d6fb-4076-afd0-34b8fcfb3588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fe43fe5-4305-4eb6-93af-dbfb99562c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75feb185-9c86-4d6b-955e-0c08065e689c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d174102-3fe3-4a80-ae01-ae4da26f20f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05781f19-861f-4959-8187-533de86a212e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a647eb5a-2a93-44be-a5ff-d634d3710ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eb53fb4-d632-4546-b3eb-25ae223a1bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53df31e5-6a32-4129-a420-a604613170f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcb432b8-d1bb-468e-89dc-d0c2588e299b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9546cc69-c164-4ab6-89df-12a42ebffcb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63b66b56-8407-4724-a974-4876524b548c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 654088e3-ee02-422f-bf1c-27f4c8d82ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9b4d258-74b9-453b-bf96-fd642a7aeac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29dd34c7-fa1d-4abd-8211-98bbc3ce28d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 698a561c-3d0d-4020-9b56-f8a0c40d2cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48207e06-322e-47dc-8f7d-ee9f788fc3e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f535603-406f-4692-8366-011a736738c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 247e9051-2e52-42d5-8a3b-239615c78de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31c16bfe-851b-43d7-b9a7-49c029045b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c9c9b55-acd6-45d4-8b09-ee521f550046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daa6915a-0a84-4e5f-8eee-39b511474d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09c9994a-a2f4-4956-bc61-d6dd433628e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 177ab75b-b8e0-4e78-9c10-1f798742a81d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc9d294c-bc05-42ed-be61-a41f803d2c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ace68a-9442-4126-9db8-d9e5d0a71470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efaa3d0d-5fb9-4d82-81b1-7def15b2e66d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f20c144-21e2-48f9-aa67-93f9d0460823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c07f91e-a48c-4d31-adc0-bc1ae1bda0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f78a2bca-2142-471e-a373-ba8e61764a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cdd630e-d92a-470c-8941-3132dd21fde9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 790a7708-ed22-452f-879f-8fb51d0726c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4acb1202-a7da-48c0-9719-1d975683e16a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02a16317-8852-4f9e-8751-e6889f2a677e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4144aecc-a48c-4cf3-925c-1ee758ba4424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed453135-d647-492a-9ec7-50dc59878a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 104b85c1-0a87-4b58-b938-7da5598b09a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b55a1d31-5b10-4679-870d-06d03fbf26ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be0c0f38-db12-4a2e-949a-9f8adaa5a2fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aae9cd9-6041-41cc-8d8a-ce121c62d135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 513b7c65-21c6-4a53-b447-25862b5d394f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5e16082-3303-4e0b-926c-a49f4b07d926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9d44234-7e9e-4674-a508-672900d453eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1d53480-8f9c-46f2-9af1-fe57f1f3f9f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa741f34-cf6a-4ffd-98c6-c68699d5691d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65c6bf55-d9ef-4598-9399-8307400c133d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ca2ebeb-d93f-4c54-875a-1266cc03fd7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b146e7a8-5abc-41bf-914a-3ea5d0251507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c5a5bbe-cbc0-46d4-a053-68f4737854c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8713e226-625e-4df4-bef2-ebf31fc68919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 765e7f7f-8145-47ab-b311-20876d07f90a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95f66cb7-2761-4057-b9ed-66d9ef403102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66d48c88-d474-412d-8366-de82890c6c7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76be3f6d-d58e-49d2-a371-0e32d63cdb95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb28f0f3-f96c-4501-b3b0-7a5ba13d382e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a074527-ff5c-43e4-8dbc-45d0624fb4c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c68d5857-bd0f-482e-ac00-ffd6bc33d166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1366788a-69e3-4ac3-823d-11ea3ed5c5da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93d536e5-cc2c-4d4e-9178-601f50f22b8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9ef9295-5fc7-4c58-a50f-67d12faded3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac2e6efc-2c72-4087-b24f-c58d688f764b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23dd7f4f-4d1c-4717-b4e9-9d33b0a4b778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b1f925b-ef6b-42a0-875d-fda7fb0b9414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 854c57ac-d56e-45aa-b0a1-dcf8f4dc33e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e29e4044-0d9c-48b3-8394-62976a0c8187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03f1fa4e-3a18-4499-8545-a0b6afb90dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab86ca30-a904-4356-902e-832c30f45806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31130b17-3b00-4c8a-a7aa-d482bcbbf40e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b72c3e-a12c-4a73-a5f5-0e4391e6e36e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25a02511-fb3f-4635-8a16-cade4be63ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 577a6f48-85b2-4c0e-b315-fe4da96d710e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f07458c8-6a57-4136-b188-97b5e26e9218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db2ebbdc-bccc-435a-afae-c02e27badf25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79054505-62a6-4ba4-b2d0-3ca990f5cb2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 854ccdae-e3a2-42a6-87a5-91eeb09fd52e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c11e20c-11ec-4e11-99f9-86ad9944df19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da3eea75-0968-4161-84ff-fce6ea97fe76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a36a6b11-d5c4-487d-9c86-3ee568cbeafd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a14e7048-eea6-4078-86e9-4cccebbd583c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 772cf659-4705-4fde-89fe-f4c6220bd0f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c6f757-35dc-47a8-b974-78a161f95b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5befabbf-5c29-4c6b-a3fb-9c1189a354b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dddeabf-810f-4489-b113-4e3500764b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 206948ba-d299-448f-9d24-eef510c794a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93e31f64-67f6-49f1-a1a7-32201d1b9744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7deec66-4dde-436f-a38f-6bca8b608c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84c7e6d0-2a38-477b-ad86-ae7da514b6f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ec07a95-993e-4426-8cae-ccb4460c3f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3efde474-f55c-4690-b777-d3fcf787e76b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb8ac417-9fec-4199-8c6d-05ee942c7cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcaeeb6c-0187-445e-ab4e-c84131455f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b47e2250-4f5d-4f70-95c5-785df3a0d0ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be78d351-1085-435f-91da-bc9276097726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b15765f1-4db3-4f26-aa8d-b8256ea43ff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 329c7dde-a180-4285-8359-bb1941ca69b4
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_94
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/test_labels.txt

📊 Raw data loaded:
   Train: X=(860, 24), y=(860,)
   Test:  X=(215, 24), y=(215,)

⚠️  Limiting training data: 860 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  206 samples, 5 features
✅ Client client_94 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2415, R²: -0.0076

============================================================
🔄 Round 2 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0864 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0857, val=0.0859 (↓), lr=0.001000
   • Epoch   3/100: train=0.0854, val=0.0858, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0851, val=0.0858, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0850, val=0.0859, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0832, val=0.0860, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 2 Summary - Client client_94
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0063
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0113
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2407, R²: -0.0031

📊 Round 2 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2405, R²: -0.0020

============================================================
🔄 Round 5 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0926 (↓), lr=0.000250
   • Epoch   2/100: train=0.0823, val=0.0927, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0822, val=0.0928, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0820, val=0.0929, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0819, val=0.0930, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0814, val=0.0933, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 5 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0034
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0105
============================================================


============================================================
🔄 Round 6 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0856 (↓), lr=0.000063
   • Epoch   2/100: train=0.0840, val=0.0856, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0840, val=0.0856, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0839, val=0.0857, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0839, val=0.0857, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0836, val=0.0858, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 6 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0091
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0023
============================================================


============================================================
🔄 Round 8 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0780 (↓), lr=0.000016
   • Epoch   2/100: train=0.0859, val=0.0781, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0858, val=0.0781, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0858, val=0.0782, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0857, val=0.0783, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0855, val=0.0785, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 8 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0116
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0128
============================================================


============================================================
🔄 Round 10 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0824 (↓), lr=0.000004
   • Epoch   2/100: train=0.0848, val=0.0824, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0848, val=0.0824, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0848, val=0.0824, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0847, val=0.0823, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0846, val=0.0823, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 10 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0072
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0013
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2412, R²: -0.0068

📊 Round 10 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2412, R²: -0.0074

============================================================
🔄 Round 16 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 16 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0041
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0192
============================================================


============================================================
🔄 Round 19 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 19 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0065
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0119
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

📊 Round 19 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

📊 Round 19 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

============================================================
🔄 Round 24 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 24 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0100
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0049
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

============================================================
🔄 Round 25 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 25 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0081
   Val:   Loss=0.0936, RMSE=0.3059, R²=0.0061
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

📊 Round 25 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

📊 Round 25 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

============================================================
🔄 Round 29 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 29 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0142
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0177
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

============================================================
🔄 Round 30 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 30 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0087
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0028
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

============================================================
🔄 Round 31 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 31 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0050
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0004
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

============================================================
🔄 Round 32 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 32 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=0.0080
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0012
============================================================


============================================================
🔄 Round 36 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 36 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0057
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0138
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

============================================================
🔄 Round 38 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 38 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0095
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0005
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

============================================================
🔄 Round 39 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 39 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0058
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0154
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

📊 Round 39 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

============================================================
🔄 Round 46 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 46 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0080
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0045
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

============================================================
🔄 Round 48 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 48 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0105
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0137
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

============================================================
🔄 Round 49 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 49 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0040
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0228
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

============================================================
🔄 Round 51 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 51 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0036
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0190
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0077

============================================================
🔄 Round 54 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 54 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0077
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0065
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

============================================================
🔄 Round 55 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 55 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0012
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0181
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

============================================================
🔄 Round 61 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 61 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0015
   Val:   Loss=0.0903, RMSE=0.3004, R²=0.0403
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0077

============================================================
🔄 Round 62 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 62 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0070
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0081
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0077

============================================================
🔄 Round 65 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 65 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0078
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0069
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0076

============================================================
🔄 Round 69 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 69 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0042
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0098
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0077

📊 Round 69 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0077

============================================================
🔄 Round 74 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 74 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0041
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0003
============================================================


============================================================
🔄 Round 75 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 75 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0066
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0118
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0077

📊 Round 75 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 81 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 81 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0034
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0247
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0077

============================================================
🔄 Round 82 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 82 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0106
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0037
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0077

============================================================
🔄 Round 84 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 84 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0090
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0009
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0077

📊 Round 84 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0077

📊 Round 84 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0077

📊 Round 84 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0077

============================================================
🔄 Round 92 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 92 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0038
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0177
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0077

📊 Round 92 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0077

📊 Round 92 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0077

📊 Round 92 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0077

============================================================
🔄 Round 97 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 97 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0132
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0155
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0077

📊 Round 97 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

📊 Round 97 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

📊 Round 97 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 104 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 104 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0120
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0455
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0077

============================================================
🔄 Round 107 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 107 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0062
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0084
============================================================


============================================================
🔄 Round 108 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 108 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0052
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0146
============================================================


============================================================
🔄 Round 110 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 110 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0078
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0140
============================================================


============================================================
🔄 Round 111 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 111 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0088
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0011
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 113 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 113 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0127
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0194
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 114 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 114 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0107
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0044
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 115 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 115 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0025
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0296
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 117 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 117 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0071
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0103
============================================================


============================================================
🔄 Round 118 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 118 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0067
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0106
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 120 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 120 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0081
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0062
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

📊 Round 120 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

📊 Round 120 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 127 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 127 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0096
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0024
============================================================


============================================================
🔄 Round 129 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 129 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0151
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0448
============================================================


============================================================
🔄 Round 130 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 130 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0057
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0145
============================================================


============================================================
🔄 Round 131 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 131 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0027
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0190
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

📊 Round 131 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

📊 Round 131 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 135 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 135 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0074
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0224
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 136 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 136 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0033
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0248
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 139 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 139 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0119
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0097
============================================================


============================================================
🔄 Round 140 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 140 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0043
   Val:   Loss=0.0706, RMSE=0.2658, R²=-0.0394
============================================================


============================================================
🔄 Round 141 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 141 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0035
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0102
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

📊 Round 141 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

📊 Round 141 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0077

📊 Round 141 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0077

============================================================
🔄 Round 149 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 149 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0015
   Val:   Loss=0.0849, RMSE=0.2915, R²=0.0272
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0077

📊 Round 149 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

📊 Round 149 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

📊 Round 149 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2413, R²: -0.0077

============================================================
🔄 Round 157 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 157 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0095
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0013
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0077

============================================================
🔄 Round 160 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 160 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0068
   Val:   Loss=0.0840, RMSE=0.2897, R²=-0.0130
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

📊 Round 160 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

📊 Round 160 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 165 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 165 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0117
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0090
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 166 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 166 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0014
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0294
============================================================


============================================================
🔄 Round 167 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 167 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0077
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0003
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 171 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 171 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0124
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0108
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0079

============================================================
🔄 Round 172 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 172 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0035
   Val:   Loss=0.0946, RMSE=0.3076, R²=0.0218
============================================================


============================================================
🔄 Round 173 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 173 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0101
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0039
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 179 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 179 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0077
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0066
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

📊 Round 179 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 181 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 181 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0067
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0014
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

📊 Round 181 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 183 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 183 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0065
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0078
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

📊 Round 183 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 189 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 189 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0086
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0048
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2414, R²: -0.0078

============================================================
🔄 Round 190 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 190 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0075
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0082
============================================================


❌ Client client_94 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
