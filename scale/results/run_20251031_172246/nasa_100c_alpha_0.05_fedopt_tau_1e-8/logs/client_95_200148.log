[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ecae723-db28-4b9a-b4a4-fe1eef3d1a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6dbeff0-d4f5-439a-b823-175dbc8fd4e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 617463ef-ad56-4155-8173-d62f635b409e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6348b2ed-b88d-44cd-b58a-425b7c5fc66c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa843c66-d677-48d1-8b89-2f2f591d7978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f4d1122-436c-4f04-8e5e-d09512d91f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19cf7559-7513-4997-9724-ebf3c7abda9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97fd07fc-26ad-49d3-af30-c36a5c7fbe26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21283d62-3328-4a43-928b-2e1b618f99a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5018e87-a666-4c8b-9bef-9197037d2b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86314ea9-e8c2-4b22-a84b-465189cd4bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13367c7b-2541-40ca-bc46-44f6b3ec7ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d99addcd-a951-4022-9bcd-31224c15045e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82917aa1-d059-4a9f-bfd5-5fde3d2b9a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 084147c7-3b5f-45da-a5eb-3040eb44a04f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21b7ee90-aad6-4edc-8eb9-7323846927c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad202b8b-5621-4c8f-8bd6-8f279cd9df62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68af5d34-e6dc-4f26-9daa-bd56a9773827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f54f18aa-403f-44a3-8bf5-466672d592b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f714954e-709a-4d64-b0db-715f4d0d1221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 486564a2-7da2-4865-a5d1-17bea064a948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12a9d7f6-80ac-4cf6-9a49-b8d56e459835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c19f2a07-c3ef-4df2-b8b7-c43b6706bbc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2810f07-9c69-40a8-a6ff-c77d018c1d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09bf1ad4-a232-4d06-9d85-5adf77d0ac77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ece49546-b918-44b5-8ca2-fe6d2e5fbca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4656061-5513-4b79-aedb-575190c9b263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 379b7c16-9bc4-4bad-875a-0ba69718589c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5d42577-ab56-4a09-be6c-3054603abecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37518882-3f94-47fc-8514-9a32bc66031f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60017dd9-c3ad-4ff2-afc2-91668f95aaac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5d96c48-6794-4e22-9223-0ee00908b87c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5953297-cba1-495b-9124-c3c950ad2077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5d071ee-d486-4348-a9ba-7bccc017c2c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95475166-7cb3-495b-9f91-3d145b57751e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ed78df8-567a-4ab8-b99e-5b79a0c41b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34f37642-a5f8-4e54-b72a-c78e4d9742a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffbb9766-4119-4103-852d-aae5d7d339d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fc5244d-e58d-4933-8d0c-542e61468d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4b29a6c-763f-4632-95fb-48f158b2b492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f63a2ab6-8687-4272-ba2a-2e530c98c114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 364efc52-21e3-4005-aaf7-93ac0afdd84b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e446fdb-cf54-44bc-8ac4-d0df11e301f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff17e4cd-285a-4939-8c70-31f343d08839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3552a3c0-d3de-40d3-95c6-c1cd1c0fe991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33590320-df1b-47f8-b1db-9c185664a82c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35e516ef-af0c-4bfb-a874-d7f33114e7da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91cf1d7b-e49b-4977-9f98-2ae81c6a5c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 325310f9-3e81-4ed0-a933-05a2ec13b8aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 195b1d62-2e30-42cc-a826-9c4ab09f9987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7eed744-04d4-4060-b26a-17d4e741e35b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b5261f7-d355-4a93-9de3-89501ef89206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d241178-687a-423c-ab4e-10ce6179e6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04ed6211-1795-4295-8ddc-0dc74d4a0cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95429e75-91b9-4c75-ab93-8eed7cacc308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5694cb8a-4331-41c4-a064-167119ec7bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a17f43f3-4884-4494-bdae-beb9b46a5f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c734dd7f-4c67-4135-89ba-60483c757b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87871aee-e576-42fc-a275-9d37ef6d5e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9225862-15c8-4696-a0ed-687d526c2acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ea38c92-d4da-4cbe-a035-066ccc2d59b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94e869ad-afd1-42db-9a2a-e16771db64b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e43a969b-3e1b-4bea-a1d6-9f3f3cce302f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4da6dfe0-ca44-4d08-81f0-6c85eab21719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ab89d2d-f0ce-4436-a8fc-357ff585956b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fc35576-9882-460d-bdc5-ff99cc1574e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfba3c77-9831-45a4-98cf-2d9acbfd6124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 488ad3a6-067c-4873-b585-2f7988e0ae71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cb0bb2d-7f14-4ff3-8841-cd288195484e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b74ec198-fcd4-450e-95c7-1da3a315b332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 185b99a0-fd55-4f92-9a00-79d01817cdf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c52dbb7-bf7b-4141-acc1-51f4247540ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6458363b-3dbb-4b3e-91b6-6988b80e1ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9130fc8e-4aba-4f69-873a-f7bb8bb89de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a4fedd2-f430-4790-8c01-537aabde2cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 376097d6-1e5e-45b4-8b98-2ac02f798ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c1c4f9f-88c6-4927-89a3-cf44db265155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65178ebd-320c-4904-858d-12fc0373d65f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a6108d6-0e40-4450-9323-f41962763584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81cbc44a-00ac-4d1f-9ff8-0ac7e07aed9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd8f5e3a-3079-4890-95dd-594445dc5458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15b76a2f-7a78-4d64-ab94-37e5d21236f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67f19b08-ff83-4c74-8783-76737d21f806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f4bfad1-107f-4479-b381-f64ed2e86bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2215648-84f1-41f3-bf8e-e7c0d4926abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3f6b4da-14d6-4d0c-b85b-4668fbcc9d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34cd956e-b268-4684-8b47-2a69fd1c1ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81b12538-88b5-4139-8927-63ff62cc7c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73947b13-d19c-44ea-8674-f4e82c4227ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 911869a8-02a8-4b57-866b-2eecf562fee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65219341-cda3-4a04-9feb-632c9759b455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28cb542e-6228-47a6-8b0a-8a2f0bbf905a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6dc0f15-b1c2-41fe-928f-573381b2dbf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e186fe7-5327-43ac-bea9-e6e482d1d6a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b36df30-a1ba-4dcb-b6a7-0b120ce819f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cdaec84-ae01-42f4-97c5-0c5e7a05f046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07305e83-4c5c-4f7b-97ab-5d1b338b3dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddeefd3b-81e8-4960-a7ba-e7b6ffc9a851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b35739c0-67f8-4466-b090-7e11f7d464ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b1f0c54-9fc8-475a-a82e-aebb78301510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76da7c5c-de62-4d26-a1c5-c89e4759d956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c2bad5b-8e87-4882-bf1f-ce05c96dccc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4d54c46-5862-4eed-a8ba-f149ec600364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e35166e4-8613-4038-9535-3f0603521080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3254ae7c-5bdd-4de0-b56b-4f62eaffdb3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3583241-e8ba-4f7c-8094-105ecbcc0a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7745bb0b-a824-4dc5-9788-3cc0fe71289a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9625a03c-c7e4-4acd-abbc-e7ae7651b7b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41d78f01-283d-4e63-b133-72a581e62e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfbba6a3-79da-4c6d-b32e-78d1f065251e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e8ba11e-1209-4cc0-badf-3c7218caf276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46c327d4-1c82-4f62-8135-cf7af3c519e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d012fe0-afa9-4213-8aa1-284b034e367c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 482f1839-6625-4906-9e88-dafe1e0fbb02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8da2fbd8-9b0d-4e1b-83a3-a9c09304c26b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea36d91b-7422-4a15-a7dc-6414cc9ba59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 182b4b75-a821-45a3-ada3-8d3da73cbf3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 199de44c-ad65-43aa-9a9e-34bc0c439ae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b275e8fa-4e11-4390-a6e6-8626a9dc58bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3addffc2-a6d0-45c1-8e96-14172939d439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee53a1c3-74a4-4517-8f33-19eed4bec466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0282e0a-8c16-4829-a71a-4a1e51361cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 686553dc-f6f1-44e3-a78a-979ff3dbdc98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 411b8caa-5b7d-4153-8c89-470977d25a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d5d96ee-ec40-404c-8a5b-41ccbde71bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a959e12-b48b-401b-8152-c55eaf09baa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 338af616-626e-45e1-8b54-39be93be3b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c3cc383-39a4-4651-acc0-27fbeef5de39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f2b9830-d6ac-4211-8a7c-57baae09223a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd614470-c59a-4331-9459-799759e7e13f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1519574-1a98-4167-8a96-2ee5d6be1670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8796005-e343-4dc6-a223-bc3afcf6e4ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89133d1a-7cf7-4663-81a5-0f61d636afc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 004ae364-bb87-46a7-a504-215711d4a48a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd05e374-eb28-495b-a90b-62ba5eae372d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09c8fc3c-6e01-4c15-8906-f61fdc7a96b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5444c56c-36fb-46bd-bc7f-f398c4e4d7cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ed1005b-924c-4cab-9ce5-7a374a15cc43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 341896a3-cbf8-46f0-be7a-96bd3f5acc55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21082471-fcff-4a94-aaa2-5bbc9ac6c81c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ae86002-9dfb-431a-bda8-6ac295c4a618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87f62e87-f453-493c-a56c-4f7a40170b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87b395e8-feec-4126-bfd5-7b17be40bdf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b3c30f4-e1e8-4c43-8109-24bbdf21dcc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e0e4a58-dbfb-4a7d-bf1e-c6919fbd0b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 982fda30-567b-48c8-b8f0-2d555d23853c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2a30492-7fba-4ca7-94ec-692e2a61d217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b09f7b4-6246-4f40-b9a2-f2243551864d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c332728-fd1c-4456-a74f-2c5fa1f6395d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48a004fb-d20b-4647-b4d8-420476c42ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f380e3d5-f900-4912-94e3-19462f402e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abcecae4-541b-45b2-abb7-674df442561e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d95191f-5e00-41e5-bd4e-e28c0ba46705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76aee8c7-59e1-4248-8d2d-7be23d96d893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eb3690f-22b0-42b7-a15d-5c243de7eeda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdc9923c-e3bc-41b6-83b1-5094e28bbf6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b66410cb-69b8-4190-ab2b-7c8b7f436a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 544ae231-a76c-4d8d-8623-77197be64d9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6875626e-6d11-4e0d-b3f2-f737a86788b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd98d0ac-ac6c-49c0-8220-566a035e521b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_95
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/test_labels.txt

📊 Raw data loaded:
   Train: X=(1176, 24), y=(1176,)
   Test:  X=(295, 24), y=(295,)

⚠️  Limiting training data: 1176 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  286 samples, 5 features
✅ Client client_95 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3047, val=0.1083 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0927, val=0.0955 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0819, val=0.0812 (↓), lr=0.001000
   • Epoch   4/100: train=0.0803, val=0.0810, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0803, val=0.0816, patience=2/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0798, val=0.0813, patience=8/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 1 Summary - Client client_95
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0013
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0205
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2526, R²: 0.0013

📊 Round 1 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2534, R²: -0.0042

============================================================
🔄 Round 4 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0751 (↓), lr=0.000250
   • Epoch   2/100: train=0.0831, val=0.0750, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0830, val=0.0750, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0829, val=0.0750, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0828, val=0.0750, patience=4/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0825, val=0.0750, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 4 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0095
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0088
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0852, RMSE: 0.2918, MAE: 0.2540, R²: -0.0073

============================================================
🔄 Round 5 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0768 (↓), lr=0.000125
   • Epoch   2/100: train=0.0827, val=0.0775, patience=1/15, lr=0.000125
   📉 Epoch 3: LR reduced 0.000125 → 0.000063
   • Epoch   3/100: train=0.0826, val=0.0773, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0826, val=0.0773, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0825, val=0.0772, patience=4/15, lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0824, val=0.0771, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 5 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0117
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0545
============================================================


============================================================
🔄 Round 6 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0736 (↓), lr=0.000031
   • Epoch   2/100: train=0.0840, val=0.0736, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0839, val=0.0735, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0838, val=0.0735, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0838, val=0.0734, patience=4/15, lr=0.000031
   • Epoch  11/100: train=0.0837, val=0.0733, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 6 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000031 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0150
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0184
============================================================


============================================================
🔄 Round 7 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0826 (↓), lr=0.000031
   • Epoch   2/100: train=0.0822, val=0.0826, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0821, val=0.0825, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0820, val=0.0825, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0820, val=0.0824, patience=4/15, lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0817, val=0.0823, patience=10/15, lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 7 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0205
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0184
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2551, R²: -0.0129

============================================================
🔄 Round 8 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0760 (↓), lr=0.000008
   • Epoch   2/100: train=0.0843, val=0.0759, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0843, val=0.0759, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0843, val=0.0759, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0843, val=0.0758, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0842, val=0.0757, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 8 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0245
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0345
============================================================


============================================================
🔄 Round 9 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0797 (↓), lr=0.000002
   • Epoch   2/100: train=0.0835, val=0.0797, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0835, val=0.0797, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0835, val=0.0797, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0835, val=0.0797, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0834, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 9 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0263
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0334
============================================================


============================================================
🔄 Round 10 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 10 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0339
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0537
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2557, R²: -0.0170

📊 Round 10 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2559, R²: -0.0174

📊 Round 10 Test Metrics:
   Loss: 0.0861, RMSE: 0.2933, MAE: 0.2560, R²: -0.0179

📊 Round 10 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2560, R²: -0.0185

============================================================
🔄 Round 15 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 15 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0365
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0468
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0189

============================================================
🔄 Round 17 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 17 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0323
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0549
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0189

============================================================
🔄 Round 19 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 19 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0330
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0596
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0189

📊 Round 19 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 21 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 21 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0359
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0421
============================================================


============================================================
🔄 Round 22 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 22 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0315
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0707
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 23 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 23 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0401
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0281
============================================================


============================================================
🔄 Round 25 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 25 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0376
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0338
============================================================


============================================================
🔄 Round 26 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 26 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0356
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0519
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 28 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 28 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0270
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0772
============================================================


============================================================
🔄 Round 29 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 29 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0368
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0680
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 31 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 31 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0383
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0306
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 33 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 33 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0344
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0473
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 34 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 34 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0372
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0394
============================================================


============================================================
🔄 Round 35 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 35 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0368
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0537
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 38 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 38 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0345
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0646
============================================================


============================================================
🔄 Round 39 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 39 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0390
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0301
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 39 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0187

============================================================
🔄 Round 45 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 45 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0422
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0150
============================================================


============================================================
🔄 Round 46 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 46 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0383
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0319
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0187

============================================================
🔄 Round 50 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 50 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0404
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0236
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0187

📊 Round 50 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 53 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 53 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0363
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0523
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0187

============================================================
🔄 Round 54 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 54 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0382
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0329
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0187

📊 Round 54 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0187

============================================================
🔄 Round 56 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 56 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0368
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0694
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0187

============================================================
🔄 Round 60 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 60 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0357
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0438
============================================================


============================================================
🔄 Round 63 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 63 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0384
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0438
============================================================


============================================================
🔄 Round 64 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 64 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0401
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0310
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0187

📊 Round 64 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0187

============================================================
🔄 Round 68 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 68 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0409
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0260
============================================================


============================================================
🔄 Round 74 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 74 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0360
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0412
============================================================


============================================================
🔄 Round 75 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 75 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0369
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0373
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 75 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 81 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 81 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0384
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0427
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 81 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 83 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 83 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0295
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0736
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 83 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 83 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 89 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 89 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0400
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0274
============================================================


============================================================
🔄 Round 90 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 90 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0352
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0443
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 90 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 93 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 93 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0380
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0320
============================================================


============================================================
🔄 Round 95 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 95 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0393
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0283
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 95 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 98 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 98 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0366
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0426
============================================================


============================================================
🔄 Round 99 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 99 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0375
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0546
============================================================


============================================================
🔄 Round 102 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 102 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0333
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0552
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 104 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 104 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0391
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0275
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 105 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 105 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0332
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0531
============================================================


============================================================
🔄 Round 107 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 107 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0300
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0685
============================================================


============================================================
🔄 Round 110 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 110 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0416
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0194
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 111 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 111 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0342
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0545
============================================================


============================================================
🔄 Round 114 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 114 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0380
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0405
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 116 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 116 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0336
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0516
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 116 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 118 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 118 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0357
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0454
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 121 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 121 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0374
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0457
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 122 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 122 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0373
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0363
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 123 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 123 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0306
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0718
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 124 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 124 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0327
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0560
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 125 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 125 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0357
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0480
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 126 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 126 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0365
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0418
============================================================


============================================================
🔄 Round 128 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 128 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0370
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0505
============================================================


============================================================
🔄 Round 129 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 129 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0327
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0578
============================================================


============================================================
🔄 Round 131 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 131 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0300
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0700
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 131 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 131 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 136 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 136 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0416
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0343
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 136 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 142 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 142 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0304
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0636
============================================================


============================================================
🔄 Round 143 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 143 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0415
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0186
============================================================


============================================================
🔄 Round 144 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 144 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0335
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0701
============================================================


============================================================
🔄 Round 145 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 145 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0336
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0494
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 147 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 147 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0376
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0457
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 147 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 149 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 149 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0371
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0417
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 149 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 149 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 155 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 155 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0367
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0400
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 156 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 156 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0382
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0760
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 159 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 159 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0391
   Val:   Loss=0.0849, RMSE=0.2915, R²=-0.0310
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 160 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 160 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0456
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0109
============================================================


============================================================
🔄 Round 161 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 161 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0359
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0487
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 163 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 163 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0363
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0393
============================================================


============================================================
🔄 Round 166 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 166 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0432
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0199
============================================================


============================================================
🔄 Round 169 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 169 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0385
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.1656
============================================================


============================================================
🔄 Round 170 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 170 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0409
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0204
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 170 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 175 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 175 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0336
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0705
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 175 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 177 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 177 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0338
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0545
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 177 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 177 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

📊 Round 177 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 186 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 186 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0423
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0168
============================================================


============================================================
🔄 Round 187 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 187 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0381
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0330
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2561, R²: -0.0188

============================================================
🔄 Round 188 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 188 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0405
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0233
============================================================


============================================================
🔄 Round 189 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 189 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0371
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0457
============================================================


❌ Client client_95 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
