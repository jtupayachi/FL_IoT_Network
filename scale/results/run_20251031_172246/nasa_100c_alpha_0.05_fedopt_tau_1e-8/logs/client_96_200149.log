[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d202b19a-7f4a-4447-8bbd-c3061e884487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3563a564-6126-49a4-a0dc-ef426ae830ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c030cc90-1553-4112-85ca-0469f9baa6c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f627b94-56ee-4210-a91a-2b809c34c5b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a9e7d55-42be-429f-825f-994964d5e23a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbc712eb-69ba-445d-9b34-4c1dcae36704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f442ad34-78d5-4311-bffe-caad87fbe690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f0be44b-aef9-4cb1-8a1d-bf9d8c6ba50d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 137537d0-084e-4e0d-a0fb-4f0671f4b716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b96064fa-9f4c-470e-ab1a-0961700c751b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a885013d-769d-45b2-8e9e-e8e2e68b22ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0509a7de-9f8b-4753-bb7f-ba300640c2ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bb7a922-fdec-40dc-8932-89be3a2e8b2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d5df6ee-cf4d-4a49-9a7f-f19ae2fc09ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b817f009-7683-40aa-8c9d-167d7f28564a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5cb85e0-4a18-4645-b278-7821d623065f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 612e3b9c-77d5-47aa-a8ca-c04b30d7713d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73f96ba5-88ba-4584-8495-9f0278fd3e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5529fecf-4452-4c01-bf9a-6ad9a7032b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4394e747-1cef-4036-90b4-540f79ff8522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa0d8f3-3922-4ebd-b58e-667be8f61b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cab18ec-e151-4ffa-bdc5-38caa5b00b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89cebaa8-10ff-43a8-8e4c-69f2cb447030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b2d4ca0-7bb2-4f49-a054-9749c81a5514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33949b61-11e5-4c2a-af8f-03783ff2fe20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e94b21d9-eb04-48f0-95fe-0c4ecf18bba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a96de14d-b4c7-4fa6-9d4f-22944839518b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 654cfe3e-c699-4c13-9366-c6f08402391c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53bcbda9-1dad-428c-a790-6cd7e15096e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 031cdcce-1347-4ed6-8ff7-462b39d2709f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df43b0fb-10ef-4d9a-aee3-c0e205bcfbc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a654cbb-4e95-42b6-b3aa-6f5fa14d4d75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c820a26b-b5a9-45b3-96b5-25bb08fc46ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6204c51-2b1f-40af-b197-08d306c2a63a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5db7381-fa2e-429b-9a83-d1349886aafa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88d20a4d-e9b5-42d6-9feb-768bbbfb8c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71c833ec-99bf-4fa5-b7fb-d562b20e85bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae68c74e-854b-4f07-aa54-b2d5b5743058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd5e6b60-a9bf-44ef-8610-266284a1bf96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2c717ea-223d-4916-88d1-2caa26db93d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d774af-2559-44e9-9128-a44d2b427ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dff36de-4ca5-4abe-a4c3-978aea2fd0b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f23df1c-b15e-4c56-a9ea-f56b0311af4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc263476-c4a2-4256-a85b-ca54e5f0a9cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd053a5a-1bdd-461e-9efc-871c7844894c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95706530-0f11-4ce0-b319-30a0a68fe1dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 069562ff-1e27-4d92-809a-da1795c6830d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51ca80aa-bfb4-40f2-b395-ed164c7e2b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29a7267b-e49f-47d9-b0f1-77156a0b462f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24ae97b4-059b-46aa-9f96-75e38a65661b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 614caf46-8304-4bed-8af6-b48fcb4e13eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bfd9895-d3f2-49fe-91cf-9ff95f0bc16c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d217856-d1b7-4bb4-8780-3ece3f0e7b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e15ac491-2e51-412a-a8e3-e4a1a9c7ef60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af0d0406-8f04-47c3-8db1-e1ce26abb035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51fc1466-2404-4386-9001-63f637ad8f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93206b3c-5e9d-480e-9bb9-4f5961cdbba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94eb9b56-b515-4ea3-8d27-f5d8c6c24e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b7c2ecb-f0d5-46c2-82e2-ce3cf324e2f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ac55f7e-4873-4974-8e95-7359ccce43dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 333d27f8-3f12-40b1-a818-39909d7eb653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309c1ece-14f0-4a98-a6d8-c96fdfc9a062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1b66cda-52d6-4a41-adfb-263d880e84b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9168c5dd-9f5c-4415-af4a-6336f390aa15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9340ba92-e0a7-49cb-b9e4-c3d38d28df1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a4c0c1c-5d22-427c-8d06-bd6129d614cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd50d56a-6e91-4811-80f3-ec41cf1010e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa6632c-eb36-4a51-acbb-ccfdd0d41214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14b97ddc-3ffb-44af-b432-445ff28c0ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ddc5d23-c439-404d-b353-8012ea6cdc57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1ec6625-5fdb-4bed-a0aa-6a51553fd4a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e64378f-f80b-4566-affd-8c335825144c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63071b8d-dcd9-4d09-ad1f-5e6eba188ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb7ea263-7392-41b8-90c1-865de780a47e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a2f7c9e-2909-4a56-b05f-2d6d1135f939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f694d15-02ec-4124-9a4c-6ae7b4589763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31aa40b1-ee54-4a53-946c-4efcb0378d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d57192ab-988f-4031-a2f1-14f2ed62269d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6977ac17-942a-4650-97c6-124abdcec692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e1b7aff-de95-48b3-a133-8b4c0731257e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db7b1754-9146-461f-912b-d7929d7f9334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 502692ef-7517-4d78-a4cd-5d8bbf7a1572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85bfe30d-2be7-4349-a7e0-1baf9ba22a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1563187b-bff6-46fd-af85-184f47c10442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4991897-d086-44bd-bae5-cbee8bbf7293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5435320f-6cac-4cb3-a90c-e0339344f951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 456b2304-74d9-44c5-b1e3-f7e66c1d481d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ede350ac-a509-480a-a2b3-5c04e53a970f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a315b91-41dd-41f3-8ffa-5d591a02e575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e713ccd5-13ed-4c37-8de2-8c31483efb11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2def71e-e588-47c1-8a74-79c498800f06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db538dba-8870-49d6-9f9d-4829796b680b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f57268a-1346-4ab7-ba2e-cc589656aae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 662eff67-861d-4ea9-ac09-0815d133e5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0db574ce-69db-4dfb-8cf3-c08e0a0e762a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 469a9aec-dbc1-44a6-8d50-6ac8035d24e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98423741-5010-4230-93b5-86ff7dd71146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af44a3ae-f105-469d-a014-7bcca236602c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f97a9c-080a-4c64-a27f-d148894d8a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b20d5720-405a-496a-b7a4-917fc8096430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 644618d6-65bd-4224-b51e-a02aff8893c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea492df-0581-4b9c-8ba0-696a8659e23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22ca4c0d-176a-4818-b018-73719f130107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9d42ac6-5280-47d2-a0ca-d7c0f35e0afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92fc85a1-fce0-4ea7-bb6f-76f33c0b3747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef4a31f6-c717-4baf-a7bc-4bcecac8ffde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12ded9be-2786-4492-970f-865180ba98be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edd56756-d244-40c2-9ed2-c8a76c00c755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 547c7b07-29ce-482c-9267-d088a64ecdb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82c9e8f6-dc82-4f3a-8e61-24c484376cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8f64a0f-7415-417c-bced-0aa7600f97e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e3925e0-67f1-48a1-bcc0-2fc8168a2b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 562075f5-0512-43b6-8a03-86d227fbae12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b75de72a-cf01-4999-a1e4-4bd081dd0df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02e23f4f-6083-4120-90d6-808919fe23d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d625d7cb-c15b-46dd-b201-2093ca86a931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c564d16e-ba20-4c23-866f-5216181cedf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6dcc41c-73e3-4d37-83b6-ca9f47d6cd7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b5fa9ba-ace7-498b-a143-c6bdbfc0b680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d7997f1-7844-41d7-be93-0bdf5bab0824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d452d85-ec1d-419d-9716-56017d590389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 032fa151-f901-44ac-9701-e7ec5ad1cd91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 946a97ad-c691-42fd-835b-27c77dae643c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d5c5921-c617-42ba-abf8-759f162b2257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4160586c-1f51-49a7-961a-772aafce66f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e72a4223-4781-4603-aea2-1231c4084d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88c29eb-a1ee-4358-bdd6-67d10a037935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd66288c-2b72-4bf4-aeb8-3efb02588c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 677b6e60-de39-4b90-9838-d45d9e6c2748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b8c526-8339-4fa1-af1c-78f8c90a954f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6b9b0c5-87d6-4614-a4d4-4b5724008934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f923249-fd63-4ddd-b889-52e9e35c7634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6761d14-6309-4595-9db2-9ecf988ac545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c06690ef-689b-4288-a429-28339d41a1ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa58c2e4-12e8-4e85-9752-35df95591d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec21ce65-a10f-46d0-b653-5beedc798985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4612bcd-fb15-4625-9ffd-7a9ec17d2ab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b398de97-7cbc-4e1f-a00b-d8562cfeeb94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51a3fd0b-3e72-44b5-88cd-87b5a1c3d93e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_96
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/test_labels.txt

📊 Raw data loaded:
   Train: X=(1516, 24), y=(1516,)
   Test:  X=(379, 24), y=(379,)

⚠️  Limiting training data: 1516 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  370 samples, 5 features
✅ Client client_96 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 4 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0792 (↓), lr=0.001000
   • Epoch   2/100: train=0.0838, val=0.0790, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0837, val=0.0782 (↓), lr=0.001000
   • Epoch   4/100: train=0.0827, val=0.0781, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0823, val=0.0773 (↓), lr=0.001000
   • Epoch  11/100: train=0.0765, val=0.0744, patience=1/15, lr=0.001000
   📉 Epoch 19: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0676, val=0.0797, patience=8/15, lr=0.000500
   📉 Epoch 27: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 4 Summary - Client client_96
   Epochs: 28/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0742, RMSE=0.2723, R²=0.1237
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0736
============================================================


============================================================
🔄 Round 5 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0814 (↓), lr=0.000250
   • Epoch   2/100: train=0.0827, val=0.0811, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0824, val=0.0809 (↓), lr=0.000250
   • Epoch   4/100: train=0.0821, val=0.0807, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0819, val=0.0805, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0811, val=0.0801, patience=4/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0803, val=0.0796, patience=5/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031
   📉 Epoch 31: LR reduced 0.000031 → 0.000016
   • Epoch  31/100: train=0.0800, val=0.0794, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 5 Summary - Client client_96
   Epochs: 31/100 (early stopped)
   LR: 0.000250 → 0.000016 (4 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0431
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0318
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2478, R²: 0.0035

============================================================
🔄 Round 9 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0843 (↓), lr=0.000016
   • Epoch   2/100: train=0.0812, val=0.0844, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0811, val=0.0844, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0811, val=0.0844, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0810, val=0.0844, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0808, val=0.0844, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 9 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0238
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0346
============================================================


============================================================
🔄 Round 11 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0786 (↓), lr=0.000004
   • Epoch   2/100: train=0.0823, val=0.0786, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0823, val=0.0786, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0822, val=0.0786, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0822, val=0.0786, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0821, val=0.0787, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 11 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0316
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0101
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2464, R²: 0.0121

============================================================
🔄 Round 12 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 12 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0315
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0224
============================================================


============================================================
🔄 Round 13 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 13 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0262
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0412
============================================================


============================================================
🔄 Round 14 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 14 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0309
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0197
============================================================


============================================================
🔄 Round 17 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 17 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0312
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0240
============================================================


============================================================
🔄 Round 19 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 19 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0352
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0041
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2464, R²: 0.0125

============================================================
🔄 Round 26 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 26 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0351
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0135
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2464, R²: 0.0125

============================================================
🔄 Round 27 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 27 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0294
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0100
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2464, R²: 0.0126

============================================================
🔄 Round 28 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 28 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0260
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0331
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2464, R²: 0.0126

============================================================
🔄 Round 30 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 30 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0307
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0280
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2464, R²: 0.0126

============================================================
🔄 Round 31 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 31 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0359
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0077
============================================================


============================================================
🔄 Round 33 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 33 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0331
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0170
============================================================


============================================================
🔄 Round 34 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 34 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0310
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0282
============================================================


============================================================
🔄 Round 35 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 35 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0311
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0173
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2464, R²: 0.0125

============================================================
🔄 Round 36 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 36 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0341
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0175
============================================================


============================================================
🔄 Round 37 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 37 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0313
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0171
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2464, R²: 0.0126

📊 Round 37 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2464, R²: 0.0126

============================================================
🔄 Round 42 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 42 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0325
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0240
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2464, R²: 0.0126

📊 Round 42 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2464, R²: 0.0127

============================================================
🔄 Round 46 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 46 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0281
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0373
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2464, R²: 0.0127

============================================================
🔄 Round 47 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 47 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=0.0329
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0204
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2464, R²: 0.0127

📊 Round 47 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2464, R²: 0.0127

============================================================
🔄 Round 51 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 51 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0325
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0237
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2464, R²: 0.0127

============================================================
🔄 Round 53 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 53 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0284
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0242
============================================================


============================================================
🔄 Round 54 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 54 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0269
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0391
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2464, R²: 0.0128

📊 Round 54 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

============================================================
🔄 Round 63 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 63 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0310
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0213
============================================================


============================================================
🔄 Round 64 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 64 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0257
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0372
============================================================


============================================================
🔄 Round 68 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 68 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0265
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0439
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

============================================================
🔄 Round 77 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 77 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0395
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0054
============================================================


============================================================
🔄 Round 78 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 78 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0291
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0357
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

📊 Round 78 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 78 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 78 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 78 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

============================================================
🔄 Round 85 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 85 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0271
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0456
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

============================================================
🔄 Round 86 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 86 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0245
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0569
============================================================


============================================================
🔄 Round 87 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 87 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0252
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0510
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

📊 Round 87 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

============================================================
🔄 Round 93 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 93 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0185
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0752
============================================================


============================================================
🔄 Round 95 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 95 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0298
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0337
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

📊 Round 95 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

============================================================
🔄 Round 101 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 101 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0299
   Val:   Loss=0.0958, RMSE=0.3095, R²=0.0325
============================================================


============================================================
🔄 Round 104 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 104 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0307
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0313
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

📊 Round 104 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

============================================================
🔄 Round 106 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 106 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0267
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0461
============================================================


============================================================
🔄 Round 108 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 108 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0284
   Val:   Loss=0.0677, RMSE=0.2602, R²=0.0165
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 108 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

============================================================
🔄 Round 111 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 111 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0315
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0245
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 111 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 111 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 111 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 111 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 111 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 111 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

============================================================
🔄 Round 124 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 124 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0326
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0194
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 124 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 124 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

============================================================
🔄 Round 129 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 129 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0271
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0454
============================================================


============================================================
🔄 Round 131 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 131 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0318
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0168
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 131 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

============================================================
🔄 Round 137 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 137 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0323
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0014
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

============================================================
🔄 Round 139 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 139 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0309
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0153
============================================================


============================================================
🔄 Round 141 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 141 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0311
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0039
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 141 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

============================================================
🔄 Round 144 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 144 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0342
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0178
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

============================================================
🔄 Round 145 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 145 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0342
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0111
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

============================================================
🔄 Round 146 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 146 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0269
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0396
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

📊 Round 146 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

============================================================
🔄 Round 149 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 149 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0279
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0404
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

📊 Round 149 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

📊 Round 149 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

============================================================
🔄 Round 153 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 153 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0283
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0417
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 153 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

📊 Round 153 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

============================================================
🔄 Round 156 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 156 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0324
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0258
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0128

============================================================
🔄 Round 157 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 157 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0319
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0064
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

============================================================
🔄 Round 158 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 158 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0308
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0265
============================================================


============================================================
🔄 Round 159 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 159 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0239
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0558
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

============================================================
🔄 Round 162 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 162 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0284
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0324
============================================================


============================================================
🔄 Round 164 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 164 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0378
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0009
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0130

============================================================
🔄 Round 165 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 165 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0328
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0241
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0130

============================================================
🔄 Round 168 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 168 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0289
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0320
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0130

📊 Round 168 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0131

============================================================
🔄 Round 175 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 175 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0333
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0134
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0131

📊 Round 175 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0131

📊 Round 175 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0131

============================================================
🔄 Round 178 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 178 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0208
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0629
============================================================


============================================================
🔄 Round 181 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 181 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0287
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0404
============================================================


============================================================
🔄 Round 182 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 182 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0248
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0547
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0129

============================================================
🔄 Round 183 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 183 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0328
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0224
============================================================


============================================================
🔄 Round 185 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 185 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0346
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0188
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0130

📊 Round 185 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0130

============================================================
🔄 Round 187 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 187 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0314
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0298
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0130

📊 Round 187 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2463, R²: 0.0130

❌ Client client_96 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
