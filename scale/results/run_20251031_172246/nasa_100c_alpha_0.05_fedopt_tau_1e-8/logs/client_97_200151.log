[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59a6869c-1197-4fe0-a0dd-e8fd41d66460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4627af8-c8f8-4dda-902a-945f257e91fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611407a5-9ced-4771-b800-4c3965dce6b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85e35f3b-72e6-49a4-93f5-bbdc21247bab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 101ab900-ffe9-431f-abd3-d7fde9a9424a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efda98d0-1bf4-409d-b243-034add335f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3709ead-f13e-4e39-850c-84bece6a9d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dfd2617-0d4b-4032-a0a6-04bb84b30687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e835da6-3e67-479b-b8e5-fdc00c193f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f520ee14-c8c0-4114-84c9-b8722085189c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5cb6799-535b-4101-b0a3-d75ce93c0edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1853341-f568-4f99-bace-e9725c7e8ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6845e0d9-3214-47bc-a209-e41b22a7430b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 610f4ea7-a62f-433c-a3a8-3699e8b7cd4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5df9b146-5f79-4be6-847d-6eedf36e1311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f702864-28d2-4b21-9dc9-b86c8e928cfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65b66bf5-d8fe-4f13-83bc-8385609bf8c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c51169-a365-4dc5-88cf-b59f4a9ee39b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48dd8bef-3f4c-4c5d-aa15-b0466aa350db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20e064cd-9a1d-4380-a589-91440daeb679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36aeac24-1023-4d6d-9e08-8a72e64d5e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75e3b6d9-f7f3-4a5c-8461-d1131d905d30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f77ad57-6e51-499f-b067-ed1eec49b313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 195fae8b-6351-4bba-97f9-acd908005df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfbfda8d-2b11-4ac1-b99f-8bb6b5ec1a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a6b4eee-e13e-4610-8884-346c764158bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb012bd3-5718-4525-8e40-fc60bbfdff8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 385edb43-4583-4b7e-8460-815634f1bad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86bcee9f-88bb-47ae-8df0-05a28017bd00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df486ed8-2227-4fe6-aaeb-6c65c3e63a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d3aacf-b4b2-4d97-8ee1-6211d51b6a27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8129a6c-94fc-459b-9293-0973c2ef1f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08a3214a-2843-4a53-b0d7-818d054fd824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c90379-36ab-4e1d-b7ed-290c898c0053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 969df3b5-3422-4e07-abe9-ef6be4b8dbbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 273f7f0e-c252-42dd-bd59-05f392b1472e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5478154c-3fa9-4b5c-8270-91c88978ad61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7bd3898-fa60-4150-805c-861071d30304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 117e6b94-5e0c-4211-b7fb-e62b26b02b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e4accac-f3b7-47c4-b40c-b8f4c93f9ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85b1aff6-486b-45d0-86ad-9a438c001087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5743e3fd-7d34-41b2-a150-725aacdb390a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d0e348a-c003-4851-a062-c7192c0cdca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 354b7e70-c8a2-435e-8638-0a7e9b3b54ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5187d8f9-906e-4cab-bd94-f60f0c1386ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b8df753-2e25-4349-9fad-39390f0a2727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28439912-16e1-4a38-8096-20c89ad5da6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b90adcc2-033a-4e90-84b1-f551771b72fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f647c7c-b6e9-4517-8d5d-541a8c710dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5009eec6-2b8d-4106-8fa6-75a7e7690368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9592538-9084-4874-9110-f9cb7ddaeb07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3c6ae6e-e925-474e-823e-1e383e05ccee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d916239b-4ca5-4017-8b36-234e379fd360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c5e8430-3337-4aff-b966-3a1bef93faa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 291529a8-3bfd-45d2-8590-f83a66dbc76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c195f1de-2b54-4ba4-8791-2a06569d0141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ba1a0bf-ab8a-4bb2-ab55-de6d0c28d202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5538c331-8939-460e-a451-38446abc0558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b86345a-efad-4e34-9155-6c37d4f0a00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89fbcd20-ab76-4cea-8cef-6a6cd1fd2fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed16c98b-c12e-4592-8bf6-134ab3e2d857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2023b2e7-12d7-44ea-a01b-b87c849bbbdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 929f44a0-8610-4516-9157-b5692a31e1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aba1b57e-76cb-4375-8d79-4fe4498bddbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0bd78de-9ce9-4252-bfd1-1d9be17e72bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 679e78f3-0a95-45a6-a47b-c1c0920a281e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 776d4be3-cad4-4673-b3d5-9195d99d874d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 196eb3ea-48c4-47b8-8b5a-24935c52cea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 124bf768-de4f-4499-bdd6-055d0d41c54f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01a9d63a-7ba9-45f0-bf8a-5ee3744c3540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567e654e-f6ec-402c-9a4d-cedb11f1f594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17e05153-1783-4ce7-963a-698dead77a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a75fb2a-8190-4e2f-a7a2-0bc690c01e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4209557-9013-4eeb-8d2c-be3afe29687e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d6d524b-3fc5-47c1-bac4-ab976cd6f6e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 670c95fb-495b-46f4-9c23-ffb3532dff92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bdd3ee1-f85b-44c1-bfb7-3070c8db9572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdc52e97-1a39-4f11-b872-945bd17b053b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f2f9a8b-849c-40bb-9152-8408e95e703f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02ce97e1-a48b-4715-bb0f-b07bd75bb13e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c54416cc-1639-41e7-81b6-03f8d50916c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 003875c3-d79e-4449-b240-3933d713e439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd630371-8d17-4965-8078-ba8fe1ef4a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d70117e-174e-4dee-89a8-2220f2998b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e9f0e73-faa0-423f-a0a4-8e9f9b885ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ff48806-0b05-4d2c-894f-8e0d3019e59a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f24c3804-c2f6-4bdf-a52f-7f4327e88221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f3b50c8-f8d5-47f7-97be-d192be662d1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aea645a-935a-4763-83dc-6d00e591922b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fb0c36c-7d3d-44a0-84a1-80f1409d23a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efd1c1c8-44c2-4e59-a1bb-1e479345bca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89daee1d-c1d3-4d07-905d-413d1d700c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7721c020-aea7-41fd-951b-e9a8bb670a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d148101-280c-402a-941b-e6dc40e5f832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30c1471e-445d-403a-af26-8d8192572266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de38f76e-c89a-4507-aa1b-5a5a4d33d9cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b56c3ad8-ce28-43e9-8e57-ab7496b09295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85bb52d6-d992-4c0e-8d4f-944c57c8ea21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12ecab44-9ff9-47e6-9c53-077d9c057e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a9c216f-fb8e-4791-a5b8-d0f7e86ea6e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 666fb6ef-eec0-46ec-a704-cdf468bceca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89fe5d91-137f-4a0e-93d9-d04b01550102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf20caaf-8627-453b-91cc-4181ee095534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4750e6a5-d936-4d8e-874d-c60c2bcdee5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a85ab23-f013-4349-bc7d-f1fa0b3f1dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45da8221-bb70-467f-b575-bfd135fb8e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9024c19d-fcce-4dd2-9934-5fb5ca57b7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3dc4b8f-40cd-4bea-9d2d-a67c2795cc78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9de68cfd-f4c5-4a0e-8875-8e6b789384fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9797c32-2a57-4601-90c3-7909be9ba88d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6404cd89-9c44-4317-9281-2c03b0bff892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f37c71d7-80a9-41b3-a7bf-a1a7958e1d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf2179b4-cb49-45d1-b062-2478bf18e5c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a80b958-531f-4067-9b01-9b427148686d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91c5e452-868d-4c4b-8f3c-89808272b4c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d65b2f1-6186-4769-90b2-c4f587afe40f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e025bcf4-2108-476c-8db2-34e901940caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 605466a3-1b04-43bd-b38d-5171ba644b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8c85a4b-18eb-4825-8216-e3ee1962219a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af2403ee-6978-424c-860e-211d30a1ff30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 491d4400-f6c2-4d5c-8bcb-f46fa4cc9afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55333fde-99f1-4b49-8405-b0f146ccfdbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce9e5dd-b20e-4833-9ae2-3c15a305d832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bc000ea-63b7-4c68-998b-79a196a39218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d3f6d54-292f-47a6-bc44-ef419e689743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 450c17fa-756b-4789-9d51-210f8406764f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9540b73-ce48-406b-a927-c36fc53842e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0857afa-009b-4a93-a76a-e67da807a04e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93b55a6a-ae24-4783-8307-1c4ffe0d5a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df5ed7d8-5007-40c5-86ec-ad1ddb909adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e523265-87d2-4a15-ada9-dcd0a488ca7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1ebe901-63a3-451c-9da6-27522841c88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fd8a65d-0eba-4485-be9a-476ca4a671af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be9fbe46-497a-4cb7-ac96-e877143973ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33b787c5-194d-4b41-8a44-126f1ed01184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19f08d17-5ea8-4834-81a1-01ee6fe0254d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85860898-615a-47bf-b45f-abf1ca26acdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad4a6321-3aa4-4c00-9c4e-1c84a057d716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0f52f27-3745-420e-9e66-914f7b01a9fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07884510-8a06-4861-9f88-462352696cca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e68ee73-0e2a-4706-bddf-74eb9ed03665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 558705ba-cd17-4bcc-8ebc-f47215472f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a7a5185-d599-4198-b05c-08de5b4124d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eff56514-27e3-44e5-a550-45f2a9843c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f562a43-7f0c-445d-aa65-ca7f1049be94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e47e44e3-c316-496c-9b9e-529aa2366461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae8d99b7-7fe8-4b01-8b61-3a63e6f4e8e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cd07c70-0922-4e89-91b0-2486ccbd7eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d58e5c7d-1f79-43eb-8a1b-4a4f5f896370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dfa470a-1d1a-4188-8393-c5df33562453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d462d11-26d2-4a37-964d-226b691fce7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d4c12a6-e600-4553-9162-956412003c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c30a93a-c817-4bf0-804e-dcf948b8bd53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58427472-a325-4d12-939a-3a7557a28578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ab62d90-e7dd-419d-bb0f-83b4ca7b74da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 783ffac4-30c6-4bf3-ab16-10f93174d447
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_97
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_97
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_97/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_97/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_97/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_97/test_labels.txt

📊 Raw data loaded:
   Train: X=(1124, 24), y=(1124,)
   Test:  X=(282, 24), y=(282,)

⚠️  Limiting training data: 1124 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  273 samples, 5 features
✅ Client client_97 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2490, R²: 0.0001

📊 Round 0 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2488, R²: 0.0022

📊 Round 0 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0044

============================================================
🔄 Round 9 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0791 (↓), lr=0.001000
   • Epoch   2/100: train=0.0815, val=0.0802, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0812, val=0.0799, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0806, val=0.0793, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0800, val=0.0792, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0767, val=0.0815, patience=10/15, lr=0.001000
   📉 Epoch 13: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 9 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0338
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0064
============================================================


============================================================
🔄 Round 11 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0794 (↓), lr=0.000500
   • Epoch   2/100: train=0.0809, val=0.0791, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0803, val=0.0794, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0799, val=0.0797, patience=3/15, lr=0.000500
   📉 Epoch 5: LR reduced 0.000500 → 0.000250
   • Epoch   5/100: train=0.0796, val=0.0800, patience=4/15, lr=0.000250
   • Epoch  11/100: train=0.0784, val=0.0813, patience=10/15, lr=0.000250
   📉 Epoch 13: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 11 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0313
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0083
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2486, R²: 0.0049

============================================================
🔄 Round 13 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0803 (↓), lr=0.000125
   • Epoch   2/100: train=0.0808, val=0.0802, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0806, val=0.0801, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0804, val=0.0801, patience=3/15, lr=0.000125
   📉 Epoch 5: LR reduced 0.000125 → 0.000063
   • Epoch   5/100: train=0.0803, val=0.0801, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0798, val=0.0802, patience=10/15, lr=0.000063
   📉 Epoch 13: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 13 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0339
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0066
============================================================


============================================================
🔄 Round 15 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0805 (↓), lr=0.000031
   • Epoch   2/100: train=0.0804, val=0.0808, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0803, val=0.0811, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0802, val=0.0812, patience=3/15, lr=0.000031
   📉 Epoch 5: LR reduced 0.000031 → 0.000016
   • Epoch   5/100: train=0.0801, val=0.0813, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0800, val=0.0813, patience=10/15, lr=0.000016
   📉 Epoch 13: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 15 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0208
   Val:   Loss=0.0805, RMSE=0.2836, R²=0.0342
============================================================


============================================================
🔄 Round 16 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0740 (↓), lr=0.000008
   • Epoch   2/100: train=0.0824, val=0.0739, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0824, val=0.0739, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0823, val=0.0739, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0823, val=0.0739, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0821, val=0.0739, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 16 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000004 (1 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0204
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0416
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

📊 Round 16 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0046

📊 Round 16 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0046

============================================================
🔄 Round 20 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0773 (↓), lr=0.000004
   • Epoch   2/100: train=0.0818, val=0.0773, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0818, val=0.0773, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0818, val=0.0773, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0818, val=0.0773, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0817, val=0.0773, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 20 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0230
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0299
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

📊 Round 20 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

📊 Round 20 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 23 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 23 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0243
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0059
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 25 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 25 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0204
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0367
============================================================


============================================================
🔄 Round 27 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 27 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0262
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0160
============================================================


============================================================
🔄 Round 31 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 31 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0288
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0060
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 32 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 32 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0165
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0375
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 33 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 33 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0218
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0273
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 37 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 37 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0188
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0450
============================================================


============================================================
🔄 Round 40 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 40 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0197
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0412
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 43 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 43 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0193
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0409
============================================================


============================================================
🔄 Round 44 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 44 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0251
   Val:   Loss=0.0947, RMSE=0.3077, R²=0.0220
============================================================


============================================================
🔄 Round 45 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 45 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0184
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0471
============================================================


============================================================
🔄 Round 47 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 47 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2828, R²=0.0273
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0195
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 52 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 52 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0200
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0405
============================================================


============================================================
🔄 Round 53 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 53 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0261
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0176
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 56 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 56 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0228
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0302
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

📊 Round 56 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

📊 Round 56 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

📊 Round 56 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

📊 Round 56 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 65 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 65 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0240
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0259
============================================================


============================================================
🔄 Round 69 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 69 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0245
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0079
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 71 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 71 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0201
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0402
============================================================


============================================================
🔄 Round 72 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 72 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0251
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0171
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 73 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 73 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0246
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0163
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 74 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 74 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0304
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0077
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 75 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 75 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0271
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0124
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 76 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 76 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0255
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0190
============================================================


============================================================
🔄 Round 78 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 78 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0298
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0011
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 80 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 80 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0200
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0309
============================================================


============================================================
🔄 Round 81 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 81 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0278
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0115
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 82 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 82 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0239
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0247
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 83 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 83 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0187
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0235
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

📊 Round 83 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

📊 Round 83 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 86 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 86 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0307
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0008
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 88 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 88 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0201
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0384
============================================================


============================================================
🔄 Round 89 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 89 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0286
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0073
============================================================


============================================================
🔄 Round 90 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 90 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0201
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0406
============================================================


============================================================
🔄 Round 92 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 92 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0297
   Val:   Loss=0.0722, RMSE=0.2688, R²=-0.0023
============================================================


============================================================
🔄 Round 95 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 95 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0293
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0056
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 96 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 96 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0162
   Val:   Loss=0.0738, RMSE=0.2718, R²=0.0455
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 97 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 97 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0176
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0466
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

📊 Round 97 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 102 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 102 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0219
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0254
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 103 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 103 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0236
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0268
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

============================================================
🔄 Round 105 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 105 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0216
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0365
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0047

📊 Round 105 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 108 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 108 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0227
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0145
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

📊 Round 108 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 110 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 110 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0224
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0286
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 112 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0981, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 112 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0272
   Val:   Loss=0.0981, RMSE=0.3132, R²=0.0099
============================================================


============================================================
🔄 Round 115 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 115 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0263
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0151
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 117 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 117 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0208
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0256
============================================================


============================================================
🔄 Round 118 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 118 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0236
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0251
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 120 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 120 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0198
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0440
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

📊 Round 120 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 123 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0655 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0655, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0655, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0655, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0655, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0655, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0655)

============================================================
📊 Round 123 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0170
   Val:   Loss=0.0655, RMSE=0.2560, R²=0.0586
============================================================


============================================================
🔄 Round 127 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 127 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0266
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0165
============================================================


============================================================
🔄 Round 130 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 130 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0281
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0013
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 134 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 134 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0304
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0220
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 136 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 136 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0226
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0322
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 139 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 139 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0276
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0055
============================================================


============================================================
🔄 Round 140 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 140 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0309
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0033
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 141 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 141 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0201
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0099
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

📊 Round 141 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

📊 Round 141 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 146 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 146 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0262
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0097
============================================================


============================================================
🔄 Round 148 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 148 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0242
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0242
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 149 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 149 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0227
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0305
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 152 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 152 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0198
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0375
============================================================


============================================================
🔄 Round 153 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 153 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0243
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0096
============================================================


============================================================
🔄 Round 154 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 154 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0272
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0112
============================================================


============================================================
🔄 Round 156 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 156 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0214
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0323
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

📊 Round 156 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 160 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 160 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0243
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0244
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 161 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 161 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0279
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0009
============================================================


============================================================
🔄 Round 163 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 163 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0274
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0138
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 164 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 164 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0286
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0053
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 165 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 165 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0213
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0372
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 166 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 166 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0228
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0091
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2486, R²: 0.0048

📊 Round 166 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 170 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 170 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0231
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0289
============================================================


============================================================
🔄 Round 171 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 171 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0283
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0064
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 172 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 172 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0240
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0268
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2486, R²: 0.0048

📊 Round 172 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2486, R²: 0.0048

📊 Round 172 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 176 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 176 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0249
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0216
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2486, R²: 0.0048

📊 Round 176 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 181 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 181 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0222
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0037
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2486, R²: 0.0048

📊 Round 181 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2486, R²: 0.0048

📊 Round 181 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 187 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 187 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0259
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0162
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2486, R²: 0.0048

============================================================
🔄 Round 190 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 190 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0304
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0019
============================================================


❌ Client client_97 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
