[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4e90ce0-3649-4d09-9a38-7d92bc1e7c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dd7648b-35de-41b0-8bb9-4106019639b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bb20e92-46e5-4086-9211-77a9bb3b74e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 514dd14a-4315-4051-9bf9-a8fd26f2eb92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 593a3e61-ab8c-41fe-a0af-6515684014a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08c250f9-2bdb-48e9-93c3-031bd831ec43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85928125-2a99-49a0-98c7-63488a092184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76493f89-6a29-49e7-b7af-272e7db6dd88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b4d39f0-934a-469e-b8cf-4e7298f5a258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a97d58b-b772-424e-987d-1737ef2b579e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5692a475-9b0b-4909-803d-dafea2365516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f74cd8b-e40e-458f-9910-2e401c9ab172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1ac1fbc-e135-401d-9fcd-58e29984ead9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfd059dc-39de-4780-a2e9-fd335190e6f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 603211d0-c888-4d13-bc73-883728e14366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f97dd295-92d5-4be5-aef3-58f26586e2ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a836673-18e0-4452-8bf9-c74bcb8bb669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a4a5975-d37b-4898-b8b4-ebf39619c5bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10892162-5405-44f8-a7d7-6f4dd0008e53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ee3074c-ed1f-49bd-9783-aff6c91d1783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 788efcec-6587-45e7-aa04-b6ef1c62ceb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1595f9c5-b465-4fcc-90f5-2174ed05f531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b497ff-236b-4fc4-b298-da7b785eb804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 594083cf-b7f3-481c-9809-c7a0154073aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f789b01-df18-4779-9b8e-3b115e0bdd6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e28192b-5b52-404b-a31b-054dc3d8d692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6157dc56-b322-4919-ade6-8fcb8ce2f4ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec02b32d-b23d-4b0d-800f-437c65ccc2bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d3dcdc1-c6cc-4bb6-9bb2-0362a37e5678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4c411b2-3c2b-447f-bbd0-5a47b9bed0f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e64b9a4-5dd1-4ed5-b426-e41fa347c5f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aa8f501-8a22-46f8-9e71-4ed45cfb2bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13948b9c-f84c-4d8a-9324-7e060969db63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8973eec7-ca3b-40f7-8a2e-5f5e0049855b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b8ff933-437b-46c2-b23e-f5e179fbb3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48dd22c0-d062-473b-8595-2dd730c3a5d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c846f615-22af-45a5-9ca9-018ece935d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c35e022-fa24-4a2b-857a-27d60926f9a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b526305-56b9-430b-a8be-592a78b05376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b99938a1-4b63-4bc5-80ff-bbfc56638ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dc39be2-93f8-4abf-8441-a16dad5ccf97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47c87285-9641-4cc0-b24c-5cffbf61ebb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a45ad3f-8655-4613-94c3-b3c82f6770c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4736f336-2869-44c8-8bf6-0c011b196fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86b92809-577a-445d-9ef4-0412c26357c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff44a3d0-2e9a-4b2a-90d4-fe515e8b47b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e05d9826-2314-427d-8a11-7a70f4a980fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a16a1f1d-da1b-4e50-9e5c-123c047eed66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75775808-ed6d-4085-8b78-0e5831ec2d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fd652fa-b3ef-4243-aa8f-9ad6b4a5ba7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f36e111-af7f-4958-9c37-10637b30eacb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c17041bf-6ea1-43ec-869e-3bd4284c2962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 042e1d4f-cd08-4b3f-b9ae-084278197869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c7d3f8e-893d-4353-be89-822067d30c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d98e079-1609-424e-a545-e2745a27310d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad3e2121-64c0-4ef6-b663-62c342d11d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edcee5a7-4e91-48d1-90d8-2ba6cbc1b10c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 092ab546-5fb8-4c85-85d8-8102ff0c842b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55baef11-e825-4e39-9e05-6661663de90b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50e57f94-f04b-4448-8c00-54f5ec6410ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f08dc44-fb40-4bee-88c8-e024a4a9e302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dda7dab1-1890-4a47-8359-9c52cc079e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4183f599-c643-4ccd-ad53-568d82d38b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbb3d897-1e5d-4eff-9872-e1ee2826fbfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fbc72cc-4089-4382-bbfb-80d12a7df49b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7919948-37f9-4e55-94d7-73af073cdc6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d31d7e3-7ea8-4315-aa96-b8445197ab3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e5db3f1-b0b1-41c9-9ad1-ff91e708d9bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 743cfa27-201b-40a4-96ef-0976d746dedb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2dbddfb-13fb-48d1-9944-5fb915f2bcb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93a2aa0d-d4b1-4822-acc7-0cfa36553654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75dfdce5-9d6c-4c90-bb8e-227d821520c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad775d36-dd51-4882-a047-524af82f97d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f53f59c-704b-460a-973e-50ac0bba4263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca0a3648-6cf2-4771-97da-0dcbd1d4c3ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3ff2175-977f-4697-997a-be9a82795595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb24d1c1-88a3-4eef-b7a9-1e1584eee764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f175c23-bdf0-4453-91dd-68c841bdbab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21dda789-c7fd-4fca-b633-22f41ab3161c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e34f49af-2312-4404-afb8-1354a88f8f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c78f5fb-15d9-421f-8637-f0605bd4072f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ed99651-adbe-4a93-b24e-08b24b3cd842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29663b68-f51e-4d07-8acf-6d7dffbd07d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 322dcfdf-67a7-4bb5-b0d5-1ecec5041a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4c87379-17c3-42a5-956d-6765472f8425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53042b97-2157-4222-aeae-955dc67aa1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c074a171-112b-41ca-bdb7-5ba0ce9c26ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89f58587-dfcd-47a7-bf1e-2c58bdf682a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b21f2fbb-a449-40cd-b329-ed9ef9ab05a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c5d3421-fedc-4811-b3cb-b5d6bd6522fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b525100-f3b9-4eb7-bdae-b3d28df4438e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ec133bc-6f2f-42cf-ae8e-107304a1ff21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 702c18a6-89b3-43d6-816c-c5c326334bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6222efa-3ca2-4679-90ac-db760d4cd4a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e30da1d-c04c-4c70-a876-86533455c0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08d18c75-8bfc-495b-8e3b-b358a7ea1f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c277710-084c-494b-a3f6-b3264b903894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f417d65-d2be-49de-9d74-c440fd04fde4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bb880e5-3386-4103-9dbc-c0cf3d42beb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3461cdb8-5c45-48b7-a3f4-8fe030145db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e311d1e-d2df-4e4d-b398-6d54dd7768ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07d74b47-b9ff-4435-bd7a-e2a97847acc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee997391-a2ec-48ce-887f-173048d2bbc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4ade10f-e499-46c7-8eea-28e1e32f0db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a1877cb-7504-4ccb-8fb8-8b6ef070ef70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b8de633-cd34-405b-9136-9b21b6c80318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69e46cbf-d495-41d4-a45f-76ae95cb1c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a9844d4-387e-4193-b823-4a8970385e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93be1260-389f-4bcc-8ed8-ca50d21e2c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba4cccca-2d11-46bd-a56a-867cf3d891f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41300556-1f2b-4bf0-b245-b7d1943a5941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33f73a35-2876-48b3-b113-dc814e706953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e13ef7b-2569-43d2-a86e-6a051b2ce2c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a18ea28c-c913-49d9-82aa-473e37b70904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b637d7a0-3d9f-4f48-9d1f-573eb8070702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d946bbdb-e480-4751-ba27-5de9c95dd720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b71e9fb-12c3-4675-a588-facfdaea20dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e8cdcac-9e98-4877-a70f-a5b760f53b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d68a686-602b-4851-9801-9b9010c6b614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c708080a-acd5-4a3f-b07a-d0aea5d098d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61cca0f2-cfb3-4772-b752-4277e264337e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3dbfd3f-2644-4dea-ae35-891e59600865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00d75ae9-3db2-46b1-9820-100c9dda3fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7d4ca3c-e150-4ff8-9849-3ea0110ecb56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9b74c7a-bf71-4380-badf-9267b15dff9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23ac1d0b-eae9-4d8a-9cc5-8de623fb1756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95b64f5f-8774-48b5-9110-c5cb68c1103a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca2c8cb5-3ea6-4a20-a65f-f0b086c0aeb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f25ae479-aee8-4b7c-bc40-d2b60cb02906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c8d411c-75f0-479c-bc87-12673e0b6ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50dfce6f-0384-44f2-9871-f193a92c4155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06bf2ed9-c38a-4901-89f4-119b3e8727b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49aaa686-3ef2-4ca0-aace-d246f974cfb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10dfa50b-7a85-4b3c-92fc-5fe42ba252f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ce41769-88f8-4822-8c63-06b0e22fc174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1294abca-8e3b-498b-a9fd-5c71b6dc9f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96d890e1-6ce3-466a-9aca-f441c7634914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd922c08-a2a3-44ac-841f-c7215df4d491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d4aed0a-8745-48f5-9c68-048580c36d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8618ebf-f3a1-445e-9b50-32240eba36cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8c2436e-d530-46be-b3fc-99181a81b0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce91842c-cc95-4660-85f6-bdc3a9fb27a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9cec2ee-d110-49b5-ba0c-4f212e37de62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 440d937e-f8ea-42d1-ac5b-826d52d9f748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d276d724-0dfd-4064-a19e-07268a825837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76321601-0584-40f4-b9ff-ca152040ee2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b25b915-6320-4e90-84ec-43b66d81555b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ea857f6-4263-4a2e-8424-e867e292436a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e05c9dd6-7a78-4337-8691-071d172abc05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7a4f09f-ae52-4e7c-929e-177f85edc8a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fab33fc-a0b9-4f94-9dfa-b187f86ea8fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33ffbfba-ea19-4a08-9c35-b1f3fc0b6bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97a505ef-99a2-4acf-a2ae-135b3c9997be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 656ef0ea-1137-4f37-a370-3259396bd91b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_99
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_99
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_99/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_99/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_99/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_99/test_labels.txt

📊 Raw data loaded:
   Train: X=(339, 24), y=(339,)
   Test:  X=(85, 24), y=(85,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 330 samples, 5 features
   Test:  76 samples, 5 features
✅ Client client_99 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2662, R²: -0.0309

============================================================
🔄 Round 3 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0924, val=0.0668 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0905, val=0.0661 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0888, val=0.0655 (↓), lr=0.001000
   • Epoch   4/100: train=0.0879, val=0.0650, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0873, val=0.0650, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0825, val=0.0689, patience=5/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500
   📉 Epoch 20: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0777, val=0.0737, patience=15/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0649)

============================================================
📊 Round 3 Summary - Client client_99
   Epochs: 21/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0241
   Val:   Loss=0.0649, RMSE=0.2548, R²=0.0372
============================================================


============================================================
🔄 Round 4 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0702 (↓), lr=0.000250
   • Epoch   2/100: train=0.0853, val=0.0697, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0848, val=0.0696 (↓), lr=0.000250
   • Epoch   4/100: train=0.0844, val=0.0701, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0840, val=0.0706, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0825, val=0.0719, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 4 Summary - Client client_99
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0032
   Val:   Loss=0.0696, RMSE=0.2639, R²=-0.0338
============================================================


============================================================
🔄 Round 5 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0894 (↓), lr=0.000063
   • Epoch   2/100: train=0.0833, val=0.0891, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0831, val=0.0889, patience=2/15, lr=0.000063
   ✓ Epoch   4/100: train=0.0830, val=0.0888 (↓), lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   • Epoch   5/100: train=0.0829, val=0.0888, patience=1/15, lr=0.000031
   • Epoch  11/100: train=0.0826, val=0.0887, patience=7/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 5 Summary - Client client_99
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0054
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0262
============================================================


============================================================
🔄 Round 6 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0892 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   • Epoch   2/100: train=0.0816, val=0.0892, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0816, val=0.0892, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0816, val=0.0892, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0816, val=0.0892, patience=4/15, lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0815, val=0.0893, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 6 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0175
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0060
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2695, R²: -0.0557

============================================================
🔄 Round 7 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0814 (↓), lr=0.000004
   📉 Epoch 2: LR reduced 0.000004 → 0.000002
   • Epoch   2/100: train=0.0872, val=0.0814, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0871, val=0.0815, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0871, val=0.0815, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0871, val=0.0815, patience=4/15, lr=0.000002
   📉 Epoch 10: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0871, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 7 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0178
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0420
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0935, RMSE: 0.3058, MAE: 0.2727, R²: -0.0845

============================================================
🔄 Round 11 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 11 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0226
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.1135
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0943, RMSE: 0.3071, MAE: 0.2739, R²: -0.0936

📊 Round 11 Test Metrics:
   Loss: 0.0943, RMSE: 0.3071, MAE: 0.2740, R²: -0.0936

📊 Round 11 Test Metrics:
   Loss: 0.0947, RMSE: 0.3077, MAE: 0.2743, R²: -0.0975

============================================================
🔄 Round 17 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 17 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0318
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0087
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0947, RMSE: 0.3077, MAE: 0.2743, R²: -0.0974

📊 Round 17 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2744, R²: -0.0985

============================================================
🔄 Round 21 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 21 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0257
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0383
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2744, R²: -0.0984

📊 Round 21 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2744, R²: -0.0984

📊 Round 21 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2744, R²: -0.0984

📊 Round 21 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2745, R²: -0.0985

📊 Round 21 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2744, R²: -0.0984

============================================================
🔄 Round 29 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.1038 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.1038, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.1038, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.1038, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.1038, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.1038, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1038)

============================================================
📊 Round 29 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0204
   Val:   Loss=0.1038, RMSE=0.3222, R²=-0.0549
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0985

============================================================
🔄 Round 31 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0929, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0929, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0929, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0929, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0929, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0928, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 31 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=-0.0371
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0155
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0985

============================================================
🔄 Round 32 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 32 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0203
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0604
============================================================


============================================================
🔄 Round 34 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 34 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0191
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0820
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0985

============================================================
🔄 Round 35 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 35 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0204
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0588
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2744, R²: -0.0983

============================================================
🔄 Round 38 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 38 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0258
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0414
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2744, R²: -0.0984

============================================================
🔄 Round 41 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 41 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0221
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0668
============================================================


============================================================
🔄 Round 42 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 42 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0171
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0800
============================================================


============================================================
🔄 Round 43 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 43 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0361
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0220
============================================================


============================================================
🔄 Round 44 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 44 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0167
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0746
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0986

📊 Round 44 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0986

============================================================
🔄 Round 48 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 48 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0227
   Val:   Loss=0.0792, RMSE=0.2813, R²=-0.0668
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0985

============================================================
🔄 Round 50 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 50 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0140
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0861
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0985

============================================================
🔄 Round 55 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 55 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0226
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0549
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0987

============================================================
🔄 Round 59 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 59 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0182
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0790
============================================================


============================================================
🔄 Round 62 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 62 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0359
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0002
============================================================


============================================================
🔄 Round 63 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0914, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 63 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0267
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0443
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0985

============================================================
🔄 Round 65 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.1056 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.1056, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.1056, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.1056, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.1056, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.1056, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1056)

============================================================
📊 Round 65 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0153
   Val:   Loss=0.1056, RMSE=0.3250, R²=-0.0644
============================================================


============================================================
🔄 Round 67 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 67 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0376
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0486
============================================================


============================================================
🔄 Round 68 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 68 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0249
   Val:   Loss=0.0973, RMSE=0.3119, R²=-0.0496
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0986

============================================================
🔄 Round 70 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 70 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0262
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0311
============================================================


============================================================
🔄 Round 71 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 71 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0206
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0671
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0986

📊 Round 71 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0986

============================================================
🔄 Round 74 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 74 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0399
   Val:   Loss=0.0675, RMSE=0.2599, R²=0.0165
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0948, RMSE: 0.3079, MAE: 0.2745, R²: -0.0988

============================================================
🔄 Round 79 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 79 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0301
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0138
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0948, RMSE: 0.3079, MAE: 0.2745, R²: -0.0988

============================================================
🔄 Round 80 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 80 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0426
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0223
============================================================


============================================================
🔄 Round 81 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 81 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0243
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0549
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0948, RMSE: 0.3079, MAE: 0.2745, R²: -0.0989

============================================================
🔄 Round 88 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 88 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0248
   Val:   Loss=0.0962, RMSE=0.3101, R²=-0.0750
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0987

============================================================
🔄 Round 90 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0987)

============================================================
📊 Round 90 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0322
   Val:   Loss=0.0987, RMSE=0.3142, R²=-0.0107
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0987

📊 Round 90 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0987

============================================================
🔄 Round 94 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0982 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0982, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0982, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0981, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0982)

============================================================
📊 Round 94 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0208
   Val:   Loss=0.0982, RMSE=0.3133, R²=-0.0493
============================================================


============================================================
🔄 Round 95 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0666, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0916, val=0.0666, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 95 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=-0.0247
   Val:   Loss=0.0666, RMSE=0.2581, R²=-0.0428
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0987

============================================================
🔄 Round 99 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 99 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0274
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0450
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0948, RMSE: 0.3079, MAE: 0.2745, R²: -0.0987

============================================================
🔄 Round 103 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 103 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0265
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0459
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0987

============================================================
🔄 Round 105 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 105 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0261
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0368
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0987

📊 Round 105 Test Metrics:
   Loss: 0.0948, RMSE: 0.3079, MAE: 0.2745, R²: -0.0987

📊 Round 105 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0987

============================================================
🔄 Round 110 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 110 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0283
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0443
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0948, RMSE: 0.3079, MAE: 0.2745, R²: -0.0988

============================================================
🔄 Round 111 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 111 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0361
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0065
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0948, RMSE: 0.3079, MAE: 0.2745, R²: -0.0988

📊 Round 111 Test Metrics:
   Loss: 0.0948, RMSE: 0.3079, MAE: 0.2745, R²: -0.0988

📊 Round 111 Test Metrics:
   Loss: 0.0948, RMSE: 0.3079, MAE: 0.2745, R²: -0.0987

============================================================
🔄 Round 116 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 116 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0332
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0134
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0987

📊 Round 116 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0987

============================================================
🔄 Round 120 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 120 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0334
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0085
============================================================


============================================================
🔄 Round 121 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 121 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0293
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0407
============================================================


============================================================
🔄 Round 123 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 123 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0327
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0036
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0948, RMSE: 0.3079, MAE: 0.2745, R²: -0.0987

============================================================
🔄 Round 125 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 125 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0253
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0563
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0948, RMSE: 0.3079, MAE: 0.2745, R²: -0.0988

============================================================
🔄 Round 127 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0995 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0997, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0995)

============================================================
📊 Round 127 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0297
   Val:   Loss=0.0995, RMSE=0.3155, R²=-0.0485
============================================================


============================================================
🔄 Round 128 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 128 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0209
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0715
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0948, RMSE: 0.3079, MAE: 0.2745, R²: -0.0989

============================================================
🔄 Round 130 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 130 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0307
   Val:   Loss=0.0708, RMSE=0.2660, R²=-0.0138
============================================================


============================================================
🔄 Round 131 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 131 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0327
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0177
============================================================


============================================================
🔄 Round 133 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 133 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0178
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0759
============================================================


============================================================
🔄 Round 134 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 134 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0244
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0519
============================================================


============================================================
🔄 Round 135 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 135 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0361
   Val:   Loss=0.0718, RMSE=0.2679, R²=-0.0125
============================================================


============================================================
🔄 Round 136 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 136 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0421
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0305
============================================================


============================================================
🔄 Round 138 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 138 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0297
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0318
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0985

📊 Round 138 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0985

============================================================
🔄 Round 140 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 140 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0255
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0424
============================================================


============================================================
🔄 Round 141 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0919, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0919, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0919, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0918, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 141 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0354
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.1158
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0986

============================================================
🔄 Round 142 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 142 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0295
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0181
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0985

============================================================
🔄 Round 143 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 143 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0129
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0892
============================================================


============================================================
🔄 Round 146 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 146 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0273
   Val:   Loss=0.0679, RMSE=0.2607, R²=-0.0422
============================================================


============================================================
🔄 Round 147 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0971, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 147 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0248
   Val:   Loss=0.0971, RMSE=0.3116, R²=-0.0540
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2744, R²: -0.0983

📊 Round 147 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2744, R²: -0.0983

📊 Round 147 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2745, R²: -0.0984

============================================================
🔄 Round 152 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 152 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0263
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0572
============================================================


============================================================
🔄 Round 153 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 153 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0281
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0290
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2745, R²: -0.0984

📊 Round 153 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2745, R²: -0.0985

============================================================
🔄 Round 156 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 156 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0255
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0339
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2744, R²: -0.0983

============================================================
🔄 Round 161 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 161 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0292
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0185
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2745, R²: -0.0984

📊 Round 161 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0985

📊 Round 161 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0986

============================================================
🔄 Round 166 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 166 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0292
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0222
============================================================


============================================================
🔄 Round 167 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 167 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0361
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0017
============================================================


============================================================
🔄 Round 168 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 168 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0321
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0155
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0986

============================================================
🔄 Round 169 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 169 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0303
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0330
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0987

============================================================
🔄 Round 170 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.1017 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.1017, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.1017, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.1018, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.1018, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.1019, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1017)

============================================================
📊 Round 170 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0119
   Val:   Loss=0.1017, RMSE=0.3189, R²=-0.1038
============================================================


============================================================
🔄 Round 171 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 171 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0233
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0592
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0987

============================================================
🔄 Round 173 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 173 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0339
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0446
============================================================


============================================================
🔄 Round 176 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 176 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0190
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0661
============================================================


============================================================
🔄 Round 177 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 177 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0267
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0387
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0987

============================================================
🔄 Round 178 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 178 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0160
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.1392
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0986

📊 Round 178 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0986

📊 Round 178 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2745, R²: -0.0984

============================================================
🔄 Round 181 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 181 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0329
   Val:   Loss=0.0688, RMSE=0.2622, R²=-0.0163
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2745, R²: -0.0984

============================================================
🔄 Round 182 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 182 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0325
   Val:   Loss=0.0729, RMSE=0.2699, R²=-0.0078
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2745, R²: -0.0984

============================================================
🔄 Round 184 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 184 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=-0.0261
   Val:   Loss=0.0695, RMSE=0.2636, R²=-0.1344
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0947, RMSE: 0.3078, MAE: 0.2745, R²: -0.0984

============================================================
🔄 Round 185 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 185 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0210
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0575
============================================================


============================================================
🔄 Round 186 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 186 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0250
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0473
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2745, R²: -0.0985

============================================================
🔄 Round 189 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 189 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0240
   Val:   Loss=0.0958, RMSE=0.3096, R²=-0.0440
============================================================


❌ Client client_99 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
