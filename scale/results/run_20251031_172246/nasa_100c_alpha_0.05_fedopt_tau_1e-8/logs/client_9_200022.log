[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09847e23-4d6c-4e2c-bb53-7cdef13c9c9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57455285-60c8-46a8-91d3-b67d8d01475f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 236e87b0-1f3b-4400-8dd7-7f48e551bcd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd5fd5bc-7be6-4e04-a6e7-78fe3de25812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 584b76f8-e6b2-4a26-bff8-38a234be1e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7245cf0-07a3-4dc4-9966-4aa83e41213d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6ad5890-a8e4-431d-b6da-956d51e27f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57b2f51f-afe8-48b3-b360-c8e5671cccaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ca1b000-f945-4aa4-9e3d-6a82b9f6219d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d32806e0-68fe-45ec-a9dc-7d9f388d713f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8ad9bb3-1b73-4f46-b402-da5221991ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f0d12cf-5d8f-4a83-9169-32fba0bc1c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 629fbfd4-64a8-4c9b-9d0b-fabaf3aaa1cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93ed5122-de52-4703-84ca-22d65968ea4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b713011f-a976-4656-ba27-dbdd46f83849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 050ff37c-0021-47fc-bd14-0a8ac3d9e9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 210f582c-a86a-440c-9d61-ecc00f1d9e6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3623dfc-7ba5-44ce-a2da-6b157aef820e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e6ed8a5-7875-4820-9155-981579c4c4a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56893d4a-7d51-4b10-8f30-f7aad16f9066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65cfb372-47c5-4b06-a8bd-bd0501c1c0bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 135e9241-6352-48df-96ac-09a3eeeb8a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a6078ca-43d9-42f3-917f-199acb2d830f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6e9b15b-8cda-4dda-af71-4a1320bd4ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8d003c2-9f35-443d-8aaa-1e8789d5d209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54a45aa6-fa58-47b8-85c9-3da2ec088608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 771911a4-b5b5-412f-829e-79a334d64dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a56d4d27-8e88-4d54-8271-7e308397a989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cefeb2a3-ffbb-4153-9999-17886cdeb619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 057ec514-8b0c-4aa2-86aa-ecca17d87772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c7a0db-d7eb-40d8-ba6f-cb9fa3d2ee6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a10c447-7f24-4d33-930d-83b950a1013e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56529c0c-ca41-4013-a51d-83818169e2a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d8eadc6-8057-4b56-8ead-5fcbf12b595b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 541bdd5d-f925-4078-b48d-32469807dfc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da3371b6-5dff-4640-b2d3-cc462f28a6c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22496434-2c06-4466-bf04-8fb6e845a0fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bc7855a-e685-40f1-84e0-7148f51537be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9d33a82-f647-41b2-8118-e1b472610d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec121177-82cf-4550-a37f-da3d3680c182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92a5990d-d7b5-4dae-985f-f1908dcfb961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2a61430-6c67-41e6-8bf2-baca1f0aab4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0810998f-6fd3-48e5-a4ff-520f89d33095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f48e105-0509-4a6e-91fe-6f60def044f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e9bc5c4-466f-4a71-acb3-390daa55b707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d49ee204-ed91-4145-8cf5-b9cfacf68284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 685e0fd2-c287-49b4-8007-f3edab8f3326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c4202b6-3ca4-44d8-81a3-8df798ff3931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2960095f-09d1-416f-a0dd-6a6b4c703d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb0be2cc-6004-46be-839f-ce72585ce163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 701fa03f-e0c9-47db-8d6a-5cf86e8d8308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbd92dd5-3aca-48fb-9549-7c29eb4b9895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9fb18ec-8dac-43b2-8441-f1f8bd92a861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d92d793d-2ca0-4c0f-968b-2a1da9fd386a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89d5e9c7-8db8-4a17-8a37-8018a1c07c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6741be06-b7da-4dfd-b2d4-97c5037d4943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 557e5757-33ae-4b80-b384-1ddf07290220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13f4b568-6f9a-48fa-9a16-0faf083590a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f2bbc4b-5305-4c01-95dc-1d9289084130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1accde6f-9b77-4392-bf67-ba32d83570ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13428264-736b-4a73-9c17-bfef2a44748d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 090d3c27-0539-491c-85b5-88cbd37150dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0ad5727-d3de-4e53-9ad5-82dffae5461c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 012509c6-7488-4c86-8a7e-92f9d979b28b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91ae77f1-fd11-448c-95a5-b60a3177b978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98e5436b-2595-44db-ab42-b23a735b84d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a68a0d2a-4d3c-4646-944c-f375fb114027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a6f5fcc-b0ab-4ac7-b3b2-2fdfa4d640ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 439eae79-c245-45c2-97ef-e0c6dd2b29de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44cd3160-bd30-4fb9-818b-56ecb3b40cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 494a762c-1fd8-43fa-ba6c-9c4478d0e938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61b5f328-e537-4714-be27-2a47ba5ec4f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fe72462-4f5d-4853-b118-5e867e7d295f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90ac2e17-4364-48cc-affc-9e9f298b2580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b54a7d3a-ce25-4486-85bd-6b703a6b5e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b6f2c49-52f6-42ec-98d0-e29bda5eed1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e082d023-3a3c-42d0-a981-33557e283010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 961c420e-4faf-4f89-94ba-63e2285e1598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e38886c-2b13-4605-93f7-31294f7f7413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3899ace-2fac-4f1a-9ddf-3f4886039284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1463d692-47b8-4fc4-a60c-e45b0d4098d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 702b695e-6102-4230-ade3-d19ea77317d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2a559f1-5b40-4bfc-b04d-23015605c787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2e5435b-576e-409b-bfd2-57e5f23ec3ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ee378b9-15b0-40f8-b7ff-1ed5d269e8e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2987410a-a060-4a37-86b4-09e30666335b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dfc59a2-731d-4183-8f34-646b05e62315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbe8e64f-4518-4d82-8a1b-139085549d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 527453c6-da53-4184-8258-0c096215dfb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d293b38c-2817-4ea2-bb5c-e87becc1cea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e381d674-6bae-43a8-b1ac-ae5dd4721b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ec5bcb9-149c-41d6-892f-85ac8558f8e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6409aa0b-c44f-41fd-b98f-a2c1579fe32d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588f12a5-a926-4ffe-aa48-77426c231cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5a54b7a-871f-466d-87be-842312adfca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4995f935-f36f-42f9-b709-15416b0c7a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fd74a4f-3bf1-4cd7-9e85-2c248110dded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87e67ac7-39cc-4a5a-b4cf-686ffea6c121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c59cd706-6a92-4dcc-8eda-b5798e198f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c6fe17a-369d-4e99-9b01-2b5abdb20723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c6a676b-c290-4b57-af9d-638eae890389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81ee3bd6-c955-4e56-87fd-f3202d94c974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26a1d85d-dd0e-4af7-86bb-10ccb031ea24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b757e6ef-06a3-4852-8cd8-220392645ddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de8f4678-bc71-458b-8963-14a51182ac23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f44e0977-68e0-4fcd-83e5-ede8abf1ed70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41b7c726-55bc-494d-8ddd-07d06a9e3e57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68fe5f69-95ba-4be5-b595-7625864ed1d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a05f65d-0189-47af-83cd-4d73da1ee156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2572a2f8-be04-4758-bc2d-1dc325255499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 752328e7-f61c-4b2d-ab38-ab531177ae0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0abea1ac-1cce-461f-9b40-3c3078d12ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b594a0a-79c9-4273-92e1-14124d1b7625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0cfdb52-662d-471e-b2ba-04e75327987f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f577002f-a9b4-4089-bfb1-0b3eb36f6ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd0d520f-ef88-40cb-a23a-a5bf6dde140f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa1fa838-47ad-4158-956b-5fc6549aafb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ee153be-639d-46fc-8b7b-57f5dba74da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4433680a-f58b-44de-b468-3dd670e6a16a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ce34bec-4c5c-4aca-85b0-abb94f9e53a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c173dab6-b79a-4549-9183-93e384599f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e82dfb28-d074-44d3-abbe-a66251ee0432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2debb64-2315-4fc0-b376-0bba2e048837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e98b570e-f73a-4611-a993-dac8042a52da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c74c7e11-bf42-440a-823a-bc40389b701d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4efdbc0e-4357-454a-b192-0345f5c86c40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdd86b6b-25f6-4ddd-bfe6-eff3bf14c010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c12fd53-0f9a-4320-a33f-da93adc8f580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c71722c-0631-4507-bf02-aa496e5f282c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a17f7f06-9c5d-47df-9351-ae103b594d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 904da8e5-22bb-48df-9d1b-c19ee006195a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c6d1df1-707a-45c6-9ce8-cc8a81932d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e68eb1-a743-42fb-b21b-f0715437a88c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d06c0e31-1767-4732-9ffd-f75c78691709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f364970-9a7f-40cf-9db8-5845c4f4f467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60a35457-bb1c-49d5-8cf2-352f1eb3bf14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f605660c-5dba-45a4-ac39-cf80008944b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa4e0053-433c-448f-bafc-63c5edef8e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c8b4379-6c67-4618-946c-c03f77ec32ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0a46478-3aa2-4171-adf3-ffbea28b85da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82f66307-6eec-4ee2-9064-6cceb7721eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7647affe-c34a-435e-9542-9333b7d1b2ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 995170e8-c49b-459f-a0dc-a4497ccb6f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64a0f08a-383b-4ae6-9b2e-2b7b97ddeb47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53d32dbb-2aaa-4916-86b5-916041631e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d09dda8-ec2b-4e87-8eb6-e432e029af75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8def4ff3-d68f-43d9-af9c-bf5ed1e62c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e87040d-1587-4b69-8429-9ca3723c8902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb1d26fd-3748-42e0-a5ff-d78d914a34b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd9f2394-5679-43fd-9d8c-ccc77aba35a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 342414ec-06c9-4fa1-ae01-f569afd4a25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b7dff66-bc68-43ca-bcd1-41c075230f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ada254d-1676-4484-bded-84d90245ba71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c67711a-1021-4cfa-8c4c-486c1f547cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee8a92a9-dbe7-4acf-b4a5-97703a695e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f39d997-9110-41dd-bb2f-3f50da689d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f333db4-28ee-439b-b248-9124654b7981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6da9ee3-c60a-4876-a9a7-2aa8a33fe08a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d349fca-37a2-4b9f-9a25-4c2bde80cdc0
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_9
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/test_labels.txt

📊 Raw data loaded:
   Train: X=(755, 24), y=(755,)
   Test:  X=(189, 24), y=(189,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 746 samples, 5 features
   Test:  180 samples, 5 features
✅ Client client_9 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2474, R²: 0.0006

============================================================
🔄 Round 3 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0821 (↓), lr=0.001000
   • Epoch   2/100: train=0.0854, val=0.0820, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0855, val=0.0820, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0845, val=0.0822, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0842, val=0.0821, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0828, val=0.0831, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 3 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0058
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0099
============================================================


============================================================
🔄 Round 4 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0865 (↓), lr=0.000250
   • Epoch   2/100: train=0.0831, val=0.0869, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0827, val=0.0874, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0824, val=0.0877, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0822, val=0.0881, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0814, val=0.0892, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 4 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0008
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0060
============================================================


============================================================
🔄 Round 9 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0866 (↓), lr=0.000063
   • Epoch   2/100: train=0.0833, val=0.0865, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0832, val=0.0864, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0831, val=0.0863, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0830, val=0.0861, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0827, val=0.0859, patience=5/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0825, val=0.0857, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 9 Summary - Client client_9
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0052
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0263
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2455, R²: -0.0015

============================================================
🔄 Round 10 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0791 (↓), lr=0.000016
   • Epoch   2/100: train=0.0853, val=0.0791, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0853, val=0.0790, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0852, val=0.0789, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0852, val=0.0789, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0849, val=0.0787, patience=10/15, lr=0.000016
   • Epoch  21/100: train=0.0846, val=0.0785, patience=8/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 10 Summary - Client client_9
   Epochs: 28/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0041
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0092
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0002

📊 Round 10 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2455, R²: -0.0014

📊 Round 10 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2455, R²: -0.0025

============================================================
🔄 Round 18 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0836 (↓), lr=0.000016
   • Epoch   2/100: train=0.0842, val=0.0836, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0842, val=0.0836, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0841, val=0.0836, patience=3/15, lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   • Epoch   5/100: train=0.0840, val=0.0836, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0838, val=0.0836, patience=10/15, lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 18 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0106
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0068
============================================================


============================================================
🔄 Round 20 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0852 (↓), lr=0.000004
   • Epoch   2/100: train=0.0845, val=0.0852, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0844, val=0.0852, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0844, val=0.0852, patience=3/15, lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0844, val=0.0852, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0843, val=0.0853, patience=10/15, lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 20 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0133
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0128
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 20 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 22 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 22 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0050
   Val:   Loss=0.0879, RMSE=0.2966, R²=-0.0305
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 25 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 25 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0097
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0157
============================================================


============================================================
🔄 Round 26 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 26 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0050
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0177
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 32 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 32 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0102
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0010
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 33 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 33 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0145
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0139
============================================================


============================================================
🔄 Round 34 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 34 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0089
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.0032
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 34 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 34 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 34 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 34 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 44 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 44 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0158
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0266
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 44 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0023

============================================================
🔄 Round 47 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 47 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0130
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0439
============================================================


============================================================
🔄 Round 48 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 48 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0125
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0055
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 49 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 49 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0048
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0371
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 50 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 50 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0146
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0174
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 52 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 52 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0024
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0364
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 54 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 54 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0105
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0202
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 54 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0023

============================================================
🔄 Round 58 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 58 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0093
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0049
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0023

============================================================
🔄 Round 60 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 60 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0025
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0293
============================================================


============================================================
🔄 Round 63 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 63 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0068
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0108
============================================================


============================================================
🔄 Round 64 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 64 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0087
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0205
============================================================


============================================================
🔄 Round 66 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 66 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0077
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0116
============================================================


============================================================
🔄 Round 69 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 69 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0074
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0088
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0023

============================================================
🔄 Round 70 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 70 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0025
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0933
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0023

============================================================
🔄 Round 71 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 71 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0103
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0145
============================================================


============================================================
🔄 Round 72 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 72 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0038
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0266
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0023

============================================================
🔄 Round 73 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 73 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0109
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0043
============================================================


============================================================
🔄 Round 74 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 74 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0110
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0026
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0023

📊 Round 74 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 79 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 79 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0130
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0087
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0023

============================================================
🔄 Round 80 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 80 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0022
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0360
============================================================


============================================================
🔄 Round 82 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 82 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0157
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0153
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0023

============================================================
🔄 Round 85 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0988 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 85 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0073
   Val:   Loss=0.0988, RMSE=0.3142, R²=-0.0175
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 87 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 87 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0142
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0159
============================================================


============================================================
🔄 Round 88 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 88 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0054
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0157
============================================================


============================================================
🔄 Round 89 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 89 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0125
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0020
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 90 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 90 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0040
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.0231
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 92 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 92 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0010
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0386
============================================================


============================================================
🔄 Round 93 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 93 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0138
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0149
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 93 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 93 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 99 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 99 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0125
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0114
============================================================


============================================================
🔄 Round 100 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 100 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0072
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0092
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 102 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 102 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0114
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0107
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 104 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 104 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0119
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0008
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 106 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 106 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0040
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0243
============================================================


============================================================
🔄 Round 108 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 108 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0097
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0147
============================================================


============================================================
🔄 Round 109 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 109 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0020
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0448
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 110 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 110 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0111
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0045
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 111 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 111 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0076
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0234
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 111 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 113 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 113 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0077
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0070
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 114 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 114 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0032
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0249
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 117 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 117 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0039
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0298
============================================================


============================================================
🔄 Round 118 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 118 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0002
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0442
============================================================


============================================================
🔄 Round 121 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 121 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0063
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0134
============================================================


============================================================
🔄 Round 122 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 122 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0028
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0280
============================================================


============================================================
🔄 Round 123 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 123 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0125
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0101
============================================================


============================================================
🔄 Round 124 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 124 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0025
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0468
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 126 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 126 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0107
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0038
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 127 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 127 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0081
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0060
============================================================


============================================================
🔄 Round 128 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 128 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0121
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0035
============================================================


============================================================
🔄 Round 129 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 129 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0094
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0080
============================================================


============================================================
🔄 Round 131 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 131 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0039
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0405
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 131 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 134 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 134 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0098
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0018
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 135 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 135 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0061
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0384
============================================================


============================================================
🔄 Round 136 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 136 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0053
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0176
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 137 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 137 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0070
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0115
============================================================


============================================================
🔄 Round 139 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 139 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0089
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0046
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 139 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 139 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 147 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 147 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0062
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0223
============================================================


============================================================
🔄 Round 148 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 148 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0053
   Val:   Loss=0.0981, RMSE=0.3131, R²=-0.0193
============================================================


============================================================
🔄 Round 149 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 149 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0045
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0312
============================================================


============================================================
🔄 Round 151 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 151 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0072
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0198
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 152 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 152 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0100
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0022
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 153 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 153 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0106
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0049
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 153 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 153 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 153 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 153 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 153 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

📊 Round 153 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 165 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 165 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0113
   Val:   Loss=0.0926, RMSE=0.3042, R²=0.0054
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0023

📊 Round 165 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0023

============================================================
🔄 Round 167 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 167 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0093
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0138
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0023

============================================================
🔄 Round 168 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 168 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0055
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0186
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0023

============================================================
🔄 Round 170 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 170 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0105
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0053
============================================================


============================================================
🔄 Round 171 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 171 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0109
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0157
============================================================


============================================================
🔄 Round 173 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 173 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0038
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0291
============================================================


============================================================
🔄 Round 174 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 174 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0103
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0007
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0023

============================================================
🔄 Round 178 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 178 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0078
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0094
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0023

============================================================
🔄 Round 180 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 180 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0035
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0297
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 181 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 181 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0061
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0150
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 183 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 183 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0077
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0073
============================================================


============================================================
🔄 Round 184 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 184 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0141
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0053
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0024

============================================================
🔄 Round 187 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 187 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0091
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0029
============================================================


❌ Client client_9 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
