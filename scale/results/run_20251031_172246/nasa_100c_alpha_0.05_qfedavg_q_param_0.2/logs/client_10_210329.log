[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fdebfb2-2bba-4fa5-9517-d16ef696fd6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e86f46cc-801d-456d-9d05-833e7143fc43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4886b4ee-f963-4bfc-b812-b976ec1b9a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2207453-959c-4133-92ad-83f42b76aa01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d03ba63-13fc-414a-86b0-a177144960ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf82034b-52da-45b2-bb43-eac07295ef9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b79e1ec9-1df4-4cc5-9b75-3ea820288a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e440d9f0-cf5e-4974-9e1d-751255e79a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06683b48-3e4b-44df-833c-9a315f91ea10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7735812c-f216-4691-9647-b4953be30f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c350601-2228-4f9c-836f-071641302adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e91e6fa0-e138-4c79-b6d7-622c08979312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e6f6e40-c66f-4869-af89-5f15f6ddeef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ce1f353-ba52-440e-80e3-76e8cba11011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5de239a8-8563-4cd0-be68-efaf85d6b19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdf9e9c3-53a6-46da-9b9e-516e8a671541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67cb02a7-142d-4fd3-8fb6-41d6de97aa2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 922f4943-fc31-48c9-8b22-ff4456ea3642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49c27115-e992-4d7e-8e9c-7fd79102b401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93d8338a-c1b6-4104-8af8-28377c010a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e47be99e-01a0-499e-91b4-fdfee26102d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 758a57cd-a4d3-4601-8cbb-095141003165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac60b737-c17d-4ca9-b953-6d4a5b8a0cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a101b8b5-6431-424a-b802-9e14b4cd5885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0faf4d7-b84b-42a9-8cdf-a7d53ace7efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c81c869b-da2b-425d-b983-eadab96f8902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41423f0f-355d-4cba-879e-bad55913a17d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0516f6b3-072f-4c61-9589-a72d922f7c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6186ce61-d2f2-444e-889f-f47c2d593d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb05a9df-70a7-4e35-93f2-2debbf486624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21315428-595e-4e4d-a6e8-d622629c5754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 366392d9-bce6-4967-9c7b-6d2dde21dd09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6c9f489-8538-478b-bbfb-7f9114e56e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ced896f8-165c-4faf-8575-159c0a690088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37d9fca3-39fe-420c-8ae2-8cadc6403400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93d6ba2d-d784-4a43-92f0-ccddc6fce33c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23186280-f93e-4e83-b2a7-786c511792c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98809575-9747-4e4f-b037-996ae19ebcaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1093e29d-586b-4a42-965c-7e276b5c89cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41a4a5cf-fe81-4dc5-930e-6dc1171da92d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f8150e6-25a4-46a8-93c3-64436e2953e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50b7b1c0-917a-40f0-977e-f9c00fa67342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ede16681-ad5d-4bdf-b9b2-5dbbddc1d99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6648128-b89e-4fb1-ae70-f7f6cd08f70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67d1b633-909f-456d-9445-95bf39ebe5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5564d15-3a9b-49a6-9a27-d716a500d038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0e2b370-bb3a-4d9d-857e-cb42d84b9227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bee1a195-9fe1-4e40-a6c5-f58e908389f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca99071d-46fc-48f9-b221-94323ff4e2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69fa2853-a04f-4fcc-b5c0-98cd72dcf927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2aacabe-a445-4a8a-8f86-7e6abeedb288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09130241-b076-4154-a0db-0f2575d66138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ad02e9c-d085-43e4-8a47-f3d1e7c426e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 178cbe2e-c0c8-44f0-8ad3-e3faaf999f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 592aebea-7f63-4776-80d3-18758ff076b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53456cc1-ad3d-4bf6-8d69-bf0dbd08b266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f152a49-4d0b-4a89-9992-873af5f304db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ebd995a-9b24-4e6d-8b2b-2b653343111a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ec53954-0044-4b06-9436-9d7b2d914691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43bb2fed-652d-4217-943c-accce9f93459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb5f7dfa-cbc5-455a-aa05-e0adc87c2b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05f5ce25-ed3a-4901-8375-c1bffa9f7a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0cd0865-88bd-43b9-9777-2be568bd6457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb4659b5-68ac-431d-9be2-88f0532f7ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b946ed69-5a9c-4b56-849b-4dcdb3aa200d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 441d79e7-4179-44ef-98bd-6616533568af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d54b55c9-4e4a-450b-a061-cca3666fa070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5667df8c-81db-41b7-9cf4-0ac5c5b9c59f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1a134d4-1d56-463c-b43b-048935abf3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 276dc339-96ab-4f5c-9b8b-54cf15728c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fc8df1c-b433-4af0-bb52-7fd64a86588b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d9cb5c0-7f9d-465e-9d3b-4a2427094fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3976ff0a-8a13-40da-9c87-d192c4246c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 879b7379-b9d9-408b-a188-a45c22021a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7635580-6c1d-4355-bac9-99d615bff64d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52347b94-a82e-4c33-9324-c7b8bcb6da63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99019169-2ce5-4077-882b-8a069338da43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 250b9b4a-bef4-4e89-925e-7f6691565fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c42bb417-1601-45ea-b6ac-63b4ca0dcbdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33e4cd36-02d8-4015-96e3-45b5940d8f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e686ce04-8554-45a9-9fd9-e66681632d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a617bbc6-31c5-4f92-8a90-f944522438c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84354553-a125-415b-87c9-d1c00e178b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54cad9f5-82a4-4b49-96da-6ede9b9c6eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c93b63c-0aae-46fa-8aed-24e6b618f247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e357c266-1f4f-42c7-9d77-ad4fe7e8e27e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aefcbe6-e731-413e-93bb-4b7deadb36ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59c9ff43-56b7-4bc8-9c7c-b2f0f7005651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab6534fa-7b81-4f94-bac0-f54ec83fa1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9cb4fd7-bb44-4dc6-add8-e908459bcd85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 287880f3-6ec6-4b38-aae8-bac9f0ab9092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 792a769a-31c1-4b13-90fb-8eefed57d249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaa0d365-de50-41ba-bf55-33b474051dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e0462e7-b4d4-4986-a1ae-23e5e26c913e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eede100e-b483-414c-b8c2-aab4b13d9d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 284e6d95-b660-4907-968e-e4e48d52ac81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5235ff56-7ba8-4adb-a44a-3e07aeeadf9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c663ca07-ece7-4873-a069-cf56c53a8dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcab5c07-3f1a-495e-bc0d-589f52f88edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6e2f23b-d5c0-4f92-ba97-fc3158459f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b394bb6-6399-4810-92c3-89ec8c92691a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5a732e1-78db-407d-930f-33eb62fa2e80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 008b2df7-42c5-4148-9d15-01c6fbb1df40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbedf46e-029d-4bca-a672-3272d0fa711d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81b31f08-3b87-4445-890d-71f8b711c712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3cab3b6-09f7-4b88-ac9b-71c6a4489e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33c409b0-42c6-44f8-b969-1ba62d9254a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2603b2b3-a88f-4266-9bd9-8832375fdb64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd02e233-55ce-404e-8598-23de110a6451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d0d6db4-5535-4b3f-a36c-09fd69137a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 276f8d68-08dc-40c1-99b4-d72f17cd0d53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bfd2e5c-b6b2-42ab-9085-917776474d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f3e9994-0ade-474b-abec-1ca4e0a4c5c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37488420-6186-47a3-9a9c-c04ded8d7d59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a4075f3-4427-434e-89fb-cb1b252458cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c75443e7-e736-4674-a443-23f8b5bc46a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3ffa83e-5b6d-4c4e-9671-953ae9453541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b3e6b26-7873-4a15-94b4-5ad53f5ff34f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfd748ff-81c7-4165-99c0-b23ad035a736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fa076a3-6bfa-48e1-bf67-cf5524f908ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea08fee8-56fd-4f68-b5d9-f601371593eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2aa2c58-432a-4b02-bf33-f3c45d0d9548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8777d397-9ff6-4a87-9b3e-d12d053fa5d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26379bce-f024-4708-aace-dfbdf55132b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dc64431-9e00-46fd-8343-86d878741a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35cfe6d1-d473-4805-a055-ed6811c9514f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9161bec7-9091-45f7-b23e-535b568f7654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d788f3-2171-4ab5-bd4d-e1d3b92d2203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f32fbca-0112-4a8a-b7b5-c41d07926f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff05ef79-54ef-4d82-b95e-b4b203cb9a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e521e3f8-d835-412a-80b9-650095998d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e2f125d-ae3a-46fb-820c-a9194aa8fcc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3fa2083-18ee-4418-a468-16d14badd411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11f57571-af98-4115-a608-41b72aaeee40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17613c2a-f8fc-45ff-b632-e832a8023de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfff9110-32fc-48d4-96f0-4193855138ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f83dda2b-1be0-40a8-bd4d-29a075655c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2fdc699-3728-4d6a-9e92-6d8542af8ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f98c6da9-41d9-46ea-af5e-f71e4564cdbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0755fb69-89df-460e-8835-1753d221b55f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e264ed2d-e73b-4907-9d24-68e48cc287cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d216a550-d671-46db-b133-d39e6da05318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9359042-4dc0-4ecf-92a9-c4c040ab6a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e651ed1c-e752-422c-a602-013f2dd5faec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a495e16e-c7af-48ce-b954-2ef0df72f040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b42269a-69c0-44f6-bb0a-eef948e63a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34073bef-ea19-4f9e-b6e4-23eb2e4725e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f682b5a5-31b9-4971-b23c-67e18a67c863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf56dcbe-4699-437d-90e6-8d6901097061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eba2942c-33a0-42cc-89f3-b8e5c62b3be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbfbda5e-fd87-4b25-aa50-3e037a901703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ffdfde9-529a-4055-b844-2fc0adcd1a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac770c2d-f149-4b07-a058-3a7a799a9805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 027cf093-959b-49df-a2f2-7565cbc8100f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73a331e9-3081-42ae-883e-3c6397417678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eac76c17-9001-4795-8c47-d8670a264612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f10690cc-d739-4604-a888-bc089e7a163b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91633a0d-e23c-438e-8574-f9317764c6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fb829ed-8502-4568-bf44-78af70e85406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b840ed3-3481-4813-8249-af8d364ac6eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56dfc9ac-82b6-48af-b546-d7f4ed3ac894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 571bf804-8a57-4745-aa37-25ff6bf5e83d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21a8caaf-6db0-4668-b5a8-cc22000c1dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 135cc15b-10c4-493c-9427-9c782cbf1987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ef11c3a-1631-4eb1-9683-eb44e1dff716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 864f1fd0-328a-4a79-b5b5-67951889cc91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dedfeb9e-a5a7-405e-b9e3-a612141e3c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf66efe2-cb37-4c1a-afaf-68504a1982ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d790200c-5196-415d-90a2-cd0549ca2ecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e0b52d3-3570-4e43-85e5-e90aa7954eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70e4482d-76d2-4e21-b0a2-f112e077232b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02f7acd9-55b4-44b9-86d0-1ebf511a01d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dee7ab95-1037-4e20-bbd7-6cf9814820a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 516cd1eb-5d2c-4ad9-b388-246006401381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59f2f951-2412-4425-a988-a811e6bce6a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77596102-6464-4474-b79b-16d4d95f9903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38483356-9976-4cae-aaaa-f5934915d21d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 582450c8-6536-4a29-ab35-aea5f9ed9cb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b51c39ab-52dc-4147-9c7c-9ab7e9e7d866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62e51a83-3c8a-4cb2-ad19-da119775ae9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be10cb7a-44fc-4e32-963d-5cbb81bb8737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb094dd1-ab15-450f-a8b1-16ca09644c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d589289a-15a3-41cb-8a30-fc451fe8dad3
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_10
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/test_labels.txt

📊 Raw data loaded:
   Train: X=(424, 24), y=(424,)
   Test:  X=(106, 24), y=(106,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 415 samples, 5 features
   Test:  97 samples, 5 features
✅ Client client_10 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1581, val=0.0960 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0940, val=0.0824 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0813, val=0.0808 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0827, val=0.0799 (↓), lr=0.001000
   • Epoch   5/100: train=0.0813, val=0.0796, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0794, val=0.0793, patience=5/15, lr=0.001000
   • Epoch  21/100: train=0.0749, val=0.0793, patience=15/15, lr=0.001000

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 1 Summary - Client client_10
   Epochs: 21/100 (early stopped)
   LR: 0.001000 → 0.001000 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0264
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0072
============================================================


============================================================
🔄 Round 2 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1642, val=0.1210 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0941, val=0.1076 (↓), lr=0.001000
   📉 Epoch 3: LR reduced 0.001000 → 0.000500
   ✓ Epoch   3/100: train=0.0804, val=0.0947 (↓), lr=0.000500
   ✓ Epoch   4/100: train=0.0776, val=0.0941 (↓), lr=0.000500
   • Epoch   5/100: train=0.0776, val=0.0947, patience=1/15, lr=0.000500
   📉 Epoch 11: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0764, val=0.0945, patience=7/15, lr=0.000250
   📉 Epoch 19: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 2 Summary - Client client_10
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=-0.0039
   Val:   Loss=0.0941, RMSE=0.3067, R²=0.0141
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.2357, RMSE: 0.4855, MAE: 0.4025, R²: -1.6660

📊 Round 2 Test Metrics:
   Loss: 0.2279, RMSE: 0.4774, MAE: 0.3948, R²: -1.5776

📊 Round 2 Test Metrics:
   Loss: 0.2196, RMSE: 0.4686, MAE: 0.3868, R²: -1.4838

📊 Round 2 Test Metrics:
   Loss: 0.2160, RMSE: 0.4647, MAE: 0.3835, R²: -1.4424

============================================================
🔄 Round 7 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1678, val=0.1408 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.1457, val=0.1199 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.1236, val=0.1020 (↓), lr=0.000125
   ✓ Epoch   4/100: train=0.1048, val=0.0878 (↓), lr=0.000125
   ✓ Epoch   5/100: train=0.0902, val=0.0793 (↓), lr=0.000125
   • Epoch  11/100: train=0.0798, val=0.0761, patience=1/15, lr=0.000125
   • Epoch  21/100: train=0.0791, val=0.0751, patience=1/15, lr=0.000125
   • Epoch  31/100: train=0.0785, val=0.0747, patience=11/15, lr=0.000125
   • Epoch  41/100: train=0.0780, val=0.0745, patience=7/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 7 Summary - Client client_10
   Epochs: 49/100 (early stopped)
   LR: 0.000125 → 0.000125 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0289
   Val:   Loss=0.0747, RMSE=0.2732, R²=0.0306
============================================================


============================================================
🔄 Round 9 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1582, val=0.1175 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.1343, val=0.1006 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.1109, val=0.0886 (↓), lr=0.000125
   ✓ Epoch   4/100: train=0.0926, val=0.0837 (↓), lr=0.000125
   • Epoch   5/100: train=0.0821, val=0.0868, patience=1/15, lr=0.000125
   📉 Epoch 6: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0783, val=0.0886, patience=7/15, lr=0.000063
   📉 Epoch 14: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 9 Summary - Client client_10
   Epochs: 19/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0914
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0045
============================================================


============================================================
🔄 Round 10 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1533, val=0.1612 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.1474, val=0.1540 (↓), lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   ✓ Epoch   3/100: train=0.1406, val=0.1470 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1355, val=0.1438 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1326, val=0.1407 (↓), lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.1170, val=0.1246 (↓), lr=0.000008
   📉 Epoch 19: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.1068, val=0.1147 (↓), lr=0.000004
   📉 Epoch 27: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.1031, val=0.1109, patience=1/15, lr=0.000002
   📉 Epoch 35: LR reduced 0.000002 → 0.000001
   ✓ Epoch  41/100: train=0.1016, val=0.1093 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1006, val=0.1082 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.0996, val=0.1072 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.0986, val=0.1062 (↓), lr=0.000001
   • Epoch  81/100: train=0.0977, val=0.1052, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0969, val=0.1043, patience=2/15, lr=0.000001

============================================================
📊 Round 10 Summary - Client client_10
   Epochs: 100/100
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.0955, RMSE=0.3090, R²=-0.2030
   Val:   Loss=0.1034, RMSE=0.3216, R²=-0.2362
============================================================


============================================================
🔄 Round 11 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1569, val=0.1505 (↓), lr=0.000001
   • Epoch   2/100: train=0.1567, val=0.1503, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1565, val=0.1500, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1563, val=0.1498 (↓), lr=0.000001
   • Epoch   5/100: train=0.1561, val=0.1496, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1549, val=0.1484, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1531, val=0.1466, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.1515, val=0.1450, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1500, val=0.1434 (↓), lr=0.000001
   • Epoch  51/100: train=0.1486, val=0.1420, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1472, val=0.1406 (↓), lr=0.000001
   • Epoch  71/100: train=0.1459, val=0.1393, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1447, val=0.1380 (↓), lr=0.000001
   • Epoch  91/100: train=0.1434, val=0.1367, patience=2/15, lr=0.000001

============================================================
📊 Round 11 Summary - Client client_10
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1366, RMSE=0.3696, R²=-0.6564
   Val:   Loss=0.1355, RMSE=0.3682, R²=-0.9124
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1795, RMSE: 0.4237, MAE: 0.3501, R²: -1.0305

============================================================
🔄 Round 18 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1020, val=0.1145 (↓), lr=0.000001
   • Epoch   2/100: train=0.1019, val=0.1144, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1018, val=0.1142, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1017, val=0.1141, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.1016, val=0.1140, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.1011, val=0.1133 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1002, val=0.1122 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.0993, val=0.1110 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.0985, val=0.1099 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.0977, val=0.1088 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.0968, val=0.1077 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.0960, val=0.1066 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.0952, val=0.1056 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.0945, val=0.1045 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_10
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0927, RMSE=0.3044, R²=-0.1595
   Val:   Loss=0.1036, RMSE=0.3218, R²=-0.2923
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.1139, RMSE: 0.3375, MAE: 0.2815, R²: -0.2886

============================================================
🔄 Round 19 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.1094 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.1093, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.1092, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.1091, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.1090, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.1084, patience=5/15, lr=0.000001
   • Epoch  21/100: train=0.0902, val=0.1074, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0895, val=0.1065, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0889, val=0.1055, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0883, val=0.1046, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0876, val=0.1037, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0871, val=0.1028, patience=5/15, lr=0.000001
   • Epoch  81/100: train=0.0865, val=0.1019, patience=3/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0859, val=0.1011 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_10
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0570
   Val:   Loss=0.1004, RMSE=0.3168, R²=-0.1599
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0928, RMSE: 0.3046, MAE: 0.2616, R²: -0.0494

============================================================
🔄 Round 24 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 24 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0054
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0017
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2606, R²: -0.0310

📊 Round 24 Test Metrics:
   Loss: 0.0910, RMSE: 0.3016, MAE: 0.2605, R²: -0.0287

============================================================
🔄 Round 29 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 29 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0048
   Val:   Loss=0.0780, RMSE=0.2794, R²=-0.0047
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0909, RMSE: 0.3014, MAE: 0.2604, R²: -0.0276

============================================================
🔄 Round 31 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 31 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0077
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0085
============================================================


============================================================
🔄 Round 32 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 32 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0031
   Val:   Loss=0.0699, RMSE=0.2645, R²=0.0049
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2604, R²: -0.0267

============================================================
🔄 Round 34 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 34 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0038
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0048
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2603, R²: -0.0261

📊 Round 34 Test Metrics:
   Loss: 0.0907, RMSE: 0.3011, MAE: 0.2603, R²: -0.0254

============================================================
🔄 Round 37 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 37 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0064
   Val:   Loss=0.0695, RMSE=0.2637, R²=-0.0297
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0906, RMSE: 0.3011, MAE: 0.2603, R²: -0.0252

============================================================
🔄 Round 38 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 38 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0035
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0247
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0906, RMSE: 0.3011, MAE: 0.2602, R²: -0.0250

📊 Round 38 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2602, R²: -0.0243

📊 Round 38 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2602, R²: -0.0241

📊 Round 38 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2602, R²: -0.0238

============================================================
🔄 Round 44 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 44 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0035
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0132
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2602, R²: -0.0238

============================================================
🔄 Round 48 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 48 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0043
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0051
============================================================


============================================================
🔄 Round 50 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 50 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0016
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0041
============================================================


============================================================
🔄 Round 52 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 52 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0019
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0041
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2601, R²: -0.0232

============================================================
🔄 Round 54 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 54 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0025
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0057
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2601, R²: -0.0233

============================================================
🔄 Round 55 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 55 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0020
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0033
============================================================


============================================================
🔄 Round 56 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 56 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0039
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0074
============================================================


============================================================
🔄 Round 60 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 60 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0061
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0180
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2601, R²: -0.0231

============================================================
🔄 Round 61 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 61 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0034
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0016
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2601, R²: -0.0230

📊 Round 61 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2601, R²: -0.0228

📊 Round 61 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2601, R²: -0.0227

============================================================
🔄 Round 65 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 65 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0027
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0036
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2601, R²: -0.0226

============================================================
🔄 Round 67 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 67 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0041
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0041
============================================================


============================================================
🔄 Round 69 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 69 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0024
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0035
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2601, R²: -0.0226

============================================================
🔄 Round 71 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 71 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0029
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0015
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2601, R²: -0.0222

============================================================
🔄 Round 72 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 72 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0033
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0108
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2601, R²: -0.0221

📊 Round 72 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2600, R²: -0.0219

📊 Round 72 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2600, R²: -0.0218

📊 Round 72 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2600, R²: -0.0217

============================================================
🔄 Round 79 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 79 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0006
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0035
============================================================


============================================================
🔄 Round 80 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 80 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0022
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0029
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2600, R²: -0.0216

============================================================
🔄 Round 82 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 82 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0030
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0021
============================================================


============================================================
🔄 Round 83 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 83 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0030
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0198
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2600, R²: -0.0214

📊 Round 83 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2600, R²: -0.0216

📊 Round 83 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2600, R²: -0.0217

============================================================
🔄 Round 87 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 87 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0027
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0018
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2600, R²: -0.0216

📊 Round 87 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2600, R²: -0.0215

📊 Round 87 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2600, R²: -0.0214

============================================================
🔄 Round 90 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 90 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0005
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0139
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2600, R²: -0.0213

============================================================
🔄 Round 91 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 91 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0005
   Val:   Loss=0.0714, RMSE=0.2673, R²=-0.0166
============================================================


============================================================
🔄 Round 92 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 92 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2820, R²=-0.0036
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0128
============================================================


============================================================
🔄 Round 93 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 93 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0038
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0265
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2600, R²: -0.0211

============================================================
🔄 Round 95 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 95 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0050
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0274
============================================================


============================================================
🔄 Round 96 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 96 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0009
   Val:   Loss=0.0690, RMSE=0.2627, R²=-0.0112
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2600, R²: -0.0212

📊 Round 96 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2600, R²: -0.0212

============================================================
🔄 Round 100 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 100 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0045
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0178
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2600, R²: -0.0209

============================================================
🔄 Round 102 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 102 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0001
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0076
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2600, R²: -0.0208

============================================================
🔄 Round 103 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 103 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0053
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0393
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2599, R²: -0.0207

📊 Round 103 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2599, R²: -0.0207

============================================================
🔄 Round 107 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 107 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0018
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0002
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0206

📊 Round 107 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0205

============================================================
🔄 Round 110 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 110 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0031
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0135
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0204

============================================================
🔄 Round 111 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 111 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0023
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0006
============================================================


============================================================
🔄 Round 112 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 112 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0086
   Val:   Loss=0.0714, RMSE=0.2673, R²=-0.0390
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0204

📊 Round 112 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0206

============================================================
🔄 Round 116 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 116 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0039
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0055
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0205

============================================================
🔄 Round 117 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 117 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0047
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0111
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0206

============================================================
🔄 Round 123 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 123 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0015
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0004
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0205

============================================================
🔄 Round 125 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 125 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0032
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0129
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0203

============================================================
🔄 Round 128 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 128 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0013
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0049
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0203

============================================================
🔄 Round 131 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 131 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0014
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0034
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0203

============================================================
🔄 Round 132 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 132 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0085
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0058
============================================================


============================================================
🔄 Round 133 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 133 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0016
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0027
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0202

============================================================
🔄 Round 134 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 134 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0018
   Val:   Loss=0.0672, RMSE=0.2593, R²=0.0017
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0201

============================================================
🔄 Round 136 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 136 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0042
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0246
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0200

============================================================
🔄 Round 139 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 139 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0027
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0046
============================================================


============================================================
🔄 Round 140 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 140 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=-0.0033
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0076
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0198

============================================================
🔄 Round 142 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 142 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0004
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0058
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0200

============================================================
🔄 Round 143 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 143 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=-0.0045
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0076
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0201

============================================================
🔄 Round 144 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 144 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0002
   Val:   Loss=0.0680, RMSE=0.2608, R²=-0.0034
============================================================


============================================================
🔄 Round 148 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 148 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0003
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0010
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0204

📊 Round 148 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0204

📊 Round 148 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0205

============================================================
🔄 Round 154 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 154 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0065
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0692
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0204

📊 Round 154 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0203

📊 Round 154 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0204

============================================================
🔄 Round 158 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 158 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0025
   Val:   Loss=0.0712, RMSE=0.2669, R²=-0.0131
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0203

============================================================
🔄 Round 159 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 159 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0039
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0069
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0203

📊 Round 159 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0202

============================================================
🔄 Round 161 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 161 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0070
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0351
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2599, R²: -0.0203

============================================================
🔄 Round 164 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 164 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0023
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0012
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0202

📊 Round 164 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0200

📊 Round 164 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0200

============================================================
🔄 Round 169 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 169 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0027
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0061
============================================================


============================================================
🔄 Round 170 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 170 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0020
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0043
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0198

📊 Round 170 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0197

============================================================
🔄 Round 173 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 173 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0020
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0005
============================================================


============================================================
🔄 Round 175 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 175 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0006
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0050
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0197

============================================================
🔄 Round 176 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 176 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0002
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0011
============================================================


============================================================
🔄 Round 179 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 179 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0000
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0073
============================================================


============================================================
🔄 Round 181 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 181 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0056
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0284
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0199

📊 Round 181 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0199

============================================================
🔄 Round 185 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 185 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0038
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0112
============================================================


============================================================
🔄 Round 186 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 186 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0037
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0055
============================================================


============================================================
🔄 Round 187 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 187 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0024
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0248
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0201

============================================================
🔄 Round 188 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 188 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0005
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0089
============================================================


============================================================
🔄 Round 190 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 190 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0060
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0540
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0200

============================================================
🔄 Round 191 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 191 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0030
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0300
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0199

============================================================
🔄 Round 193 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 193 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0032
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0167
============================================================


============================================================
🔄 Round 194 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 194 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0011
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0016
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0197

============================================================
🔄 Round 196 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 196 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0009
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0029
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0199

============================================================
🔄 Round 197 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 197 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0028
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0215
============================================================


============================================================
🔄 Round 198 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 198 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0002
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0094
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0199

============================================================
🔄 Round 202 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 202 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2778, R²=0.0048
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0089
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0198

📊 Round 202 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0197

============================================================
🔄 Round 206 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 206 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0009
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0016
============================================================


============================================================
🔄 Round 207 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 207 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0004
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0003
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0198

============================================================
🔄 Round 208 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 208 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0044
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0574
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2599, R²: -0.0199

============================================================
🔄 Round 210 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0655 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0655, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0655, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0655, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0655, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0654, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0655)

============================================================
📊 Round 210 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0045
   Val:   Loss=0.0655, RMSE=0.2560, R²=-0.0172
============================================================


❌ Client client_10 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
