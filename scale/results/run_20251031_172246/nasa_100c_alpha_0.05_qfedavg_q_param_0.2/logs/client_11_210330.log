[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88ba46e5-0b4f-4152-8bb4-cfe2e571fb55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af9a0b5a-fc11-4113-ba95-1d41cf69bcde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e1d557e-c85a-4231-a574-0453a93869f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aca63d7-220f-48d2-987a-fcc31f5a35bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73515e87-38c8-4cce-887a-3b7d829d6706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04075eef-97fc-42ba-b501-6010a4e46b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1d99173-3708-4c2f-b5ac-66eb2aa8960e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18689166-63ab-4b99-9c62-30d6f0f70f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 510c4037-686d-46aa-ac13-bcadee9e5a9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7d74611-aa68-46a4-8ec6-94df0edaf249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35d22f2e-c112-4988-93d8-4a0ee012573f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28ffa043-c0bd-4609-8af5-a926ffe66813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 861ad476-92b7-412c-bd63-ade4db3c72c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57051907-372c-4df5-9002-79e273f45068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2791486b-11f7-4409-ae67-c0c11f2615be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2bab45b-894f-412e-ad29-514e904dedee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b0b8f6c-b24f-4917-9602-839c2d2882cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c51b2c73-fc1c-4114-b4d1-b90dcb0ccdbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d9e3b6d-82c4-451c-aaa8-7b9d989763a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 392a0758-5e2c-45ca-9bdc-3ad312addc8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c586716f-a55b-49fe-a840-264fc43c3fc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9758a626-3acf-41af-8d70-e9e8cd3a9133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27b56ce1-9d59-49fc-80cb-3119aad4711e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 801c8139-92dd-4a31-b688-5d79e6da50b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc23664d-42c9-4d42-8347-eac23abecfcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5646d666-27c4-4416-bba5-0d7e83f214ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bce95593-b699-406e-8391-5f6a6eaeca94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc172558-e63e-4d04-817a-f25422e79cf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2cd1cf1-ae5e-4912-acfb-ac43c4805401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 629a8a67-4c87-43ba-bf16-44337193bb7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5de7b26-32ed-4b61-b2f3-2ea59bc69249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 338ff034-1961-46ba-94f2-5a045e1f44d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb696a66-6094-4ac9-b350-5ee34b9ba5e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8213f5a-7afe-4118-a6ca-5c4506b3a5f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35cceb7f-f75b-403d-8de9-2af5509d2b6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a54005f-8c6b-449a-b2d7-171f99dc58ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0bd8b78-b085-4283-8b69-27511b05f965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 054c8ece-2289-4cbe-a070-9dfb7157160d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46cb2495-2f61-42ea-b7e9-ecdbcd8e6dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 868841d0-5cad-4a2c-ba50-260f5c6caef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d91c2d0-d876-4baa-8e04-a1382a603541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 881d33e5-fa71-4c56-9a88-94d5fbcd5ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5daba322-a911-4a09-910a-8cef1b9c47cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d618a6e-3f3c-43b4-846f-39cb7d44ece5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d1fda61-b683-4c75-9e51-7cafdb3e0309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6449c68a-f918-43d0-931e-a392cfa47a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69ecdbad-cdbf-4a21-a1f5-710a9eb51f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc64f7a1-bc95-4555-bf1d-526f2ba93f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 721bed49-b247-4372-ad13-bd22e830324a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1f57b4a-3141-4304-90b6-4528118be347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7ebe71b-7827-4d88-8fd0-4cc76d50e167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bf08e72-3e17-438b-a30b-76643107e909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c571fdc4-4ad1-4f03-a5c3-a9c547501ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66660311-3482-4e62-82de-685b6eb0ef92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d992cbc-6fc7-45aa-99f7-34dc2032b8e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfc2fb79-b838-420b-86d2-1aae046f7611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb785ba0-7121-4389-be61-d9ae0895d941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5377060a-b051-4671-ba0c-2d01244391ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0678490e-d982-420c-988e-a6774d26ccb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58f90431-7235-4143-897c-dfbe2bf9d332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6006bf4-b7d2-45f8-93a9-b7b4af19158e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee4a859d-04a6-42aa-8dc4-151cebac24f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96f10d7d-a536-4704-83e7-2b4abc194757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7a6341f-6393-461f-887b-5f8d6d336b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08863b1c-5b11-444e-83c2-aa48e41ee7ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2e65daa-34cc-4503-89e4-eca3b7d6f149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74b43a26-8e66-40d6-b190-f30797814944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec360031-49f4-4f05-b30b-459785d603b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f9e1b95-a652-41ad-9c24-1e7966c30e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef27e3fe-851a-41a9-95e7-954171489dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd04cca2-db4a-4fec-8326-6959268a18ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19d1adfb-afd8-4c4b-9cb4-054377a1371f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 375d3a77-ac5c-4409-8ae5-0a6d4254c9ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4cf2bd8-0a01-4684-a41b-3166b104b7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99e253a5-0ee4-4247-a140-8c267969b731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21a5001c-ced5-4dbf-b8ef-21d3465616d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dac84cd-d9a0-4791-bae1-4d822f049c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e326a397-000b-452a-8fee-2b8d0c0235fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3109daa8-ee70-4b6b-92f8-cc116e9b75f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2faabfe4-2476-4fed-8fb9-740bd3007391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f44b2fdc-f03e-43b9-be5c-623b86c4d09a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4636c50b-cd65-40d8-ad27-e14e2d65152a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52bce99a-89c9-4f18-81b7-12b6e5dbb629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf6d3a90-179e-4308-957c-59a69cbfc0e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 863778d3-e978-4c12-9a35-4bbd040d45ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1bcd232-f06a-4e46-9786-fff6ae6e8827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd00944-1baa-4960-863e-8b8707dbeb66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ef2c81c-e33d-4966-9070-fa876fb351d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51ba4e01-80e0-4242-b9be-04ec64ccf135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c59d6d99-ce1b-4ea9-b4d0-b005c98a6f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d28d6c4-99b3-4f65-9aba-4ca9dbbfb72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a4f98fe-e9e7-4e66-a7cc-0fb6ddcd55f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e234edb8-07bd-4567-a34f-1bef36a52aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed1a2783-98d4-4f59-ac51-a13e9aeaccde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0f4ac05-e133-4383-8737-3a5893ecb57b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d97adec1-78a7-446e-aec3-c5fb4e96b4ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 733be29b-1cd5-445d-8d68-6e216e888261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64355c3c-c8d7-40c4-b014-436bea081260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfd6846f-a0b7-4327-bd74-b2923bfe7cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d689711d-39d7-4686-8c54-44bbac2ee1ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1fc0a97-ea25-4926-802e-b2d5cb38f192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 423f2cb3-97c6-46f4-a6ed-81848fea1f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26d82949-c65f-45f6-afc3-09d3d86f46bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c18dcb2d-06c7-469c-a046-d70551a92a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e21cd8d-e017-4523-bba3-9b89b20683b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0cec22f-b717-4c10-8c42-374d42ca9a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba7175a2-3e3c-4650-b71b-a7bac078bc89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18125b88-498d-41d4-97aa-4a0ce03bb39c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b91da32d-ed8b-434a-83bf-01a4c2b0d815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31ea3d99-b1c1-48a9-ad8a-a052a43db5e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d419e83c-7786-4821-97a7-aa7e1071c564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a18825-f2cf-41e8-974a-cf3c3f379f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec5631bc-ed6f-4b3e-89c7-7b180a988d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c04a8b8-ee24-4df0-84f9-8d12f1b71849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa353024-8acd-4715-83a6-d022d39637c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 285b2899-afcf-42e7-a9ea-ecfab550713c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a21b58b5-d89a-4fd5-b1e5-fdd2a1155262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b8a4869-0ed3-4ae9-9b83-50f5eeee7177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4621e4dd-2c00-4c11-9554-2a2e3fc3f947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc089663-1bd6-442a-afe4-75c8f1c29294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 191a8c9e-7c3b-43f1-8e62-1adf95ebe3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a1e4772-28b0-46af-845c-a30e160fd45a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 824def00-fc73-4c8c-b3eb-3d200936eba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be28d7f7-afca-480c-9aa5-c4e1fd0705b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55a1ab98-f489-4d6c-ad84-3193f56bb404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acc9b15a-1ca6-4524-a0a5-799f2980e59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a6b0d3b-185e-49cf-8ee3-6835a66eadd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5965a83-3017-4436-a2c1-feb46d542d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43510198-c03a-445a-86d9-f0d5e060cd4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f14b2cd1-abd2-4985-a700-8050ba966e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a91252e-35d9-4db1-af25-2f93862622a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f348af4f-79b2-423d-9932-b5b476cdf904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 055b4f74-84f9-4ef0-a034-3e413f8eac07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e2b5865-c287-4443-812c-382bc6620c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4111f5d8-d8b2-4b2f-9921-0cd1ef0f601d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54d60245-25a1-48d5-a4c3-02cd1011d032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58c59e02-5c49-46a6-bcff-e7f0d6bcb82f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40914329-810b-429d-9678-9dd787a63467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72fad9fe-0dcd-4413-ab0f-d9bf5a90a658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3aa2d2b-4dc2-4a41-bc1b-69d36d1993a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4765331-5d69-4ca1-9f44-c9aaba9a8206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8165ebea-7637-41e7-8ccc-0116c676dd14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8c58426-fde1-476e-9ed1-112c34e7edb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5eb1703-6e39-4bda-8e13-9e8feb86976a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd0c17e-88e0-48c0-91b1-ab7adbffd9bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da3ccbce-50bd-40eb-ae61-18a75112828b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a9029e6-e37a-4740-9c05-6fe9829062f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c0e93b4-d425-4e09-94c3-8203d63dac16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17f2e047-944a-4ed9-915d-abfb587e5270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 594d54de-a7e4-425c-8e19-e649506250ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6200e743-09f9-425a-b5b5-d8020e5abc5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 107acb3b-7ce9-4257-aafb-62f55c044ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8af9b513-36e2-43e7-8245-551c61a61d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bb2717b-5aa3-46f5-97a8-e4a357118b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 806a45e4-d74d-4ef2-9996-5ed51c397339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc6d5a53-97e1-420d-a72e-53f6923618df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5f4f455-6ff8-444c-9cc8-34541e06e2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a57131fd-5ec1-480b-8fc1-f444efa7f792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59a78c7f-03a8-4e8c-bc90-b57d034b4c16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 478ed65a-cfcb-4e2f-a039-fc8e584bb09f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1dbc324-2a01-43dd-b915-db39b9dc9b9a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_11
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/test_labels.txt

📊 Raw data loaded:
   Train: X=(301, 24), y=(301,)
   Test:  X=(76, 24), y=(76,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 292 samples, 5 features
   Test:  67 samples, 5 features
✅ Client client_11 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1847, val=0.1244 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1122, val=0.0765 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0944, val=0.0754 (↓), lr=0.001000
   • Epoch   4/100: train=0.0861, val=0.0760, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0881, val=0.0735 (↓), lr=0.001000
   • Epoch  11/100: train=0.0846, val=0.0727, patience=3/15, lr=0.001000
   📉 Epoch 20: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0824, val=0.0733, patience=13/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 1 Summary - Client client_11
   Epochs: 23/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0162
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.0250
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.2036, RMSE: 0.4512, MAE: 0.3658, R²: -1.4465

============================================================
🔄 Round 2 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2105, val=0.1690 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.1655, val=0.1281 (↓), lr=0.000500
   ✓ Epoch   3/100: train=0.1215, val=0.0921 (↓), lr=0.000500
   ✓ Epoch   4/100: train=0.0872, val=0.0850 (↓), lr=0.000500
   📉 Epoch 5: LR reduced 0.000500 → 0.000250
   • Epoch   5/100: train=0.0880, val=0.0875, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0839, val=0.0832, patience=4/15, lr=0.000250
   📉 Epoch 13: LR reduced 0.000250 → 0.000125
   📉 Epoch 21: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0836, val=0.0833, patience=14/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 2 Summary - Client client_11
   Epochs: 22/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0184
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0365
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.1994, RMSE: 0.4466, MAE: 0.3613, R²: -1.3970

============================================================
🔄 Round 3 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2057, val=0.1878 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1980, val=0.1794 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1886, val=0.1708 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1795, val=0.1628 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.1712, val=0.1556 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.1418, val=0.1314 (↓), lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   ✓ Epoch  21/100: train=0.1204, val=0.1132 (↓), lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008
   📉 Epoch 31: LR reduced 0.000008 → 0.000004
   ✓ Epoch  31/100: train=0.1120, val=0.1061 (↓), lr=0.000004
   📉 Epoch 39: LR reduced 0.000004 → 0.000002
   • Epoch  41/100: train=0.1089, val=0.1037, patience=2/15, lr=0.000002
   📉 Epoch 47: LR reduced 0.000002 → 0.000001
   • Epoch  51/100: train=0.1077, val=0.1026, patience=4/15, lr=0.000001
   • Epoch  61/100: train=0.1070, val=0.1020, patience=6/15, lr=0.000001
   • Epoch  71/100: train=0.1062, val=0.1014, patience=7/15, lr=0.000001
   • Epoch  81/100: train=0.1056, val=0.1008, patience=8/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1049, val=0.1002 (↓), lr=0.000001

============================================================
📊 Round 3 Summary - Client client_11
   Epochs: 100/100
   LR: 0.000063 → 0.000001 (6 reductions)
   Train: Loss=0.1079, RMSE=0.3285, R²=-0.2851
   Val:   Loss=0.0997, RMSE=0.3158, R²=-0.1821
============================================================


============================================================
🔄 Round 6 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2002, val=0.1563 (↓), lr=0.000001
   • Epoch   2/100: train=0.2000, val=0.1562, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1999, val=0.1561, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1997, val=0.1560, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1996, val=0.1558 (↓), lr=0.000001
   • Epoch  11/100: train=0.1986, val=0.1551, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1972, val=0.1540, patience=1/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1960, val=0.1530 (↓), lr=0.000001
   • Epoch  41/100: train=0.1948, val=0.1521, patience=4/15, lr=0.000001
   • Epoch  51/100: train=0.1937, val=0.1512, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1926, val=0.1504 (↓), lr=0.000001
   • Epoch  71/100: train=0.1915, val=0.1495, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.1905, val=0.1487, patience=6/15, lr=0.000001
   • Epoch  91/100: train=0.1894, val=0.1480, patience=2/15, lr=0.000001

============================================================
📊 Round 6 Summary - Client client_11
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1898, RMSE=0.4357, R²=-1.2726
   Val:   Loss=0.1473, RMSE=0.3837, R²=-0.7817
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.1652, RMSE: 0.4064, MAE: 0.3236, R²: -0.9850

📊 Round 6 Test Metrics:
   Loss: 0.1615, RMSE: 0.4019, MAE: 0.3197, R²: -0.9415

============================================================
🔄 Round 10 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1771, val=0.1665 (↓), lr=0.000001
   • Epoch   2/100: train=0.1770, val=0.1664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1769, val=0.1663, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1768, val=0.1662, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.1767, val=0.1661, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.1762, val=0.1655, patience=4/15, lr=0.000001
   • Epoch  21/100: train=0.1752, val=0.1646, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1743, val=0.1636 (↓), lr=0.000001
   • Epoch  41/100: train=0.1734, val=0.1627, patience=4/15, lr=0.000001
   • Epoch  51/100: train=0.1725, val=0.1618, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1716, val=0.1608 (↓), lr=0.000001
   • Epoch  71/100: train=0.1707, val=0.1599, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.1697, val=0.1590, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1688, val=0.1581 (↓), lr=0.000001

============================================================
📊 Round 10 Summary - Client client_11
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1622, RMSE=0.4027, R²=-0.8683
   Val:   Loss=0.1573, RMSE=0.3966, R²=-1.1390
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.1561, RMSE: 0.3951, MAE: 0.3138, R²: -0.8763

============================================================
🔄 Round 12 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1598, val=0.1406 (↓), lr=0.000001
   • Epoch   2/100: train=0.1597, val=0.1405, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1596, val=0.1404, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1595, val=0.1403, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.1595, val=0.1403, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.1590, val=0.1398, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.1581, val=0.1390, patience=6/15, lr=0.000001
   • Epoch  31/100: train=0.1573, val=0.1382, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.1565, val=0.1375, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.1557, val=0.1367, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1549, val=0.1360, patience=4/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1540, val=0.1352 (↓), lr=0.000001
   • Epoch  81/100: train=0.1532, val=0.1344, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.1524, val=0.1337, patience=6/15, lr=0.000001

============================================================
📊 Round 12 Summary - Client client_11
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1566, RMSE=0.3957, R²=-0.8343
   Val:   Loss=0.1330, RMSE=0.3647, R²=-0.6911
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1471, RMSE: 0.3836, MAE: 0.3043, R²: -0.7685

📊 Round 12 Test Metrics:
   Loss: 0.1418, RMSE: 0.3765, MAE: 0.2992, R²: -0.7040

============================================================
🔄 Round 18 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1038, val=0.1633 (↓), lr=0.000001
   • Epoch   2/100: train=0.1037, val=0.1632, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1037, val=0.1631, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1036, val=0.1630, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.1036, val=0.1629, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.1032, val=0.1623 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1026, val=0.1612 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1019, val=0.1602 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1013, val=0.1591 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1007, val=0.1581 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1002, val=0.1570 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.0996, val=0.1560 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.0990, val=0.1550 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.0984, val=0.1539 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_11
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0977, RMSE=0.3126, R²=-0.2272
   Val:   Loss=0.1530, RMSE=0.3912, R²=-0.6270
============================================================


============================================================
🔄 Round 21 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 21 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=-0.0512
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0008
============================================================


============================================================
🔄 Round 24 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 24 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0008
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.1250
============================================================


============================================================
🔄 Round 25 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 25 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0106
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0065
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2516, R²: 0.0027

============================================================
🔄 Round 28 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 28 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0021
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.1483
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0031

============================================================
🔄 Round 31 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 31 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0115
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0109
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2518, R²: 0.0037

📊 Round 31 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2518, R²: 0.0040

============================================================
🔄 Round 35 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 35 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0091
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0107
============================================================


============================================================
🔄 Round 36 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 36 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0016
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0337
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2518, R²: 0.0043

============================================================
🔄 Round 37 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 37 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0115
   Val:   Loss=0.0921, RMSE=0.3034, R²=0.0027
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2519, R²: 0.0045

📊 Round 37 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2519, R²: 0.0046

============================================================
🔄 Round 44 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 44 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0112
   Val:   Loss=0.0930, RMSE=0.3050, R²=0.0016
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2519, R²: 0.0047

============================================================
🔄 Round 45 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 45 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0116
   Val:   Loss=0.0689, RMSE=0.2625, R²=-0.0183
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2519, R²: 0.0047

============================================================
🔄 Round 47 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.1029 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.1029, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.1029, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.1029, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.1029, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.1029, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1029)

============================================================
📊 Round 47 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0040
   Val:   Loss=0.1029, RMSE=0.3207, R²=-0.0082
============================================================


============================================================
🔄 Round 49 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 49 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0075
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0018
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2520, R²: 0.0048

============================================================
🔄 Round 50 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 50 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0017
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0274
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2520, R²: 0.0048

📊 Round 50 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2520, R²: 0.0048

============================================================
🔄 Round 55 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 55 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0053
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0034
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2520, R²: 0.0048

============================================================
🔄 Round 56 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0977 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0977, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0977, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0977, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0977, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0976, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0977)

============================================================
📊 Round 56 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0021
   Val:   Loss=0.0977, RMSE=0.3125, R²=-0.0090
============================================================


============================================================
🔄 Round 58 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 58 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0078
   Val:   Loss=0.0929, RMSE=0.3047, R²=0.0097
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2520, R²: 0.0048

============================================================
🔄 Round 60 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 60 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0093
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0046
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2520, R²: 0.0048

============================================================
🔄 Round 63 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 63 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0050
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0022
============================================================


============================================================
🔄 Round 66 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 66 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0122
   Val:   Loss=0.0678, RMSE=0.2603, R²=-0.0144
============================================================


============================================================
🔄 Round 67 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 67 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0095
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0186
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2520, R²: 0.0049

📊 Round 67 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2520, R²: 0.0049

📊 Round 67 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2520, R²: 0.0050

============================================================
🔄 Round 71 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 71 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0128
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0141
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2520, R²: 0.0050

📊 Round 71 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2520, R²: 0.0050

============================================================
🔄 Round 74 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 74 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0008
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0132
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2521, R²: 0.0051

📊 Round 74 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2521, R²: 0.0051

============================================================
🔄 Round 77 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 77 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0039
   Val:   Loss=0.0918, RMSE=0.3031, R²=0.0000
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2521, R²: 0.0051

============================================================
🔄 Round 79 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 79 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0001
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0375
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2521, R²: 0.0051

📊 Round 79 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2521, R²: 0.0051

📊 Round 79 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2521, R²: 0.0051

📊 Round 79 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2521, R²: 0.0051

============================================================
🔄 Round 84 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 84 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0002
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0625
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2521, R²: 0.0051

============================================================
🔄 Round 86 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.1025 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.1025, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.1025, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.1025, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.1025, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.1025, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1025)

============================================================
📊 Round 86 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0056
   Val:   Loss=0.1025, RMSE=0.3202, R²=-0.0333
============================================================


============================================================
🔄 Round 87 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 87 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0027
   Val:   Loss=0.0920, RMSE=0.3032, R²=-0.0033
============================================================


============================================================
🔄 Round 89 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.1048 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.1048, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.1048, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.1048, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.1048, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.1049, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1048)

============================================================
📊 Round 89 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0104
   Val:   Loss=0.1048, RMSE=0.3237, R²=-0.0087
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2521, R²: 0.0051

============================================================
🔄 Round 90 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 90 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0009
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0130
============================================================


============================================================
🔄 Round 91 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 91 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0036
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0013
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2521, R²: 0.0052

============================================================
🔄 Round 99 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 99 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0117
   Val:   Loss=0.0736, RMSE=0.2714, R²=-0.0446
============================================================


============================================================
🔄 Round 100 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 100 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0019
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0047
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2521, R²: 0.0052

============================================================
🔄 Round 104 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 104 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0028
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0419
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

📊 Round 104 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

============================================================
🔄 Round 108 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 108 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0008
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0144
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

📊 Round 108 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

📊 Round 108 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

📊 Round 108 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

============================================================
🔄 Round 113 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 113 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0031
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0013
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

============================================================
🔄 Round 114 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 114 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0003
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0427
============================================================


============================================================
🔄 Round 115 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0920, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0920, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 115 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0030
   Val:   Loss=0.0692, RMSE=0.2630, R²=-0.0107
============================================================


============================================================
🔄 Round 118 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 118 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0036
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0029
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

📊 Round 118 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

============================================================
🔄 Round 120 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 120 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0118
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0718
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

============================================================
🔄 Round 121 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 121 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0035
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0371
============================================================


============================================================
🔄 Round 123 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0985, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0985, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0985, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0985)

============================================================
📊 Round 123 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0080
   Val:   Loss=0.0985, RMSE=0.3139, R²=0.0124
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

============================================================
🔄 Round 126 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.1088 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.1088, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.1087, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.1087, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.1087, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.1087, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1088)

============================================================
📊 Round 126 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0032
   Val:   Loss=0.1088, RMSE=0.3298, R²=-0.0264
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

📊 Round 126 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

📊 Round 126 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

📊 Round 126 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

📊 Round 126 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

============================================================
🔄 Round 135 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 135 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0008
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0195
============================================================


============================================================
🔄 Round 137 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 137 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0026
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0278
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

============================================================
🔄 Round 140 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 140 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0011
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0397
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0052

============================================================
🔄 Round 143 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0976, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 143 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0008
   Val:   Loss=0.0975, RMSE=0.3123, R²=-0.0126
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

============================================================
🔄 Round 147 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 147 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0073
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0152
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

📊 Round 147 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

============================================================
🔄 Round 152 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 152 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0042
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0041
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

📊 Round 152 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

============================================================
🔄 Round 155 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 155 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0031
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0490
============================================================


============================================================
🔄 Round 157 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 157 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0010
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0147
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

============================================================
🔄 Round 159 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 159 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0034
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0341
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

📊 Round 159 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

📊 Round 159 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

📊 Round 159 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

============================================================
🔄 Round 167 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 167 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0041
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0120
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

📊 Round 167 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

📊 Round 167 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

📊 Round 167 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

============================================================
🔄 Round 173 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 173 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0068
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0024
============================================================


============================================================
🔄 Round 175 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0987)

============================================================
📊 Round 175 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0000
   Val:   Loss=0.0987, RMSE=0.3141, R²=-0.0186
============================================================


============================================================
🔄 Round 176 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 176 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0027
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0007
============================================================


============================================================
🔄 Round 177 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 177 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0014
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0306
============================================================


============================================================
🔄 Round 178 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 178 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0042
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0124
============================================================


============================================================
🔄 Round 182 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 182 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0076
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0033
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2523, R²: 0.0051

============================================================
🔄 Round 183 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 183 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0004
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0249
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

📊 Round 183 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2523, R²: 0.0051

============================================================
🔄 Round 186 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 186 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0040
   Val:   Loss=0.0900, RMSE=0.3001, R²=0.0034
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

============================================================
🔄 Round 187 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 187 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0008
   Val:   Loss=0.0955, RMSE=0.3091, R²=-0.0339
============================================================


============================================================
🔄 Round 188 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 188 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0014
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0690
============================================================


============================================================
🔄 Round 190 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 190 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0014
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0043
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2522, R²: 0.0051

============================================================
🔄 Round 191 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 191 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0069
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0083
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2523, R²: 0.0051

============================================================
🔄 Round 193 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 193 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0033
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0243
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2523, R²: 0.0051

============================================================
🔄 Round 196 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 196 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0011
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0077
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2523, R²: 0.0050

============================================================
🔄 Round 197 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 197 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0071
   Val:   Loss=0.0717, RMSE=0.2677, R²=-0.0006
============================================================


============================================================
🔄 Round 199 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 199 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0120
   Val:   Loss=0.0943, RMSE=0.3070, R²=-0.0471
============================================================


============================================================
🔄 Round 200 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 200 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0012
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0531
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2523, R²: 0.0050

============================================================
🔄 Round 201 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 201 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0004
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0093
============================================================


============================================================
🔄 Round 202 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 202 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0032
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0029
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2523, R²: 0.0050

📊 Round 202 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2523, R²: 0.0050

📊 Round 202 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2523, R²: 0.0050

============================================================
🔄 Round 210 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 210 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0065
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0139
============================================================


❌ Client client_11 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
