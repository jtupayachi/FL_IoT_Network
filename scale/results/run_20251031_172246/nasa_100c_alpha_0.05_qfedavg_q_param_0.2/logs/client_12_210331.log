[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 041ee824-a233-4b4c-b39d-dc9752eff03c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c627a6c-ce3c-48ae-b841-6d0eb504eb0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d72ce06-6f6a-4a12-abb9-b75ec9ccd0b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47da98fb-5ec1-4566-9872-f2f699165651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7e0cddc-4006-44b9-a68a-a12c6d5cf995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83c8941e-63c4-4611-8310-58343d1163de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6ce7067-f9b7-4e5b-ba51-f22817612fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffd22c37-d96d-4bbd-9804-501dd97f497b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9644c709-38cd-4e68-ad77-777fc9e5efa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8486560-3239-457e-affe-78c2ac9c1557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3ccba13-f078-41f6-a62f-ed95e154341b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbd55230-93d9-4ec3-add3-47080ed31ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9a88031-b74b-4907-9622-3f627811d54c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71aa102f-f372-448e-b013-8309f0e07ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01af4800-da7e-47d4-ac14-f16dddc6a1c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5883e6cd-8a8f-4fe3-abea-c50b75382fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44246ba3-d82c-4235-8a51-ba57fbe26195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46e27961-5796-4ff0-81c7-8fe44abe6772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e08b01cb-7805-4d03-aea7-559c013c13ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2f2f666-e956-431d-96ca-014c6e195e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7599ee57-5168-4065-96eb-3ff90a6da2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24cfe219-0b65-4b59-8428-a5d77e9b1ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cab1dfd2-d3ce-49e8-a910-a31df557f4c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1c0ea5a-0a70-4a17-b2fa-5f6e6ffcc367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5540cea-0c62-4a6e-a9cd-c2f4dc63bdef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb73873b-3422-4d65-999e-2c7d4305cf1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b753af8-27f9-4fcc-9085-6d32c94f9691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aad95565-ad39-4dda-8c8e-84f4f9264dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 697ad9c5-4308-42b9-b64b-c4f66d2375a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b820793-8b9b-4a3f-b5fe-0bc388269863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a646478-e21f-4258-8636-a8ca16dab9e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef89b358-eb0f-4aeb-a4ca-e7125573eb27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76ffa332-12a4-4711-8fa3-4f07e53c53db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 892f81ab-13c7-4351-ba34-9b415f127387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 545694e1-f79d-4843-a1ac-c346c384ba39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18afdc59-b439-4990-bbdc-fec13b451dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77cbb3b5-fe96-4819-a2b8-46a11775cae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d581ae50-6dfc-4057-a392-91fa43dc7746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52a16894-7975-48c5-8574-945e8902e120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 086e73ab-8505-4111-a8f2-6824842b0539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71c7cee2-7275-4df9-8496-abc9ad3ab8b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee21d763-d770-4e64-b4e6-414409d6d766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b3bd274-2c12-477e-8306-7a6e59e0224b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 911e1c1a-44ad-437d-85db-5ed98e519206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52499e71-3af1-4673-b636-1d7c1a0ecc63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19fb8530-3191-4c67-9406-5a5fcf01ebf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90521582-cfc8-454c-972a-f256d1eb8021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aca4ee79-fda2-485b-8228-76f45a517ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ef29b82-f417-4a62-a4ec-412d817940f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db3936e6-4663-4fe6-852b-6f5157478385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81c741eb-6524-4c46-8255-bd1afc4488e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ab895bd-4ddd-4054-9c6d-4b35ee0debe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83e30671-2824-4a92-8a09-4ebd58372586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3e80954-eb68-4936-b041-f39b6dc5b9e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22672c6e-5a50-4305-a89b-73606a2e65d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 455e6826-10a1-4a57-9380-06c6742322d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b903031b-61e9-4c0d-97d7-12a4f7eaef14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0727cc9d-4c24-4cdc-881e-e6fe805590c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17b8f0c7-d069-4f34-91d5-6941ce238a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9190ccc-e40e-4fd6-9181-a98731bebb99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29748668-0a6d-46ab-a6ff-cf1c00db00f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 742ff6bb-665d-44a4-aa36-611f59507fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a56a53b9-a90a-4bff-a791-67fbe4bfeef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce6d8e07-ac02-4c95-9bcd-867097a17dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14997a47-a1b8-4179-bd74-37d8ff100dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bbe14df-c76b-46b7-b491-3bc98138b31d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4776e0d6-b8ca-499b-8455-35049f8eb02b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46d8d6b9-b129-4bfb-9eba-f103e4305b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc060921-0ce7-4fad-97bb-e57f4f65ea1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af5455cd-4c06-47e4-b268-0b201ceb5272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd8e2a55-bf5a-40f1-83f0-71b52f6e5d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd798a7-7f52-4376-b769-50ee7ba560b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2da51bf4-7607-42a8-8413-d2fe6c39bb62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e58abaa9-1106-4e98-bf45-59acc9ec61c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf26706b-9f08-493b-89dd-7c0bdb263c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3202637-ffae-4b0f-9546-ac4c07990b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68f7b574-8268-4120-ae31-0d14d2cead12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1af970f3-a3b4-4f01-9f64-c144f8230954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d63e3b49-01c9-4f45-aa66-0ef77365c6c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf101616-c8d6-4973-916c-8c9906fae7da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c89e1d9-6ffe-4f20-9ec0-7737abc83475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecd6abf2-c245-4df1-87fb-04cd12d2bf19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f090cfe4-d438-45d8-8a8d-b02dd0c76f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 576dbea9-195d-4f74-9a9b-2f400365d74f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9049745-70b9-42ed-a3e5-685dbacb5258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f29c3f84-d83f-463b-8ec6-8aa9936632cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cc32bfa-809a-42c9-ae7a-2506191461aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f26307d5-bc0f-4d40-b0e6-1da870662b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ae4bdec-a59f-4fdf-b60a-e84c04886677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 592477a2-2964-434f-a1ba-ad434491eb99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5969de64-ef22-4d69-b27a-87178d52419d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d7066a9-9c79-4a04-be30-244cbed5dbaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dfcfdb2-5c14-4b83-a589-ff6f703ca745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b4f5f0-70b4-42dc-b3e1-bba279baf184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0198540-d82b-42dc-b91b-db97f858d245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3286ec11-5612-41b1-a1b0-a8d79eae6c59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30e3c58b-fd88-44d9-8334-42b0c883f2f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99fd762e-b890-41df-8dd1-d752ecc87ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc31b320-b653-4acf-97f2-e85f7e7b475b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48c4d679-6150-4147-9fb1-9b5ea98d6e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45942d29-e356-4730-b38f-c79f93492e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08371106-d1cf-4865-a38f-ee3a19ed38ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7196230a-9da2-491b-a04b-b62c038039aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c60ad3a1-9ffb-416d-8b3d-34fb8691965d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9015ebd-f5ea-4b03-8a97-4558c1987eb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c17579a-ab7a-47a2-bdd4-4d8eba2fff5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 274649f3-132d-41f4-84b7-621f61021274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56602346-2696-4597-8a5a-64fb55dd438f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f3c8dc6-13c3-433b-bc75-83ac3b493d39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29fa7d6d-f8f0-45e5-8d74-b14bc6bb452b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69385955-803a-466d-93ef-a09acbc9c3ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3e5bbab-1f86-476e-9bf2-3b70967be46b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36a60384-47da-4f28-9392-5efdd95796b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c18ce96-3994-4e78-9aaf-0d38c60dbd28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a815871-355d-487c-948d-41277194bc34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e68526f-4864-4e17-b974-d5f688210437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b67d0d9d-d30e-4f40-a812-33e4524a7c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06d8f1c9-3645-49bb-a764-36543eb45d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bee377a4-8df2-44eb-9ba3-19a867363418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 835bfb55-0a5b-4616-bb87-adf2abfd0a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ebf6f9b-e5b7-45c6-a69a-af8a4d269b4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b14370a7-39b1-45c2-bd39-6fbfdf1454b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a25beda-dc83-468d-913b-0cb3c5964c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ff6f2ab-bd21-475b-87b6-aaa3ab406d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fa191d9-7170-41b0-8114-c38c135eb9ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 088f84d6-47f1-43c6-907b-7ccdaf6492f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b3c8164-2835-43bf-bc6f-ff99297b9439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 637e685a-3ffb-4179-afb7-271081042017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 470b19fb-93c8-485c-957e-5ee185a22be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dccf3bce-d101-4950-acfc-979349102509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aebd99a-47f3-46bd-85f2-04a4cf327613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00ae38f2-3781-43b1-9aca-1408978f873b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e196794-95be-4e21-8f31-fb18ebafced2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17af73e7-cc2e-4d41-84ca-8cf54cec2e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3f6093c-50e4-4f09-8f0d-afb58ddc6e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01c577d9-6add-444b-bedf-d138a9619517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e81cd0d1-30c9-41d7-b2e0-53d244d9e291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d271690b-ecd2-4fd6-91ba-ef14bb31b000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c55564a-c4f6-436b-997f-2f874f5c1332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 728cfefc-0e67-4fcf-9e49-d307888fdb51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1135aa9-91b2-4346-9a54-97b4385f769e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e7ecbf2-d3e7-448b-818d-262570836d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50e65e81-c269-4777-befe-1129d86d9ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa63b744-291d-4c3f-89eb-85a073ff80d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa3ecd95-391d-41c4-bdfa-4c78f2e15e90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57d888af-16f2-45e8-81eb-72d7b01ae032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d47eba9-be24-406f-882c-93032e32ba07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dc78f1f-25a2-4ede-a4b0-275afb08a122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0c901cd-8718-438f-adac-ab851f2fc984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f654952-065d-4159-9434-a244048e77ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b5a466-0895-4e0f-9aae-7663f3f8d0c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93d6a36f-a40c-414d-b45c-0078a70a0ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b08b90e-94d2-4d6b-aeb4-2b783d0d46fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82d0c264-6f90-4113-bc1c-16a597b8d49e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd532cd2-a9fd-4b5b-80cb-0c5f91fd2de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d76a62b-a116-4ac1-b967-c475ee4ba200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e042519-32d5-4245-ab64-970b7a66e197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afd22f43-05d2-4299-86a7-334ee425c314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83402813-6ef2-40ed-89f1-7288f2558e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eef224fd-187e-4150-ba11-3e6c72f81ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddfded04-d561-4355-9cce-47fb02b82ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14abf041-6c30-43a0-9089-6a7d24595d64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c6c663e-ef32-4112-a70b-ba6da281a02e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eb5f230-a8ec-4621-bb08-dbd8aef8ab6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8a37a22-11e8-4876-aafc-7793a0af3d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0139c23c-0c9d-494f-8850-257a3447f1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d038bc69-77ff-4f0c-9c11-99922c50ccf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 316d4a54-a6ab-46bf-a32b-76e1077f89a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b128d007-4531-4410-bf43-e1fde909261f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3b8e7fd-1615-4b93-ae78-ad76c28a277a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d96f575-2f35-452c-8f0f-d01e48fd93af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58a2928d-c9ca-43bf-960d-40b8324c763b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 102fc985-0bf9-4652-8949-b7fff644b74b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d88fc183-fec3-4478-92ea-4f06a2999511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ba8a791-ba98-4c87-9a1a-6d046513480e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 094ea985-a484-4502-9449-89a1fa1ab59c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99a93904-1ce5-4169-8ec3-161400164fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 454ffa48-3256-45d5-9ad5-6cfbc54acc40
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_12
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/test_labels.txt

📊 Raw data loaded:
   Train: X=(1530, 24), y=(1530,)
   Test:  X=(383, 24), y=(383,)

⚠️  Limiting training data: 1530 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  374 samples, 5 features
✅ Client client_12 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1315, val=0.0792 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0855, val=0.0784 (↓), lr=0.001000
   • Epoch   3/100: train=0.0858, val=0.0791, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0861, val=0.0779 (↓), lr=0.001000
   • Epoch   5/100: train=0.0854, val=0.0779, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   ✓ Epoch  11/100: train=0.0842, val=0.0771 (↓), lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0829, val=0.0772, patience=10/15, lr=0.000250
   📉 Epoch 26: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 1 Summary - Client client_12
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0182
   Val:   Loss=0.0771, RMSE=0.2778, R²=-0.0134
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.2189, RMSE: 0.4679, MAE: 0.3877, R²: -1.6546

============================================================
🔄 Round 4 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1762, val=0.1544 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.1331, val=0.1224 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.0983, val=0.1014 (↓), lr=0.000125
   • Epoch   4/100: train=0.0799, val=0.1031, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0793, val=0.1016, patience=2/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0788, val=0.1014, patience=8/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1014)

============================================================
📊 Round 4 Summary - Client client_12
   Epochs: 18/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0722
   Val:   Loss=0.1014, RMSE=0.3185, R²=-0.0232
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.1999, RMSE: 0.4471, MAE: 0.3690, R²: -1.4235

============================================================
🔄 Round 6 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1796, val=0.1712 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.1664, val=0.1586 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.1542, val=0.1480 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.1440, val=0.1389 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.1349, val=0.1305 (↓), lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   ✓ Epoch  11/100: train=0.1056, val=0.1056 (↓), lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008
   ✓ Epoch  21/100: train=0.0883, val=0.0910 (↓), lr=0.000008
   📉 Epoch 22: LR reduced 0.000008 → 0.000004
   📉 Epoch 30: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0848, val=0.0883, patience=2/15, lr=0.000002
   📉 Epoch 38: LR reduced 0.000002 → 0.000001
   • Epoch  41/100: train=0.0839, val=0.0877, patience=7/15, lr=0.000001
   • Epoch  51/100: train=0.0835, val=0.0874, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 6 Summary - Client client_12
   Epochs: 60/100 (early stopped)
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0147
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0292
============================================================


============================================================
🔄 Round 7 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1722, val=0.1830 (↓), lr=0.000001
   • Epoch   2/100: train=0.1718, val=0.1825, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1713, val=0.1821 (↓), lr=0.000001
   • Epoch   4/100: train=0.1709, val=0.1816, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1705, val=0.1812 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1684, val=0.1790 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1655, val=0.1758 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1629, val=0.1731 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1604, val=0.1705 (↓), lr=0.000001
   • Epoch  51/100: train=0.1581, val=0.1680, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1559, val=0.1656, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1538, val=0.1633 (↓), lr=0.000001
   • Epoch  81/100: train=0.1517, val=0.1611, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1496, val=0.1588, patience=2/15, lr=0.000001

============================================================
📊 Round 7 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1477, RMSE=0.3843, R²=-0.7701
   Val:   Loss=0.1568, RMSE=0.3960, R²=-0.9294
============================================================


============================================================
🔄 Round 8 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1675, val=0.1735 (↓), lr=0.000001
   • Epoch   2/100: train=0.1672, val=0.1733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1670, val=0.1730, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1667, val=0.1728 (↓), lr=0.000001
   • Epoch   5/100: train=0.1665, val=0.1725, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1651, val=0.1711, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1628, val=0.1688, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1606, val=0.1665 (↓), lr=0.000001
   • Epoch  41/100: train=0.1584, val=0.1643, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1563, val=0.1621, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1542, val=0.1600 (↓), lr=0.000001
   • Epoch  71/100: train=0.1521, val=0.1578, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1500, val=0.1557, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1479, val=0.1536 (↓), lr=0.000001

============================================================
📊 Round 8 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1454, RMSE=0.3813, R²=-0.7601
   Val:   Loss=0.1517, RMSE=0.3895, R²=-0.7878
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1778, RMSE: 0.4216, MAE: 0.3469, R²: -1.1553

============================================================
🔄 Round 10 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1627, val=0.1581 (↓), lr=0.000001
   • Epoch   2/100: train=0.1624, val=0.1579, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1622, val=0.1577, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1620, val=0.1575 (↓), lr=0.000001
   • Epoch   5/100: train=0.1618, val=0.1572, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1604, val=0.1560, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1582, val=0.1539, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1561, val=0.1519 (↓), lr=0.000001
   • Epoch  41/100: train=0.1540, val=0.1499, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1518, val=0.1479, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1497, val=0.1459 (↓), lr=0.000001
   • Epoch  71/100: train=0.1476, val=0.1439, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1456, val=0.1419, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1435, val=0.1400 (↓), lr=0.000001

============================================================
📊 Round 10 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1415, RMSE=0.3762, R²=-0.7215
   Val:   Loss=0.1382, RMSE=0.3718, R²=-0.5985
============================================================


============================================================
🔄 Round 11 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1548, val=0.1629 (↓), lr=0.000001
   • Epoch   2/100: train=0.1546, val=0.1627, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1544, val=0.1625, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1542, val=0.1623 (↓), lr=0.000001
   • Epoch   5/100: train=0.1539, val=0.1620, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1527, val=0.1607, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1506, val=0.1585, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1486, val=0.1563 (↓), lr=0.000001
   • Epoch  41/100: train=0.1465, val=0.1542, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1445, val=0.1521, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1425, val=0.1499 (↓), lr=0.000001
   • Epoch  71/100: train=0.1405, val=0.1478, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1385, val=0.1457, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1365, val=0.1436 (↓), lr=0.000001

============================================================
📊 Round 11 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1345, RMSE=0.3667, R²=-0.6291
   Val:   Loss=0.1417, RMSE=0.3764, R²=-0.6648
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1330, RMSE: 0.3647, MAE: 0.3020, R²: -0.6125

============================================================
🔄 Round 17 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1246, val=0.1204 (↓), lr=0.000001
   • Epoch   2/100: train=0.1244, val=0.1202, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1242, val=0.1200, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1240, val=0.1198 (↓), lr=0.000001
   • Epoch   5/100: train=0.1238, val=0.1196, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1226, val=0.1184, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1206, val=0.1165, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1187, val=0.1146 (↓), lr=0.000001
   • Epoch  41/100: train=0.1167, val=0.1127, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1148, val=0.1108, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1129, val=0.1090 (↓), lr=0.000001
   • Epoch  71/100: train=0.1110, val=0.1072, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1091, val=0.1054, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1073, val=0.1036 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1056, RMSE=0.3249, R²=-0.2642
   Val:   Loss=0.1020, RMSE=0.3194, R²=-0.2537
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1177, RMSE: 0.3431, MAE: 0.2867, R²: -0.4276

============================================================
🔄 Round 18 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1128, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.1126, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1124, val=0.0981, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1122, val=0.0980, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1120, val=0.0978 (↓), lr=0.000001
   • Epoch  11/100: train=0.1109, val=0.0969, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1091, val=0.0954 (↓), lr=0.000001
   • Epoch  31/100: train=0.1074, val=0.0939, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1057, val=0.0925 (↓), lr=0.000001
   • Epoch  51/100: train=0.1040, val=0.0911, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1024, val=0.0898 (↓), lr=0.000001
   • Epoch  71/100: train=0.1008, val=0.0885, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0993, val=0.0873, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.0978, val=0.0862, patience=2/15, lr=0.000001

============================================================
📊 Round 18 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0966, RMSE=0.3109, R²=-0.1471
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0936
============================================================


============================================================
🔄 Round 19 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0972, val=0.1052 (↓), lr=0.000001
   • Epoch   2/100: train=0.0971, val=0.1050, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0969, val=0.1049, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0968, val=0.1047, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0967, val=0.1046 (↓), lr=0.000001
   • Epoch  11/100: train=0.0959, val=0.1036, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0946, val=0.1021 (↓), lr=0.000001
   • Epoch  31/100: train=0.0934, val=0.1006, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0922, val=0.0991 (↓), lr=0.000001
   • Epoch  51/100: train=0.0911, val=0.0978, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0900, val=0.0965 (↓), lr=0.000001
   • Epoch  71/100: train=0.0891, val=0.0952, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0882, val=0.0941, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0873, val=0.0930, patience=1/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0463
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0935
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0937, RMSE: 0.3061, MAE: 0.2622, R²: -0.1360

📊 Round 19 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2542, R²: -0.0530

📊 Round 19 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2512, R²: -0.0239

============================================================
🔄 Round 23 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 23 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0049
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0061
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2508, R²: -0.0205

============================================================
🔄 Round 25 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 25 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0011
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0142
============================================================


============================================================
🔄 Round 30 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 30 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0027
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0359
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2498, R²: -0.0123

📊 Round 30 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2497, R²: -0.0117

============================================================
🔄 Round 35 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 35 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0010
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0056
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0099

============================================================
🔄 Round 38 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 38 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0019
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0052
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0097

📊 Round 38 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2494, R²: -0.0094

============================================================
🔄 Round 40 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 40 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0014
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0049
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2494, R²: -0.0090

============================================================
🔄 Round 43 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 43 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0024
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0007
============================================================


============================================================
🔄 Round 44 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 44 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0001
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0045
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0086

============================================================
🔄 Round 47 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 47 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0006
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0032
============================================================


============================================================
🔄 Round 48 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 48 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0004
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0047
============================================================


============================================================
🔄 Round 49 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 49 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0017
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0056
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0080

============================================================
🔄 Round 51 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 51 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0007
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0030
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0079

============================================================
🔄 Round 52 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 52 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0002
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0014
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0078

📊 Round 52 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0079

📊 Round 52 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0080

============================================================
🔄 Round 55 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 55 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0010
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0017
============================================================


============================================================
🔄 Round 56 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 56 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0000
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0003
============================================================


============================================================
🔄 Round 58 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 58 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0004
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0003
============================================================


============================================================
🔄 Round 59 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 59 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0024
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0100
============================================================


============================================================
🔄 Round 60 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 60 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0008
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0023
============================================================


============================================================
🔄 Round 61 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 61 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0010
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0234
============================================================


============================================================
🔄 Round 62 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 62 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0000
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0018
============================================================


============================================================
🔄 Round 64 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 64 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0019
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0059
============================================================


============================================================
🔄 Round 65 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 65 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0012
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0132
============================================================


============================================================
🔄 Round 67 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 67 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0025
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0112
============================================================


============================================================
🔄 Round 69 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 69 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0027
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0098
============================================================


============================================================
🔄 Round 70 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 70 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0002
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0012
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0069

📊 Round 70 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0067

============================================================
🔄 Round 74 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 74 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0025
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0032
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0065

📊 Round 74 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0064

============================================================
🔄 Round 78 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 78 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0013
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0034
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0062

============================================================
🔄 Round 80 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 80 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0007
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0035
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0061

📊 Round 80 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0060

📊 Round 80 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0061

============================================================
🔄 Round 87 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 87 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0009
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0047
============================================================


============================================================
🔄 Round 88 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 88 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0001
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0017
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0060

============================================================
🔄 Round 89 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 89 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0011
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0065
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0059

============================================================
🔄 Round 91 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 91 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0010
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0030
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2489, R²: -0.0056

============================================================
🔄 Round 94 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 94 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0005
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0036
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2489, R²: -0.0054

📊 Round 94 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2489, R²: -0.0055

============================================================
🔄 Round 98 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 98 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0025
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0084
============================================================


============================================================
🔄 Round 99 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 99 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0012
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0064
============================================================


============================================================
🔄 Round 100 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 100 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0013
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0038
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2489, R²: -0.0054

📊 Round 100 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2489, R²: -0.0053

============================================================
🔄 Round 102 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 102 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0007
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0075
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2489, R²: -0.0052

📊 Round 102 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2489, R²: -0.0052

============================================================
🔄 Round 104 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 104 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0016
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0105
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2489, R²: -0.0051

============================================================
🔄 Round 105 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 105 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0008
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0057
============================================================


============================================================
🔄 Round 106 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 106 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0016
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0120
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2488, R²: -0.0050

============================================================
🔄 Round 108 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 108 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0005
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0255
============================================================


============================================================
🔄 Round 111 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 111 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0004
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0009
============================================================


============================================================
🔄 Round 113 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 113 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0004
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0027
============================================================


============================================================
🔄 Round 115 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 115 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0017
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0061
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2488, R²: -0.0048

📊 Round 115 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2488, R²: -0.0049

📊 Round 115 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2488, R²: -0.0047

============================================================
🔄 Round 123 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 123 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0012
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0069
============================================================


============================================================
🔄 Round 124 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 124 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0014
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0343
============================================================


============================================================
🔄 Round 127 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 127 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0016
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0057
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2488, R²: -0.0046

📊 Round 127 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2488, R²: -0.0046

📊 Round 127 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2488, R²: -0.0045

============================================================
🔄 Round 131 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 131 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0005
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0019
============================================================


============================================================
🔄 Round 133 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 133 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0011
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0015
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0044

📊 Round 133 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0043

📊 Round 133 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0042

============================================================
🔄 Round 138 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 138 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0000
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0028
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0042

============================================================
🔄 Round 139 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 139 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0023
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0088
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0042

📊 Round 139 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2488, R²: -0.0044

============================================================
🔄 Round 145 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 145 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0007
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0017
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2488, R²: -0.0046

============================================================
🔄 Round 147 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 147 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0017
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0096
============================================================


============================================================
🔄 Round 149 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 149 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0030
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0079
============================================================


============================================================
🔄 Round 150 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 150 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0006
   Val:   Loss=0.0742, RMSE=0.2725, R²=0.0062
============================================================


============================================================
🔄 Round 152 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 152 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0020
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0111
============================================================


============================================================
🔄 Round 153 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 153 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0002
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0023
============================================================


============================================================
🔄 Round 154 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 154 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0000
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0029
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2488, R²: -0.0046

📊 Round 154 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2488, R²: -0.0045

============================================================
🔄 Round 156 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 156 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0019
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0051
============================================================


============================================================
🔄 Round 157 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 157 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0019
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0030
============================================================


============================================================
🔄 Round 158 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.1015 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.1015, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.1015, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.1015, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.1015, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.1016, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1015)

============================================================
📊 Round 158 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0028
   Val:   Loss=0.1015, RMSE=0.3186, R²=-0.0105
============================================================


============================================================
🔄 Round 159 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 159 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0008
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0134
============================================================


============================================================
🔄 Round 160 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 160 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0007
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0043
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0043

============================================================
🔄 Round 161 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 161 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0029
   Val:   Loss=0.0960, RMSE=0.3098, R²=-0.0135
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0043

📊 Round 161 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0042

📊 Round 161 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0041

📊 Round 161 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0040

============================================================
🔄 Round 170 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 170 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0013
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0048
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0039

============================================================
🔄 Round 171 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 171 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0019
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0168
============================================================


============================================================
🔄 Round 172 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 172 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0005
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0058
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2487, R²: -0.0039

============================================================
🔄 Round 173 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 173 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0016
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0035
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2487, R²: -0.0038

============================================================
🔄 Round 175 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 175 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0008
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0032
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2487, R²: -0.0039

============================================================
🔄 Round 176 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 176 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0015
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0030
============================================================


============================================================
🔄 Round 177 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 177 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0009
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0049
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0040

============================================================
🔄 Round 178 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 178 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0015
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0049
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2487, R²: -0.0039

============================================================
🔄 Round 180 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 180 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0001
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0014
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0039

📊 Round 180 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2487, R²: -0.0038

============================================================
🔄 Round 183 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 183 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0015
   Val:   Loss=0.0963, RMSE=0.3104, R²=-0.0227
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0040

📊 Round 183 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2487, R²: -0.0038

============================================================
🔄 Round 186 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 186 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0014
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0032
============================================================


============================================================
🔄 Round 187 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 187 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0010
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0067
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0041

============================================================
🔄 Round 188 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 188 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0008
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0143
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0040

============================================================
🔄 Round 192 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 192 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0012
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0001
============================================================


============================================================
🔄 Round 194 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 194 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0008
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0035
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2487, R²: -0.0037

📊 Round 194 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2487, R²: -0.0039

============================================================
🔄 Round 198 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 198 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0007
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0009
============================================================


============================================================
🔄 Round 199 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 199 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0007
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0051
============================================================


============================================================
🔄 Round 200 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 200 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0002
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0023
============================================================


============================================================
🔄 Round 201 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 201 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0014
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0033
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2487, R²: -0.0037

📊 Round 201 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2487, R²: -0.0039

============================================================
🔄 Round 205 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 205 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0019
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0138
============================================================


============================================================
🔄 Round 206 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 206 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0006
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0267
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2487, R²: -0.0038

============================================================
🔄 Round 207 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 207 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0016
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0052
============================================================


============================================================
🔄 Round 209 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 209 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0004
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0128
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2487, R²: -0.0038

============================================================
🔄 Round 210 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 210 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0014
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0062
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2487, R²: -0.0038

============================================================
🔄 Round 211 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 211 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0017
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0064
============================================================


❌ Client client_12 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
