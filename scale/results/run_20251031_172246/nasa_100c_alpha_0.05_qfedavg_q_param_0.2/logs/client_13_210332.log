[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f7cb5b0-469a-480f-bc83-8e02fae12985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38bd0ecc-1b9c-493d-8cfa-c514fe833a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc942ea-74ab-4a6b-8517-23ab33a91c1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0354f6cc-6fe4-463c-9451-9fbd8e96adde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0647b6dc-9ad8-400d-83b3-54aa833bff4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb182d2d-b874-4f20-b589-1e3f841e78ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df50e8a8-196e-4b28-bd8f-c6a661aec39b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a3df27b-404d-4acb-92ee-8363d574d4d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfad0d32-de54-4da4-b2ed-d993540a40ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d671c53b-38d3-466a-9b58-456aa3209145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3cbc3da-7f47-4949-8bb6-3c477bf99aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3691f7dd-ed85-4655-b43a-75a2fc7e1a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07770653-ea90-4718-b702-f9d6ae9761cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f352e1d-a7b1-4ce7-bfd6-3dbdb2e86680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36390afd-452a-4a78-bd30-5c40a18facac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75a544f6-217c-49f3-a4ea-01c63dee03b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5faeb957-1d23-4278-89a0-bfc0bc4f0843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e366c9a-0004-4cc8-b140-4fccf3015bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20aa9918-cb79-482c-9789-028af90eec19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67e91e43-4944-4ee0-ad58-748281627f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 688d59a5-0cce-4f38-854b-98ad878426bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edf59fa2-199b-451b-b834-a6b3cfec3067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ac30218-68ec-4b69-951a-ec758f6fb4d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1711b8a4-c988-402f-ba78-0271659d2055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 811cd249-042b-4596-8800-7f3f6dbb7a95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a4cdc0a-74cd-4ee3-86b6-4a6e661678a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6c6cd1a-a4b3-4dae-bfb0-f3a9b76a1fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6257c4f2-f037-4f2c-b5a7-964226e905a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cae7688-03de-4e00-8a93-16bec13fe33e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08fca83b-cac7-4c64-b7b0-fbe0499b5511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb271588-d792-46df-bdee-4ec7be888fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18180dd2-5255-4167-9298-0372029bfd91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69c85b0a-016f-4a73-954b-fab655bf7d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe0f4945-df95-4ebb-8083-29b01a01260a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b437817-0102-45a8-a4b3-1a7794e064a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message badd5bde-037f-4729-8d1c-7f6123a1c681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 697af4a8-0dff-4957-ba9c-71f9348366f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f588807-b24d-4335-b219-733183b7ff64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e11f7aed-ca0e-4920-abec-e43a24d8a04e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5445b8ac-cdee-40bd-8cda-57685852ebca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2147916c-ccd6-47ea-9af8-dc7d01498b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edcde2f5-a6b3-492b-b60a-6a62bc229c96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17635ac1-ff55-4bc0-99a4-46e93a5db7a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35cb1086-b575-4f5b-93d7-7c74f2a189cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b5f17ba-5751-4050-ab50-7508964a4788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd5b97a1-c40e-44d9-ac41-c7335481809d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2963594-3bfa-47d6-bb43-0b437cf7b838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad605a93-59e6-49df-99c3-d3714ad2cf57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c21af2f-c049-4381-8417-28b65e651514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74768fe6-6cb6-42af-aa3a-2c380e341494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cca9a79c-06ba-4da1-9702-9f2116a8a2ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 508aaecb-2ac7-4693-a8c2-f7b25b79e972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61db3693-4723-4c98-9926-478d87aaeb8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1484cf3-4989-47ac-b24c-927677c4dd29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d31ae90-fced-4bd2-997b-0d34cc8692f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7db9d289-ea3f-43cc-8320-444c297022ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b56f8984-ba62-420f-88b4-8d8dd1a9218c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 058df101-170d-4531-bb21-0395d861ddef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8e71052-5dee-4171-8e46-c3905fe4edda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4df2f5e5-38a5-49a5-ad47-e77add60a7ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e6f39d5-0bc0-4582-ada8-e25383a94a9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66e329e5-bb43-4b6e-95a1-52497f439d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cd84adf-d431-4a04-aaa5-316bc214d358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eceb9925-4b0e-4185-8bd3-62cd0272a35b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f453bdb7-1b01-4abf-9e2a-5078c87dcb70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eda1ba0-f3c8-40a2-8462-b8036e3cc3ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 071dad5b-99ab-49a0-8a8a-e348929e6245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aad0180-3375-4540-bdab-c790868abbe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd8f0ebf-ec51-4146-a238-ccefa010dba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47301abc-1faa-4379-9845-e9b15075b507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9de3bea8-6ea7-4afb-a352-b99b15fa76f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f6983a-a4ca-4aff-9f66-326f27dba809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca695ccf-ecfc-4948-acac-65b50a5a73fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e491a19-5df3-4a77-840b-44d97f0d5265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388562ab-2e8c-4f58-8292-261deba34485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1930a814-1d16-4c91-b853-9a4690b39e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b699ddb-2526-4fdc-9518-27b098e2935a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b70f41c-ec7e-4a0f-9c24-b26ee19d3412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8fa545d-b60a-4d4c-9e76-f48476ea93c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27ce7568-69af-4f0e-8d99-ddcb235c933e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b082b821-9850-4cba-a924-b0d7a8448728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 827107f0-a8ab-4728-aed6-84d31f656202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0417e8ca-52b3-4be4-81a1-bd9bca44ecec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 073c7aa5-4b46-4319-a45c-74ccf0556353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc4d66c2-df37-4317-9828-873d04be68de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb853884-f94a-41d8-a382-3c9903c2041a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1140522-7708-4279-b846-01d51785b65c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 773f3e08-e4b0-43e1-90b1-0aa958e6586f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cebdafa3-fd04-4b64-92cc-0e32a6842810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43a26d48-2294-4134-b5b7-7b20f3e8f52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef53c30d-ee1b-453c-9d30-f317f7aa6696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c77e98c-e9b7-4c66-8cff-fd813add9551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a055663e-02d9-48a3-9873-126654bf6e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c41bc2de-7c59-45c1-9d44-d05864742471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a5cca33-e5ab-4ad3-9534-0d21fa36d221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07b6eb97-14ca-4c00-a917-174715cb26a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f9fe9e0-c3d6-48d0-b55a-3f5db8fe84a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d9d831f-d450-4dc9-9ee6-2ee2c847ef25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d27261cb-db05-4527-b0a7-8dc843b7abee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7094cdcb-731d-4571-912b-9fce2635ceea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31ea6df4-e12b-4d57-b7fc-088ca74af43f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfcbd178-61e7-4a5f-9fef-1bc183b43160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aee03053-febe-4843-892a-8e8d81121bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e204aea-addd-42db-b36f-8d3992b38701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dacdbd43-c813-4c8e-bd60-e21d0c88e8ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab6f7328-665b-44b8-a21f-8d426d199721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d785cfd-ec65-4e2d-9997-8143280ffdb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f986126b-77a8-4996-b46d-6ee3fd50ed59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9991bae-1c99-41e5-a618-e23650968d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5afdc32f-98e5-4883-99b3-caf02c7075e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf453c95-dc00-4a37-8096-2f6f8d6eec3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26e9de07-9a74-4235-9c94-12535104328e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a7835b4-5ac0-45df-9a05-ed2a9a3b4995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 504f188b-66c6-4a18-b7e5-3604e655ba8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2a87ad8-c095-437f-916f-bfd57a71c172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6931ce6e-324a-45c6-b6d8-ff2bdcc03d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba2602fe-19e8-4cb5-a4d7-51fd9bebf9f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ee4df92-dcc0-4f0d-984f-d84db4a28220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdd712e9-369f-412f-8ccf-befc5f3e0976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bad8ec15-e519-46d4-83d4-0166ccb19be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96c1e684-3edf-49ba-961b-ea89065f1aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 369adcaf-0f70-4886-b91a-c39b64ef7886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa40d25e-1c06-495f-a289-407b9462d5e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc9e2992-30ba-4daf-b963-1774d212e629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ea8e17c-2ed1-4fc3-a1d7-f1ae51c2fa73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b26b4bcd-22f5-40c9-93b2-170700adcb4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dd9e13d-5376-4a56-a1ce-dcf2ca86c7a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd9e3b17-714f-4227-8a73-b228bc622e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae4d8b2a-c9c0-4101-96ec-9e88a0fd7605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1c1eb46-63e5-4aee-8141-dd5dfb0f4b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ff174b5-e5fe-4d62-9a02-8be7d1a0a340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3260df48-9e65-428a-afbc-37965e3808da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d290bb4-a40a-4611-8b11-94edd44eae21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f025737f-b1ac-4363-849e-dfbab7b09027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d79c6cdc-3ca4-4db9-9a64-ffa7551d22ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2892d63c-6f7f-48d3-9fa8-6a1eb1d0eb3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73edb506-cd37-45e3-9743-51e0b46cde73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70c33c1d-47e9-404a-b9d8-33dd1e7cb294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 954ec1f4-ffee-40e9-94ed-45f5a4cd6413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab7ac34f-2e5f-4545-9589-b2b6bc2b3292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6f9c01d-0e2b-4bd7-a3bb-a2814fae0c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51e7fa11-fc78-477e-b6e7-c614db129972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6030a55b-c068-4b23-82b2-6eb6e408d32a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef075d46-3b35-4a22-bacf-df9ae18d8211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15e414af-7658-43bc-a775-fc2082dd456b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 349936a5-3942-4fc6-8eb4-5a239c53259a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83c8f746-ccb0-4ab0-860c-9c7e715a4990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae51b324-02cc-4ae5-a5f1-2c57f85e2807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d9cc180-6eb6-4758-bdb6-1d4e4008002d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8315cb4-3990-4e73-bbbf-fee917b6781e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84802f08-f39e-4b19-9b51-ec93143a175c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16e8541a-6b23-4235-ae8f-2cf170fa82de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7401d0ea-8d1d-4dff-9204-ec5559a6bf88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f4e80fc-2694-41b3-8286-139d305dd56d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1eb6c38-bcc8-4493-9795-13f3b63da6c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bae9ed47-eb24-4172-b97f-46478809737c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a20ca105-7bb8-4455-8590-6c729cdbfe5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 068c39cd-5a88-4d8a-959e-b48b5fc9e71d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e9ade84-f8c2-4c1f-a78e-7f027e5597d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 060e0a3d-671d-4015-b241-d441a8ab2e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bc1949d-c49d-4a2c-b704-9cf66f37a46b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 170a4dd1-9aaa-4b65-9cd5-69fbf3e6bbd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39aa6527-2797-48da-9f46-d5d7562a95bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c04df5e7-8e5e-43b6-b5e3-ea2cea911435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9cf7980-316e-463d-90dd-a7cd66d9800c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5cfcbbc-1ca9-4d1a-8237-b54b1341865e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd866e9e-9baf-45ce-b10d-deff9bbf9878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69f5db10-cd0b-4494-bea5-b92bde4a7d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ec4f8af-ffe7-4f6b-8cfb-20cb9ddc4ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 011b7c92-a15b-440c-a2f5-7ebeb5fdbd48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d8063ad-04c9-4c91-9628-e9e10254f200
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_13
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_13
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_13/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_13/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_13/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_13/test_labels.txt

📊 Raw data loaded:
   Train: X=(1098, 24), y=(1098,)
   Test:  X=(275, 24), y=(275,)

⚠️  Limiting training data: 1098 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  266 samples, 5 features
✅ Client client_13 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 4 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1262, val=0.0980 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0764, val=0.0873 (↓), lr=0.001000
   • Epoch   3/100: train=0.0773, val=0.0872, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0774, val=0.0876, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0769, val=0.0875, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0756, val=0.0882, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 4 Summary - Client client_13
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0020
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0057
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.1961, RMSE: 0.4429, MAE: 0.3517, R²: -1.1496

📊 Round 4 Test Metrics:
   Loss: 0.1929, RMSE: 0.4392, MAE: 0.3486, R²: -1.1142

============================================================
🔄 Round 6 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1617, val=0.1387 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1035, val=0.0786 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0804, val=0.0716 (↓), lr=0.000250
   • Epoch   4/100: train=0.0817, val=0.0737, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0806, val=0.0731, patience=2/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0801, val=0.0739, patience=8/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 6 Summary - Client client_13
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0097
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0370
============================================================


============================================================
🔄 Round 7 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1668, val=0.1857 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1447, val=0.1624 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1259, val=0.1426 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1101, val=0.1251 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0965, val=0.1099 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0768, val=0.0879, patience=1/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0767, val=0.0874, patience=8/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 7 Summary - Client client_13
   Epochs: 28/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0034
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0192
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.1748, RMSE: 0.4181, MAE: 0.3314, R²: -0.9160

============================================================
🔄 Round 10 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1665, val=0.1656 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1633, val=0.1621 (↓), lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   ✓ Epoch   3/100: train=0.1600, val=0.1588 (↓), lr=0.000004
   ✓ Epoch   4/100: train=0.1576, val=0.1573 (↓), lr=0.000004
   ✓ Epoch   5/100: train=0.1562, val=0.1558 (↓), lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   ✓ Epoch  11/100: train=0.1488, val=0.1484 (↓), lr=0.000002
   📉 Epoch 19: LR reduced 0.000002 → 0.000001
   ✓ Epoch  21/100: train=0.1438, val=0.1436 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1414, val=0.1412 (↓), lr=0.000001
   • Epoch  41/100: train=0.1392, val=0.1388, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1370, val=0.1365, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1349, val=0.1343 (↓), lr=0.000001
   • Epoch  71/100: train=0.1328, val=0.1321, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1307, val=0.1299, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1286, val=0.1277 (↓), lr=0.000001

============================================================
📊 Round 10 Summary - Client client_13
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.1267, RMSE=0.3560, R²=-0.5705
   Val:   Loss=0.1258, RMSE=0.3547, R²=-0.7241
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.1655, RMSE: 0.4068, MAE: 0.3225, R²: -0.8139

📊 Round 10 Test Metrics:
   Loss: 0.1614, RMSE: 0.4017, MAE: 0.3185, R²: -0.7686

============================================================
🔄 Round 13 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1513, val=0.1544 (↓), lr=0.000001
   • Epoch   2/100: train=0.1511, val=0.1541, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1508, val=0.1538 (↓), lr=0.000001
   • Epoch   4/100: train=0.1505, val=0.1535, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1503, val=0.1533 (↓), lr=0.000001
   • Epoch  11/100: train=0.1488, val=0.1518, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1464, val=0.1494 (↓), lr=0.000001
   • Epoch  31/100: train=0.1441, val=0.1472, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1420, val=0.1450, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1398, val=0.1428 (↓), lr=0.000001
   • Epoch  61/100: train=0.1377, val=0.1406, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1355, val=0.1385, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1334, val=0.1363 (↓), lr=0.000001
   • Epoch  91/100: train=0.1312, val=0.1341, patience=1/15, lr=0.000001

============================================================
📊 Round 13 Summary - Client client_13
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1292, RMSE=0.3594, R²=-0.6368
   Val:   Loss=0.1322, RMSE=0.3636, R²=-0.6472
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1507, RMSE: 0.3882, MAE: 0.3086, R²: -0.6517

============================================================
🔄 Round 15 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1401, val=0.1184 (↓), lr=0.000001
   • Epoch   2/100: train=0.1399, val=0.1182, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1397, val=0.1180, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1395, val=0.1178 (↓), lr=0.000001
   • Epoch   5/100: train=0.1392, val=0.1176, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1379, val=0.1164, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1357, val=0.1144, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1335, val=0.1124 (↓), lr=0.000001
   • Epoch  41/100: train=0.1313, val=0.1104, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1291, val=0.1084, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1269, val=0.1064 (↓), lr=0.000001
   • Epoch  71/100: train=0.1247, val=0.1045, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1225, val=0.1025, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1204, val=0.1006 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_13
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1183, RMSE=0.3439, R²=-0.4531
   Val:   Loss=0.0988, RMSE=0.3144, R²=-0.4125
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1325, RMSE: 0.3640, MAE: 0.2932, R²: -0.4519

============================================================
🔄 Round 17 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1317, val=0.1067 (↓), lr=0.000001
   • Epoch   2/100: train=0.1315, val=0.1065, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1313, val=0.1064, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1311, val=0.1062 (↓), lr=0.000001
   • Epoch   5/100: train=0.1308, val=0.1060, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1295, val=0.1050, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1273, val=0.1033, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1250, val=0.1016 (↓), lr=0.000001
   • Epoch  41/100: train=0.1228, val=0.0999, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.1206, val=0.0983, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1184, val=0.0966, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.1162, val=0.0950, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1141, val=0.0935, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.1119, val=0.0919, patience=1/15, lr=0.000001

============================================================
📊 Round 17 Summary - Client client_13
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1098, RMSE=0.3313, R²=-0.3787
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.1990
============================================================


============================================================
🔄 Round 18 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1102, val=0.1168 (↓), lr=0.000001
   • Epoch   2/100: train=0.1100, val=0.1166, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1098, val=0.1164, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1096, val=0.1162 (↓), lr=0.000001
   • Epoch   5/100: train=0.1095, val=0.1160, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1084, val=0.1148, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1066, val=0.1128, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1049, val=0.1108 (↓), lr=0.000001
   • Epoch  41/100: train=0.1031, val=0.1088, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1014, val=0.1068, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0998, val=0.1049 (↓), lr=0.000001
   • Epoch  71/100: train=0.0982, val=0.1030, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0966, val=0.1012, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0951, val=0.0994 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_13
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0938, RMSE=0.3063, R²=-0.1797
   Val:   Loss=0.0979, RMSE=0.3128, R²=-0.2653
============================================================


============================================================
🔄 Round 19 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0961, val=0.1098 (↓), lr=0.000001
   • Epoch   2/100: train=0.0959, val=0.1096, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0957, val=0.1094, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.0956, val=0.1093 (↓), lr=0.000001
   • Epoch   5/100: train=0.0954, val=0.1091, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.0944, val=0.1081, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.0927, val=0.1065, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0911, val=0.1050, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0895, val=0.1036, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0881, val=0.1022, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0867, val=0.1009, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0854, val=0.0997, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0841, val=0.0986, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.0830, val=0.0975, patience=2/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_13
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0793
   Val:   Loss=0.0966, RMSE=0.3109, R²=-0.0543
============================================================


============================================================
🔄 Round 21 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0936, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.0786, val=0.0929, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0782, val=0.0923, patience=7/15, lr=0.000001
   • Epoch  41/100: train=0.0779, val=0.0917, patience=8/15, lr=0.000001
   • Epoch  51/100: train=0.0777, val=0.0913, patience=8/15, lr=0.000001
   • Epoch  61/100: train=0.0774, val=0.0909, patience=6/15, lr=0.000001
   • Epoch  71/100: train=0.0773, val=0.0905, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0771, val=0.0902, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 21 Summary - Client client_13
   Epochs: 84/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=-0.0073
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0200
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0921, RMSE: 0.3035, MAE: 0.2674, R²: -0.0094

📊 Round 21 Test Metrics:
   Loss: 0.0917, RMSE: 0.3028, MAE: 0.2676, R²: -0.0049

📊 Round 21 Test Metrics:
   Loss: 0.0916, RMSE: 0.3026, MAE: 0.2677, R²: -0.0035

📊 Round 21 Test Metrics:
   Loss: 0.0915, RMSE: 0.3024, MAE: 0.2678, R²: -0.0025

📊 Round 21 Test Metrics:
   Loss: 0.0914, RMSE: 0.3023, MAE: 0.2679, R²: -0.0018

============================================================
🔄 Round 27 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 27 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0089
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0111
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0914, RMSE: 0.3023, MAE: 0.2680, R²: -0.0014

📊 Round 27 Test Metrics:
   Loss: 0.0913, RMSE: 0.3022, MAE: 0.2681, R²: -0.0010

============================================================
🔄 Round 30 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 30 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0055
   Val:   Loss=0.0698, RMSE=0.2642, R²=-0.0225
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0913, RMSE: 0.3022, MAE: 0.2681, R²: -0.0009

============================================================
🔄 Round 32 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 32 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0125
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0055
============================================================


============================================================
🔄 Round 33 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 33 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0122
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0058
============================================================


============================================================
🔄 Round 36 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 36 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0128
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0018
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0913, RMSE: 0.3021, MAE: 0.2683, R²: -0.0003

============================================================
🔄 Round 39 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 39 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0027
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0223
============================================================


============================================================
🔄 Round 40 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 40 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=-0.0056
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0064
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2684, R²: -0.0000

📊 Round 40 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2684, R²: -0.0000

📊 Round 40 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2684, R²: -0.0001

============================================================
🔄 Round 46 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 46 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0053
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0039
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2684, R²: -0.0000

📊 Round 46 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2684, R²: 0.0000

📊 Round 46 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2684, R²: 0.0001

============================================================
🔄 Round 52 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 52 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0035
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0152
============================================================


============================================================
🔄 Round 53 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 53 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0034
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0123
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2684, R²: 0.0000

============================================================
🔄 Round 54 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 54 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0017
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0194
============================================================


============================================================
🔄 Round 56 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 56 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0053
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0012
============================================================


============================================================
🔄 Round 57 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 57 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0088
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0007
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2684, R²: 0.0001

📊 Round 57 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2684, R²: 0.0001

============================================================
🔄 Round 60 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 60 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0079
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0013
============================================================


============================================================
🔄 Round 62 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 62 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0018
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0185
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2685, R²: 0.0001

============================================================
🔄 Round 63 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 63 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0062
   Val:   Loss=0.0695, RMSE=0.2636, R²=-0.0003
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2685, R²: 0.0001

============================================================
🔄 Round 65 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 65 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0054
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0016
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2685, R²: 0.0001

============================================================
🔄 Round 66 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 66 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0017
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0213
============================================================


============================================================
🔄 Round 69 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 69 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0054
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0003
============================================================


============================================================
🔄 Round 71 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 71 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0051
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0007
============================================================


============================================================
🔄 Round 72 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 72 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0068
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0046
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2685, R²: 0.0002

============================================================
🔄 Round 74 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 74 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0059
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0041
============================================================


============================================================
🔄 Round 75 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 75 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0116
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0102
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2686, R²: 0.0002

============================================================
🔄 Round 76 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 76 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0033
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0066
============================================================


============================================================
🔄 Round 77 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 77 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0034
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0062
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2686, R²: 0.0002

============================================================
🔄 Round 80 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 80 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0025
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0087
============================================================


============================================================
🔄 Round 81 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 81 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0053
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0020
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2686, R²: 0.0002

============================================================
🔄 Round 83 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 83 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0075
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0030
============================================================


============================================================
🔄 Round 88 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 88 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0048
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0009
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2686, R²: 0.0002

============================================================
🔄 Round 91 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 91 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0045
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0017
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2686, R²: 0.0002

============================================================
🔄 Round 92 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 92 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0036
   Val:   Loss=0.0685, RMSE=0.2618, R²=-0.0022
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2686, R²: 0.0002

📊 Round 92 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2686, R²: 0.0002

============================================================
🔄 Round 95 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 95 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0021
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0143
============================================================


============================================================
🔄 Round 99 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 99 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0035
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0046
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2687, R²: 0.0002

============================================================
🔄 Round 101 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 101 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0020
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0181
============================================================


============================================================
🔄 Round 102 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 102 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0037
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0012
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2687, R²: 0.0002

============================================================
🔄 Round 106 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 106 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0021
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0136
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2687, R²: 0.0002

============================================================
🔄 Round 107 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 107 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0063
   Val:   Loss=0.0796, RMSE=0.2820, R²=0.0051
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2687, R²: 0.0002

============================================================
🔄 Round 108 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 108 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=-0.0054
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0035
============================================================


============================================================
🔄 Round 110 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 110 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0052
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0010
============================================================


============================================================
🔄 Round 111 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 111 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0081
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0033
============================================================


============================================================
🔄 Round 113 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 113 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0012
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0116
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2687, R²: 0.0002

📊 Round 113 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2687, R²: 0.0002

📊 Round 113 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2687, R²: 0.0002

============================================================
🔄 Round 117 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 117 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0021
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0083
============================================================


============================================================
🔄 Round 118 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 118 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0012
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0109
============================================================


============================================================
🔄 Round 119 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 119 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0053
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0026
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2687, R²: 0.0002

📊 Round 119 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2687, R²: 0.0002

============================================================
🔄 Round 121 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 121 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0056
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0054
============================================================


============================================================
🔄 Round 122 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 122 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0032
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0061
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2687, R²: 0.0002

============================================================
🔄 Round 126 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 126 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0038
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0005
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2687, R²: 0.0002

============================================================
🔄 Round 128 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 128 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0018
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0077
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0002

============================================================
🔄 Round 129 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 129 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0025
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0034
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0002

============================================================
🔄 Round 131 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 131 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0052
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0017
============================================================


============================================================
🔄 Round 132 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 132 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0036
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0003
============================================================


============================================================
🔄 Round 133 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 133 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0025
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0030
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0002

============================================================
🔄 Round 135 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 135 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=-0.0044
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0004
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0002

============================================================
🔄 Round 137 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 137 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0002
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0149
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0002

📊 Round 137 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0002

============================================================
🔄 Round 139 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 139 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=-0.0019
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0074
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0002

============================================================
🔄 Round 140 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 140 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0029
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0011
============================================================


============================================================
🔄 Round 141 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 141 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0006
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0138
============================================================


============================================================
🔄 Round 143 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 143 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=-0.0022
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0044
============================================================


============================================================
🔄 Round 144 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 144 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0059
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0054
============================================================


============================================================
🔄 Round 145 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 145 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0026
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0034
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0001

============================================================
🔄 Round 147 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 147 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0043
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0003
============================================================


============================================================
🔄 Round 151 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 151 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0044
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.0049
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0001

============================================================
🔄 Round 153 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0659 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0659, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0659, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0659, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0659, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0658, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 153 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0023
   Val:   Loss=0.0659, RMSE=0.2568, R²=-0.0200
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0001

============================================================
🔄 Round 155 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 155 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0004
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0212
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0001

============================================================
🔄 Round 157 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 157 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0017
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0080
============================================================


============================================================
🔄 Round 159 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 159 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0001
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0208
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0001

📊 Round 159 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0001

============================================================
🔄 Round 162 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 162 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0008
   Val:   Loss=0.0695, RMSE=0.2637, R²=-0.0309
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0001

============================================================
🔄 Round 165 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 165 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0001
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0266
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0001

📊 Round 165 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0001

📊 Round 165 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0001

============================================================
🔄 Round 171 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 171 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0029
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0007
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0001

📊 Round 171 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2688, R²: 0.0001

============================================================
🔄 Round 174 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 174 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=-0.0037
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0004
============================================================


============================================================
🔄 Round 177 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 177 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0020
   Val:   Loss=0.0712, RMSE=0.2668, R²=-0.0069
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2688, R²: 0.0001

============================================================
🔄 Round 179 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 179 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0009
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0146
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2688, R²: 0.0000

📊 Round 179 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2688, R²: 0.0000

📊 Round 179 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2688, R²: 0.0000

📊 Round 179 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2689, R²: 0.0000

📊 Round 179 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2688, R²: 0.0000

============================================================
🔄 Round 188 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 188 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0031
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0025
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2688, R²: 0.0000

============================================================
🔄 Round 190 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 190 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0041
   Val:   Loss=0.0718, RMSE=0.2679, R²=-0.0014
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2688, R²: 0.0000

============================================================
🔄 Round 191 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 191 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0056
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0061
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2688, R²: 0.0000

============================================================
🔄 Round 193 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 193 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0001
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0297
============================================================


============================================================
🔄 Round 194 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 194 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0038
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0002
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2689, R²: 0.0000

============================================================
🔄 Round 198 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 198 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0005
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0132
============================================================


============================================================
🔄 Round 199 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 199 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0049
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0045
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2689, R²: 0.0000

📊 Round 199 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2689, R²: 0.0000

============================================================
🔄 Round 203 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 203 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0024
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0038
============================================================


============================================================
🔄 Round 208 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 208 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0005
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0105
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2689, R²: -0.0000

📊 Round 208 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2689, R²: -0.0000

❌ Client client_13 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
