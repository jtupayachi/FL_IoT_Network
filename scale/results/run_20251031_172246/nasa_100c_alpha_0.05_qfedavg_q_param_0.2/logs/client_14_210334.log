[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7a2eee4-85f4-4ddf-9358-a68e294d1a3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c6f36f6-5125-483a-8677-d508d21ad902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b2f888d-d87e-4011-be10-d16e8a3d7890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5086cc9c-63d9-474c-adaa-a8fe2187dcf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c340d820-aa2d-49ef-89a6-39ecb9e9900a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 033540b3-ac75-4374-84e4-f905656bfa1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 606dbd8d-b187-4e75-8943-e67693137469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2999e98e-9acd-443d-917c-77af93b5b2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f9ac8fc-0708-4a4c-93d9-b573ce30d00f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 843cc6d2-8ead-4396-a6be-9cbd9f2b8716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e63ff69-34b9-4b47-a664-e903a7c37a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02d4505d-92bf-4b57-b4bd-a7a6b09c4dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba96a7ff-3025-463a-ace7-df8c3250201a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3f14844-ead4-4454-8af1-e1a16d3dafdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a384737-b110-4ec1-a715-3f35066cd472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1dc3e2e-c0c7-428b-ba28-e4f78b1db616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abbd796d-60aa-4a85-873b-a94263aa5671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba77e195-9b27-4d58-b668-e247dfc0016b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 609d6714-3eca-452a-a944-90b6c0cbca12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0edf557b-2cb5-49bd-92e5-e3d96ed863a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6279d2f3-8c0a-455c-a4a2-a56412e9d353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bc2be93-b3d4-49ae-b2c3-d0add03e2c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c73974d-2ce5-4b51-9d9c-5acd1fef8c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61fbb093-ec71-4bbc-9072-f4a67c6a0b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bc9fa9e-c98e-4131-aad3-7f6cf8c0201e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4dce1f8-6cf7-402a-bc88-8ca1db620cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e43fd003-f6cf-42e3-a8db-6358470857be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b83f46ce-0435-4ed5-a091-acf60b4f0e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cba95fd-a6d2-4b07-9dfc-1fc29612d8d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e797f0c-d034-44ca-b00a-9824d064885a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03bf0df1-25b6-4f48-8caa-fcc1f2d61869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01e3a039-f540-438a-bc85-f9fd88d8acf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbb9ec01-ec20-4ad9-b042-438117539c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a6dc876-3351-4c40-9282-470f90ee6b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b844257-c728-453d-84b3-d6100f6d5aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a702cd8e-d0e7-4b71-a367-7a864acb8d37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c861d25f-8c34-4d38-bffa-3bea90d4288f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 823e986b-d7bb-4345-8131-13337c4fe697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd53e081-e895-45c1-b67e-279684818f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ede1c1a3-fe6a-4811-9179-a6db972d8114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 691f52a0-7dc8-4fd6-a6a9-722d38266a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ba7f7f6-595a-463c-a876-7f33835f6d30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfafe27a-cba8-4d87-8dfe-ec1ccc70804b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 666c296a-bbc9-4c90-b534-419ceb4e74eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e2a2409-710f-476e-8c6a-c01ba3846437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26c579a1-e4d9-47db-82dc-55b70dc75088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab1866a2-b3f4-4c0c-bbf6-759ee8ed2216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fec9fbdd-eff2-40e8-b3d5-6ce07be86a3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c819823e-fb58-41aa-9005-cb489cb7a6c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c27b65fc-60fd-46e8-9696-e2318f5fbf1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9728396-62a1-4516-93df-1f807657dbe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f672ec0-a685-4981-8720-73f46cd32b9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b8a80bb-2e3a-4541-a67e-6c6a878f1f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1942f21f-4bae-4f94-b229-ec9c877ca657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d686a6bf-693b-4a49-a49e-0d5631793c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88f201f4-05da-436f-922a-07fc2fadf0a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cf2bb1e-8eee-41c3-a65e-0e5a2ff334d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e55c3c08-ed1a-4b5f-aa44-2607881b6987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42592ca3-541e-4c84-8c2d-8259767d201f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85400fa6-c999-4e4c-a882-5cb571a67655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acde8185-45b7-48c3-861d-ec5d5fd176d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac9cf40c-9f51-4d78-b98e-6a1fe141f528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6696d5f2-d3f5-46df-abba-3e937de6e081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c3be3a3-7349-461c-8b03-32529a5f95d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83a962c8-9e01-4293-a20a-49ddbde4aa37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cff298b-9fa7-4463-88c6-102798d92904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a032ea2-08eb-418f-98e8-092901dea67c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c5a8717-e3b0-42d1-8641-5a7159013d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b789892-0db1-4539-bb6f-869c06c8748d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccade35b-b39f-4fcd-847f-696dee59cb7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee685e88-38f2-4e11-a4f8-42df7bf721bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5108afa5-0d13-4e01-91c3-778f8c33959f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a153b77-e7d7-457e-9ed5-726aedb6884d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44fee732-d9bf-4507-9393-0166b6ba9c30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42ed8071-6080-4e06-8ca5-bf342d7197f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 097851c3-ca16-49d3-9406-468370d5b92c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca3d4a2b-bd21-4d57-b052-189fca1bca51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 802be655-5513-4be5-bfaf-7793c21e05b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c3d3daf-235a-49fe-b716-919e261dc706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04e0247c-3c18-4dd6-b093-058ecbd00edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f0c0872-72ba-4bbc-8efc-92f6cda5e96c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06ed3829-2248-4a58-ae37-89dae1eac833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4fbc17f-a649-4721-a755-3bf8c17e3890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dcf1045-7f03-45f9-92e8-9f2775c354df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e09a5411-00c6-4fa3-8436-deb21b39339e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 412150a9-0cea-47df-bf64-145f5249ddc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7de922d5-aba6-480c-ae27-79576ed7adab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd4dd23d-c539-454d-8c43-4fd6429015e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73b8f51a-5f01-46a5-ade8-885f74548d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91698ba9-db6c-4140-9e26-2d317a9ddffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7156dc5-8ade-430a-97f6-415c1dbc67b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f461cb63-e7f6-4837-aeca-7c3b724eabd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caf9cb93-3d48-45de-bb8a-17871e942615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 409fd041-122e-4438-8732-7c58cb739b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 867dc77f-97d6-444b-a84f-76a8c7464d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f4473ec-4eb3-4c10-911e-bd66ec146a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 236a0262-8a63-4cbb-a794-e78b87d39325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3def5837-25ae-42ca-94c9-99c83da6441e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2723199d-920d-42ac-afbf-4ce16413d74f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4b3c89d-a7a3-4249-bf49-dcc3ea95667f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e2c1084-b331-4e75-bed8-e34ae9a37c9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71c30bf2-2589-49e4-b929-5cc73e303877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adaeebb8-2f3d-4c69-8aa9-d98f53dcab61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d45aaef-56ac-40c7-84a7-b7efdcacf873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cef94585-0d06-4067-8848-b3d9516b9552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f0a83d4-7e61-4aa4-b0b3-a98fce1d3f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de23e4d1-5642-41a4-ab20-f8448e8a4711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8793e9c5-55e3-4bf6-8001-c81de2dfbf2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9885328b-0087-4cb2-89ef-1f0d8a14611a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c392f67-ffa5-4abc-839f-626adc2dd389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eec2cc85-0db9-4093-93f0-b470f237b7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d3cc62c-0b3a-46f6-aa1f-422cc85d9022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4283c00-6b16-4c05-9b05-2888e9bc3726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f63829cd-f3d3-4a4b-88e4-6de0134d32c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb215f79-7232-4d0e-818e-2ce41eded3f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb216f4d-8706-4b78-85e4-3836472a6b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85359de4-6dca-4c38-aa40-99fa958e7d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8181043d-4c16-4076-9817-a57c1a3acc6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fc91fe1-abfb-49ed-8caf-0efb7ef48c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a45c3b0b-8f07-4052-861a-b500214491ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79b8803f-73aa-478a-8dd4-52f7c71d6e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b3f84f3-3837-4c77-8b99-ed4701f8b265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a63eeaf-9604-449c-bdba-f3b5e155a95c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93f4715f-f2f7-49ea-b3be-745e1986a35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45feb50a-a7ce-4f4e-bd30-9a22212cfb2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faecf09d-9691-401f-a658-65bb21bc2b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8821a635-082e-49e5-989f-3eb7eaf20444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb4c91c4-148a-4790-b2f3-aff7ecc5c6ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d05db382-26a5-4e33-910b-0dc9713f7b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 355134c4-ffc7-4ab4-b36e-08e8b9391abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45d09dc2-f467-4ef3-8adc-ab88d1e6e76d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a525eb2d-1f31-4b8e-bc1d-b79833ef95b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fde5785a-5b06-4374-acf4-56f523f766f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 124d89f8-069c-47cb-8449-12c0e0ea4d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ebf8d7-f5f4-4dda-b2e2-531de0bd48a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d36b43af-6552-43f4-8254-c9f5f847bfac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f652d63a-6bb9-43ec-9e43-ccf8f91f78a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d0ccd2e-ddce-4d5f-a8e9-54e7dd63727e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c4f207b-81a3-492b-b963-313ab10d99e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 089688bd-6aba-49da-822f-3642caf1ea63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1604b9cd-9c18-41e8-b762-0d8c59ef7ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c535bf43-bc67-42bc-bf86-397ac996a9aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d364c8ec-4099-4375-9708-cb3a2293e29d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70f86daa-0eac-4d45-9c75-f7d3787035d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ae04593-ac08-4d78-bb7a-9c922e19476e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fed103e3-7337-474a-9640-0d1fb6652099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 503f521e-1573-48ff-a711-cd7dfdba6099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb42461-975e-4bcd-8b47-9866d66065b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84a7af61-b25d-4a0c-897d-2041dc77481e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4b6a109-a600-42cc-8b3b-efd139538069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf039b32-d76a-4bc9-bcf7-683be5ee1be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be42bff3-946e-489c-bf36-2d7d862aa311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c68fbc8-999d-47e0-9194-ac1382ffcc73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95d0f451-375e-4d99-9303-6b5ffa11b5ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b04e5e90-ef41-4dd0-a0db-7549bec58ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbe80a51-897e-40f9-9653-0af75b7156f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5f6884c-3ce9-49c0-88c4-8d334617b970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8a931a0-c5b3-418d-8865-9fe13b9a0db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14012693-5e1c-4695-9f86-76ac81a72c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5e1bdc6-b130-41ad-ae52-e56292ebef4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f4b8cfc-0ad6-4c3f-84ff-1a617f543bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e3d02f0-4dde-4645-b97e-47bebe236d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c642fcf-bab6-4774-bc3f-ea6a8337574e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b708fea-33cc-4a29-90ce-e811ce7af764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3669f29a-9c4f-4ea6-8b79-b181e472e998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdc4fd42-1ddf-4329-9712-a2567f087c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a663a317-4c0d-46ce-a9c9-f2bb6e9e8e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c6fdec8-9b99-46bd-a564-6eb542e13472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c56c3f7e-e3f3-428d-8726-51ea9c0a9d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d466760-1e83-4429-b6ea-46d2df6497b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a120e8ee-4314-45f8-878a-70a55a37b4c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cc1494d-f5dc-4b12-895f-cd46eb8668ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b65291be-c016-45e0-8218-08f4c6f5fdde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 067a6558-b177-48d9-961e-800f6659e3c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52eab938-9aa4-4b2f-b76f-471e093c3acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2abe08cf-8624-4d26-8cb0-659dc6d5a3fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2e63d20-385a-4ab5-8025-4f071db56528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53957260-40e2-4246-8089-7bf673d06d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83787241-82cf-43ea-a3e8-99a0bf8a17b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0894a245-474c-43b6-a915-df80d5a64291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31c64426-8319-45e8-8d89-2b764016826f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f4deed3-1137-4b07-b748-e5e9ab6e12f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbabddb2-a358-4f78-9bb8-95c0ed9e12f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53e56301-2bb3-450c-a650-07fbe07313eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa020dbb-b9cc-485a-8962-e1e5db4ffdda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27cb39b9-3c94-4f3d-81b6-a4b14cd8028a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3febd882-5d7e-4119-91c1-479739162435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07056cd7-65ae-4f81-8a58-130e80c11a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 806f298b-fa1a-402b-b966-10e0a6f063b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59fc42d1-dd55-4f2d-9a68-8a8bf08f2ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 153b85e5-92a4-448a-bc0a-8fa5b33416df
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_14
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_14
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_14/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_14/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_14/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_14/test_labels.txt

📊 Raw data loaded:
   Train: X=(601, 24), y=(601,)
   Test:  X=(151, 24), y=(151,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 592 samples, 5 features
   Test:  142 samples, 5 features
✅ Client client_14 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1967, RMSE: 0.4435, MAE: 0.3578, R²: -1.3780

📊 Round 0 Test Metrics:
   Loss: 0.1926, RMSE: 0.4389, MAE: 0.3533, R²: -1.3286

📊 Round 0 Test Metrics:
   Loss: 0.1791, RMSE: 0.4232, MAE: 0.3387, R²: -1.1650

============================================================
🔄 Round 5 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1280, val=0.0930 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0889, val=0.0884 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0837, val=0.0852 (↓), lr=0.001000
   • Epoch   4/100: train=0.0828, val=0.0848, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0820, val=0.0849, patience=2/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0808, val=0.0866, patience=8/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 5 Summary - Client client_14
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0081
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0110
============================================================


============================================================
🔄 Round 6 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1771, val=0.1352 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1282, val=0.0941 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0934, val=0.0803 (↓), lr=0.000250
   • Epoch   4/100: train=0.0858, val=0.0808, patience=1/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0835, val=0.0790 (↓), lr=0.000250
   ✓ Epoch  11/100: train=0.0837, val=0.0785 (↓), lr=0.000250
   • Epoch  21/100: train=0.0835, val=0.0782, patience=10/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 6 Summary - Client client_14
   Epochs: 26/100 (early stopped)
   LR: 0.000250 → 0.000250 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0091
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0096
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.1676, RMSE: 0.4094, MAE: 0.3264, R²: -1.0259

============================================================
🔄 Round 7 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1698, val=0.1332 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1234, val=0.0919 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0900, val=0.0778 (↓), lr=0.000250
   • Epoch   4/100: train=0.0851, val=0.0786, patience=1/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0844, val=0.0773 (↓), lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0838, val=0.0776, patience=6/15, lr=0.000125
   📉 Epoch 19: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 7 Summary - Client client_14
   Epochs: 20/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0072
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0012
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.1616, RMSE: 0.4020, MAE: 0.3200, R²: -0.9535

============================================================
🔄 Round 8 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1761, val=0.1494 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1579, val=0.1330 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1401, val=0.1189 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1244, val=0.1066 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.1102, val=0.0964 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0826, val=0.0862, patience=4/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0822, val=0.0870, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 8 Summary - Client client_14
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0335
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0209
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1590, RMSE: 0.3987, MAE: 0.3172, R²: -0.9214

📊 Round 8 Test Metrics:
   Loss: 0.1502, RMSE: 0.3875, MAE: 0.3083, R²: -0.8152

============================================================
🔄 Round 11 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.1645, val=0.1609 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1614, val=0.1585 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1590, val=0.1561 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1566, val=0.1539 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1544, val=0.1517 (↓), lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1441, val=0.1423 (↓), lr=0.000004
   📉 Epoch 17: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.1372, val=0.1358 (↓), lr=0.000002
   📉 Epoch 25: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.1344, val=0.1332 (↓), lr=0.000001
   • Epoch  41/100: train=0.1326, val=0.1314, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1308, val=0.1296, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.1291, val=0.1280, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.1274, val=0.1263, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1258, val=0.1247, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.1242, val=0.1231, patience=1/15, lr=0.000001

============================================================
📊 Round 11 Summary - Client client_14
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.1224, RMSE=0.3499, R²=-0.4705
   Val:   Loss=0.1217, RMSE=0.3489, R²=-0.4567
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1362, RMSE: 0.3691, MAE: 0.2942, R²: -0.6469

📊 Round 11 Test Metrics:
   Loss: 0.1271, RMSE: 0.3565, MAE: 0.2851, R²: -0.5365

📊 Round 11 Test Metrics:
   Loss: 0.1227, RMSE: 0.3503, MAE: 0.2807, R²: -0.4835

============================================================
🔄 Round 16 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1328, val=0.1401 (↓), lr=0.000001
   • Epoch   2/100: train=0.1326, val=0.1399, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1325, val=0.1397, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1323, val=0.1396 (↓), lr=0.000001
   • Epoch   5/100: train=0.1321, val=0.1394, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1311, val=0.1384, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1294, val=0.1367, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.1278, val=0.1350, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1261, val=0.1334 (↓), lr=0.000001
   • Epoch  51/100: train=0.1245, val=0.1317, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1229, val=0.1301 (↓), lr=0.000001
   • Epoch  71/100: train=0.1214, val=0.1285, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1198, val=0.1269 (↓), lr=0.000001
   • Epoch  91/100: train=0.1183, val=0.1254, patience=2/15, lr=0.000001

============================================================
📊 Round 16 Summary - Client client_14
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1169, RMSE=0.3420, R²=-0.4242
   Val:   Loss=0.1240, RMSE=0.3521, R²=-0.4050
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1191, RMSE: 0.3452, MAE: 0.2770, R²: -0.4400

📊 Round 16 Test Metrics:
   Loss: 0.1063, RMSE: 0.3260, MAE: 0.2635, R²: -0.2848

============================================================
🔄 Round 18 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1182, val=0.1046 (↓), lr=0.000001
   • Epoch   2/100: train=0.1180, val=0.1044, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1179, val=0.1043, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1177, val=0.1042, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1176, val=0.1040 (↓), lr=0.000001
   • Epoch  11/100: train=0.1166, val=0.1033, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1151, val=0.1020 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1135, val=0.1008 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1120, val=0.0996 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1105, val=0.0984 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1091, val=0.0973 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1076, val=0.0961 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1062, val=0.0951 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1049, val=0.0940 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_14
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1036, RMSE=0.3219, R²=-0.2425
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.1346
============================================================


============================================================
🔄 Round 20 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0938, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0937, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0936, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0935, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0934, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0929, val=0.0896, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0920, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  31/100: train=0.0911, val=0.0884, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0903, val=0.0878, patience=6/15, lr=0.000001
   • Epoch  51/100: train=0.0896, val=0.0873, patience=6/15, lr=0.000001
   • Epoch  61/100: train=0.0888, val=0.0868, patience=6/15, lr=0.000001
   • Epoch  71/100: train=0.0882, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0876, val=0.0860, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0870, val=0.0857, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 20 Summary - Client client_14
   Epochs: 95/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0519
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0245
============================================================


============================================================
🔄 Round 21 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0853, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0863, val=0.0849, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0860, val=0.0845, patience=5/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0856, val=0.0842 (↓), lr=0.000001
   • Epoch  51/100: train=0.0853, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 21 Summary - Client client_14
   Epochs: 56/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0239
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0198
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2460, R²: -0.0012

============================================================
🔄 Round 26 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 26 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0146
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0057
============================================================


============================================================
🔄 Round 27 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 27 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0123
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0105
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2461, R²: -0.0010

============================================================
🔄 Round 29 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 29 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0037
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0774
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2462, R²: -0.0010

📊 Round 29 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2462, R²: -0.0009

============================================================
🔄 Round 31 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 31 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0099
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0136
============================================================


============================================================
🔄 Round 32 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 32 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0060
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0282
============================================================


============================================================
🔄 Round 33 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 33 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0089
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0149
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2462, R²: -0.0010

============================================================
🔄 Round 34 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 34 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0107
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0072
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2463, R²: -0.0010

📊 Round 34 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2463, R²: -0.0010

============================================================
🔄 Round 36 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 36 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0096
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0163
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2463, R²: -0.0010

============================================================
🔄 Round 37 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 37 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0078
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0118
============================================================


============================================================
🔄 Round 38 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 38 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0064
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0189
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2463, R²: -0.0011

📊 Round 38 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2464, R²: -0.0012

============================================================
🔄 Round 45 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.1017 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.1017, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.1016, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.1016, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.1016, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.1015, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1017)

============================================================
📊 Round 45 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0039
   Val:   Loss=0.1017, RMSE=0.3189, R²=-0.0404
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2464, R²: -0.0012

📊 Round 45 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2464, R²: -0.0012

📊 Round 45 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2464, R²: -0.0012

============================================================
🔄 Round 49 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 49 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0096
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0028
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2464, R²: -0.0013

============================================================
🔄 Round 50 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 50 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0025
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0275
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2464, R²: -0.0013

============================================================
🔄 Round 52 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 52 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0117
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0094
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2464, R²: -0.0013

============================================================
🔄 Round 54 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 54 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0107
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0019
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2464, R²: -0.0013

============================================================
🔄 Round 56 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 56 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0073
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0062
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2464, R²: -0.0012

📊 Round 56 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2464, R²: -0.0012

📊 Round 56 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2464, R²: -0.0013

📊 Round 56 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2464, R²: -0.0013

📊 Round 56 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2464, R²: -0.0013

============================================================
🔄 Round 62 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 62 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0023
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0258
============================================================


============================================================
🔄 Round 63 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 63 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0072
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0075
============================================================


============================================================
🔄 Round 64 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 64 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0069
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0072
============================================================


============================================================
🔄 Round 65 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 65 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0034
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0318
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2464, R²: -0.0013

============================================================
🔄 Round 68 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 68 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0072
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0224
============================================================


============================================================
🔄 Round 69 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 69 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0091
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0014
============================================================


============================================================
🔄 Round 70 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 70 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0024
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0255
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2465, R²: -0.0014

============================================================
🔄 Round 72 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 72 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0089
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0039
============================================================


============================================================
🔄 Round 76 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 76 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0068
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0037
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2465, R²: -0.0016

📊 Round 76 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2465, R²: -0.0016

============================================================
🔄 Round 79 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 79 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0075
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0066
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2465, R²: -0.0016

============================================================
🔄 Round 80 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 80 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0097
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0104
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2465, R²: -0.0016

📊 Round 80 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2465, R²: -0.0016

============================================================
🔄 Round 83 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 83 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0037
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0249
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2465, R²: -0.0016

============================================================
🔄 Round 85 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 85 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0113
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0070
============================================================


============================================================
🔄 Round 86 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 86 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0074
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0011
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2465, R²: -0.0016

============================================================
🔄 Round 91 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 91 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0044
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0120
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2465, R²: -0.0017

============================================================
🔄 Round 94 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 94 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0081
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0056
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2465, R²: -0.0017

📊 Round 94 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2465, R²: -0.0016

📊 Round 94 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2465, R²: -0.0017

📊 Round 94 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2465, R²: -0.0017

============================================================
🔄 Round 100 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 100 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0068
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0024
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2465, R²: -0.0017

📊 Round 100 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0017

📊 Round 100 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0018

============================================================
🔄 Round 104 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 104 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0072
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0007
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0018

============================================================
🔄 Round 106 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 106 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0087
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0043
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0018

============================================================
🔄 Round 108 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0655 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0655, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0654, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0654, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0654, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0654, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0655)

============================================================
📊 Round 108 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0044
   Val:   Loss=0.0655, RMSE=0.2559, R²=-0.0247
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

📊 Round 108 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

📊 Round 108 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

============================================================
🔄 Round 111 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 111 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0043
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0225
============================================================


============================================================
🔄 Round 112 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 112 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0091
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0080
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

============================================================
🔄 Round 113 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 113 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0060
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0028
============================================================


============================================================
🔄 Round 114 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 114 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0078
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0068
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0018

📊 Round 114 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0018

📊 Round 114 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0018

============================================================
🔄 Round 119 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 119 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0052
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0064
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0018

============================================================
🔄 Round 120 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 120 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0048
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0070
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

============================================================
🔄 Round 122 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 122 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0050
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0098
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

============================================================
🔄 Round 123 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 123 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0061
   Val:   Loss=0.0718, RMSE=0.2679, R²=-0.0011
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

============================================================
🔄 Round 127 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 127 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0047
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0075
============================================================


============================================================
🔄 Round 129 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 129 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0046
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0085
============================================================


============================================================
🔄 Round 130 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 130 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0070
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0028
============================================================


============================================================
🔄 Round 132 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 132 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0041
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0185
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

📊 Round 132 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

============================================================
🔄 Round 135 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 135 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0040
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0092
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0020

============================================================
🔄 Round 136 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 136 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0074
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0060
============================================================


============================================================
🔄 Round 138 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 138 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0068
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0093
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0021

📊 Round 138 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0021

📊 Round 138 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0020

============================================================
🔄 Round 142 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 142 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0042
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0113
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0020

📊 Round 142 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0018

============================================================
🔄 Round 146 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 146 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0057
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0175
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0018

📊 Round 146 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

============================================================
🔄 Round 151 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 151 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0054
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0135
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0018

============================================================
🔄 Round 153 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 153 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0064
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0006
============================================================


============================================================
🔄 Round 154 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 154 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0028
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0260
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0018

============================================================
🔄 Round 155 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 155 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0037
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0181
============================================================


============================================================
🔄 Round 158 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 158 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0051
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0057
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0018

============================================================
🔄 Round 160 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 160 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0037
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0193
============================================================


============================================================
🔄 Round 161 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 161 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0001
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0301
============================================================


============================================================
🔄 Round 162 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 162 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0029
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0267
============================================================


============================================================
🔄 Round 163 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 163 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0052
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0148
============================================================


============================================================
🔄 Round 164 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 164 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0068
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0009
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0020

============================================================
🔄 Round 169 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 169 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0010
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0194
============================================================


============================================================
🔄 Round 171 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 171 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0061
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0011
============================================================


============================================================
🔄 Round 172 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 172 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0048
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0145
============================================================


============================================================
🔄 Round 173 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 173 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0012
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0332
============================================================


============================================================
🔄 Round 175 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 175 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0002
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0268
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0020

📊 Round 175 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0020

============================================================
🔄 Round 181 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 181 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0025
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0247
============================================================


============================================================
🔄 Round 183 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 183 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0102
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0165
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

============================================================
🔄 Round 184 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 184 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0004
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0251
============================================================


============================================================
🔄 Round 185 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 185 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0043
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0118
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0020

============================================================
🔄 Round 186 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 186 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0073
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0046
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

============================================================
🔄 Round 189 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 189 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0061
   Val:   Loss=0.0813, RMSE=0.2850, R²=0.0004
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

📊 Round 189 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

📊 Round 189 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0020

============================================================
🔄 Round 193 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 193 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0063
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0018
============================================================


============================================================
🔄 Round 195 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 195 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0045
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0059
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0020

============================================================
🔄 Round 196 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 196 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0034
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0106
============================================================


============================================================
🔄 Round 197 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 197 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0087
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0114
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

📊 Round 197 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

============================================================
🔄 Round 199 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 199 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0098
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0091
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

============================================================
🔄 Round 201 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 201 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0042
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0130
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0020

============================================================
🔄 Round 202 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 202 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0002
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0361
============================================================


============================================================
🔄 Round 203 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 203 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0024
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0158
============================================================


============================================================
🔄 Round 204 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 204 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0028
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0124
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0019

============================================================
🔄 Round 205 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 205 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0023
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0645
============================================================


============================================================
🔄 Round 207 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 207 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0059
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0013
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0020

============================================================
🔄 Round 208 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 208 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0069
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0003
============================================================


============================================================
🔄 Round 209 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 209 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0090
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0111
============================================================


============================================================
🔄 Round 210 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0662 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0662, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0662, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0663, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0663, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0662)

============================================================
📊 Round 210 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0062
   Val:   Loss=0.0662, RMSE=0.2573, R²=-0.0190
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2466, R²: -0.0020

❌ Client client_14 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
