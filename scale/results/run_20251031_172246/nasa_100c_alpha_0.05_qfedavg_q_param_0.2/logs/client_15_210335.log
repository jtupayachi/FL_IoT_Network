[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d1500aa-ed08-461a-9b86-98c97a15f664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9b65a5d-9a24-4ad0-96fb-8ae992461334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa740bf8-184f-4934-9403-0e267f09a806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5093a604-2be2-436c-8481-9266dbfe82d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac446799-79dd-4ba5-bb1f-e2857f8cce52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3519cdd0-9380-424f-bde1-53f2e1b0f913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67d87c65-d095-4a82-b083-cf67cc67bb8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6701f550-6f81-428e-acce-88379baf2e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d09d424c-66b9-426a-a38a-7512a8c4a3f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2db59ce4-003e-43a7-ae3a-36dea0ef27bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 701e8bd3-87f6-4436-9ea1-839e971cfb1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2f136c9-48b6-4cc3-bb29-42aa63b4825b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d82c8d4-c4b4-425c-9467-887d6fad2413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0635ce92-79a4-48df-98f2-f3a175663a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e24bd2b1-92c4-4256-b73f-bb3ec8868a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26907bd5-f7af-4afa-8123-2371a09412cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 763825d7-a098-4723-bc4b-56eb0756d1be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6da0d00f-da6c-48b8-a64c-7f78da484795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8df22cc2-99fe-4e96-b830-abf5c43f5b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1078a11-7112-4eba-9ee3-4b33c267c56b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a1464c4-ff43-47ce-bab8-399f6d72b2d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3df9969f-4ded-4604-992a-17c95ee5024c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7196593e-dceb-4ab1-b3d5-17ec3782899b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 601c061b-ad65-4db2-a8c8-2ce139ca1e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aa2ee46-9f5c-461e-942d-4098112342fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e6862af-01ff-44b5-ada4-e1d7ae147d30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dbea08e-02d3-43f3-bc12-5d18f1796f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e8d8d82-beff-4bad-9e81-f143512f64b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 768127f4-1eba-4e09-b226-05117ef1a95d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07d8fe5b-cab9-4837-981d-f8c0854ba2f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ce64f5e-f959-45db-b322-bd58fbbdd85b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cca13b66-bf54-4aea-a625-d44fc374238a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac52271a-8566-4389-a713-d7e31c389e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6bc8c81-c017-4c7d-aa1a-58c6af3f1528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b9e29c3-121b-4d89-bcf4-654e3bc1c92b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81c7f376-2468-43cd-8df6-601701a9c6ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60e9bb0b-807d-42fe-9290-f34a988155ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fbb075e-f644-4a97-942d-89fba3090e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccbf6494-fdbc-4168-873e-651b38783410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99aa69df-8c2a-4f9e-8d48-32f73eaaba50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5999350-f12b-48d1-81cb-9ce69cf802a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63eaeec7-e81b-4380-9a6a-6fd83b1a5680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc723b54-68d7-42af-8893-e0bca6b877b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86adc8da-12fa-4cb0-8529-973ca97358a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2b54515-d3d9-4973-9f78-858814af4c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bafa39bf-2fd5-48ef-966c-d4ac764f12f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d8084f9-06a4-4b11-913b-02c352011099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b566d528-04be-43f5-a742-b13bce39c747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 631ef698-81f6-4985-a707-965cad2feab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cba43b2e-544e-48a9-b41c-489bd5b55ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 967283a8-00ee-4536-b829-e09dda3f5d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ebbfb52-688d-45bd-89dc-1aff75b661ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6125a36-a241-4912-a94a-f9d2e208e36e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee454535-3166-4fc3-8837-889359e0e68c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b328ca6a-196e-4894-bd9b-6ec166daa95d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 681168d1-b4e5-425d-87b9-029e8bbcd538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2064349-2d26-443a-a92d-28fa995591e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75f61360-122d-4437-9894-5106aa7b5c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbb9bf04-e20f-4569-9e79-03c42636ebdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da8f00b3-eebb-4418-9c59-642ecf86680e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6747edaa-4130-4e14-9eb4-d94ece4b6c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f17c677-460e-47c2-9f3b-41a57d4d7edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01fcfb96-edff-4086-8a4c-c1be1d04999e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9242b0b6-5960-4fe3-9a89-7a48ab1566fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0183bb3-fc9f-4af8-ab39-a45821e05d30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3981ce14-f33c-4ed2-b4d1-86be37339f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64402469-7ae9-4cb5-b69f-b2b89b89a34d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa5a642d-e68c-4390-9520-3bc3fecd0589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 099c531b-37c8-41fe-8f63-afa033f8f23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 993874d0-b171-403b-9d4b-042e68bca7e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00a5895b-5ada-4fd0-8193-3f9271b22f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c2014d-8a7a-444a-b843-121a1ef99078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10b548c1-7c7a-453f-aedb-8cb949510eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 325f3d5a-262f-4294-921d-3c4ec60f6f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef31f651-612d-4d3d-b576-05d9c03589e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b634867e-ad85-40c5-b62b-174ee8f2cc3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d26199a3-d382-41e2-9554-4b5db585e4b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae7dada7-26a3-43ba-a159-2f94a47ea2e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1029b229-a336-4ad8-bbec-e64b6563461d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec393ec3-74a4-4259-acf8-e88d26a595aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ce34d3d-b440-4459-9951-2fca841bc082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76ece13b-1bed-4620-9b4d-b365328642bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 599fa6ab-cb83-4d93-9111-d9699c2f9035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60e326e3-49c9-4085-9dd1-a0908353fef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0eb85ed-382e-4ee8-96b4-d47fce1e406e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88a86931-f39a-47da-8b05-c99959f13fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73a16f77-7d3e-4126-b0c2-a9fad74f9efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76686158-bc1e-47cf-a900-a83e1b60d1e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94c9b6f1-1be2-420b-b15e-89fd20af80cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c7bc40a-8572-4719-b72c-e94a23c9c2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97ed23a8-3099-48a8-9fef-97c3bca5173f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3081477-b47b-4286-b391-40f7d59cfaee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e92b329-f7a8-4a52-956f-e0be370b9e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d68c6fc2-318c-4ba8-be76-e108ef5bd127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e830c7f-bdd7-46ee-b8ab-2cd6ba288dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 764e4af9-dabb-4a91-954a-377b9b594654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5922a2bc-e7a4-4bfe-908d-338a17994f2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 839f9983-f07d-46ff-9d11-67fa97217986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01dd9980-af00-4d73-b458-d121907923a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3570b06b-0480-4f75-8beb-760aae8b9494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8473925f-29e2-46a4-b018-57af3138b7e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd332657-8c73-4f33-8ee0-0a69924ec4e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac17c2a8-e74c-4d03-bc1e-4b014e332edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6f19eeb-e18d-4717-a434-57f4e6642b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3597fd87-cc5d-43ad-ba06-c16777703702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e87f36d3-d1a8-46cb-bc66-514553f766bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dc782ee-91eb-4e2f-b04a-66b87fed6f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52c99b4c-98fc-4c99-915f-4cc0984cf83b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b845033-21a9-499f-83f3-c5b96474c928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1012014-1609-4dcd-a9e7-f396c9f0522f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dd1b9fc-bbd2-4fa2-b525-ce40b2e0b4a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32cac73c-49ff-411a-a39f-2a640a37e703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7a35149-8975-4b70-bcfb-3f29d6d0f2a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5425659-f2a8-4542-be69-0cd2a2be4a5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce7227ac-7836-43ac-b506-c4ac685f138d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9113ac42-426a-4c80-a787-6578a8b64639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c43db29-29be-4e3e-908f-c79478acc4e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dab068c7-aec4-42b7-8ad2-b9e8d031263a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02c3878e-045c-4ee8-bdfb-c38797d9cf58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a4d58bd-fbd8-47a4-9688-f97d57fe6424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8466605a-55b5-4552-8527-ed65727610fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58d97610-5876-4ed8-a676-27573b80f811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d472a5b-b81d-4a94-b3dc-67a29dfdb265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2615946-5c5a-4962-9716-a48602a8882a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82792e71-5ad7-4757-9020-b0366d6418c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b34a4fd-5dba-4974-bcb2-dc3e755293fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20caf319-21b8-4ffb-ac03-4319fbfe670a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 404cd158-b1f1-479e-aeda-a431ac57b46d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38a37e8b-dab1-49d8-bf95-279e4b685f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 493ef5ef-d8ff-4793-ae55-15a9db67335d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3955ca98-3f44-44f4-b655-ba67882b0cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95517f23-ca32-44b0-90ca-bbf1e2968f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e2d569d-8940-4e92-9f78-03818b36b310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b51ac89-c8b0-4732-aa1d-3e33acc5a032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c6fa2a1-118c-4815-a2a3-dc3d73a4da65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db6e32c4-3e4a-4fe1-ab90-e0e80846119c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a3d93fd-9ae3-4ee5-89d5-ab96dc37ab66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c37d0e1a-338d-4f80-9146-e6c7a17163d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bd5d819-5b49-42b9-9329-c0a46e2c13c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14d4d59e-a06b-474a-84f5-a6b4af6e1657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e87b3b79-93e1-42a3-a66e-46fb17a6ee90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5ca549e-44fa-4924-a22e-f9a37a22b246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d22af7a-1ae4-43af-9e35-48607c9290e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d07aaaa-5309-487b-be38-e9c2edaa62e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 706c07d8-ee64-4c4b-bad0-42493c029804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd796a93-a845-4641-844f-f18a6693cc33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65e24556-0e56-4e2e-946e-fa7a4c6920e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc312081-6d67-49a9-ac3f-1e3105b0d941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fea7fbc2-5712-4d4b-bdbe-b69bb4444d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57faa1ef-5f62-4897-ac83-a05ff04ff774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ec8f128-fa5e-4671-80ac-978808206566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8800e915-fcf8-4799-8e3d-c2e4967692a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7641b0d-fb0d-43c2-a136-abf39bc90aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e797c6e0-0b4e-4e10-b46f-91315431f5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8760dcd-c3f9-42d5-8506-3a901ec9b230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d309b4d-3a30-4839-a4db-0304f4a797d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b1916de-207e-49da-aab2-3e4198ad2560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96b750aa-54dd-4e54-9d2c-0ec1566f193e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdf19e63-8d73-4214-8cac-08e08c64933e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f79f11a6-cc18-490b-94f1-f869b22e39d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63c80558-79a8-4138-a00f-6d8b793b50d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1067690-9647-42de-b59c-0771cb1a17b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15b30534-1e42-4333-b92b-af819f98a980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7005b08e-f32c-45b2-8fd4-e21988efab5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bb7835a-4d91-4076-844a-21e764647dc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d55de47-722e-4247-ba34-1905eaf581c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9cd7797-1ee6-419b-91cd-746b3ae41ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c095b449-6cea-4f64-8dd6-de001bd179c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47d003dc-d47f-4280-bb82-42a11df28ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 303e38e5-eefa-4f27-afb8-b9c2a76e8336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a7520aa-5aa1-4cc2-9eaf-62587daee4bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbe53ffa-b308-4340-9621-566f0eb795ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72734e24-872b-4ed9-b6e6-e3113e7fefec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2c37fb9-77a3-4770-b9e0-c0e57f2e549e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 513afc2a-fa53-48bc-8a01-cebe8034550c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2180ee2c-4ebe-4ee7-a526-f231f615a808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 131d249a-1198-49e7-bc50-6d62871bb6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b476eadd-c3e4-4cf8-b68a-6dc7d4ced846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 105fa70a-3bb1-4423-8301-c2302ef36e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83853727-4688-4cce-a17f-b8d77ae4b2af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dd81b49-4ec4-4e2d-b85b-f11981da699a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fc641e3-f3a0-48ab-ad36-a5470c11bfd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb9861bd-e070-45ce-ac01-03a9f6a4f655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4455cb5-777a-4a0d-9ad9-0c355c481f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cd5fe0e-3bf7-40f4-afeb-f8a3b0330aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2a85fb3-4c9f-4344-9241-490951f0a851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b2ecb5e-6c3a-4945-bfb2-b551e7084686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ed484f2-0995-43b2-9193-56941fe8b953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 043ff989-a2ee-4649-9186-ed2dba635f31
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_15
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/test_labels.txt

📊 Raw data loaded:
   Train: X=(875, 24), y=(875,)
   Test:  X=(219, 24), y=(219,)

⚠️  Limiting training data: 875 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  210 samples, 5 features
✅ Client client_15 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1232, val=0.0994 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0880, val=0.0854 (↓), lr=0.001000
   • Epoch   3/100: train=0.0823, val=0.0851, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0816, val=0.0853, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0817, val=0.0851, patience=3/15, lr=0.001000
   • Epoch  11/100: train=0.0798, val=0.0852, patience=9/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500
   📉 Epoch 20: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0758, val=0.0848, patience=8/15, lr=0.000250
   📉 Epoch 28: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 2 Summary - Client client_15
   Epochs: 28/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0644
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0265
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.1810, RMSE: 0.4254, MAE: 0.3377, R²: -1.3365

============================================================
🔄 Round 3 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1964, val=0.1455 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.1475, val=0.1086 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.1093, val=0.0830 (↓), lr=0.000125
   ✓ Epoch   4/100: train=0.0873, val=0.0808 (↓), lr=0.000125
   • Epoch   5/100: train=0.0848, val=0.0805, patience=1/15, lr=0.000125
   • Epoch  11/100: train=0.0840, val=0.0801, patience=5/15, lr=0.000125
   📉 Epoch 12: LR reduced 0.000125 → 0.000063
   📉 Epoch 20: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0836, val=0.0800, patience=15/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 3 Summary - Client client_15
   Epochs: 21/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0022
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0074
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.1745, RMSE: 0.4178, MAE: 0.3304, R²: -1.2535

============================================================
🔄 Round 5 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1929, val=0.1892 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.1787, val=0.1739 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.1655, val=0.1612 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.1544, val=0.1503 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.1444, val=0.1401 (↓), lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   ✓ Epoch  11/100: train=0.1085, val=0.1049 (↓), lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008
   ✓ Epoch  21/100: train=0.0897, val=0.0853 (↓), lr=0.000008
   📉 Epoch 23: LR reduced 0.000008 → 0.000004
   📉 Epoch 31: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0864, val=0.0816, patience=2/15, lr=0.000002
   📉 Epoch 39: LR reduced 0.000002 → 0.000001
   • Epoch  41/100: train=0.0857, val=0.0807, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0854, val=0.0803, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0852, val=0.0800, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 5 Summary - Client client_15
   Epochs: 65/100 (early stopped)
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0085
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0279
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1565, RMSE: 0.3956, MAE: 0.3102, R²: -1.0207

============================================================
🔄 Round 7 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1783, val=0.2155 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1779, val=0.2149 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1774, val=0.2144 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1769, val=0.2139 (↓), lr=0.000001
   • Epoch   5/100: train=0.1765, val=0.2134, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1742, val=0.2108, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1711, val=0.2072, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.1683, val=0.2040, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1658, val=0.2011, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1633, val=0.1983, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1610, val=0.1956, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1587, val=0.1930, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1565, val=0.1904, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1543, val=0.1878, patience=1/15, lr=0.000001

============================================================
📊 Round 7 Summary - Client client_15
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1522, RMSE=0.3901, R²=-0.8525
   Val:   Loss=0.1855, RMSE=0.4308, R²=-1.1146
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.1481, RMSE: 0.3848, MAE: 0.3007, R²: -0.9121

============================================================
🔄 Round 9 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1690, val=0.2045 (↓), lr=0.000001
   • Epoch   2/100: train=0.1687, val=0.2043, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1685, val=0.2040 (↓), lr=0.000001
   • Epoch   4/100: train=0.1683, val=0.2037, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1680, val=0.2034 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1666, val=0.2017 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1643, val=0.1990 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1621, val=0.1963 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1599, val=0.1936 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1577, val=0.1909 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1556, val=0.1883 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1535, val=0.1857 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1513, val=0.1831 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1492, val=0.1805 (↓), lr=0.000001

============================================================
📊 Round 9 Summary - Client client_15
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1474, RMSE=0.3839, R²=-0.7562
   Val:   Loss=0.1781, RMSE=0.4220, R²=-1.2367
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1447, RMSE: 0.3803, MAE: 0.2967, R²: -0.8677

============================================================
🔄 Round 10 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1763, val=0.1574 (↓), lr=0.000001
   • Epoch   2/100: train=0.1760, val=0.1572, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1757, val=0.1570, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1755, val=0.1567 (↓), lr=0.000001
   • Epoch   5/100: train=0.1752, val=0.1565, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1737, val=0.1552, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1713, val=0.1529, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1689, val=0.1508 (↓), lr=0.000001
   • Epoch  41/100: train=0.1665, val=0.1487, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1641, val=0.1466, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1618, val=0.1445 (↓), lr=0.000001
   • Epoch  71/100: train=0.1595, val=0.1424, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1572, val=0.1404, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1549, val=0.1383 (↓), lr=0.000001

============================================================
📊 Round 10 Summary - Client client_15
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1525, RMSE=0.3905, R²=-0.8149
   Val:   Loss=0.1365, RMSE=0.3695, R²=-0.6738
============================================================


============================================================
🔄 Round 14 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1505, val=0.1518 (↓), lr=0.000001
   • Epoch   2/100: train=0.1503, val=0.1516, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1501, val=0.1514, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1499, val=0.1512 (↓), lr=0.000001
   • Epoch   5/100: train=0.1497, val=0.1510, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1484, val=0.1497, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1463, val=0.1475, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1441, val=0.1454 (↓), lr=0.000001
   • Epoch  41/100: train=0.1420, val=0.1433, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1398, val=0.1411, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1377, val=0.1390 (↓), lr=0.000001
   • Epoch  71/100: train=0.1355, val=0.1368, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1334, val=0.1346, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1312, val=0.1325 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_15
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1293, RMSE=0.3595, R²=-0.5385
   Val:   Loss=0.1305, RMSE=0.3612, R²=-0.5886
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1132, RMSE: 0.3365, MAE: 0.2632, R²: -0.4619

📊 Round 14 Test Metrics:
   Loss: 0.1098, RMSE: 0.3314, MAE: 0.2598, R²: -0.4178

📊 Round 14 Test Metrics:
   Loss: 0.0978, RMSE: 0.3127, MAE: 0.2488, R²: -0.2627

📊 Round 14 Test Metrics:
   Loss: 0.0883, RMSE: 0.2971, MAE: 0.2424, R²: -0.1397

📊 Round 14 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2392, R²: -0.0510

📊 Round 14 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2395, R²: -0.0129

📊 Round 14 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2414, R²: -0.0088

============================================================
🔄 Round 24 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 24 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0169
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0092
============================================================


============================================================
🔄 Round 25 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 25 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0161
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0050
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2424, R²: -0.0100

============================================================
🔄 Round 26 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 26 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0180
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0018
============================================================


============================================================
🔄 Round 27 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 27 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0067
   Val:   Loss=0.0972, RMSE=0.3117, R²=-0.0296
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2425, R²: -0.0103

============================================================
🔄 Round 28 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 28 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0118
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0096
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2426, R²: -0.0105

============================================================
🔄 Round 30 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 30 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0062
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0264
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2428, R²: -0.0110

============================================================
🔄 Round 31 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 31 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0128
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0010
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2429, R²: -0.0112

============================================================
🔄 Round 32 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 32 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0125
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0031
============================================================


============================================================
🔄 Round 33 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 33 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0149
   Val:   Loss=0.0920, RMSE=0.3032, R²=0.0023
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: -0.0114

============================================================
🔄 Round 35 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 35 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0056
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0265
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2431, R²: -0.0118

📊 Round 35 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2432, R²: -0.0120

📊 Round 35 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2432, R²: -0.0121

============================================================
🔄 Round 38 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 38 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0088
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0026
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2432, R²: -0.0122

📊 Round 38 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2433, R²: -0.0124

📊 Round 38 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2433, R²: -0.0126

============================================================
🔄 Round 44 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 44 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0071
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0062
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2434, R²: -0.0129

📊 Round 44 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2435, R²: -0.0131

📊 Round 44 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2435, R²: -0.0132

============================================================
🔄 Round 51 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 51 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0131
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0146
============================================================


============================================================
🔄 Round 53 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 53 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0104
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0022
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2436, R²: -0.0132

============================================================
🔄 Round 60 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 60 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0004
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0410
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2436, R²: -0.0134

============================================================
🔄 Round 62 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 62 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0105
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0027
============================================================


============================================================
🔄 Round 64 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 64 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0091
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0057
============================================================


============================================================
🔄 Round 65 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 65 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0057
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0063
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2437, R²: -0.0137

============================================================
🔄 Round 66 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 66 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0051
   Val:   Loss=0.0735, RMSE=0.2710, R²=-0.0086
============================================================


============================================================
🔄 Round 67 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 67 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0107
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0010
============================================================


============================================================
🔄 Round 68 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 68 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0084
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0020
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2437, R²: -0.0138

📊 Round 68 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2438, R²: -0.0139

============================================================
🔄 Round 71 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 71 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0032
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0137
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2438, R²: -0.0140

============================================================
🔄 Round 72 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 72 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0070
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0014
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2438, R²: -0.0141

============================================================
🔄 Round 73 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 73 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0052
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0066
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2438, R²: -0.0141

📊 Round 73 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2439, R²: -0.0144

📊 Round 73 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2439, R²: -0.0144

============================================================
🔄 Round 79 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 79 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0042
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0082
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2439, R²: -0.0144

============================================================
🔄 Round 80 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 80 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0024
   Val:   Loss=0.0690, RMSE=0.2626, R²=-0.0208
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2439, R²: -0.0146

📊 Round 80 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2439, R²: -0.0145

============================================================
🔄 Round 87 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 87 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0029
   Val:   Loss=0.0943, RMSE=0.3072, R²=-0.0171
============================================================


============================================================
🔄 Round 88 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 88 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0086
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0032
============================================================


============================================================
🔄 Round 89 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 89 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0009
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0462
============================================================


============================================================
🔄 Round 90 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 90 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0063
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0026
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2440, R²: -0.0147

📊 Round 90 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2440, R²: -0.0149

📊 Round 90 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2440, R²: -0.0150

📊 Round 90 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2440, R²: -0.0149

============================================================
🔄 Round 97 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 97 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0026
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0131
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2440, R²: -0.0148

📊 Round 97 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2440, R²: -0.0149

============================================================
🔄 Round 100 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 100 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0027
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0272
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2441, R²: -0.0150

============================================================
🔄 Round 101 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 101 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0026
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0108
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2441, R²: -0.0152

============================================================
🔄 Round 105 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 105 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0006
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0381
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2441, R²: -0.0152

============================================================
🔄 Round 106 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 106 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0083
   Val:   Loss=0.0938, RMSE=0.3063, R²=0.0062
============================================================


============================================================
🔄 Round 107 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 107 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0008
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0250
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2442, R²: -0.0156

============================================================
🔄 Round 112 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 112 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0037
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0032
============================================================


============================================================
🔄 Round 117 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 117 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0027
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0107
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2442, R²: -0.0154

============================================================
🔄 Round 118 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 118 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0035
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0051
============================================================


============================================================
🔄 Round 119 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 119 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0028
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0095
============================================================


============================================================
🔄 Round 121 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 121 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0036
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0053
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2442, R²: -0.0156

📊 Round 121 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2442, R²: -0.0156

============================================================
🔄 Round 123 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 123 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0017
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0192
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2442, R²: -0.0155

📊 Round 123 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2442, R²: -0.0155

============================================================
🔄 Round 126 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 126 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0046
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0035
============================================================


============================================================
🔄 Round 127 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 127 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0013
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0193
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0157

📊 Round 127 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2442, R²: -0.0156

📊 Round 127 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0157

============================================================
🔄 Round 132 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 132 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0058
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0013
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0157

📊 Round 132 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0158

📊 Round 132 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0159

📊 Round 132 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0159

📊 Round 132 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0160

📊 Round 132 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0161

📊 Round 132 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0159

📊 Round 132 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0159

📊 Round 132 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0158

📊 Round 132 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0157

📊 Round 132 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2442, R²: -0.0155

============================================================
🔄 Round 146 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 146 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0054
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0029
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2442, R²: -0.0155

============================================================
🔄 Round 149 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 149 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0003
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0552
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2442, R²: -0.0156

============================================================
🔄 Round 150 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 150 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0078
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0034
============================================================


============================================================
🔄 Round 151 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 151 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0053
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0005
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0787, RMSE: 0.2804, MAE: 0.2442, R²: -0.0155

============================================================
🔄 Round 152 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 152 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0005
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0550
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2442, R²: -0.0155

============================================================
🔄 Round 153 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 153 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0008
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0281
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2442, R²: -0.0156

============================================================
🔄 Round 156 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 156 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0006
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0168
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0156

============================================================
🔄 Round 158 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 158 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0020
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0122
============================================================


============================================================
🔄 Round 160 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 160 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0059
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0049
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0158

============================================================
🔄 Round 162 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 162 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0026
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0062
============================================================


============================================================
🔄 Round 163 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 163 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0023
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0086
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0157

============================================================
🔄 Round 164 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 164 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0015
   Val:   Loss=0.0948, RMSE=0.3080, R²=-0.0243
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0157

📊 Round 164 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0158

============================================================
🔄 Round 166 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 166 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0009
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0213
============================================================


============================================================
🔄 Round 167 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 167 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0012
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0110
============================================================


============================================================
🔄 Round 168 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 168 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0102
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0278
============================================================


============================================================
🔄 Round 170 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 170 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0014
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0226
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2444, R²: -0.0161

============================================================
🔄 Round 172 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 172 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0054
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0010
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2444, R²: -0.0162

============================================================
🔄 Round 174 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 174 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0035
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0009
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2444, R²: -0.0161

============================================================
🔄 Round 176 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 176 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0015
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0108
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2444, R²: -0.0160

============================================================
🔄 Round 177 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 177 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0032
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0035
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2444, R²: -0.0160

============================================================
🔄 Round 178 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 178 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0024
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0071
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2444, R²: -0.0160

============================================================
🔄 Round 180 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 180 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0059
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0022
============================================================


============================================================
🔄 Round 181 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 181 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0038
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0003
============================================================


============================================================
🔄 Round 182 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 182 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0054
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0035
============================================================


============================================================
🔄 Round 183 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 183 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0031
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0026
============================================================


============================================================
🔄 Round 184 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 184 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0046
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0086
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2444, R²: -0.0160

============================================================
🔄 Round 185 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 185 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0058
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0069
============================================================


============================================================
🔄 Round 187 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.1016 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.1016, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.1016, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.1015, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.1015, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.1015, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1016)

============================================================
📊 Round 187 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0005
   Val:   Loss=0.1016, RMSE=0.3187, R²=-0.0247
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0158

📊 Round 187 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0159

============================================================
🔄 Round 189 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 189 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0010
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0161
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2444, R²: -0.0160

============================================================
🔄 Round 191 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 191 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0039
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0008
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2444, R²: -0.0161

============================================================
🔄 Round 193 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 193 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0007
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0195
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2444, R²: -0.0161

============================================================
🔄 Round 194 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 194 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0084
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0014
============================================================


============================================================
🔄 Round 195 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 195 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0014
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0156
============================================================


============================================================
🔄 Round 196 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 196 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0055
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0060
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2443, R²: -0.0159

📊 Round 196 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2444, R²: -0.0159

📊 Round 196 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2444, R²: -0.0159

============================================================
🔄 Round 200 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 200 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0033
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0021
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2444, R²: -0.0160

============================================================
🔄 Round 202 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 202 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0031
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0029
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2444, R²: -0.0161

============================================================
🔄 Round 203 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 203 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0016
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0212
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2444, R²: -0.0161

============================================================
🔄 Round 209 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 209 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0009
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0318
============================================================


============================================================
🔄 Round 210 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 210 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0021
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0177
============================================================


============================================================
🔄 Round 211 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 211 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0033
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0027
============================================================


❌ Client client_15 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
