[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 450b26fb-e7e3-40a6-ad51-386e46b13442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b11a34c0-3693-4444-8651-423e2e53363a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a545a0cd-2c7f-41a9-9174-39d89b21a266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb38859-c69e-4aa7-a6a9-25c6fe4e8bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 863f7654-0f3c-4547-bdc9-573c9c896442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 043ee074-93ac-4208-9848-f034671070d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ee578a6-1a45-451e-be8f-2ba6bdda57fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b16c7b6-817c-4776-9b90-a5cca4281077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b07180f0-75a1-4b94-89b7-56b7ff390384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2870bdd-f59c-4236-b6ee-a0fceebc233e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ce83374-f39c-4bf4-be1f-4852aaed5d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17b90515-ca41-44a1-9a24-c6a9c1dd21ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdc31fd2-06a9-4ae5-b623-bbc7e5d19284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf0f3175-bcce-45a6-8782-454dfdadd109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e59666e-3b98-49cb-9db9-103d582c9c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbf76cba-7426-472d-a6a6-3731cc534f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01aa765c-5a0e-4009-bd7d-1ab75516b10c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b8225a7-b8b9-4b80-a267-72ff20d26a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8698c7d6-dbee-4c08-aa4a-a4ef29bd2c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3465863d-1a0b-4288-ba41-ecfc2d0794eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0097e2e-1212-48a9-9245-f951da8b6db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b40a047e-89da-4054-b2e3-104c0519644a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 888494d0-f932-4a1b-8dc9-1aef323f617a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e94438eb-96cd-4dae-a649-96e9ff7cfc8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c79580ad-d422-494a-9da4-090c7bfabaa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf813363-079c-45e8-b397-9bd411e4b4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38f6e3cc-0cf7-48df-92c4-25abc88ff0d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e92cf8f4-f759-4927-9c55-5f9e15b89763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71727b6f-e7cd-4d9f-a222-30ee01c04ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10213d5d-d560-440f-8581-134f20540a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63146925-164b-4cfc-8e5f-a0210648caa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab6351e9-937a-4833-9b79-a19b54a6485b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6767ad62-ec69-4f69-85f9-7177477b6837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0af5a64f-d4fb-415a-ade3-7d8cd4bd30f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 594d62da-5772-4e12-b690-265dd72f3868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6d97c81-9330-4b91-a3f2-704f1a2de02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c2b7e4e-2369-423a-a096-848f4609d805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a3db925-6e6e-43ee-b7ff-5e94a84485e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7ef54bd-762b-4b0c-9955-4236ad99adb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94a2288d-a0df-4f0c-abc5-0a10447b4418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b853c796-061f-4de2-a18c-5eaf8fdb533e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24f37800-fdef-4425-935f-2bdfdb2727a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82140f83-a81e-4dfa-9da5-914ac7fc24dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9db5b20a-eda9-4cc1-aeea-01288ce1ff92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f72659fe-93e2-49ea-ba7e-7f8a2e70d1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f7d5e3d-0c20-462f-a214-0dbf4d8183aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1eb4543-1192-4e14-aebf-e281c33f4dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac4508f5-8c73-4732-927f-4f7fa3026a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47192ce8-d356-4b60-b43f-0586d36c4735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be8c1d66-4898-4fc1-a422-e9a7af026429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bf11dc7-8d26-4e64-a0f5-0c018c9d8887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74944b02-10ba-4064-ad09-db97ffdf8e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7524a55f-abd1-4e50-bf3c-6267f66a61d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf8eee56-c94e-4f77-833c-c0737bf8e96c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd8cbdfa-3ead-4aae-8194-c96fc343bbb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94a00426-1b8a-416a-81f1-111d9ded42f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 479479b3-8fb9-42e5-9b2d-d72103bf4bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11d842b4-5807-419d-855f-cae8bfb3e8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c5ea26b-330f-45d5-bb1c-8e3585f347b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43a4091f-a453-4fbb-be39-b8240276b483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 037d1edd-e22b-44bd-911e-5f6f49e4befc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34c47ea7-1837-4a0b-b453-cc7fd55becc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e518a20-ee07-4720-889c-7abf05dc19d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a31d985-a262-4276-bde5-844213597962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd13b0fb-68c4-401d-8848-d41152ff83d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a1c1cf1-a8a3-4c81-ad45-04e358dbaeda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5be3e919-e946-4849-a064-82b93bb950b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1b0dd11-d19a-4157-9f12-a2c2ff9ceb6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22dd93cb-df87-4dea-92ca-9dc6df849f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ff91c2d-070c-497a-b992-d77b255127d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 615e049f-6f9e-4bc5-96b5-b2a933d2d7e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4128261-6903-4571-8012-6d75ad35ad67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76dd2228-7da9-450a-a040-79766964d811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fd39026-a6b0-4745-b205-471153fda1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59ada1d0-9cb7-4264-808e-b128bdb12a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2644ec0c-1e8b-4ed3-82b0-93a69eed47d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f718e42-6d5a-4524-bf5a-d0d4da97db5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31f847ee-545b-4b87-8f1f-4dfeb00955be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a0d6cfd-2577-4771-8524-fb935bdf8623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96980d95-a19f-4864-95fb-5bc530126dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1c1f7b9-0105-45cf-a066-5c580b364317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62edf17c-7306-4d82-86a0-934160b39504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2b1f24e-d5dd-4b65-9084-327f4feddc6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28ef64c3-ce11-484f-8188-bbb884ef378e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 205b3687-d89e-4112-82ca-492596c76fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69736f05-ed3a-49c0-afa3-6a5cc36e1b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b81cb4a-2f58-4087-b345-394827ce52e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8716c9b8-fe3a-436b-9fe7-c79428140337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3085df0b-6f89-4a6f-93ee-b78ee05f64b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26dc071f-f205-4858-95e9-235c39e02b4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71020f34-5063-44ae-8091-4a1943538a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4f868fc-32e0-4106-a41c-20d74c4168e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31596e65-4c8a-42b1-87b9-547f1196414c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b934f4c-0852-4a83-af64-4b215715fee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb2c3395-c753-418e-a5fa-f81e07e77d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0c3bec2-f948-4a93-8d27-be76cd5ce364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31dcd6bf-08ed-4e00-b021-a2ff18e11264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f8cf446-c7cd-41ce-9896-cdfa7a493d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b93934df-892b-4c52-b38a-dd637599bdc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92a8d5d8-3ce3-45ca-84e5-55dbdc89e1b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34fca36b-7a24-4a13-8664-10d1a29d3de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 100a2c5a-728d-4d1b-999b-346c52f66306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92832d9c-3182-46ee-ab3c-9a2b464cb6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0f5d18e-02e3-4d4f-a37b-eaed4be3a5aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adcfcca1-b350-4d26-bf50-c33c39279123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff48c738-4565-4bab-b49b-993440f9ab16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e4370b6-5555-4594-89d9-f4bff779fb4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98577de9-a446-436f-9bb7-d8bba2eb72e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ceedd6-d4b3-4aa7-907b-008169eeafad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3c7cb69-f1a3-47d6-8ff3-54e79d77b111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 419f54ea-a6d7-46d7-a60a-9ea390397f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2209af2-ad62-4878-a61c-9c5e86c51f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65f2030a-77bb-43c9-8f22-8ab4441aaa7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b90d1b67-646c-455a-ac7b-64d0e8e2cf77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b6ef6f9-e761-42ba-b2a1-d4924b20076a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d516360c-e8b2-44ec-88ff-1597d6752659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4c714b8-149b-4f70-b566-7f22af71f367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab06b78e-2172-422d-8d99-06765447c4ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42f000e8-3f68-4e49-b827-305d43e91841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9c17682-d62e-45a8-9107-7e4103afeb11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1521eb1d-7742-4c77-a78c-fea16a3f2cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87994772-39c7-48c6-aa58-20708888f4b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9683b6db-3536-4995-be3d-cc630ddb1e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff1a23ec-1ebf-43b9-a815-43883050a2ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 721b2d35-a52b-4cd5-b26d-25120a376dba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c94c5c7-dbf7-4b2d-a27f-ea39536b8ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb6a60eb-167f-4cb6-b6e8-e8020e4a29ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a04eb6b0-acdf-4c25-a421-fcc86ec1c4f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3608898-70b7-42b2-935e-4b8114e377a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cab7056-568c-4131-aed1-46cca4cc1fd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3d1f8d1-871e-49ac-812e-a33ad6aac296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f620af02-b7a9-4b1e-b91d-a66d69516b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f633cfaa-8f34-46ec-b9ab-db0a866e3f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02dd4eed-8b9a-4074-9104-4b3213e4cd4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2b12e87-ab20-4bde-8cbf-bba4a3a43f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52ecde47-05e8-4ac0-a8e2-afc15c7ad290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b8ca47-5853-4669-bb43-7248746e8bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a53893c-c032-48d6-9bd6-0e4dae0fedd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49fef323-0bc9-40d0-a6a6-d8df9227983e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ac4926a-b61d-4dff-b197-093955787095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b237f257-5b83-483b-8407-a1b9159bb8ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ae6ded6-be30-452f-81f6-5c343eac35bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 992cab50-8369-430e-b9fd-8079e81ef9ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18374f2c-e679-438b-8594-ca81a5e9ce28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 012b26bf-bb99-440a-95a1-6cbc72dcbed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1763c2ae-aa8a-4af4-b0b6-998ecfa8433e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dfc180f-4674-4d63-808b-f74f6b67d94a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cd257f2-9d41-4f2e-b8a5-d553bb7c7044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9e9c322-ae9f-4bb4-bfb0-05493e7fd391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eef3c29-e2f9-457e-a506-b032e43ff47d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6320b37f-a8f2-46d4-8ece-d2fb988fbe1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 652a5fd5-8281-4fa8-907d-690abb14e8b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e04bf12-cf43-4ce8-bfd6-eb072e95d6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58cb12a4-6d99-4719-ac5b-762017a70bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10aeb2ae-172c-4ee9-8ec7-6fae24eaab92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65fb9d78-663b-40ab-bcbb-f3a35a6140b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51f02ea8-dce0-4a0d-8e3c-49ef803125df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c2b1eb4-294d-4285-8ec9-d9838ee035a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2583b3de-b241-485e-98c5-3d7c0207d67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64e2c8b6-408a-40e5-bcb7-e61f04998a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac3da4f2-8058-47e2-857b-b048f4bf2bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35d2df7c-61d8-4680-9e07-7d14221f39c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a3ce95e-8d3a-4ff6-b22c-448c0c623f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68987524-4e58-41d0-a11b-949868ed311c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dad690f-835d-4df5-9536-a6a155b640c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d87e9db-a50d-4b5c-a64f-249163608579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7082228a-b5cf-40f5-98ff-ab782269fa12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf47f7b8-99a8-41c2-a8ca-316908d1641f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 163ff282-869d-4cbc-ba44-d9b6644aeea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01fe2f94-8f27-464a-b4fd-920f6cb4b760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e2d848a-3604-46ed-b630-0acf9252ac7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a09df00-c5fd-42ae-89ed-f6a049ce3c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7536605-40ec-489d-bc6d-5b9e2446f9cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1b4d7cd-1130-4fc3-8d1f-4649be48ca16
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_16
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/test_labels.txt

📊 Raw data loaded:
   Train: X=(1530, 24), y=(1530,)
   Test:  X=(383, 24), y=(383,)

⚠️  Limiting training data: 1530 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  374 samples, 5 features
✅ Client client_16 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1247, val=0.0994 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0821, val=0.0923 (↓), lr=0.001000
   • Epoch   3/100: train=0.0804, val=0.0928, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0797, val=0.0924, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0794, val=0.0926, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0779, val=0.0940, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 2 Summary - Client client_16
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0029
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0099
============================================================


============================================================
🔄 Round 3 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1793, val=0.1419 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1118, val=0.0848 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0834, val=0.0804 (↓), lr=0.000250
   • Epoch   4/100: train=0.0840, val=0.0803, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0828, val=0.0800, patience=2/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0826, val=0.0802, patience=8/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 3 Summary - Client client_16
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0097
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0100
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.1969, RMSE: 0.4437, MAE: 0.3612, R²: -1.4288

📊 Round 3 Test Metrics:
   Loss: 0.1770, RMSE: 0.4207, MAE: 0.3405, R²: -1.1835

📊 Round 3 Test Metrics:
   Loss: 0.1705, RMSE: 0.4129, MAE: 0.3339, R²: -1.1028

📊 Round 3 Test Metrics:
   Loss: 0.1637, RMSE: 0.4046, MAE: 0.3270, R²: -1.0196

============================================================
🔄 Round 10 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.1541, val=0.1387 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1237, val=0.1202 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1059, val=0.1049 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0919, val=0.0943 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0836, val=0.0897 (↓), lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0802, val=0.0889, patience=5/15, lr=0.000031
   📉 Epoch 17: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0801, val=0.0889, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 10 Summary - Client client_16
   Epochs: 21/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0015
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0013
============================================================


============================================================
🔄 Round 11 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1621, val=0.1624 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1559, val=0.1560 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1497, val=0.1504 (↓), lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   ✓ Epoch   4/100: train=0.1443, val=0.1453 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1404, val=0.1429 (↓), lr=0.000008
   ✓ Epoch  11/100: train=0.1270, val=0.1300 (↓), lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004
   📉 Epoch 20: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.1162, val=0.1203, patience=1/15, lr=0.000002
   📉 Epoch 28: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.1125, val=0.1167 (↓), lr=0.000001
   • Epoch  41/100: train=0.1104, val=0.1148, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1085, val=0.1129, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1066, val=0.1110 (↓), lr=0.000001
   • Epoch  71/100: train=0.1048, val=0.1093, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1030, val=0.1075, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.1013, val=0.1059, patience=2/15, lr=0.000001

============================================================
📊 Round 11 Summary - Client client_16
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0999, RMSE=0.3160, R²=-0.2361
   Val:   Loss=0.1044, RMSE=0.3232, R²=-0.1996
============================================================


============================================================
🔄 Round 12 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1585, val=0.1656 (↓), lr=0.000001
   • Epoch   2/100: train=0.1582, val=0.1652, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1579, val=0.1649 (↓), lr=0.000001
   • Epoch   4/100: train=0.1575, val=0.1645, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1572, val=0.1642 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1555, val=0.1625 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1529, val=0.1598 (↓), lr=0.000001
   • Epoch  31/100: train=0.1506, val=0.1575, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1484, val=0.1552, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1463, val=0.1530 (↓), lr=0.000001
   • Epoch  61/100: train=0.1442, val=0.1509, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1421, val=0.1488, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1401, val=0.1467 (↓), lr=0.000001
   • Epoch  91/100: train=0.1381, val=0.1446, patience=1/15, lr=0.000001

============================================================
📊 Round 12 Summary - Client client_16
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1365, RMSE=0.3695, R²=-0.6784
   Val:   Loss=0.1428, RMSE=0.3778, R²=-0.6826
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1328, RMSE: 0.3644, MAE: 0.2951, R²: -0.6383

============================================================
🔄 Round 16 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1301, val=0.1491 (↓), lr=0.000001
   • Epoch   2/100: train=0.1299, val=0.1489, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1297, val=0.1486, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1295, val=0.1484 (↓), lr=0.000001
   • Epoch   5/100: train=0.1293, val=0.1482, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1281, val=0.1468, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1261, val=0.1445, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1241, val=0.1422 (↓), lr=0.000001
   • Epoch  41/100: train=0.1221, val=0.1398, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1200, val=0.1375, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1180, val=0.1351 (↓), lr=0.000001
   • Epoch  71/100: train=0.1160, val=0.1328, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1140, val=0.1304, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1121, val=0.1281 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_16
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1101, RMSE=0.3318, R²=-0.3603
   Val:   Loss=0.1260, RMSE=0.3550, R²=-0.4697
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1098, RMSE: 0.3313, MAE: 0.2722, R²: -0.3543

📊 Round 16 Test Metrics:
   Loss: 0.0979, RMSE: 0.3129, MAE: 0.2606, R²: -0.2077

============================================================
🔄 Round 20 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0927, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0926, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0925, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0924, val=0.0888, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0923, val=0.0887 (↓), lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0879, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0904, val=0.0868, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0894, val=0.0857, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0885, val=0.0848, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0876, val=0.0839, patience=3/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0868, val=0.0831 (↓), lr=0.000001
   • Epoch  71/100: train=0.0862, val=0.0824, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0856, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0851, val=0.0813, patience=5/15, lr=0.000001

============================================================
📊 Round 20 Summary - Client client_16
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0171
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0243
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2467, R²: -0.0265

============================================================
🔄 Round 21 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0904, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.0829, val=0.0897, patience=6/15, lr=0.000001
   • Epoch  31/100: train=0.0824, val=0.0891, patience=8/15, lr=0.000001
   • Epoch  41/100: train=0.0821, val=0.0886, patience=9/15, lr=0.000001
   • Epoch  51/100: train=0.0818, val=0.0882, patience=8/15, lr=0.000001
   • Epoch  61/100: train=0.0815, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.0814, val=0.0877, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 21 Summary - Client client_16
   Epochs: 72/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0086
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0167
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2461, R²: -0.0137

============================================================
🔄 Round 22 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0763, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0852, val=0.0758, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0849, val=0.0754, patience=12/15, lr=0.000001
   • Epoch  41/100: train=0.0846, val=0.0752, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 22 Summary - Client client_16
   Epochs: 48/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0077
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0191
============================================================


============================================================
🔄 Round 23 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0776, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0840, val=0.0772, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0838, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0836, val=0.0767, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 23 Summary - Client client_16
   Epochs: 42/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0074
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0097
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2459, R²: -0.0049

📊 Round 23 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2460, R²: -0.0035

📊 Round 23 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2460, R²: -0.0034

📊 Round 23 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2460, R²: -0.0027

============================================================
🔄 Round 32 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 32 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0050
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0299
============================================================


============================================================
🔄 Round 33 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 33 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0082
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0072
============================================================


============================================================
🔄 Round 34 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 34 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0102
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0010
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2461, R²: -0.0020

📊 Round 34 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2461, R²: -0.0019

============================================================
🔄 Round 39 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 39 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0096
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0049
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2461, R²: -0.0015

============================================================
🔄 Round 40 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 40 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0111
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0075
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2461, R²: -0.0014

============================================================
🔄 Round 42 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 42 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0077
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0005
============================================================


============================================================
🔄 Round 43 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 43 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0050
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0121
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2461, R²: -0.0012

📊 Round 43 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2461, R²: -0.0012

📊 Round 43 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2461, R²: -0.0012

📊 Round 43 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2462, R²: -0.0011

📊 Round 43 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2462, R²: -0.0010

📊 Round 43 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2462, R²: -0.0010

============================================================
🔄 Round 55 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 55 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0109
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0069
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2462, R²: -0.0010

============================================================
🔄 Round 57 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 57 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0032
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0167
============================================================


============================================================
🔄 Round 58 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 58 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0060
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0035
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2462, R²: -0.0009

============================================================
🔄 Round 60 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 60 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0041
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0094
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2462, R²: -0.0009

📊 Round 60 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2462, R²: -0.0008

📊 Round 60 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2462, R²: -0.0007

============================================================
🔄 Round 67 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 67 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0083
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0025
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2462, R²: -0.0007

============================================================
🔄 Round 70 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 70 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0007
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0323
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2462, R²: -0.0007

============================================================
🔄 Round 72 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 72 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0026
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0165
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2462, R²: -0.0006

============================================================
🔄 Round 74 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 74 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0053
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0094
============================================================


============================================================
🔄 Round 76 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 76 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0022
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0172
============================================================


============================================================
🔄 Round 77 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 77 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0007
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0335
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2463, R²: -0.0005

📊 Round 77 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2462, R²: -0.0005

📊 Round 77 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2463, R²: -0.0005

============================================================
🔄 Round 80 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 80 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0067
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0061
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2463, R²: -0.0005

============================================================
🔄 Round 81 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 81 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0011
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0281
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2463, R²: -0.0005

============================================================
🔄 Round 86 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 86 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0038
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0055
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2462, R²: -0.0005

============================================================
🔄 Round 87 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 87 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0039
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0111
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2463, R²: -0.0005

📊 Round 87 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2463, R²: -0.0004

📊 Round 87 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2463, R²: -0.0004

============================================================
🔄 Round 90 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 90 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0020
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0209
============================================================


============================================================
🔄 Round 92 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 92 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0084
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0009
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2463, R²: -0.0004

============================================================
🔄 Round 93 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 93 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0012
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0174
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2463, R²: -0.0003

============================================================
🔄 Round 94 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 94 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0023
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0107
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0003

============================================================
🔄 Round 96 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 96 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0036
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0039
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2463, R²: -0.0003

============================================================
🔄 Round 98 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 98 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0035
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0045
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2463, R²: -0.0003

============================================================
🔄 Round 99 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 99 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0049
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0005
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0003

============================================================
🔄 Round 102 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 102 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0062
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0155
============================================================


============================================================
🔄 Round 103 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 103 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0098
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0026
============================================================


============================================================
🔄 Round 104 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 104 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0095
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0090
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0002

============================================================
🔄 Round 105 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 105 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0010
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0140
============================================================


============================================================
🔄 Round 107 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 107 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0100
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0106
============================================================


============================================================
🔄 Round 108 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 108 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0007
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0159
============================================================


============================================================
🔄 Round 109 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 109 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0015
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0149
============================================================


============================================================
🔄 Round 110 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 110 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0050
   Val:   Loss=0.0827, RMSE=0.2877, R²=0.0030
============================================================


============================================================
🔄 Round 113 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 113 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0045
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0002
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0002

📊 Round 113 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0002

============================================================
🔄 Round 116 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 116 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0035
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0026
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0002

📊 Round 116 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0002

📊 Round 116 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0002

============================================================
🔄 Round 121 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 121 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0042
   Val:   Loss=0.0687, RMSE=0.2621, R²=0.0003
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0001

📊 Round 121 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0001

============================================================
🔄 Round 124 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 124 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=-0.0027
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0048
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0001

============================================================
🔄 Round 127 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 127 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0030
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0030
============================================================


============================================================
🔄 Round 128 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 128 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0010
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0124
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0001

============================================================
🔄 Round 131 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 131 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0021
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0081
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: -0.0001

📊 Round 131 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: -0.0001

📊 Round 131 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: -0.0001

📊 Round 131 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: -0.0001

📊 Round 131 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: -0.0001

============================================================
🔄 Round 137 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 137 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0052
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0008
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: -0.0001

============================================================
🔄 Round 138 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 138 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0008
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0290
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: -0.0000

📊 Round 138 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: -0.0001

📊 Round 138 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: -0.0001

============================================================
🔄 Round 144 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 144 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0035
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0025
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0001

============================================================
🔄 Round 146 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 146 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0007
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0215
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0001

============================================================
🔄 Round 147 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 147 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0046
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0019
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0001

============================================================
🔄 Round 151 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 151 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0019
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0073
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0001

============================================================
🔄 Round 152 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 152 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0041
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0006
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0001

📊 Round 152 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2463, R²: -0.0001

============================================================
🔄 Round 155 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 155 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0006
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0220
============================================================


============================================================
🔄 Round 157 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 157 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0021
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0105
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: -0.0000

📊 Round 157 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: -0.0000

============================================================
🔄 Round 168 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 168 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0029
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0023
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: -0.0000

============================================================
🔄 Round 170 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 170 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0044
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0017
============================================================


============================================================
🔄 Round 171 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 171 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0005
   Val:   Loss=0.0780, RMSE=0.2794, R²=-0.0112
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

============================================================
🔄 Round 172 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 172 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0020
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0067
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

============================================================
🔄 Round 176 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 176 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0017
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0068
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

📊 Round 176 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

📊 Round 176 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

============================================================
🔄 Round 181 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 181 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0000
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0282
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

============================================================
🔄 Round 183 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 183 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0027
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0013
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

============================================================
🔄 Round 186 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 186 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0040
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0034
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

============================================================
🔄 Round 189 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 189 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0028
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0022
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

============================================================
🔄 Round 192 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 192 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0026
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0021
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

============================================================
🔄 Round 194 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 194 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0035
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0010
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0001

============================================================
🔄 Round 196 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 196 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0000
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0338
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

============================================================
🔄 Round 197 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 197 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0067
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0004
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

📊 Round 197 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

============================================================
🔄 Round 201 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 201 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0006
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0143
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

============================================================
🔄 Round 203 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 203 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0023
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0030
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

📊 Round 203 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

============================================================
🔄 Round 206 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 206 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0049
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0020
============================================================


============================================================
🔄 Round 207 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 207 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0022
   Val:   Loss=0.0695, RMSE=0.2637, R²=-0.0034
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2464, R²: 0.0000

============================================================
🔄 Round 209 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 209 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0018
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0069
============================================================


============================================================
🔄 Round 210 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 210 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0036
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0006
============================================================


============================================================
🔄 Round 211 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 211 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0049
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0003
============================================================


❌ Client client_16 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
