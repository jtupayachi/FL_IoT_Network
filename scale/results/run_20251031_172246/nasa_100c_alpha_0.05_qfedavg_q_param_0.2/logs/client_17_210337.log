[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b0766ae-a0df-4090-b227-e8f805ef6809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7726563f-954c-4586-8e90-f0ca38b6928d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d7f60b8-7e9e-40db-8b69-d5e9e317bbce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 431ec846-2d0a-4a0f-be62-9af3199462b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ea30586-1ee0-4406-8586-c71ebe80e03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9db26bb-d059-4fe9-be0d-0cb398a8a47f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 683bb0e5-d68a-4660-a187-e11aa1499c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3709e7ef-693f-4b55-bf6d-a92b38e90a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb88bf29-18d0-4af5-9422-82fccb2a97fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80a013a3-6784-4ce6-99fd-1302dafb9a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89634e1e-86c3-4b10-b113-914070f43b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd00e587-d179-445c-b446-68743e514b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21841cc8-ba93-4d51-96f7-a9ff91ea749a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a584e4cc-e06a-4623-a2b9-637c770c0a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43a2f44e-e5bc-43ae-a46a-2271ae115a8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72123a3f-8a0d-478d-8942-269fb719f4d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b964051-6a17-4ee4-bb51-a2efad4ec27e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 338ceee8-a2f0-463f-8ddc-6889134ac036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 874e028c-aba8-4b63-88f6-2bc8b8ebce03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 553d0a71-b1bb-40bc-880c-14aeebac1578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9ab0bef-be83-45dd-a4ee-44f70f09cb10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acfb7635-9d30-4402-b32e-c9de6afb0c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71ec8cf0-4872-4f5a-9478-474e20ec7388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9bae695-5e69-43cd-80c6-7ebe10976412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1967a686-eca1-4ce6-a87e-5f2b9cbe768e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3acef61-9d14-48fd-af88-d721d0242558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b34e61fa-b226-4995-91df-1d6d4cb08f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3903693-bcdb-41a6-8609-b0fdbfed3969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a8e34ee-ecdf-459c-a949-5c0eaef76d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71d3868c-4283-479a-911a-217bff71b1cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71182af2-9612-46e9-a44d-990fb1e33669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2908826-4d7a-42af-919c-019250daa065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af542471-a7bb-4418-b810-a8595702e10b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a63e9c-1b82-4102-a0bd-f35e3cde5af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 460f84be-cddb-4934-aaeb-9b2872c76505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a889db97-d676-4515-8022-f2d19d5edf96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f81f774-1cba-4198-a5a1-ac7524128722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e8e7164-00b2-4491-bbb3-995f0880e9c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dee675ff-20a0-419c-8ecc-c715d715e54c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8c2eb5f-d640-48ef-8c07-86c5e9e2e7e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05ad13d1-3790-4f28-84e6-b1e176ac9215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dfe946d-00b1-4fac-85ff-4d98fee4896f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee61093b-bb4a-4097-9af4-ba06b773912b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdc3a2ea-7750-426c-a759-6ef5d88eabde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3168950b-5416-40ae-b2af-248d4d739f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56d8ea99-9cc7-478f-944e-77db17b33705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17040641-135e-4b40-b399-b80afde1f170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e98aede-7145-4a3f-a917-ed110b159c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05561c55-28b2-4382-97f8-c8b518ba8087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1ea6d7c-8b3b-4e51-9749-e55d61b76a3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1186279-2f8c-4208-b5bb-fc0f8e13ff26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33d91ee8-3b5c-4a23-bbfb-e8b4e4b01a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a290dcf-24c2-4b3a-b6c7-6b1c7f1029eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af02de5a-12a5-4cf2-8b36-d9c5fcd70ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55d97a3b-cdcd-4a8f-9844-1eda43473874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61861838-a385-401d-aecf-fa37e87be5df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54028c49-a645-451e-b074-0ad638e3cdb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f2b8b05-e3d4-4e5a-9691-17d04686e59c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d46556e-3d3e-44a4-a29a-ac294e4947eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc54c303-6355-4293-a81b-760ec62e2a95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a259c9e-01ed-47b2-ad60-71b91deb9fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce8876ce-1bd8-4bd6-a257-ace833883aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41dd5d6d-b3dc-4fa2-bc36-486c433a6193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21406a33-68bb-4cdb-9fce-65b06304279c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3783e6db-a73d-48f9-a495-5a5068585d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 663b6697-7bc5-486a-93a6-384368d68951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5859cadf-6df3-4b16-b0e5-3ec342db02d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81f579a9-1af8-42e7-822b-b86eedb61d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6837fb97-4db9-4a55-b2f5-5a59fe40dc76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2223510c-f15c-4cbf-b5e6-8b8971c61a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74ed9190-2b2f-4078-a261-a77753f1ebac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a827b704-7a04-4de8-a28b-cb8add99a401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3497ad75-eb30-40a3-91d1-271801bfb1aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a2e8df3-d10c-47a5-a159-16e57f5698b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46d021a7-4287-4bd8-a34f-f4647ba990ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 396fe968-8802-4211-a0f4-3be869750cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b41614ae-b325-4157-b628-80b3065a6afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8554c0ac-5298-4920-b32e-f2b48cbe5820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2453ef5-bb44-4811-ba52-93240ce1cd8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 726318ee-eed6-4c5c-b2af-49ba55c6faf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22216d67-dc4e-477a-91c4-1f50c6d5961d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78d76019-0115-49e1-b938-72a322426c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 436b0c54-2925-4402-a4f6-b8e851e83d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5ff03fa-1cbd-4678-b20a-da4f60223377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13293daa-4101-47b9-adbe-3cc9396a0863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5251688-45bf-46b7-a4f2-e5776a8dbe60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30881c53-2443-48b9-918f-e18521b233a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 594d036a-c64e-423d-8953-865f963a687a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba3a20f5-8c21-4c3b-95ff-fbd3fe1cf941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c1f8a61-ba3a-49fb-86d0-29cc98a86b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13398ddb-e57b-47e4-b5fa-96a316dbfef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e045a920-6750-4bc0-94a5-3a596801d250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9490070a-ccf1-4ea7-b658-9bc4d580c211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f875973d-5d59-4b73-b6f0-b46ad6f38750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cdb6bfd-2519-4040-97e2-a8cbc18d7f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb59078f-5a7e-4024-badf-652a8be896c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea634ba8-b232-43a8-a3a3-e122812103ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44dbd37c-2ddb-4e83-88be-236136cd4587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message befb023e-0486-4fc8-8d56-f1bbc26ed625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 973bb8ea-d52d-4500-a8b5-ff9d2504815f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30006845-1cb6-469f-85b2-c2d5f4e527b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2333773-be16-4284-b5f6-aa6836638aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef8f9e8c-c083-406c-a6e1-11522c6cc68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4add69f2-1565-4edd-998e-a39dda09da21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd1b1c5-fffa-4ca4-a801-090d99201724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd045858-a0f5-45ad-b20c-af68edae892b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e614e12-879e-45be-a137-0a41aa030930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d089795c-73d2-44e1-8a76-ac4594c36df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aba905e-afc3-4251-ac48-610983654d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0c5d31d-9976-45e0-8134-47738062cf79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0765e492-92cb-456e-adf4-b732f66e3c7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda337df-d609-4c0e-ad9e-24fe7d1ca16a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a9a17b5-6550-49c3-ad24-a32e20004a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bab93d1-a443-4f04-ad78-cbb6c1a598d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38cd88f3-3355-468d-9fb1-f98e956e4211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ce1c487-5f27-4438-ba1c-2b3624e127ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52f419b7-3dc7-4103-a43b-30044c0df34f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cb21410-1d37-4195-99de-00f4328612e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1bf4ba5-1e53-4cbd-88b8-1439b43fe51e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a81c531a-79fd-43a5-a934-f3faa975085d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa1cbaa8-c7f4-4fea-a442-f40cc2e1cf54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9ceb442-4d59-44c5-bfb4-cd9d7202cdf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a98b163f-37ea-476b-9c8b-0433495ac1a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a209388f-0070-4631-9d20-34425665c0c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f7eb337-b70a-466b-9448-7f5664324892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1d6c3bd-debe-4323-b074-d34c9be9b7e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b96bd476-a6ec-4daa-ad6f-9699d3a35fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ed12ef-5958-4629-b008-f5ce7adcafd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33de520d-02e1-4a02-a6c0-a08a08624db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a178c09-8948-4e79-8945-bd25add010fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fcb1f36-b2bd-4b19-a876-0cbef481a819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98ed1577-e4c6-4a7a-bebc-eb333c7f2d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6866a74-53f8-4543-8f32-0550812cdb8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d57e907-f21d-46c9-b74d-1ac209f2917b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4208c47-6a92-48c0-b7d7-9c55221bd96d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8290dc2-0646-4c21-95a9-c935bc4f68c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7526176-813a-4729-a591-2cfa90c935b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 286dca26-6ea6-44ed-a904-53f5b55f94f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70f175e2-e254-4608-80e6-ca8d9b5621eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 831ffc45-80cb-4cc4-bef9-7bac9ea11d58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11dd9e54-1ba8-437d-bd7b-a84471ac7148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5d3bff0-4633-4e52-8d0f-806afef25372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31c69557-3079-4699-af79-20211962f11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b20a5996-0d3e-47c9-80f2-3c5f91c2450d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3db3d98d-8e5f-4b11-9d42-5d945430d1a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90354ba0-2d60-43ff-b08a-a4422fc14502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 904b40af-0f85-48c3-a14a-a468528d06b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7267b80a-a0e5-486e-9188-a0afd23ade49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59c92ff6-a7d7-43f4-b4c1-e75809d45d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e607f65-47cb-4964-9b1a-df8888e95568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 803ee98f-ab21-495a-ba0d-ee50f82c4ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3e6af5b-4766-4b19-b2f0-e1cdbb888ce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 112edb00-95a3-459d-9d9a-bec78c755cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 141047aa-d1ae-4db6-ad22-8f531c7520ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88496bb9-5cfb-4cdd-bc6c-67d7cd4b23ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfc9d3d6-8dba-4da2-b004-06e7717bf557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a527c79f-143f-47e1-8115-c33f2162a2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b869dd7-59c5-4ba3-9dbe-37e170f67d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b86a3fa-0f8b-4866-b57b-41112b04c92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 975b22cd-dd9d-4033-aa52-1ea96d9ba489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 079c9cae-a57c-4ad4-ac58-1e442a63fcfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9235e478-ece6-460f-a1dd-60b86c5b7aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07381ac7-f59c-49ad-993e-3ec04cd1578c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bb644de-3646-4906-85f5-801f5b3d6d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6bd48d6-7e2e-4b4b-aaba-467056913913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dead18d-70eb-47bb-8c37-6fa0ea4dae1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 899f208c-5b8d-461a-ba44-b3a61ed98602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70f88cbb-76e0-4ff5-8883-616aaaf084ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5421b14b-eb33-4cde-8151-00cd5b4a18eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26a605cc-2ede-4641-93b4-4aa4329e1339
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_17
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_17
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_17/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_17/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_17/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_17/test_labels.txt

📊 Raw data loaded:
   Train: X=(1182, 24), y=(1182,)
   Test:  X=(296, 24), y=(296,)

⚠️  Limiting training data: 1182 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  287 samples, 5 features
✅ Client client_17 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1869, RMSE: 0.4323, MAE: 0.3483, R²: -1.2127

============================================================
🔄 Round 5 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1196, val=0.0836 (↓), lr=0.001000
   • Epoch   2/100: train=0.0811, val=0.0851, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0810, val=0.0869, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0817, val=0.0862, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0813, val=0.0860, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0796, val=0.0849, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 5 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0122
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0008
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1749, RMSE: 0.4183, MAE: 0.3367, R²: -1.0708

📊 Round 5 Test Metrics:
   Loss: 0.1687, RMSE: 0.4107, MAE: 0.3306, R²: -0.9966

============================================================
🔄 Round 9 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1448, val=0.1102 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0939, val=0.0813 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0821, val=0.0808 (↓), lr=0.000250
   • Epoch   4/100: train=0.0822, val=0.0808, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0820, val=0.0808, patience=2/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0814, val=0.0812, patience=8/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 9 Summary - Client client_17
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0020
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0054
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1622, RMSE: 0.4028, MAE: 0.3244, R²: -0.9202

============================================================
🔄 Round 10 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1641, val=0.1225 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1403, val=0.1046 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1188, val=0.0909 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1012, val=0.0820 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0887, val=0.0796 (↓), lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0814, val=0.0833, patience=6/15, lr=0.000031
   📉 Epoch 19: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 10 Summary - Client client_17
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0353
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0028
============================================================


============================================================
🔄 Round 11 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1601, val=0.1456 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1537, val=0.1397 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1473, val=0.1345 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1416, val=0.1298 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1363, val=0.1255 (↓), lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.1167, val=0.1104 (↓), lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.1034, val=0.1003 (↓), lr=0.000004
   📉 Epoch 23: LR reduced 0.000004 → 0.000002
   📉 Epoch 31: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.0986, val=0.0969 (↓), lr=0.000001
   • Epoch  41/100: train=0.0968, val=0.0956, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.0951, val=0.0944, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0936, val=0.0934, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.0922, val=0.0924, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0909, val=0.0915, patience=5/15, lr=0.000001
   • Epoch  91/100: train=0.0896, val=0.0907, patience=2/15, lr=0.000001

============================================================
📊 Round 11 Summary - Client client_17
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.1058
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0464
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1527, RMSE: 0.3907, MAE: 0.3153, R²: -0.8072

📊 Round 11 Test Metrics:
   Loss: 0.1422, RMSE: 0.3771, MAE: 0.3051, R²: -0.6831

📊 Round 11 Test Metrics:
   Loss: 0.1326, RMSE: 0.3642, MAE: 0.2961, R²: -0.5700

============================================================
🔄 Round 15 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1383, val=0.1203 (↓), lr=0.000001
   • Epoch   2/100: train=0.1380, val=0.1200, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1377, val=0.1198 (↓), lr=0.000001
   • Epoch   4/100: train=0.1374, val=0.1195, patience=1/15, lr=0.000001
   • Epoch   5/100: train=0.1372, val=0.1193, patience=2/15, lr=0.000001
   • Epoch  11/100: train=0.1356, val=0.1179, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1331, val=0.1158 (↓), lr=0.000001
   • Epoch  31/100: train=0.1308, val=0.1139, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1286, val=0.1120, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1265, val=0.1102 (↓), lr=0.000001
   • Epoch  61/100: train=0.1244, val=0.1084, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1223, val=0.1067, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1203, val=0.1049 (↓), lr=0.000001
   • Epoch  91/100: train=0.1182, val=0.1033, patience=1/15, lr=0.000001

============================================================
📊 Round 15 Summary - Client client_17
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1163, RMSE=0.3410, R²=-0.4154
   Val:   Loss=0.1018, RMSE=0.3190, R²=-0.2907
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1242, RMSE: 0.3525, MAE: 0.2889, R²: -0.4707

============================================================
🔄 Round 21 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0878, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0826, val=0.0872, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0823, val=0.0867, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0821, val=0.0863, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0819, val=0.0858, patience=11/15, lr=0.000001
   • Epoch  61/100: train=0.0818, val=0.0855, patience=9/15, lr=0.000001
   • Epoch  71/100: train=0.0817, val=0.0851, patience=5/15, lr=0.000001
   • Epoch  81/100: train=0.0816, val=0.0849, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 21 Summary - Client client_17
   Epochs: 81/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0057
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0472
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2533, R²: -0.0061

============================================================
🔄 Round 22 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0792, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0836, val=0.0789, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 22 Summary - Client client_17
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0129
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0194
============================================================


============================================================
🔄 Round 23 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0944, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0798, val=0.0941, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 23 Summary - Client client_17
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0060
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0419
============================================================


============================================================
🔄 Round 24 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 24 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0113
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0078
============================================================


============================================================
🔄 Round 25 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 25 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0068
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0201
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2533, R²: 0.0007

============================================================
🔄 Round 26 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 26 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0068
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0119
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2533, R²: 0.0010

============================================================
🔄 Round 29 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 29 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0086
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0048
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2534, R²: 0.0014

============================================================
🔄 Round 31 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 31 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0091
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0062
============================================================


============================================================
🔄 Round 35 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 35 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0050
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0070
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2534, R²: 0.0017

📊 Round 35 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2534, R²: 0.0018

============================================================
🔄 Round 38 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 38 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0092
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0090
============================================================


============================================================
🔄 Round 39 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 39 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0042
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0073
============================================================


============================================================
🔄 Round 40 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 40 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0037
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0114
============================================================


============================================================
🔄 Round 42 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 42 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0052
   Val:   Loss=0.0698, RMSE=0.2643, R²=-0.0022
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0019

📊 Round 42 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0020

============================================================
🔄 Round 44 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 44 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0046
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0073
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0019

📊 Round 44 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0019

============================================================
🔄 Round 47 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 47 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0069
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0035
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0020

============================================================
🔄 Round 48 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 48 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0015
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0148
============================================================


============================================================
🔄 Round 49 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 49 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0033
   Val:   Loss=0.0714, RMSE=0.2672, R²=-0.0481
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0020

============================================================
🔄 Round 51 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 51 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0025
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0161
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0020

📊 Round 51 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0020

📊 Round 51 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0020

============================================================
🔄 Round 55 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 55 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0043
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0035
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0020

============================================================
🔄 Round 56 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 56 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0047
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0022
============================================================


============================================================
🔄 Round 59 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 59 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0044
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0021
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0020

📊 Round 59 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0019

============================================================
🔄 Round 61 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 61 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0039
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0043
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0019

============================================================
🔄 Round 63 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 63 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0029
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0083
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0020

============================================================
🔄 Round 65 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 65 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0059
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0019
============================================================


============================================================
🔄 Round 68 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 68 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0037
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0081
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0019

============================================================
🔄 Round 70 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 70 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0045
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0008
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2535, R²: 0.0019

============================================================
🔄 Round 74 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 74 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0040
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0032
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2536, R²: 0.0019

============================================================
🔄 Round 75 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 75 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0058
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0056
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2536, R²: 0.0019

📊 Round 75 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2536, R²: 0.0019

============================================================
🔄 Round 79 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 79 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0038
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0022
============================================================


============================================================
🔄 Round 81 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 81 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0067
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0105
============================================================


============================================================
🔄 Round 82 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 82 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0033
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0057
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2536, R²: 0.0019

📊 Round 82 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2536, R²: 0.0019

============================================================
🔄 Round 86 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 86 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0027
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0072
============================================================


============================================================
🔄 Round 87 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 87 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0043
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0013
============================================================


============================================================
🔄 Round 88 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 88 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0026
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0062
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2536, R²: 0.0019

============================================================
🔄 Round 89 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 89 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0031
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0058
============================================================


============================================================
🔄 Round 90 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 90 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0022
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0354
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2536, R²: 0.0018

📊 Round 90 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2536, R²: 0.0018

============================================================
🔄 Round 94 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 94 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0032
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0036
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2536, R²: 0.0018

📊 Round 94 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2536, R²: 0.0018

📊 Round 94 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2536, R²: 0.0018

📊 Round 94 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2536, R²: 0.0018

📊 Round 94 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2536, R²: 0.0017

============================================================
🔄 Round 107 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 107 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0023
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0057
============================================================


============================================================
🔄 Round 108 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 108 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0038
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0011
============================================================


============================================================
🔄 Round 109 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 109 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0034
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0036
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0017

📊 Round 109 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0017

📊 Round 109 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0017

📊 Round 109 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0017

📊 Round 109 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0016

============================================================
🔄 Round 118 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 118 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0028
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0036
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0016

============================================================
🔄 Round 120 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 120 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0036
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0018
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0016

============================================================
🔄 Round 121 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 121 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0017
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0077
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0016

============================================================
🔄 Round 122 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 122 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0038
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0000
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0016

📊 Round 122 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0016

============================================================
🔄 Round 127 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 127 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0043
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0027
============================================================


============================================================
🔄 Round 128 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 128 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0037
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0018
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0016

============================================================
🔄 Round 129 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 129 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0014
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0164
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0016

📊 Round 129 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0016

📊 Round 129 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0015

📊 Round 129 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0015

============================================================
🔄 Round 133 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 133 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0055
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0079
============================================================


============================================================
🔄 Round 134 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 134 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0034
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0042
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2537, R²: 0.0015

📊 Round 134 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2537, R²: 0.0015

============================================================
🔄 Round 136 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 136 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0009
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0102
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2537, R²: 0.0015

📊 Round 136 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2537, R²: 0.0015

📊 Round 136 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2537, R²: 0.0015

============================================================
🔄 Round 140 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 140 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0046
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0085
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2537, R²: 0.0015

============================================================
🔄 Round 142 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 142 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0067
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0191
============================================================


============================================================
🔄 Round 144 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 144 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0038
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0002
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2537, R²: 0.0015

============================================================
🔄 Round 147 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 147 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0034
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0004
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2537, R²: 0.0015

============================================================
🔄 Round 148 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 148 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0022
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0050
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2537, R²: 0.0015

============================================================
🔄 Round 150 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 150 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0038
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0011
============================================================


============================================================
🔄 Round 151 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 151 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0061
   Val:   Loss=0.0699, RMSE=0.2644, R²=-0.0077
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2537, R²: 0.0014

📊 Round 151 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2537, R²: 0.0014

============================================================
🔄 Round 153 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 153 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0039
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0014
============================================================


============================================================
🔄 Round 154 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 154 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0019
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0097
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2537, R²: 0.0014

============================================================
🔄 Round 156 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 156 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0013
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0148
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2537, R²: 0.0014

============================================================
🔄 Round 162 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 162 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0045
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0154
============================================================


============================================================
🔄 Round 166 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 166 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0029
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0026
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2537, R²: 0.0013

📊 Round 166 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2537, R²: 0.0013

============================================================
🔄 Round 168 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 168 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0044
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0006
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2537, R²: 0.0013

📊 Round 168 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2537, R²: 0.0013

============================================================
🔄 Round 176 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 176 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0009
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0106
============================================================


============================================================
🔄 Round 177 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 177 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0020
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0048
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2537, R²: 0.0013

============================================================
🔄 Round 178 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 178 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0031
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0013
============================================================


============================================================
🔄 Round 180 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 180 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0033
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0001
============================================================


============================================================
🔄 Round 181 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 181 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0027
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0047
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2537, R²: 0.0012

============================================================
🔄 Round 182 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 182 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0027
   Val:   Loss=0.0920, RMSE=0.3032, R²=-0.0024
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2537, R²: 0.0012

📊 Round 182 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2537, R²: 0.0012

📊 Round 182 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2537, R²: 0.0012

============================================================
🔄 Round 189 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 189 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0028
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0017
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2538, R²: 0.0012

============================================================
🔄 Round 193 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 193 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0021
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0108
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2538, R²: 0.0012

📊 Round 193 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2538, R²: 0.0011

============================================================
🔄 Round 196 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 196 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0017
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0302
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2538, R²: 0.0012

📊 Round 196 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2537, R²: 0.0012

============================================================
🔄 Round 198 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 198 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0020
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0055
============================================================


============================================================
🔄 Round 200 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 200 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0009
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0146
============================================================


============================================================
🔄 Round 203 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 203 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0020
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0052
============================================================


============================================================
🔄 Round 204 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 204 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0030
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0002
============================================================


============================================================
🔄 Round 205 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 205 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0015
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0077
============================================================


============================================================
🔄 Round 207 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 207 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0032
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0003
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2538, R²: 0.0011

============================================================
🔄 Round 209 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 209 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0037
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.0020
============================================================


❌ Client client_17 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
