[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e54c4c5a-35cd-4365-b684-38bdc7415859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5387bb50-05da-4d8f-be6e-40fb7e5c554e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c448d6f6-d5e7-4f28-8df2-8be4b1863fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34072248-8aa7-4314-a3e2-e8e481947618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4796c83f-1bfc-46fa-a059-7eded618dcc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 224a02a7-7374-4193-bc63-272ec6777e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5aba9e5-23ea-4c5f-8940-7a02e232895e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 074e1e79-9fb3-405e-bc2a-3d0c254472f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2b13c99-9e41-4a19-b65c-96da79143b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c8b7410-0fa2-4ee7-b093-7f4b2e129d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc78cdbe-6cfa-4bbc-8f80-7aba8a2d3522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c5dfdb8-1416-433e-a528-2af0f3e38e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2526e19-ae4e-4c9a-870e-44315f76b41e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 886299a0-41f4-4358-810f-f17dfeb6d630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4d915cd-82eb-4f9c-a3fb-7a6cd442aebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 057de6ab-c3ff-4e5d-b147-c30f26207ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98f1eaac-af68-430b-b758-91933f9fdfd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac5a867f-108f-469f-97ce-5ce34f580141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d57d927-1209-4ee7-a4a8-b7e41e163e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fabaac0c-8ef7-4080-b584-1f6fe453d97c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aa24318-e06a-4391-af76-5843532ae33e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9242a5b6-a0e2-4adb-8af1-41db283c1f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd7ddb44-cf13-4d1e-88f3-7cb128903e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6187653-bfba-4ac0-87da-c2ac52c25e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1b97d7e-f06c-4390-8036-c3799cc0178d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ebc3055-2a72-4b3c-b9f8-1f4348378a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c4ad7ed-fbd6-4c97-a538-17e4982a7364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1bca354-0eaf-4397-baff-1d8aea0ab60b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bcce4aa-bf17-4376-b93b-feb3433aa07b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02fa8da7-334f-4401-a4b8-215e6907813f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1900b171-be4a-4409-a220-4e9cb20bba87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 091d71ca-4d63-4486-a456-d3b69d7e78b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 807c125a-a3b6-4be4-ba1f-fb42306922af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a030fca-60ce-45a2-8740-1814b768565c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79af6e8e-0cf4-4d46-99f6-d658e381571f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b2e697d-c0f4-4e4a-b3d1-35da01b6dc65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 605dca28-ff7e-4561-b81e-d04acbe31dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 126cc3f0-8255-4d7c-9c72-a8c7c3c0659c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63b945ad-4514-4ba3-b779-b79a450b96f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d32b278-acd8-4e8e-a9bf-106b6732c7c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47a91fe5-d5c1-45f6-974c-c151653d027d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96fcd127-1df9-477e-8e97-081d6b9b90cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2328d2e6-d9b1-44c4-859f-d27e3ef4a4a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b30202b4-0968-4bcd-856e-180f000e6a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0efcf0b-7dee-440e-a670-eb3071c1f1cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aa15aec-9f56-40c1-b281-27ac1576d608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d44b8405-aea5-4e05-bbcc-9cb315e91151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56efa6ca-a888-47aa-9a41-54fc6a1c4a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fb8fdfa-416b-4160-826e-be3b19c24a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c59a86f-2716-41d3-979d-8f2e30db8555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c788306-2cb6-4f64-9cd4-aca99c84db8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e214d0d-1b23-4a69-b1dd-75deaa500299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54080aa3-b58d-4e78-90c2-2af1d06aa5f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e091ea34-ee0f-44d4-97a3-3336f8f04967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af5e36d9-0254-4ced-8316-f113ab1fb1b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94bc666d-91f4-4f03-aea7-52d343c3b8e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc86005e-d04d-432d-b681-2b2e4741f105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd483eb6-3acd-4dc9-a3de-7de0df0f826c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65c4243e-89aa-48cb-aec6-00a689824345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a03c700-e9dd-4f3c-8c38-5a44606641a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15270a88-0a22-48b7-a41d-05a9a0ee6d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86bf8581-bff8-4ac5-8af1-e24a050c5822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd8c1f55-c663-4ff3-8aad-ebab38166677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85930eb7-74df-496e-adf0-16e4d2d9ebf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 891ab572-d491-4863-8884-5eaa95951601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53f28c1d-92bb-4d71-b84c-54466261c17d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7e8374b-f63c-4954-9e68-d9eb141cedab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9de7192-d375-4723-a041-43a40a9b0a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af01124a-d07a-4656-bfc1-5a855f68dd80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ea6f4b6-2f01-4cd4-bd4f-893187220c75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70f592e7-57a9-4577-9c6e-024f2129e4f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ff47547-c072-458b-9fc6-c83bfa54cdd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d8e161d-930f-4726-a9e8-11cc599e1eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96c7bb29-c8fa-4a5c-8c32-d2b17190fd69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a66accde-280a-424f-980f-d605ace4c4bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a7d814f-5765-4fce-92b2-be6d318fb4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1c21518-613c-4def-9dd2-b8875d87480f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9a6ffe9-3c7f-4005-9aac-4fc428f9064c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ccda09c-1606-4186-8bf5-01dd500601a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a3ab332-ef76-4db2-b692-5bca50d68efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b7202dd-7b13-4923-a6ea-e44cecc37230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4644fd8c-e2e0-4532-805e-cbec5b612563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90b1d9c7-8d88-4ac1-8aab-cf0defdccfbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6e17889-6fbc-4b31-a016-e9e87e3a921f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af1b3e9c-fd30-4b67-aa3a-84f88aa19e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67c76fbc-724e-4cd1-94c8-a71a5cb7262a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b88ef5f-2c75-4f02-a759-135e46189db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4da2c17-3b33-44ce-917d-0d4396b1a9d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a43f808-0388-4968-a473-9d51969a1026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d7a5a2e-3740-494e-a895-6b9e553f2ed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3460bde1-cb8c-4a98-b29a-7404368fb8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82d883b4-256c-4c9a-a7f3-50200b06e73d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 351c7c6d-aa6f-4a48-914d-1a74a39a5c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f49fbf-ba65-4ccb-9153-af71127ed756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a596dcd5-3129-4c65-90bf-a79f6e2bcc82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30ec9ce7-39dc-4406-a765-0bbcb15631a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06433846-c512-4e01-9414-1e07c6998cd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32e75ad8-14a4-442a-a3d5-d671972614d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c5414c3-e8b7-459a-a607-c8190488827a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8305410c-fd72-4bff-9447-6e9326b6af48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c812e2b-88de-4f78-be44-2162648bce49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2d1e620-96d1-4ded-aa35-1b8a1d29539f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58435551-1863-4a90-9190-734cb727f66a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5698bda-c612-48ca-9801-cff856329b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 849ebb5c-8431-446a-b3b4-df56eeb8af06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f810e57d-9c37-448c-a1a1-cac2d0c25018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f479dff0-ca79-4799-801d-64ecb2868d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afbaf348-3a92-41c9-9331-d5a35a6fe2b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcda1526-dfa2-4817-8d3e-dc441f081d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9058500-a933-4605-bed3-ffa206b5795e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 616af958-ce4e-420c-b1ac-0ca92ff94d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87e9177e-7460-4591-99ba-d17c346ae848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 479b8a07-ac2b-41da-ac60-da0285c47509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22ed79a6-b8a3-4a3d-984c-fed4f6bcd0b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fe36e2b-5092-489c-aa74-9c27516b0d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a50b1ef-8a38-4633-a5be-4bb58edb5f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ae7ce9a-743b-4d11-9271-8cb7986126be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97236414-e328-444d-b0b3-5155f2e1cf58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5ac4a48-6c14-41ca-91f9-528433af5b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c02ac638-9ddc-4712-add5-b02dace94e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcbb4445-69a3-4d49-92bf-e00cf9057e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d20e68-ba03-4635-b7b9-872355f7183e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28e3f760-06a7-4f1f-be33-8cb9cd6cc0bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85b3d7b6-c16a-40ca-a9f9-46ce98e0d105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c5e3767-1237-422a-b061-b0e925e06fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ccd9ea0-d5f6-4acb-9b3b-b73839eaeffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2188418c-aa59-448d-9053-a411dfbe79ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1165ac3c-a3ff-48a8-9d17-6c732c6056e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e1ed722-92b3-4fdc-bacc-552f5c2db83d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5354009-a0ce-499b-916d-8ae2401d808c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a97e7e59-1c95-4538-b7da-2499c59616b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98522bd5-d4ac-4bdd-bff6-4fbdd25f04cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee364ca9-c70f-4b76-a435-c9cc41fcc285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e67a79b3-182f-4c79-9a31-ab83d009f043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0326bb0-3158-4c6f-aa44-b946ea153133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eda815c8-59e5-4372-8bba-df9eea629e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cafc700-e2cd-41b5-b129-9a1b44e1d408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c81b054-72d6-4f3f-88ed-6e7fb63d3547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd3b619b-c552-4790-b2cf-9bcd0b1b179c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f6721fd-ec20-488e-a24c-be849c57b063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dced0eb2-ceea-41d5-9441-72c6326d34bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e60f5fe-f067-42c5-9e88-b0d451af6b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f0ce543-a539-4204-9a12-24016284dd45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891bc017-4c0c-4ecd-bb49-dfd74f00f1a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a19020c8-78df-4c94-802e-5a7ae401a252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b3f2af-2ecc-434c-9044-2f8c1d9dfce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad31a91f-dd99-4294-84b1-b7e3a29ba74c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c338e782-b03e-472e-816c-97b8b1d808c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a08bbcd2-5982-4dda-874c-99c36b37df7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d682e73-efac-4121-85da-ca5191141989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da146586-2ce6-4156-983d-278b512f61d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10eb35e7-fcb6-4395-8369-dc4ba80e196b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6464bcb9-c1d5-4e28-9fc1-d4504a5dc1bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64af68ac-d9ed-4f80-8d99-6fdf8636a7be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8c4c7aa-96be-4bf2-b9e8-04aca4aaca36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ac2182e-af49-4203-b4cb-e751e3b0bade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4f7b40e-bc0c-4322-8d28-6e70a25ac966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b318bc2-9b3c-465f-925d-c0cf39248df0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4728804-c5ed-4a1b-8e81-eedc13ffca65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 413e81ad-fc20-40c2-9700-facc2b3224f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c54c93d-a2be-4a58-a3fe-a768daf43799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1425fbe2-fb14-40f0-936b-a9f13b94b484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a93dcff-a03e-4c0d-bdcb-5576b946e4f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8ffc154-aaaa-4e04-a325-1d4a5a136647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84b8eff9-c897-4c19-82c5-9cf8462a1aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0131131e-8e36-42f9-8a58-5e818ff6f863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee55ff49-bc91-4493-99f1-a202d9b8e41f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23e2b004-79aa-40e5-be3b-c05f880fe2bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83ab670a-95fe-4ef8-9dfc-29adeeb0070d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0c69e12-6272-4e76-b304-6ee2de39d5a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0402d38c-a4a4-41af-a320-35aebacb85f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae233380-0ca9-44f4-9a88-4421d46189fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8ceff39-e1fc-4850-a356-f67a8a0ed145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8c8c267-ad5a-48c5-a4cf-ced054e4fbfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86b06da7-379f-48da-ae97-f3e0962679f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1829ab9-2b4f-4e0f-a7b3-4caef5657c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75dd60f7-04a6-4747-818b-2faba280e20b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c8cd5a7-62dc-47db-ad4c-6679182f3953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb47e36-63db-4a3e-8bb8-28c4f185171e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f886823c-8a1d-4351-888e-b0f649b117a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb92f90a-03bf-42a3-a59d-3c351e3f907c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dae4c25-7fa1-4642-b381-5710725d53cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06eb6df8-bb79-45a0-ae03-4fd13b7e3aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49d7462e-cef5-4bb9-9106-f1bd3e9b1130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaaa134e-5bbd-41e3-bbbc-5875b4f0298b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce134968-d7a4-40f8-8c47-3574607c6a9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 422e4a43-0e08-44a3-802a-aa8101a68e6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f70bd16-748f-4435-b63b-813bbe0ca2eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90366330-6584-4575-8859-9e40a7f40047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 161f5647-c258-4a3e-8b8c-c5970052266e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f88777b8-2f40-4716-bb46-a3f05df70997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82d5d2a9-7674-4047-9624-ad1c121b72ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4654240a-8af9-4e7e-ac5f-402f19515519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca7b4fed-9926-4795-84d9-f3f8fad11cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b3fabf7-6b86-4610-9ea0-c72b8cd1f159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b13decb7-4210-40a4-ba45-95851c3a6155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e47a9768-c041-4fc9-8933-1b7b161e0dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f30fb7d-f346-483b-adcb-bad9569d4469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d89ff99-909b-4332-a29b-8e8e358e536f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71dbb452-aa97-4a7e-8a47-cace8d615006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10f43b1d-1792-4e38-a1d6-309dfb5f7f17
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_18
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_18
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_18/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_18/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_18/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_18/test_labels.txt

📊 Raw data loaded:
   Train: X=(1054, 24), y=(1054,)
   Test:  X=(264, 24), y=(264,)

⚠️  Limiting training data: 1054 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  255 samples, 5 features
✅ Client client_18 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.2204, RMSE: 0.4694, MAE: 0.3863, R²: -1.6131

📊 Round 0 Test Metrics:
   Loss: 0.2155, RMSE: 0.4642, MAE: 0.3811, R²: -1.5556

📊 Round 0 Test Metrics:
   Loss: 0.1995, RMSE: 0.4467, MAE: 0.3643, R²: -1.3658

📊 Round 0 Test Metrics:
   Loss: 0.1959, RMSE: 0.4426, MAE: 0.3606, R²: -1.3229

============================================================
🔄 Round 7 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1096, val=0.0779 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0861, val=0.0757 (↓), lr=0.001000
   • Epoch   3/100: train=0.0840, val=0.0772, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0839, val=0.0773, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0839, val=0.0772, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0822, val=0.0769, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 7 Summary - Client client_18
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0034
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0042
============================================================


============================================================
🔄 Round 8 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1430, val=0.0919 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0893, val=0.0774 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0847, val=0.0756 (↓), lr=0.000250
   • Epoch   4/100: train=0.0843, val=0.0756, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0840, val=0.0757, patience=2/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0835, val=0.0760, patience=8/15, lr=0.000125
   📉 Epoch 18: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 8 Summary - Client client_18
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0002
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0015
============================================================


============================================================
🔄 Round 9 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1674, val=0.1197 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1357, val=0.0984 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1096, val=0.0848 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0910, val=0.0810 (↓), lr=0.000063
   • Epoch   5/100: train=0.0828, val=0.0848, patience=1/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0820, val=0.0856, patience=7/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 9 Summary - Client client_18
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0388
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0007
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1712, RMSE: 0.4138, MAE: 0.3356, R²: -1.0304

📊 Round 9 Test Metrics:
   Loss: 0.1650, RMSE: 0.4062, MAE: 0.3290, R²: -0.9562

📊 Round 9 Test Metrics:
   Loss: 0.1485, RMSE: 0.3854, MAE: 0.3115, R²: -0.7614

📊 Round 9 Test Metrics:
   Loss: 0.1376, RMSE: 0.3710, MAE: 0.3000, R²: -0.6321

📊 Round 9 Test Metrics:
   Loss: 0.1000, RMSE: 0.3162, MAE: 0.2647, R²: -0.1859

📊 Round 9 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2519, R²: -0.0124

============================================================
🔄 Round 21 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0812 (↓), lr=0.000016
   • Epoch   2/100: train=0.0841, val=0.0816, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0836, val=0.0820, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0833, val=0.0824, patience=3/15, lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   • Epoch   5/100: train=0.0831, val=0.0827, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0830, val=0.0832, patience=10/15, lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 21 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0151
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0051
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2515, R²: 0.0013

============================================================
🔄 Round 25 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0857 (↓), lr=0.000004
   • Epoch   2/100: train=0.0818, val=0.0858, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0818, val=0.0858, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0817, val=0.0859, patience=3/15, lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0817, val=0.0859, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0816, val=0.0861, patience=10/15, lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 25 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0026
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0041
============================================================


============================================================
🔄 Round 27 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 27 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0015
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0014
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2515, R²: 0.0039

📊 Round 27 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2515, R²: 0.0040

============================================================
🔄 Round 29 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 29 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0013
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0126
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2515, R²: 0.0043

============================================================
🔄 Round 32 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 32 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0025
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0037
============================================================


============================================================
🔄 Round 34 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 34 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0011
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0112
============================================================


============================================================
🔄 Round 35 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 35 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0014
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0073
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2516, R²: 0.0044

============================================================
🔄 Round 36 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 36 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0022
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0042
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2516, R²: 0.0045

============================================================
🔄 Round 37 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 37 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0018
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0022
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2516, R²: 0.0045

📊 Round 37 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2516, R²: 0.0045

📊 Round 37 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2516, R²: 0.0045

📊 Round 37 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2516, R²: 0.0045

============================================================
🔄 Round 45 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 45 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0019
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0075
============================================================


============================================================
🔄 Round 46 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 46 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0008
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0013
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2516, R²: 0.0045

============================================================
🔄 Round 48 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 48 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0000
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0061
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2516, R²: 0.0045

📊 Round 48 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2516, R²: 0.0045

📊 Round 48 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2516, R²: 0.0045

============================================================
🔄 Round 53 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 53 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0002
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0074
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2516, R²: 0.0045

============================================================
🔄 Round 54 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 54 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0008
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0092
============================================================


============================================================
🔄 Round 55 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 55 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0017
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0106
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2516, R²: 0.0045

📊 Round 55 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2516, R²: 0.0046

============================================================
🔄 Round 58 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 58 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0013
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0015
============================================================


============================================================
🔄 Round 59 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 59 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0007
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0063
============================================================


============================================================
🔄 Round 60 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 60 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0024
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0039
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2516, R²: 0.0046

============================================================
🔄 Round 61 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 61 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0013
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0021
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0046

============================================================
🔄 Round 62 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 62 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0040
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0013
============================================================


============================================================
🔄 Round 63 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 63 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0014
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0151
============================================================


============================================================
🔄 Round 64 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 64 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0032
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0128
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 64 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 68 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 68 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0006
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0040
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0046

============================================================
🔄 Round 69 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 69 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0017
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0002
============================================================


============================================================
🔄 Round 70 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 70 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0025
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0066
============================================================


============================================================
🔄 Round 71 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 71 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0019
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0050
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 72 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 72 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0029
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0042
============================================================


============================================================
🔄 Round 74 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 74 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0003
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0101
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 74 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 77 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 77 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0018
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0057
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 78 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 78 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0004
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0218
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 78 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 81 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 81 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0024
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0023
============================================================


============================================================
🔄 Round 82 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 82 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0043
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0082
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 83 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 83 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0009
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0142
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 84 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 84 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0018
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0041
============================================================


============================================================
🔄 Round 85 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 85 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0031
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0015
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 85 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 88 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 88 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0036
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0070
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 88 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 88 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 88 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 88 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 88 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 95 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 95 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0015
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0022
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 96 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 96 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0047
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0098
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 97 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 97 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0016
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0147
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 99 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 99 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0003
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0089
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 99 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 101 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 101 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0017
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0015
============================================================


============================================================
🔄 Round 102 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 102 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0013
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0065
============================================================


============================================================
🔄 Round 103 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 103 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0004
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0115
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 106 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 106 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0026
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0016
============================================================


============================================================
🔄 Round 108 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 108 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0026
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0013
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 110 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 110 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0018
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0017
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 111 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 111 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0007
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0130
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 113 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 113 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0001
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0251
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 115 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 115 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0015
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0027
============================================================


============================================================
🔄 Round 116 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 116 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0041
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0062
============================================================


============================================================
🔄 Round 117 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 117 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0033
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0044
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 119 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 119 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0052
   Val:   Loss=0.0707, RMSE=0.2659, R²=-0.0263
============================================================


============================================================
🔄 Round 120 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 120 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0028
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0022
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 121 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 121 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0019
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0103
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 122 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 122 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0027
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0011
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 123 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 123 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0029
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0022
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 123 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 123 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

📊 Round 123 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 127 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 127 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0014
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0058
============================================================


============================================================
🔄 Round 128 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 128 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0006
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0108
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 130 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 130 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0015
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0056
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 130 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

📊 Round 130 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 133 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 133 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0010
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0070
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 134 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 134 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0046
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0025
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 137 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 137 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0023
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0011
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 139 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 139 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0016
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0086
============================================================


============================================================
🔄 Round 140 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 140 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0024
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0047
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 146 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 146 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0038
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0022
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 149 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 149 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0020
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0030
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 151 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 151 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0007
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0069
============================================================


============================================================
🔄 Round 152 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 152 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0040
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0014
============================================================


============================================================
🔄 Round 153 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 153 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0027
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0004
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 156 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 156 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0008
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0066
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 156 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 159 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 159 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0049
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0055
============================================================


============================================================
🔄 Round 160 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 160 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0030
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0050
============================================================


============================================================
🔄 Round 162 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 162 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0013
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0112
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 164 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 164 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0017
   Val:   Loss=0.0955, RMSE=0.3091, R²=-0.0029
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 166 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 166 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0009
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0070
============================================================


============================================================
🔄 Round 168 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 168 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0030
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0127
============================================================


============================================================
🔄 Round 169 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 169 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0018
   Val:   Loss=0.0920, RMSE=0.3032, R²=-0.0055
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 171 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 171 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0011
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0091
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

📊 Round 171 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 174 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 174 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0055
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0013
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0044

============================================================
🔄 Round 175 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 175 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0005
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0267
============================================================


============================================================
🔄 Round 176 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 176 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0027
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0000
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 176 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 178 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 178 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0030
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0001
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 178 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 178 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 182 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 182 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0013
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0046
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 184 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 184 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0018
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0090
============================================================


============================================================
🔄 Round 185 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 185 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0010
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0112
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 186 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 186 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0039
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0057
============================================================


============================================================
🔄 Round 187 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 187 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0034
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0001
============================================================


============================================================
🔄 Round 188 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 188 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0047
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0008
============================================================


============================================================
🔄 Round 189 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 189 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0019
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0050
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 191 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 191 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0021
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0029
============================================================


============================================================
🔄 Round 192 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 192 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0004
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0156
============================================================


============================================================
🔄 Round 194 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 194 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0017
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0036
============================================================


============================================================
🔄 Round 195 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 195 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0004
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0090
============================================================


============================================================
🔄 Round 200 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 200 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0012
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0064
============================================================


============================================================
🔄 Round 202 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 202 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0018
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0026
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 203 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 203 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0017
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0063
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 204 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 204 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0006
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0101
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

============================================================
🔄 Round 205 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 205 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0034
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0126
============================================================


============================================================
🔄 Round 206 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 206 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0007
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0104
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 206 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

📊 Round 206 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2517, R²: 0.0045

❌ Client client_18 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
