[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f553baa7-4aa4-44b5-ba70-49df75396603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc642326-2e2f-47e6-a7f1-06504dd00628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25550c12-ce98-470d-b7e3-6d5432df7208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e29bc1-a9da-457e-895b-7dca96945f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9504a4e-ea4e-437f-9593-8847bb05be4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c2749cb-053e-4b7e-87f7-325410e49a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17e8479d-8c85-4caa-94d0-f8c65c26d568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b3a2bb3-c4ac-42e1-bf58-ebcf3704e590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64cd29ee-57f9-4567-81f9-fe1405e6198e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf75760d-b46f-43b5-8621-ad02e4022f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8db3064-880a-4720-939d-a9b4f8f42be2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a92830aa-8333-4e0d-8e7a-3a52fe5003fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45618c48-e99f-4633-92ba-f0e0285d252a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c9057b1-c97e-424b-a7fd-23d2f358b9ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d1ee2c1-052e-4acc-91ac-c6a19f2f02bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c2f2f1-0b9a-42fd-acc3-089348881709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27c983b8-1d11-44d6-87d3-60b5f00f156e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cdb73c8-384e-4d90-8c72-6308348048fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30b943f3-5e08-4beb-85f8-3eda20e50ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5590ec77-9806-4164-9996-883874e4d081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0bb12f2-ff5a-47bd-9256-4fdfb497cb05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 100c4cdb-a5a8-4158-afd0-8767d915646a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 586f30ef-99ab-47bc-8e3a-c459abeb807c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4883547a-9330-41d4-8f4a-a5eabe551b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16b9d5de-ff8d-4b5c-aadb-d33be3efa3ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8460f86f-0b4f-443b-b5c6-c89ae02f1b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b0771e7-dab1-4d28-af75-9c42890fb6e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff2c16d9-6ff7-488f-8357-e6a34c3019fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed608d4c-9589-451e-ab1e-c5c113d6c375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a37e1dff-21ea-4802-9f3c-7a2658701174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdf89e8a-aefe-4c6a-a30e-92562365762f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a366216e-99e0-4dc4-8070-72224b20be57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f088ad3a-bdaa-4d67-bba8-da460bee02cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0ccc711-a1b1-4e53-8fb6-b1b4be88805d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd06fc9d-2fc0-4703-bde0-4d97c5e55389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aae21aa-6839-4dce-b1be-aa143f81475c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a74351da-1456-4acc-a82f-c411bac8aa9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1c666a4-70dd-41c6-bc6c-80cd9c714320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2516f22-6c5d-4dd4-8d98-33abeeb1452f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 879634a1-4044-4167-bff7-18317b08dd98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebe38d89-d7a5-46be-9e47-64e91acdfe79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f0dd9f9-57c5-406c-92c3-c7b1d0239e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeb6e219-cbd4-4146-a6e6-138c4cf10e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 753c5b1f-e1a8-4164-b843-98965e4f38e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7db6dcd0-302c-42be-88cd-dffe87df0fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 759f8939-0374-4c8a-b15e-c789162ecb78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e8bd17-1967-4b43-958a-35023660b9ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 103b7af7-d5e8-48f4-beb8-c08c6e4b38e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5f3b5ef-aa19-4cdb-90f7-5895339c8b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdb7d32e-976d-49de-98ae-0b78dd5aac13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce86d326-34f4-4f83-8686-adf53a5222b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 083eb507-6121-4c64-a623-97637f7eed96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd01d5bd-1990-4070-9aa3-76e30f998d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac870598-8fe8-4440-a1e6-c6a436a283e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb7aa7ee-71aa-4ed7-97e2-f2a9f2531968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 995ac083-9ada-4ef4-9f3f-af3e1b739be0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffe453cc-e565-4364-9299-8478b6b12c75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adf07aa0-4539-425d-a943-8a3074f73375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 549c002d-f5e8-4054-8cd2-d5754d3ff188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dd68edc-d98f-4615-80e2-bc034cde812a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9a3c136-bf0a-43c8-890e-a129658e66ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b79cfe6-1c92-4cf7-a2da-257455cc9550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d445b1d-6dd9-4f4c-b2d0-bc7e1d0448bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da892e2d-9ac9-436f-aa74-ba7343427ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df68bdc7-ed24-4262-82c5-673abc466214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 948f4ab0-6223-494b-9113-b0f21168b9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67f18e40-a4d1-4f24-9007-f25a0aab07b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1becc9cb-ea21-41a7-a409-d7dc3b605eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e78d656-44f8-4585-bb32-24993159a6fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 443a0188-e329-4999-8982-a86cb4dd566c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f772beb0-6067-43da-ad70-aba961734a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1bb072c-57d4-4350-aea5-16a1aca3c8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47dd16b1-4353-486a-8d01-e4046648dc4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ff43f0e-7e49-4996-90ed-f1139b34d314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 971dc585-7f72-4a53-ad1d-7d365ed43875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc6df2a4-5e9a-481e-8ab7-696d5426c407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3324a0e7-ff29-4c97-8e60-4f15eb571ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f33945b-f30d-4884-9360-30eed645e6a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 550553c7-f422-4079-9d2c-673fd2611d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18420b46-da71-4f66-b59c-1ced6b1eb66b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92e3f885-ca6f-4873-8fda-d106ea820abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30eec1ce-5b48-4fa1-ab16-e3c810604dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 061f6bd4-bb64-41d0-8e35-3bba98678dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17831882-2f43-4d99-afe0-7b082a81d2e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf3549ab-e31c-49c2-9ff4-392c78343ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a0d1049-8586-4ea3-bf9e-dfa27d38b3b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a0bc571-d137-404b-b5c9-34f9b10d7289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a8af260-fc49-4c2b-bcad-13dc6666c942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7944fdae-6380-4831-8e6c-6f120102570e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 853756cb-ac45-4155-9749-6a69afbe3e93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff077ab5-cf2b-42a3-b6cb-f7a7bb99fbad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 540b1bd1-d084-44ef-b788-8dec7707ceb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea4991f9-d137-4ba7-9b1e-75fb1ff09f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4327b111-c102-4dbb-a3b5-5f8c9b6fe346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ccc22fb-49ce-4b00-a805-59a8135a7ac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68726871-aa38-4aae-b81b-35358571f799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ac7ad70-cddd-45a1-8513-58be95ab5b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3318735-1b96-4757-a47a-e27e9e157e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d937f1-5473-4867-9c4b-c3ca863dc9a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ce71cd2-4e7f-4f72-8865-d95a19c9b0b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d514f585-4dc1-4ebc-90e1-ab4419fdee58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d401ea16-98ca-415f-b9ff-e085e3d550ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06073473-91c7-41ec-9354-2cedfc88484e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e49e99e9-4281-4992-97c4-8f647511ef8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3136d1e-a2c7-4100-b8c1-871101fdb5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68c193dc-186e-4cc8-a34b-a6d762d7b2f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83df608f-c46c-4716-8b50-b9de8b94eeaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60ea0d36-f83e-4783-83e2-86ffc8cfa971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f3585ba-67a0-470d-bb85-af15972f118d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9f0e96e-0f3d-4ea8-a17d-253895c3f774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb168567-d3ed-4f81-a114-e085c1cd6bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5569e951-bb2d-40aa-8467-72bd75b7e168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cc66a6e-0d7f-4888-9adb-df870ddf27de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4ef0fb9-b12e-44bf-a1b7-aae0ed0497de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1a27319-93ca-4bf7-92a9-4efc41ded465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2779ec3-e41b-44e8-a9b8-fd5838bd8fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35e0a197-5e48-473a-8eb4-3ea4533858e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a2b63db-b821-48a5-8d22-e29c9d02dc67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 352fa2c3-e186-4c79-975b-019d128c5847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04784c22-59af-4088-b0fb-edf270fae30e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72186751-5796-4b0b-928d-8faca5e6893c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ecfbcd-2cb7-462b-81e5-92ecba5e6514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ebedbc8-8b51-441c-83a3-c4316b23d890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38f6f003-55fe-409a-a97f-0613afd1b706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9595305f-a76e-42a7-837d-a6d26124d043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f380927b-95fd-41e6-befc-9d7c804c4879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caa7336c-bb0f-4db4-9069-15f9a59d56f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85819b06-b347-4f5d-a8f8-7b3f7b716c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05ab7f66-a2b5-4119-92d4-987a1e9e70d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3623a39b-7229-4737-a232-9adf4d0dabb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27046cbf-b55d-4c07-9900-a2a39d7c1672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 808a9c87-2a6f-44ea-84c7-614cad4ff8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86d6f4ea-55a9-4fea-a510-cf3d25f19830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9de3e896-376a-47f6-b1d6-6634f5c5a6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3efa5064-1e77-4d36-bf0c-15820d9f589c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d4bd10-dc56-4e15-a94e-67d3785cb80c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0180039-1fdc-4a57-9c95-250459d4c77a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12b36b2c-195c-461d-bca5-cedb10c91884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce1045d-ac14-49ff-a5e5-1f04006d2105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 793d3145-e1f6-4bba-bb5a-730c39927562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ed8bf4b-420a-44f0-9453-8b8324d11497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e02da463-b3b7-4c49-b228-bbc716436067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fcf1cb6-15ec-4852-860a-dfad8e4b60dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e02dec1a-9891-430a-9c6f-1ce7033a33d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb0064df-08a7-4ef3-a287-abc27e33f8d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8eb39c2-695a-4faf-b20f-3696c307b1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4c5b9fa-d5e8-49fa-bc47-b97351c7fd3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce637c3c-6116-47b2-866c-1252e670a764
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_19
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_19
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_19/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_19/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_19/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_19/test_labels.txt

📊 Raw data loaded:
   Train: X=(1076, 24), y=(1076,)
   Test:  X=(269, 24), y=(269,)

⚠️  Limiting training data: 1076 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  260 samples, 5 features
✅ Client client_19 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1950, RMSE: 0.4415, MAE: 0.3609, R²: -1.4754

============================================================
🔄 Round 5 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1214, val=0.0856 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0814, val=0.0842 (↓), lr=0.001000
   • Epoch   3/100: train=0.0800, val=0.0842, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0797, val=0.0845, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0795, val=0.0846, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0774, val=0.0839, patience=9/15, lr=0.000500
   • Epoch  21/100: train=0.0727, val=0.0807, patience=1/15, lr=0.000500
   • Epoch  31/100: train=0.0643, val=0.0782, patience=3/15, lr=0.000500
   📉 Epoch 35: LR reduced 0.000500 → 0.000250
   • Epoch  41/100: train=0.0588, val=0.0816, patience=13/15, lr=0.000250
   📉 Epoch 43: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 5 Summary - Client client_19
   Epochs: 43/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0656, RMSE=0.2561, R²=0.1978
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0657
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1749, RMSE: 0.4182, MAE: 0.3383, R²: -1.2206

============================================================
🔄 Round 8 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1596, val=0.1392 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.1136, val=0.1007 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.0846, val=0.0894 (↓), lr=0.000125
   • Epoch   4/100: train=0.0806, val=0.0898, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0808, val=0.0890, patience=2/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0799, val=0.0886, patience=3/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0796, val=0.0885, patience=13/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 8 Summary - Client client_19
   Epochs: 23/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0083
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0010
============================================================


============================================================
🔄 Round 9 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.1690, val=0.1712 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1590, val=0.1641 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1526, val=0.1578 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1468, val=0.1520 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1415, val=0.1465 (↓), lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.1177, val=0.1230 (↓), lr=0.000008
   📉 Epoch 17: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.1034, val=0.1081 (↓), lr=0.000004
   📉 Epoch 25: LR reduced 0.000004 → 0.000002
   ✓ Epoch  31/100: train=0.0984, val=0.1027 (↓), lr=0.000002
   📉 Epoch 33: LR reduced 0.000002 → 0.000001
   • Epoch  41/100: train=0.0965, val=0.1006, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.0950, val=0.0990, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0937, val=0.0974 (↓), lr=0.000001
   • Epoch  71/100: train=0.0924, val=0.0959, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0912, val=0.0945 (↓), lr=0.000001
   • Epoch  91/100: train=0.0901, val=0.0932, patience=2/15, lr=0.000001

============================================================
📊 Round 9 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0829
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.1244
============================================================


============================================================
🔄 Round 11 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1612, val=0.1756 (↓), lr=0.000001
   • Epoch   2/100: train=0.1609, val=0.1752, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1605, val=0.1748 (↓), lr=0.000001
   • Epoch   4/100: train=0.1601, val=0.1744, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1597, val=0.1740 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1577, val=0.1719 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1548, val=0.1689 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1522, val=0.1662 (↓), lr=0.000001
   • Epoch  41/100: train=0.1498, val=0.1636, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1475, val=0.1612, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1453, val=0.1589 (↓), lr=0.000001
   • Epoch  71/100: train=0.1431, val=0.1566, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1410, val=0.1543, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1389, val=0.1521 (↓), lr=0.000001

============================================================
📊 Round 11 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1379, RMSE=0.3713, R²=-0.6978
   Val:   Loss=0.1501, RMSE=0.3874, R²=-0.7615
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1464, RMSE: 0.3826, MAE: 0.3085, R²: -0.8583

📊 Round 11 Test Metrics:
   Loss: 0.1407, RMSE: 0.3751, MAE: 0.3027, R²: -0.7863

📊 Round 11 Test Metrics:
   Loss: 0.1259, RMSE: 0.3548, MAE: 0.2879, R²: -0.5979

============================================================
🔄 Round 17 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1294, val=0.1316 (↓), lr=0.000001
   • Epoch   2/100: train=0.1292, val=0.1313, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1290, val=0.1311, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1288, val=0.1309 (↓), lr=0.000001
   • Epoch   5/100: train=0.1286, val=0.1307, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1272, val=0.1293, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1250, val=0.1271, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1228, val=0.1249 (↓), lr=0.000001
   • Epoch  41/100: train=0.1206, val=0.1227, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1184, val=0.1206, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1163, val=0.1185 (↓), lr=0.000001
   • Epoch  71/100: train=0.1142, val=0.1164, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1121, val=0.1143, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1101, val=0.1123 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1079, RMSE=0.3285, R²=-0.3276
   Val:   Loss=0.1105, RMSE=0.3324, R²=-0.2970
============================================================


============================================================
🔄 Round 18 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1137, val=0.1173 (↓), lr=0.000001
   • Epoch   2/100: train=0.1135, val=0.1171, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1133, val=0.1169, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1131, val=0.1167 (↓), lr=0.000001
   • Epoch   5/100: train=0.1129, val=0.1165, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1117, val=0.1153, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1097, val=0.1134, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1078, val=0.1115 (↓), lr=0.000001
   • Epoch  41/100: train=0.1059, val=0.1096, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1041, val=0.1078, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1023, val=0.1060 (↓), lr=0.000001
   • Epoch  71/100: train=0.1006, val=0.1043, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0989, val=0.1026, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0973, val=0.1010, patience=3/15, lr=0.000001

============================================================
📊 Round 18 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0960, RMSE=0.3098, R²=-0.1835
   Val:   Loss=0.0996, RMSE=0.3155, R²=-0.1582
============================================================


============================================================
🔄 Round 19 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1044, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.1042, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1041, val=0.0905, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1039, val=0.0904 (↓), lr=0.000001
   • Epoch   5/100: train=0.1037, val=0.0902, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1027, val=0.0892, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.1010, val=0.0876, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0993, val=0.0861, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0978, val=0.0847, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0963, val=0.0834, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0949, val=0.0821, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0936, val=0.0809, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0923, val=0.0798, patience=1/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0912, val=0.0788 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3004, R²=-0.0719
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0621
============================================================


============================================================
🔄 Round 20 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0954, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0898, val=0.0953 (↓), lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0945, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0879, val=0.0934, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0868, val=0.0924, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0859, val=0.0914, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0850, val=0.0906, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0843, val=0.0899, patience=6/15, lr=0.000001
   • Epoch  71/100: train=0.0836, val=0.0892, patience=8/15, lr=0.000001
   • Epoch  81/100: train=0.0831, val=0.0887, patience=9/15, lr=0.000001
   • Epoch  91/100: train=0.0826, val=0.0882, patience=9/15, lr=0.000001

============================================================
📊 Round 20 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0138
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0231
============================================================


============================================================
🔄 Round 24 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0803, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0836, val=0.0800, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0835, val=0.0796, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0834, val=0.0794, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 24 Summary - Client client_19
   Epochs: 43/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0037
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0506
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2439, R²: -0.0030

============================================================
🔄 Round 26 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 26 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0098
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0128
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2437, R²: -0.0008

============================================================
🔄 Round 31 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 31 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0053
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0191
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2436, R²: 0.0001

============================================================
🔄 Round 33 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 33 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0061
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0133
============================================================


============================================================
🔄 Round 35 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 35 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0071
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0060
============================================================


============================================================
🔄 Round 37 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 37 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0086
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0020
============================================================


============================================================
🔄 Round 40 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 40 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0139
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0142
============================================================


============================================================
🔄 Round 41 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 41 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0045
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0119
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2434, R²: 0.0010

============================================================
🔄 Round 44 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 44 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0046
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0161
============================================================


============================================================
🔄 Round 45 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 45 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0080
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0006
============================================================


============================================================
🔄 Round 46 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 46 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0033
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0212
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2434, R²: 0.0013

============================================================
🔄 Round 48 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 48 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0069
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0012
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2434, R²: 0.0013

============================================================
🔄 Round 49 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 49 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0048
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0085
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2434, R²: 0.0014

📊 Round 49 Test Metrics:
   Loss: 0.0787, RMSE: 0.2804, MAE: 0.2434, R²: 0.0014

📊 Round 49 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2434, R²: 0.0014

============================================================
🔄 Round 54 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 54 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0055
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0032
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2434, R²: 0.0014

============================================================
🔄 Round 57 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 57 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0061
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0003
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2434, R²: 0.0015

📊 Round 57 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2434, R²: 0.0015

📊 Round 57 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2434, R²: 0.0015

============================================================
🔄 Round 62 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 62 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0049
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0082
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2433, R²: 0.0016

============================================================
🔄 Round 64 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 64 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0035
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0095
============================================================


============================================================
🔄 Round 66 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 66 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0030
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0103
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2433, R²: 0.0017

============================================================
🔄 Round 72 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 72 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0057
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0036
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2433, R²: 0.0019

📊 Round 72 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2433, R²: 0.0019

============================================================
🔄 Round 79 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 79 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0012
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0771
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2433, R²: 0.0020

============================================================
🔄 Round 81 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 81 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0034
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0065
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2433, R²: 0.0021

============================================================
🔄 Round 84 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 84 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0030
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0068
============================================================


============================================================
🔄 Round 85 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 85 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0024
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0212
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2433, R²: 0.0021

📊 Round 85 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2433, R²: 0.0020

============================================================
🔄 Round 88 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 88 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0048
   Val:   Loss=0.0728, RMSE=0.2699, R²=-0.0060
============================================================


============================================================
🔄 Round 91 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 91 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0057
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0028
============================================================


============================================================
🔄 Round 92 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 92 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0028
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0079
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0022

📊 Round 92 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0022

📊 Round 92 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0023

============================================================
🔄 Round 96 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 96 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0063
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0054
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0023

📊 Round 96 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0022

📊 Round 96 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0023

📊 Round 96 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0023

📊 Round 96 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0023

📊 Round 96 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0023

============================================================
🔄 Round 103 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 103 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0048
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0008
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0024

============================================================
🔄 Round 106 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 106 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0030
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0105
============================================================


============================================================
🔄 Round 107 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 107 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0045
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.0023
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0024

📊 Round 107 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0024

📊 Round 107 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0025

📊 Round 107 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0025

============================================================
🔄 Round 111 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 111 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0072
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0027
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0025

============================================================
🔄 Round 112 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 112 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0031
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0054
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0025

============================================================
🔄 Round 113 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 113 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0040
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0005
============================================================


============================================================
🔄 Round 115 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 115 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0044
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0002
============================================================


============================================================
🔄 Round 116 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 116 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0029
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0047
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0025

============================================================
🔄 Round 117 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 117 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0060
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0007
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0025

============================================================
🔄 Round 118 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 118 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0036
   Val:   Loss=0.0879, RMSE=0.2966, R²=-0.0016
============================================================


============================================================
🔄 Round 121 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 121 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0022
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0083
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0026

============================================================
🔄 Round 123 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 123 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0020
   Val:   Loss=0.0705, RMSE=0.2655, R²=-0.0083
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0026

📊 Round 123 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2432, R²: 0.0026

============================================================
🔄 Round 125 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 125 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0031
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0029
============================================================


============================================================
🔄 Round 130 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 130 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0024
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0062
============================================================


============================================================
🔄 Round 131 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 131 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0015
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0128
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0026

============================================================
🔄 Round 132 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 132 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0024
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0057
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2431, R²: 0.0027

============================================================
🔄 Round 135 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 135 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0009
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0188
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2431, R²: 0.0027

============================================================
🔄 Round 137 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 137 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0022
   Val:   Loss=0.0840, RMSE=0.2897, R²=-0.0095
============================================================


============================================================
🔄 Round 138 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 138 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0029
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0024
============================================================


============================================================
🔄 Round 143 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 143 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0052
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0054
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2431, R²: 0.0027

============================================================
🔄 Round 144 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 144 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0067
   Val:   Loss=0.0792, RMSE=0.2813, R²=0.0002
============================================================


============================================================
🔄 Round 145 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 145 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0047
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0042
============================================================


============================================================
🔄 Round 152 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 152 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0027
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0050
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2431, R²: 0.0028

============================================================
🔄 Round 158 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 158 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0063
   Val:   Loss=0.0707, RMSE=0.2659, R²=-0.0076
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0028

============================================================
🔄 Round 162 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 162 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0060
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0057
============================================================


============================================================
🔄 Round 164 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 164 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0049
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0073
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0029

============================================================
🔄 Round 166 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 166 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0038
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0027
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0029

============================================================
🔄 Round 170 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 170 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0038
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0013
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0030

📊 Round 170 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0030

============================================================
🔄 Round 179 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 179 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0073
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0231
============================================================


============================================================
🔄 Round 180 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 180 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0016
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0216
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0030

============================================================
🔄 Round 183 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 183 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0026
   Val:   Loss=0.0734, RMSE=0.2708, R²=-0.0038
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0030

📊 Round 183 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0030

============================================================
🔄 Round 185 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 185 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0008
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0146
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0030

============================================================
🔄 Round 187 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 187 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0011
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0223
============================================================


============================================================
🔄 Round 191 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 191 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0006
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0320
============================================================


============================================================
🔄 Round 192 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 192 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0013
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0115
============================================================


============================================================
🔄 Round 193 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 193 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0067
   Val:   Loss=0.0681, RMSE=0.2610, R²=-0.0073
============================================================


============================================================
🔄 Round 194 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 194 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0029
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0008
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0031

============================================================
🔄 Round 196 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 196 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0031
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0007
============================================================


============================================================
🔄 Round 197 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 197 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0028
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0019
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0031

============================================================
🔄 Round 200 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 200 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0030
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0029
============================================================


============================================================
🔄 Round 202 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 202 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0029
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0012
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0031

============================================================
🔄 Round 203 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 203 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0044
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0021
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0031

📊 Round 203 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0031

📊 Round 203 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0031

============================================================
🔄 Round 207 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 207 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0048
   Val:   Loss=0.0894, RMSE=0.2989, R²=0.0052
============================================================


============================================================
🔄 Round 208 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 208 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0053
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0066
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2431, R²: 0.0031

============================================================
🔄 Round 210 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 210 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0030
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0007
============================================================


❌ Client client_19 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
