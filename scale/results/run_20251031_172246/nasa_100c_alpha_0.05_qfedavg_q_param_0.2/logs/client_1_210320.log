[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 145e4f4e-3db7-4d45-a279-bf40f15023d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d32265e1-cf19-457d-a546-67dca6ad4968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01f329ea-3eeb-485e-8742-f27f810e0c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f996f9c-2536-48fe-b853-c850c3c484f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d68ff2f-64aa-429d-88e8-4106d5f70dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a736664d-a78b-4221-aad2-e6f470009b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1e0b6ef-8967-4fdc-ad9f-19730adae3a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85f4c84f-7011-4645-970f-f817146a276d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee64233-96dd-46dc-9ab0-a26d05c190b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67d243fc-f1dc-4e7f-8d32-62cafc8f80ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d463c3f8-4fa8-4c6b-834f-9801c921ba2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19f79f6b-010e-40a7-85f2-bfc0df41a8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcd5a50e-1556-4a0c-920c-0255e7dc44a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5423f312-7dd3-4fda-8020-9f1c4051ab9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 672f3660-823c-467f-90b5-6fceee83e1b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3bba3f6-7a59-409f-a96a-229c0d5f8b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a95c64ed-43cd-4625-97c6-ce973df91883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8e73353-ba32-4188-8fb4-68a59dc6af13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d054f095-cef9-4fc9-9ebc-048db2556d5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fea0881-f10c-44ac-b2b1-120c8e1fb888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5055a61a-1855-48f3-bb0f-3df9a8089722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 311e5d4a-3cd4-410a-b7ca-37ddea501679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c23c412c-54f5-4992-8ba2-f686bcac6f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15fe0cc0-10a4-40dc-82e5-8e60f7b7fa3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3a98f20-f208-4889-bbae-30ce407b1ce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbfac480-f64e-4770-b83f-c69a770e3499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37e2a9f9-084d-41d1-bdaa-949fc96ec502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeb42183-f3fd-41df-8ebf-bf6c5bf0e72f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0234be37-324a-4534-b095-771342bc2cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02a74b81-2b38-45c3-b793-c945088caf46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0521191a-eb49-419c-abb3-aff80490e292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81fa4663-4045-46d7-a578-1770b8d65b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 658bf249-8222-4ff9-94c2-3182d2bb7bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0603538d-b72f-49b2-8146-c81327bd6775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f68d38-1f73-44af-93e4-9b0b73b26418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbbd3b26-df4a-431b-98b5-922684a2e739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0df49518-a566-4e6b-ba94-3408aff4f21d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f924d3a-e045-4b32-9076-a37cf8918c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 631cd911-30f3-4fdf-a5ed-6dafb08b9c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5e24aee-55ab-4d09-b5b3-1b25b2707697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 584df1b9-b69c-47fb-b8e2-68d94ac93583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b587496-d38b-4abe-bb03-c19069ccfe0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bfe9159-c945-47ea-923a-250d8ca2fc1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 784c3c9c-4e13-4555-919e-f79022c3f819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 709c3d7a-14e0-45f3-85fd-1d3733b4eeb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb86b387-8360-401b-9775-cf316a441f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 003b8248-34d7-43bd-bcad-a673ac2541c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b1eb9b3-389e-4a76-b15e-7ea6628e6d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4ac99fb-db55-40ab-a89b-0faeda11e368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93f8e5f4-afea-4648-a850-5e42c9257a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0127ce32-cfa0-47ca-8605-9e4a8f167d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fff85c0b-811f-4cbe-aaeb-f71a260967e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9e98271-4184-4cd1-a42b-db010cca4be2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb1111e9-70df-4014-8c43-37a171aaea4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4fcd8f9-8754-4d26-83b8-af5b0d367d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c53a637e-8357-4c06-900d-f6c07841c867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3427cb40-dd04-4f73-9561-3b58a4bb6711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88b5a67d-3181-40bc-a704-10fc43811a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f153b41d-b81f-448b-b112-d21066d505c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55dce166-b2f5-4aa0-b89a-d3c122a3126c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89bfcc24-6498-44a9-95aa-0cf21b5b4497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6b419a5-9005-4314-9095-51230c613ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70f81951-a835-4e10-b4b3-b6589a04e06a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af45304f-bd52-4776-a4a0-e14c455b2451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1627f806-0d0d-4d8d-aa3f-535b4ae3f10b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7132985f-556b-440c-8e8a-2053f91cd56f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7062d85e-5927-4dc5-b801-0544765c1133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b94e5d37-dd5f-4a85-aee4-2165f6d91adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16e679ad-68ee-4485-9488-4df7c275da22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad20acfc-64e0-42f9-8c57-1bf15d9826e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d56f0d2-7c0a-4d76-928a-a580bd21c823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d954943-c21e-4703-b56e-64dae6d2c42d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8caa2e2f-d5cc-4211-af57-bab07424a3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69dd2d6c-b0af-40af-8845-a26feafa4c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbb55576-4e85-4b83-9dd3-ed5139ac415d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3528dcf-8100-4111-b486-b59d1283ccf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d837916e-adfd-456f-bc20-bc4704c2802c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4d37ac5-5cf7-4aec-9b01-f80c1c44a323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be841ba5-442b-4228-a9ec-e3722c0f33c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f714596c-5ca8-4c84-8e5b-072e805e78cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3809391-9b74-438b-af54-4475b770d7de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5d15c10-542b-45fa-a398-5527a79894bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e984e13-a761-4481-86c9-b2d49c195fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aba1ca5-9837-4ce1-ae40-6cb86fb242b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3004e296-18ec-4337-9a2c-1bf212afb9ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec97eb2d-6409-443c-9510-e90b99339040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 158d2e9d-3010-49fb-afd3-f4a93f97901f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 051b2c76-7101-4171-8cf0-b33256041ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8649bf62-c149-4af4-8807-566f7f6c5b9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 559de797-b56f-494c-aeab-918a6e6af2cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4a3655b-d2ff-4839-8545-a318ad6a8589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e6635a8-b0a0-473b-82ee-1254bc713cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9443505b-7885-41aa-9473-76aeb37cb927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df1ffaa1-4914-4d77-9d1b-ed971228951c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05f53fc7-8324-4ee9-bd74-ebc660c78401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e7037db-2987-4020-9941-2df0bf001531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36167815-d03a-4f9d-bd02-f4cd06a308d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a116522-0e90-47db-82ad-3bd0d5a04bea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fabbf263-05ac-4a1d-855a-f53f3f271db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2ce4687-23e9-44e9-8ac1-2e6a54efee0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1fcee2c-d25b-4d01-9fd6-8a24b23568fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daa9289d-d347-4947-beda-873c8f7b42b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce3c0d66-eb34-4388-a8e5-6c915df77c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4d567a8-f931-42e6-a8b4-170e3bcd476d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7062ab03-7770-49c1-a587-c83702d2f355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdd54116-aae3-487a-a3fb-a6ca1374fc09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b8ab61f-cfec-4bc9-83f1-4037c5dcecbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5aeede8-8374-4414-a67a-0af386754687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b7efa81-7a25-466f-9130-9583f2c53045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d2caaf1-0da5-43f6-a0d8-3e1fa20bb509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a1d730c-7b18-4075-b8c8-82770498847b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 759e184a-2a85-426b-8618-c84ff1fd2d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23df9ff-e388-46e6-b5f6-d960b8fd13f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8a81604-1398-47ce-a268-be4669fca767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d9a27d9-1c1d-492f-a14e-ebed1bc53ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84be64b8-6763-437c-901f-d26f2ca6e5d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc6a447e-3210-4eb6-9f87-4cdec14ffa6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cef0e68-147e-41c0-a187-9ac1b22b1ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89defc3c-4439-42ff-b9e4-4f40cbb10ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ba00143-de84-42c7-b1fd-548c6f37c9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daa6102a-694a-494b-9695-d633eba20568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a43f3885-8ecf-456a-afa7-3c8fe4fc2adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51929f33-ca49-4339-be04-1a80a3003ab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6c9da0f-befc-4a6d-b313-6efde3ae9416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f39194d-bb2a-416a-b7a8-aa81c4f65948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96970c30-c6ef-4041-9c46-9d8a63fc4e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66a66829-f75e-4f67-b4f5-da6ef711abfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27ad0ae8-46e1-4f8c-bf82-1b2953ff0e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba90c66f-b259-4be4-8c49-bd0ddcbacd83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b92c56cd-bc75-42c2-bd76-1edbf0965fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4beb978-76cb-438e-897a-6fe476d8913d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb1a548c-0ad0-42ee-b489-e120fa8f6726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4def8211-eb44-4e52-b841-f15b98403399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0576670-ce9f-46b4-b4eb-1e5802056291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5d6ce5a-4b11-4660-89d7-e56ce9b90281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a233fcd-e47b-4087-8d46-3d86d7bf6467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8fb27b0-f5ea-47bc-876b-aff87b25ecb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3584d104-df83-4875-9a72-e78423459497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1435a27-a9bb-44f5-bdfd-2e21a691e592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f79e2734-faf2-4f83-8cf3-e30e679956d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51c05992-d21f-41ff-b763-868e8c404b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1db865e0-3e49-4d37-aa64-862ca6d4d486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeaeee89-9a7e-42f1-b761-7c48847db11d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2034a502-6b80-4804-8d77-c0932804dc36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4c16cd9-14f1-4115-9b04-f4199d904235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a453cbe-70ca-4cb7-a324-571551ed1f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b950cbe9-e0d3-4a06-ba0b-e46255c8c773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c451c51-a5e0-49b1-a3bb-68887f539a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8d9562e-9d8f-47fb-9a23-bcec3124c750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffedf845-7865-4cac-a2f6-f30fe2c99108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0391b70d-4c73-455a-bd2d-55123d748dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbeb8f46-7ef7-4bad-80b7-ce73460cb036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa0d912f-c9f6-484f-a77f-9f057cd582f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ecc626f-6c68-43dd-b0b7-f0c704dc21a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a594074-c375-4422-b75a-67ff0eb0a197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fe5749e-1d8b-41ba-86d9-f8f981283fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 214172e0-4d80-4e05-a4f5-9c39dc1c3344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1859b804-9678-43e6-94f9-c762b1258d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcc20c79-719c-4698-b743-85bee01df7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eac2156-7285-425d-9e5a-51049dbd920e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afaccdce-025e-49b9-b6a9-ec76840cfc3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9de293c-5191-46fe-9642-d0d27026d505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 510dcee5-9b01-4e34-933f-bc5930c0217f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ce4f047-1aa7-4e91-aa85-7d5f8b073424
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_1
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_1
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_1/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_1/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_1/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_1/test_labels.txt

📊 Raw data loaded:
   Train: X=(1650, 24), y=(1650,)
   Test:  X=(413, 24), y=(413,)

⚠️  Limiting training data: 1650 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  404 samples, 5 features
✅ Client client_1 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1973, RMSE: 0.4442, MAE: 0.3641, R²: -1.3845

📊 Round 0 Test Metrics:
   Loss: 0.1938, RMSE: 0.4402, MAE: 0.3607, R²: -1.3420

============================================================
🔄 Round 6 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1089, val=0.0870 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0848, val=0.0860 (↓), lr=0.001000
   • Epoch   3/100: train=0.0833, val=0.0896, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0824, val=0.0881, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0826, val=0.0876, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0815, val=0.0882, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 6 Summary - Client client_1
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0013
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0065
============================================================


============================================================
🔄 Round 9 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1415, val=0.1059 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0890, val=0.0903 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0836, val=0.0869 (↓), lr=0.000250
   • Epoch   4/100: train=0.0829, val=0.0870, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0827, val=0.0871, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0824, val=0.0872, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 9 Summary - Client client_1
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0023
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0019
============================================================


============================================================
🔄 Round 10 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1609, val=0.1361 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1368, val=0.1159 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1160, val=0.1004 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0997, val=0.0898 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0890, val=0.0856 (↓), lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0832, val=0.0860, patience=6/15, lr=0.000031
   📉 Epoch 19: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 10 Summary - Client client_1
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0231
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0141
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.1534, RMSE: 0.3917, MAE: 0.3199, R²: -0.8538

📊 Round 10 Test Metrics:
   Loss: 0.1368, RMSE: 0.3699, MAE: 0.3040, R²: -0.6535

📊 Round 10 Test Metrics:
   Loss: 0.1317, RMSE: 0.3629, MAE: 0.2991, R²: -0.5913

============================================================
🔄 Round 16 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1290, val=0.1301 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1243, val=0.1249 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1192, val=0.1199 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1144, val=0.1154 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1101, val=0.1113 (↓), lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.0958, val=0.0984 (↓), lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.0884, val=0.0914 (↓), lr=0.000004
   📉 Epoch 23: LR reduced 0.000004 → 0.000002
   📉 Epoch 31: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.0865, val=0.0895 (↓), lr=0.000001
   • Epoch  41/100: train=0.0858, val=0.0889, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.0853, val=0.0883, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0849, val=0.0879, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.0845, val=0.0875, patience=12/15, lr=0.000001
   • Epoch  81/100: train=0.0842, val=0.0872, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 16 Summary - Client client_1
   Epochs: 88/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0116
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0196
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1274, RMSE: 0.3570, MAE: 0.2950, R²: -0.5398

============================================================
🔄 Round 20 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0945, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0943, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0941, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0940, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0938, val=0.0735, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0930, val=0.0728 (↓), lr=0.000001
   • Epoch  21/100: train=0.0918, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  31/100: train=0.0908, val=0.0713, patience=7/15, lr=0.000001
   • Epoch  41/100: train=0.0900, val=0.0707, patience=9/15, lr=0.000001
   • Epoch  51/100: train=0.0893, val=0.0703, patience=9/15, lr=0.000001
   • Epoch  61/100: train=0.0888, val=0.0700, patience=5/15, lr=0.000001
   • Epoch  71/100: train=0.0884, val=0.0698, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 20 Summary - Client client_1
   Epochs: 71/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0226
   Val:   Loss=0.0702, RMSE=0.2649, R²=-0.0094
============================================================


============================================================
🔄 Round 23 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 23 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0044
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0089
============================================================


============================================================
🔄 Round 25 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 25 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0006
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0252
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2505, R²: -0.0007

📊 Round 25 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2505, R²: -0.0004

============================================================
🔄 Round 27 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 27 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0032
   Val:   Loss=0.0783, RMSE=0.2797, R²=-0.0005
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2505, R²: -0.0000

📊 Round 27 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2504, R²: 0.0003

============================================================
🔄 Round 30 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 30 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0010
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0406
============================================================


============================================================
🔄 Round 31 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 31 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0001
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0084
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2504, R²: 0.0005

============================================================
🔄 Round 33 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 33 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0005
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0035
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2504, R²: 0.0007

📊 Round 33 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2503, R²: 0.0008

📊 Round 33 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2503, R²: 0.0009

============================================================
🔄 Round 38 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 38 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0016
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0118
============================================================


============================================================
🔄 Round 39 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 39 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0026
   Val:   Loss=0.0849, RMSE=0.2915, R²=-0.0118
============================================================


============================================================
🔄 Round 41 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 41 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0009
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0053
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2502, R²: 0.0014

============================================================
🔄 Round 43 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 43 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0011
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0015
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2502, R²: 0.0014

============================================================
🔄 Round 44 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 44 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0006
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0003
============================================================


============================================================
🔄 Round 47 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 47 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0004
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0011
============================================================


============================================================
🔄 Round 48 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 48 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0013
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0025
============================================================


============================================================
🔄 Round 51 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 51 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0008
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0058
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2502, R²: 0.0016

📊 Round 51 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2502, R²: 0.0015

============================================================
🔄 Round 54 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 54 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0016
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0217
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2502, R²: 0.0015

============================================================
🔄 Round 55 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 55 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0004
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0027
============================================================


============================================================
🔄 Round 58 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 58 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0006
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0046
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2502, R²: 0.0015

============================================================
🔄 Round 61 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 61 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0006
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0041
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2502, R²: 0.0016

📊 Round 61 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2502, R²: 0.0016

============================================================
🔄 Round 63 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 63 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0006
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0010
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2502, R²: 0.0016

============================================================
🔄 Round 64 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 64 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0008
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0134
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2502, R²: 0.0016

📊 Round 64 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2502, R²: 0.0016

📊 Round 64 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2502, R²: 0.0016

============================================================
🔄 Round 70 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 70 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0018
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0082
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2502, R²: 0.0016

📊 Round 70 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2502, R²: 0.0017

📊 Round 70 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2502, R²: 0.0017

============================================================
🔄 Round 74 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 74 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0024
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0074
============================================================


============================================================
🔄 Round 75 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 75 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0007
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0001
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

📊 Round 75 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

============================================================
🔄 Round 81 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 81 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0018
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0004
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0018

============================================================
🔄 Round 85 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 85 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0005
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0015
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

📊 Round 85 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

📊 Round 85 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

📊 Round 85 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

============================================================
🔄 Round 91 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 91 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0007
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0089
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

============================================================
🔄 Round 92 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 92 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0004
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0049
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0018

============================================================
🔄 Round 96 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 96 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0006
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0077
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

📊 Round 96 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0018

📊 Round 96 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

============================================================
🔄 Round 106 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 106 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0003
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0076
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

📊 Round 106 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0018

============================================================
🔄 Round 109 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 109 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0004
   Val:   Loss=0.0866, RMSE=0.2944, R²=-0.0044
============================================================


============================================================
🔄 Round 110 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 110 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0002
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0004
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0018

============================================================
🔄 Round 111 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 111 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0004
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0267
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0018

📊 Round 111 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

📊 Round 111 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

============================================================
🔄 Round 116 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 116 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0007
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0028
============================================================


============================================================
🔄 Round 117 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 117 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0005
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0037
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

============================================================
🔄 Round 119 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 119 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0015
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0024
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

📊 Round 119 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

============================================================
🔄 Round 121 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 121 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0013
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0079
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

============================================================
🔄 Round 122 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 122 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0005
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0012
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

📊 Round 122 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

============================================================
🔄 Round 126 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 126 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0009
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0018
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

📊 Round 126 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

============================================================
🔄 Round 128 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 128 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0010
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0020
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

📊 Round 128 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

============================================================
🔄 Round 133 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 133 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0008
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0041
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

📊 Round 133 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

📊 Round 133 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0017

============================================================
🔄 Round 142 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 142 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0001
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0008
============================================================


============================================================
🔄 Round 143 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 143 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0011
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0078
============================================================


============================================================
🔄 Round 144 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 144 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0019
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0186
============================================================


============================================================
🔄 Round 145 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 145 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0003
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0071
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0016

============================================================
🔄 Round 148 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 148 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0011
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0009
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0015

============================================================
🔄 Round 153 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 153 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0013
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0020
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0015

============================================================
🔄 Round 155 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 155 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0010
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0030
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0015

============================================================
🔄 Round 159 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 159 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0008
   Val:   Loss=0.0716, RMSE=0.2677, R²=0.0076
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0015

============================================================
🔄 Round 161 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 161 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0002
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0025
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0015

📊 Round 161 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0015

============================================================
🔄 Round 164 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 164 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0004
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0052
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0015

============================================================
🔄 Round 167 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 167 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0001
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0005
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0015

============================================================
🔄 Round 169 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 169 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0000
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0098
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0015

============================================================
🔄 Round 171 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 171 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0004
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0015
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0015

============================================================
🔄 Round 172 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 172 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0004
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0049
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0015

============================================================
🔄 Round 175 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 175 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0022
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0101
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0015

📊 Round 175 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0015

📊 Round 175 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0015

📊 Round 175 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0015

📊 Round 175 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0015

📊 Round 175 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0015

============================================================
🔄 Round 183 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 183 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0017
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0122
============================================================


============================================================
🔄 Round 184 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 184 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0006
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0004
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0015

============================================================
🔄 Round 188 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 188 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0001
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0068
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0014

============================================================
🔄 Round 190 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 190 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0008
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0001
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0014

📊 Round 190 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0014

============================================================
🔄 Round 193 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 193 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0003
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0013
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0014

📊 Round 193 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0014

============================================================
🔄 Round 196 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 196 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0019
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0127
============================================================


============================================================
🔄 Round 197 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 197 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0001
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0113
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0014

============================================================
🔄 Round 199 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 199 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0006
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0311
============================================================


============================================================
🔄 Round 201 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 201 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0014
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0180
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0014

📊 Round 201 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0014

📊 Round 201 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0014

============================================================
🔄 Round 206 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 206 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0009
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0054
============================================================


============================================================
🔄 Round 207 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 207 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0007
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0018
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0014

📊 Round 207 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0014

============================================================
🔄 Round 209 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 209 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0010
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0033
============================================================


============================================================
🔄 Round 210 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 210 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0008
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0005
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2501, R²: 0.0014

❌ Client client_1 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
