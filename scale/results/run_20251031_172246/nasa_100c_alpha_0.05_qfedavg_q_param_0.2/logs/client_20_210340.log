[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ecdefbd-3cd1-4acf-bfd8-6fc1e5f34d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3660429-b55e-495a-97ee-0a5d5b78c40f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45df19b9-c2f6-48e9-bbef-67c02e35a9a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7516e75a-4a96-4abd-975f-bb3a04ddb0ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db5766a8-1c2b-4a96-bf15-c71957b43d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0d12d32-b064-436d-b4a1-b8c1bea09e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c04c3e85-d89b-407a-8b2d-3db62dd85d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cb02516-bd48-49b7-9063-a9e7c8351df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f723bff-780f-46a2-84f4-c678ee6600d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f70af9b-3cc2-4226-be2b-c9f0f46270a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3f0a06b-786b-4ca7-a237-c7d542c70100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9519d86b-a15b-43d1-bf35-146e0c5ff132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c004738f-822d-4f7f-9ca2-78aa2c8ad188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab13a86e-9c27-4160-a4af-9fca05fc55ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e253febf-fcc8-4be0-8405-22b4e5784eb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f0fdea8-365e-4531-9afe-d27ee844b91c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d27c1a3c-8a1b-451b-92b1-06a906ac3616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac6e8796-27af-4532-a4b2-d739e60b175d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2a50505-62ad-4792-9c9f-a8d4fcc73900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05eee642-09b3-4836-b01d-ceee75830778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09542143-ad6b-4447-a1c2-8ed6480f1e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33052516-860e-43af-8667-8542d299e324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcc49678-9841-470b-a306-da0514e37718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43425bee-eaf0-41ee-8345-733f581d433b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a960cc5-d823-4d24-8efb-106ee979b3bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cec0fbd-d46c-4fbf-a5c5-f5f5e1285d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a91b8297-69e7-4e4f-91a9-0a141f22f1be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a5e9c6-fefb-4e79-87c9-270f2bd94306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62bf4e71-0993-496e-9a2c-b5694f7da53c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6879dd75-cf93-4121-9bc9-3129a308b91f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2010a73-116d-4a39-8d7e-a2c3877dc0c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5081e56d-0473-40d6-992a-b72a6d4fba37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe4697f9-12c1-44a3-ae12-1afae0bf9460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78f30c84-932c-468f-9c2f-de585ea8acda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0067dd61-a1d9-4ee9-aa7e-992bcf57b702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d328babf-8de8-4be8-b660-e60011e1c135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60036b64-e960-495f-9d15-598cc05b5be0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09fce390-dba4-416c-b735-f2f96d9a5e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8f00e28-5f1e-48e3-bb6d-80ea5e6be452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd91ce1a-223e-42b6-a781-6f3d047926ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af589987-fd9f-49f9-8bbe-9804ccae3686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dd1ac95-5bda-4af4-9d71-b21d3d0c7d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 647109f2-56d8-4b50-83cf-20af971bc7de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beda3885-6fad-4f2f-aff1-1df8b2a2f4cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f82f34e-0d6f-4cea-a95a-b2eaee1d70f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2e8ed43-8f23-47a7-9456-754b731964ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b97d5c7d-a905-4498-860d-6749a90d2352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1c5e028-fc41-4b3b-b71e-629aba7e5f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55290c1a-db97-4f40-9953-d48a3a08ffb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb395a3-805f-450a-9191-0b479f827c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7e70adf-6607-4c02-bf3c-4670e11e6f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message defede59-da6d-4604-a27d-2036beb64f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f67953b-1657-462d-8b1c-46da5725dc1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42a4766e-e294-40f8-ae5d-26441773d315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80e175a1-2db3-4223-a4ea-5d8463202af0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc30e382-b86b-4943-9cd7-72f575f8fb90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aaa381e-76eb-4c2b-a790-62c80a3a6c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba4bcabe-020c-420f-88d5-943f2f20047e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b415f48-9eaf-4b67-be9e-e9ab54868f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccd6f25f-b015-46b9-950d-5c1c0420617f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 399254cb-64e9-4c5a-a850-ee63b70e7ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd314202-420a-4446-8321-c5d342773075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14619114-cb7a-4084-9559-b9936f4a01c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d5182da-4c8a-4f51-8a72-3a6cfc452d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dac99ab6-a5d7-4faf-80b2-8b65c8ba5f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a74fb8c6-8ae3-4b2f-90f5-4cdee9bad786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29c41675-5bd0-476b-af2e-456f5b7aa4e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef3dc439-86db-484a-95f4-952ac4d5584b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06257a78-d42a-4cdb-aa06-f03b5a2a8db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba00eb8c-7515-4a65-8221-b0e2ebdb911d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe9feb54-0eae-4545-a796-10ac2bf19911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f60bc2c-7e86-41ac-85ba-ef200f735c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48003cef-6282-4e53-ba21-6e4a56795208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac966011-7d96-4b98-b73f-b0e6c3011373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4517e2f8-0b0b-4f19-99e4-cd2d66750343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83f95e16-1ad6-4467-b6d7-052b1623ab29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb9ec820-e196-4613-997f-3e118b0b1da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a330395-e86d-4c29-9593-9ef3d5cd5d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0915d37-d54b-449b-b5fa-a739376f359c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a250c99-6db4-4eb4-8215-149cb91ad338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 689d559f-e4c3-43b7-9e92-b889f312879b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 321a9d82-9e46-4f52-877f-81abe26e7a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df18144c-0d1f-460f-8451-cee0046531f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d02bc182-2d1b-46a9-a55b-3211cf6ecb17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c1a15b6-230e-40fc-b6a9-618a5cb0c167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87bd87fa-c3d3-42ca-9264-14563f2a0e20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96aebb69-75e3-4da0-b251-27872ba7de5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16fc7fd4-f5c7-447e-9064-af984ed3fa10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c52da47-a2b3-4dc7-b4f1-2c953420a463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18e91689-4c88-4e31-a7ba-6ea56b98e29a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a30e99e6-b5ea-44a2-9c29-5b4a1c54a04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 810edc1b-8374-4edf-9431-4ffd3d497274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a69939-4c16-4e42-9718-26f0427e5ed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfba1e56-af32-4564-82db-972fb68c638c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8d947a4-1873-4ce7-bd99-86fb74425fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5402f9e4-846b-4fb6-a8f5-22c47b39c335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffbe57fc-7984-4cb9-b303-6a4f38584644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1baff9f-fcbb-414e-ac8d-8b48ee613885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90c9e7e6-a7bc-482f-bf77-76843ee2f394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc923599-4a7e-4796-a90d-3d8ee96df8ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fcf78b3-1751-4d38-9d98-6522ffc3d6b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54283512-2517-4af3-8588-27f03e6c83f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebd3ba7a-de35-4afd-ba83-00bb829d807c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b45f6ab4-0370-44d4-816f-d56dc61a8956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6424c171-fa53-48d1-bcce-075e8da50c1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97323945-a332-45af-a96a-9fe57af561d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73fe7b3d-9f6f-4886-8c01-e2819f8beb4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e0f1b91-8f04-4e9a-9f3f-bbd298adfa76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aecf8a6c-5f63-4751-9004-0e7f6e218079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f9c49cc-b74c-487e-946a-356880d705c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6358e6e1-ce6c-449c-ae0f-96643df48144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ccb23da-bcc4-4c00-a977-3856ba9dfd23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c512e96b-06bb-4df7-9411-aac213ffecc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0bd1474-5134-4072-95c2-0e5ec4f0e4c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0306fbeb-9526-4fe3-8cdb-c81b2bfb9801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0728c66-f20d-4a56-ba6a-d2df43b10720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dbbe0bb-7ee6-4a19-b486-e5d4ab3d368c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0567a34c-5607-4e48-881c-1c450cb6f4f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ee4683-6c19-4453-b276-60d72b21d9d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21de0e92-8cfa-47ce-99a8-2840da364a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5b49872-44cf-44e2-8f8c-06323b66c5ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2596db00-5f12-4544-995c-52593c76f252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d76d41a2-0ce8-4bd5-aed4-85f5c32e0e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9243ca8-117a-4931-b1b0-938c61149fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1812c909-efae-4631-b4d2-cbcf6988bf9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c6345b5-2c6d-4284-8c4d-f6eb0007d2bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 664e9349-22f4-4e45-b51f-01fe713974ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66c958a9-5b42-4581-9d59-8d3f88398469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e158941-b58a-4267-a19e-4681967e28ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e14ed068-09b6-43d3-8d00-a1e8ee50b58e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 074a30c5-c3c1-4ed1-871e-1d5c0558f470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e78bd8b1-1c16-491b-8b67-ce909a49b62d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14cbc3cd-c756-499f-b34c-cf3d4d29b663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f14ac79-a3a2-429d-ae4f-00f360e404eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb377bae-7064-4d0b-b47c-f422437c64db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebb5ab34-be23-4552-9387-d0e47b761b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b685bd1a-8c90-4c1f-a93a-e69ad8a05d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44ad346e-9a92-48a9-8a14-3bde7ea922df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c05f33fe-5343-44e3-a3a8-ea210e66feef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a49372a-ba63-4cf0-9d91-ba8b72ceaebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55dfe454-ab0a-4509-bdef-60dac46bd2ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94db1508-0bd0-4d97-acbe-c5915b1f439b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98a1d513-1bb7-49c7-bd73-ada137aa1e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c0faa43-65ef-4f2c-944f-d91b77de1d30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a071838c-31ca-4abd-b778-e94b4ba329c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd331873-7b8a-425f-a8f1-5839e7103060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7ceb4d4-eab2-463d-997d-2a5a1e4003d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 899afdcd-fbaf-40dc-889f-ee9dea6bda21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cd58f51-a190-407e-8e16-32f1ddee2907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3a19a8e-2454-4508-8de9-dd3ad6a7197c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d20a60a-a884-43a9-8ba5-8bdcdfd7b961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 115fa109-37d5-4894-8e6a-ddbba6c3805c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca34df8b-1807-47b0-9322-6e2c3ff45171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54f5746c-c024-49ad-9fe1-fdf6fb32d1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7e04258-5f64-4d87-889f-71c154419fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9980539d-f2b9-4e11-8c5b-13bec9f2745e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5274e883-8296-4a8e-b029-9fc6bd2ddb08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dae36c3-ee65-43bb-b632-6e4b948747bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9f2f1c3-3e4e-4dbd-88e5-99674e9c1505
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_20
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/test_labels.txt

📊 Raw data loaded:
   Train: X=(2028, 24), y=(2028,)
   Test:  X=(508, 24), y=(508,)

⚠️  Limiting training data: 2028 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  499 samples, 5 features
✅ Client client_20 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1422, val=0.0871 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0867, val=0.0800 (↓), lr=0.001000
   • Epoch   3/100: train=0.0852, val=0.0802, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0856, val=0.0799, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0854, val=0.0799, patience=3/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0846, val=0.0801, patience=9/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 1 Summary - Client client_20
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0007
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0122
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.2121, RMSE: 0.4606, MAE: 0.3755, R²: -1.4861

============================================================
🔄 Round 3 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.1679, val=0.1042 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0906, val=0.0880 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0836, val=0.0857 (↓), lr=0.000250
   • Epoch   4/100: train=0.0837, val=0.0858, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0835, val=0.0858, patience=2/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0833, val=0.0858, patience=8/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 3 Summary - Client client_20
   Epochs: 18/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0015
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0027
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.2008, RMSE: 0.4481, MAE: 0.3642, R²: -1.3531

============================================================
🔄 Round 4 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2008, val=0.1965 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1742, val=0.1698 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1520, val=0.1478 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1327, val=0.1275 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.1151, val=0.1087 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0848, val=0.0806, patience=2/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0846, val=0.0804, patience=9/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 4 Summary - Client client_20
   Epochs: 27/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0019
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0054
============================================================


============================================================
🔄 Round 5 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2106, val=0.1750 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.2066, val=0.1714 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.2025, val=0.1682 (↓), lr=0.000008
   📉 Epoch 4: LR reduced 0.000008 → 0.000004
   ✓ Epoch   4/100: train=0.1987, val=0.1652 (↓), lr=0.000004
   ✓ Epoch   5/100: train=0.1960, val=0.1639 (↓), lr=0.000004
   ✓ Epoch  11/100: train=0.1870, val=0.1568 (↓), lr=0.000004
   📉 Epoch 12: LR reduced 0.000004 → 0.000002
   📉 Epoch 20: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.1801, val=0.1516, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.1773, val=0.1494, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1747, val=0.1474 (↓), lr=0.000001
   • Epoch  51/100: train=0.1722, val=0.1454, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1698, val=0.1435, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1674, val=0.1417 (↓), lr=0.000001
   • Epoch  81/100: train=0.1651, val=0.1399, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1628, val=0.1381, patience=2/15, lr=0.000001

============================================================
📊 Round 5 Summary - Client client_20
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.1605, RMSE=0.4007, R²=-0.9706
   Val:   Loss=0.1365, RMSE=0.3695, R²=-0.5235
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1901, RMSE: 0.4360, MAE: 0.3537, R²: -1.2275

============================================================
🔄 Round 6 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1993, val=0.2125 (↓), lr=0.000001
   • Epoch   2/100: train=0.1990, val=0.2122, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1987, val=0.2119 (↓), lr=0.000001
   • Epoch   4/100: train=0.1984, val=0.2116, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1981, val=0.2113 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1965, val=0.2095 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1939, val=0.2068 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1915, val=0.2043 (↓), lr=0.000001
   • Epoch  41/100: train=0.1892, val=0.2018, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1869, val=0.1993 (↓), lr=0.000001
   • Epoch  61/100: train=0.1847, val=0.1969, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1824, val=0.1945, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1802, val=0.1921 (↓), lr=0.000001
   • Epoch  91/100: train=0.1780, val=0.1897, patience=1/15, lr=0.000001

============================================================
📊 Round 6 Summary - Client client_20
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1751, RMSE=0.4185, R²=-1.0774
   Val:   Loss=0.1876, RMSE=0.4331, R²=-1.3127
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.1679, RMSE: 0.4098, MAE: 0.3319, R²: -0.9679

============================================================
🔄 Round 12 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1633, val=0.1826 (↓), lr=0.000001
   • Epoch   2/100: train=0.1631, val=0.1824, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1629, val=0.1821 (↓), lr=0.000001
   • Epoch   4/100: train=0.1626, val=0.1819, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1624, val=0.1816 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1610, val=0.1800 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1588, val=0.1774 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1565, val=0.1748 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1543, val=0.1722 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1520, val=0.1696 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1498, val=0.1670 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1476, val=0.1644 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1454, val=0.1618 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1431, val=0.1592 (↓), lr=0.000001

============================================================
📊 Round 12 Summary - Client client_20
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1414, RMSE=0.3760, R²=-0.6655
   Val:   Loss=0.1568, RMSE=0.3960, R²=-1.0186
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1143, RMSE: 0.3380, MAE: 0.2808, R²: -0.3391

📊 Round 12 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2622, R²: -0.0909

============================================================
🔄 Round 20 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0955, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0953, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0951, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0950, val=0.0954, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0948, val=0.0952 (↓), lr=0.000001
   • Epoch  11/100: train=0.0939, val=0.0943, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0925, val=0.0929 (↓), lr=0.000001
   • Epoch  31/100: train=0.0913, val=0.0917, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0902, val=0.0906, patience=1/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0892, val=0.0896 (↓), lr=0.000001
   • Epoch  61/100: train=0.0883, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.0875, val=0.0879, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0868, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0862, val=0.0866, patience=6/15, lr=0.000001

============================================================
📊 Round 20 Summary - Client client_20
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0234
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0276
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2578, R²: -0.0300

============================================================
🔄 Round 21 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0904, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0875, val=0.0897 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.0869, val=0.0886 (↓), lr=0.000001
   • Epoch  31/100: train=0.0864, val=0.0876, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0860, val=0.0867, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0856, val=0.0859, patience=6/15, lr=0.000001
   • Epoch  61/100: train=0.0853, val=0.0853, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0851, val=0.0847, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0849, val=0.0842, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0848, val=0.0838 (↓), lr=0.000001

============================================================
📊 Round 21 Summary - Client client_20
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0064
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0362
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2571, R²: -0.0178

📊 Round 21 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2569, R²: -0.0122

============================================================
🔄 Round 23 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0803, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0864, val=0.0799, patience=11/15, lr=0.000001
   • Epoch  31/100: train=0.0860, val=0.0796, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 23 Summary - Client client_20
   Epochs: 37/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0177
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0087
============================================================


============================================================
🔄 Round 24 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0895, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0837, val=0.0892, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0834, val=0.0890, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 24 Summary - Client client_20
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0188
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0107
============================================================


============================================================
🔄 Round 25 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0956, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0825, val=0.0953 (↓), lr=0.000001
   • Epoch  21/100: train=0.0822, val=0.0949, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0819, val=0.0947, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 25 Summary - Client client_20
   Epochs: 40/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0103
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0157
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2567, R²: -0.0080

============================================================
🔄 Round 28 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0790, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.0866, val=0.0784, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0865, val=0.0779, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0864, val=0.0775, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0864, val=0.0772, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 28 Summary - Client client_20
   Epochs: 53/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0040
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0729
============================================================


============================================================
🔄 Round 29 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0798, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0860, val=0.0795, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 29 Summary - Client client_20
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0129
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0097
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2567, R²: -0.0065

============================================================
🔄 Round 31 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0913, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0833, val=0.0908, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0832, val=0.0903, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0831, val=0.0900, patience=12/15, lr=0.000001
   • Epoch  51/100: train=0.0831, val=0.0897, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 31 Summary - Client client_20
   Epochs: 58/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0035
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0439
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2567, R²: -0.0061

📊 Round 31 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2567, R²: -0.0060

============================================================
🔄 Round 34 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0909, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0835, val=0.0906 (↓), lr=0.000001
   • Epoch  21/100: train=0.0833, val=0.0903, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0832, val=0.0900, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0831, val=0.0898, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 34 Summary - Client client_20
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0059
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0175
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2567, R²: -0.0058

============================================================
🔄 Round 35 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 35 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0184
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0088
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2567, R²: -0.0057

============================================================
🔄 Round 37 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 37 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0211
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0001
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2567, R²: -0.0055

============================================================
🔄 Round 38 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0876, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0836, val=0.0873, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 38 Summary - Client client_20
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0093
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0129
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2566, R²: -0.0052

============================================================
🔄 Round 41 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 41 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0188
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0004
============================================================


============================================================
🔄 Round 42 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 42 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0218
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0025
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2566, R²: -0.0051

============================================================
🔄 Round 43 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0916, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0828, val=0.0914, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0826, val=0.0912, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 43 Summary - Client client_20
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0072
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0174
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0858, RMSE: 0.2928, MAE: 0.2566, R²: -0.0050

📊 Round 43 Test Metrics:
   Loss: 0.0858, RMSE: 0.2928, MAE: 0.2566, R²: -0.0050

📊 Round 43 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2566, R²: -0.0050

============================================================
🔄 Round 47 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 47 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0165
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0069
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2566, R²: -0.0049

📊 Round 47 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2566, R²: -0.0049

📊 Round 47 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2566, R²: -0.0048

📊 Round 47 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2566, R²: -0.0048

============================================================
🔄 Round 56 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 56 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0152
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0071
============================================================


============================================================
🔄 Round 58 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0825, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0850, val=0.0822, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 58 Summary - Client client_20
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0066
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0310
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2566, R²: -0.0047

============================================================
🔄 Round 59 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 59 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0155
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0048
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2566, R²: -0.0046

📊 Round 59 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2566, R²: -0.0046

============================================================
🔄 Round 64 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 64 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0116
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0165
============================================================


============================================================
🔄 Round 65 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 65 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0135
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0105
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2566, R²: -0.0044

📊 Round 65 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2566, R²: -0.0045

============================================================
🔄 Round 68 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0882, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0837, val=0.0878, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0837, val=0.0875, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0836, val=0.0873, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 68 Summary - Client client_20
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0046
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0384
============================================================


============================================================
🔄 Round 70 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0880, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0834, val=0.0877, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0833, val=0.0875, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 70 Summary - Client client_20
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0057
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0183
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2566, R²: -0.0044

📊 Round 70 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2566, R²: -0.0043

📊 Round 70 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2566, R²: -0.0043

📊 Round 70 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2566, R²: -0.0043

============================================================
🔄 Round 75 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 75 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0091
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0238
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2566, R²: -0.0042

============================================================
🔄 Round 76 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 76 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0170
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0022
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2566, R²: -0.0042

============================================================
🔄 Round 77 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0844, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0845, val=0.0841, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 77 Summary - Client client_20
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0048
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0433
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2566, R²: -0.0041

============================================================
🔄 Round 80 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 80 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0086
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0257
============================================================


============================================================
🔄 Round 82 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 82 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0111
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0145
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2566, R²: -0.0041

============================================================
🔄 Round 83 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 83 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0116
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0107
============================================================


============================================================
🔄 Round 86 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 86 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0096
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0208
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2566, R²: -0.0040

📊 Round 86 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2566, R²: -0.0039

📊 Round 86 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2566, R²: -0.0039

📊 Round 86 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2566, R²: -0.0039

============================================================
🔄 Round 96 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 96 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0079
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0237
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2566, R²: -0.0038

============================================================
🔄 Round 101 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 101 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0093
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0165
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2566, R²: -0.0037

📊 Round 101 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2566, R²: -0.0037

============================================================
🔄 Round 108 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 108 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0112
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0093
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2566, R²: -0.0037

📊 Round 108 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2566, R²: -0.0037

============================================================
🔄 Round 110 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 110 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0088
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0195
============================================================


============================================================
🔄 Round 111 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 111 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0128
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0089
============================================================


============================================================
🔄 Round 114 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0763, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0865, val=0.0760, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0864, val=0.0758, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 114 Summary - Client client_20
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0029
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0473
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2566, R²: -0.0036

📊 Round 114 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2566, R²: -0.0036

📊 Round 114 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2566, R²: -0.0036

📊 Round 114 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2566, R²: -0.0035

============================================================
🔄 Round 125 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 125 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0078
   Val:   Loss=0.0805, RMSE=0.2836, R²=-0.0256
============================================================


============================================================
🔄 Round 126 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 126 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0128
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0053
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2566, R²: -0.0035

📊 Round 126 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2566, R²: -0.0034

============================================================
🔄 Round 129 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 129 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0089
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0176
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2566, R²: -0.0034

📊 Round 129 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2566, R²: -0.0034

============================================================
🔄 Round 132 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 132 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0065
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0259
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2566, R²: -0.0034

📊 Round 132 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2566, R²: -0.0034

📊 Round 132 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2566, R²: -0.0034

📊 Round 132 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2566, R²: -0.0033

============================================================
🔄 Round 143 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 143 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0104
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0065
============================================================


============================================================
🔄 Round 145 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 145 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0051
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0374
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2565, R²: -0.0033

============================================================
🔄 Round 148 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 148 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0093
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0120
============================================================


============================================================
🔄 Round 149 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 149 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0076
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0253
============================================================


============================================================
🔄 Round 150 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 150 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0098
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0105
============================================================


============================================================
🔄 Round 151 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 151 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0131
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0057
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2565, R²: -0.0033

📊 Round 151 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2565, R²: -0.0032

============================================================
🔄 Round 156 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 156 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0073
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0214
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2565, R²: -0.0032

============================================================
🔄 Round 157 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 157 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0128
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0004
============================================================


============================================================
🔄 Round 161 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 161 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0187
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0010
============================================================


============================================================
🔄 Round 163 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 163 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0095
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0106
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2565, R²: -0.0032

============================================================
🔄 Round 164 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 164 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0108
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0105
============================================================


============================================================
🔄 Round 165 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 165 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0163
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0004
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2565, R²: -0.0031

============================================================
🔄 Round 167 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 167 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0086
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0128
============================================================


============================================================
🔄 Round 169 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 169 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0055
   Val:   Loss=0.0849, RMSE=0.2915, R²=-0.0358
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2565, R²: -0.0031

📊 Round 169 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2565, R²: -0.0031

📊 Round 169 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2565, R²: -0.0030

============================================================
🔄 Round 173 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 173 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0078
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0154
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2565, R²: -0.0030

============================================================
🔄 Round 177 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 177 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0130
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0020
============================================================


============================================================
🔄 Round 178 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 178 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0070
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0285
============================================================


============================================================
🔄 Round 179 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 179 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0130
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0039
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2565, R²: -0.0030

============================================================
🔄 Round 180 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 180 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0067
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0361
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2565, R²: -0.0030

📊 Round 180 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2565, R²: -0.0030

============================================================
🔄 Round 182 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 182 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0059
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0237
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2565, R²: -0.0030

============================================================
🔄 Round 183 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 183 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0074
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0164
============================================================


============================================================
🔄 Round 186 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 186 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0069
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0238
============================================================


============================================================
🔄 Round 187 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 187 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0053
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0365
============================================================


============================================================
🔄 Round 189 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 189 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0089
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0112
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2565, R²: -0.0029

📊 Round 189 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2565, R²: -0.0029

============================================================
🔄 Round 196 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 196 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0091
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0088
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2565, R²: -0.0029

============================================================
🔄 Round 199 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 199 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0162
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0077
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2565, R²: -0.0029

============================================================
🔄 Round 201 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 201 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0043
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0411
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2565, R²: -0.0029

📊 Round 201 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2565, R²: -0.0028

============================================================
🔄 Round 204 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 204 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0073
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0173
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2565, R²: -0.0028

============================================================
🔄 Round 205 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 205 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0090
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0110
============================================================


============================================================
🔄 Round 206 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 206 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0089
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0106
============================================================


============================================================
🔄 Round 207 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 207 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0071
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0175
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2565, R²: -0.0028

============================================================
🔄 Round 208 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 208 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0047
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0336
============================================================


❌ Client client_20 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
