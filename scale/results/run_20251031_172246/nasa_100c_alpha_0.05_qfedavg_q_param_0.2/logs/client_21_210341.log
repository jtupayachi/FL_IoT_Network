[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8a5687c-9295-41eb-adad-c04de87c6797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 895aebd1-918a-4864-90cd-6f0a8b7c3d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a366fde6-23b1-4b18-b3e6-b13711856ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac3d91b1-c5bb-4f4e-9aa8-06d56c6a987f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12893647-efb2-4bb3-8262-a9254a32af94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7140c5da-b58f-4e6b-8977-00ff82df2748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6071d614-d7ac-4386-b8b3-cd3c8996886a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 360332f2-14c6-4b0f-b367-7266345a83f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51c6c29e-5bff-4820-832e-6de72d681cde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e2cfbf9-9b84-4706-91e1-e19de29f5157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a88b8515-a9f9-4bf3-8c44-28d49c96a8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f13d64a6-2213-49eb-afe9-ec6f38127a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1f48a96-785c-48b8-b1a5-4c01237e8ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f64caf2b-c431-4c5c-b57d-163788f922ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cea0cc6-c00a-4b71-9449-888b611f7ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c8f97d8-ae10-4c3a-8e5f-05e5580cbcc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc1b6760-633d-4481-9265-2e89d1595915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07984624-26a5-4736-9e52-2341c4ba601a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a572d94-9186-4259-a37b-64d6e53ad86e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbe8e3bc-6420-494c-9086-3b02fd04893d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21baef7c-1bd9-41c0-b913-9e8491a1eee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1357e960-2367-45b6-a89f-746ce5a625c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04e76a1b-fa6a-4280-9406-2046f070336d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ece7647b-960f-4d1d-9810-e3e75c7c7369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f2a054b-f62d-479b-976c-917a692e9046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecda7d64-d7d4-47b4-a8b7-88ea76ee72a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c175beca-ce5d-426a-91de-54c33ace36ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ac23b8e-77f1-49db-a1ca-6f40e7778bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc4eeac8-c0f1-49ee-b398-b3a65e416ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 885cedb3-1824-478e-b367-839aabd297ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71f48121-6065-4752-97db-fdd38a756982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4311c10c-6600-43ac-9058-f3177b8dc60e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54dcaf4b-ff0b-4aa2-b474-42fa2c464dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f349841-b350-4124-ad54-7029a396f7e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a25a6c0-f35d-48e9-b087-1bfe880bcfc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ecf1d55-7ca3-41f5-b7e6-2399d9151344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05615e6d-0f19-47ef-927b-70861a04b53d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 461dd3d6-7e98-4046-ac72-2a0bb000a66b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e4f55e3-b02f-479a-b686-3c7f8d81fe25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65040be5-ea9c-4a16-91a7-e6f7b65ddcac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc325594-cf83-4df3-ae58-9c4ae8996c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e77e47b-e0b2-4e26-a4ff-eef1bdcef392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c090ff7a-9323-4806-bd0f-3feaaaca6a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e51abf7d-cd11-432e-ab11-6cf3607d7ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c59ea4e6-a265-4617-997a-b3c600ccb6a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10dedd7e-73ac-43eb-b298-13683d2d2f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 318def2d-f26d-417b-85e2-c029afe4fecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c07acc0d-3e8a-4d40-9e03-5b0f4b31d5b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5281c973-dfba-49fd-a291-f6cfc9cae76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50a573c5-543c-4644-96aa-0bf9dba4f8e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12590b35-e43a-425b-b37a-0e13f296364c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc0592b7-4e95-485d-a157-9b23c1136598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c43ca634-e4d1-40fd-81de-3bf120520448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96f65bdb-00aa-434c-9470-d53e2c205148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29667565-1319-454b-a893-78a25275332b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92955907-0d94-48d8-bcae-9812e619e7c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fb64f85-cf0f-4293-bfc9-53c42f8de4e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 077a6c68-dfc8-4629-9150-6d5b7be41703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe55ab89-9d37-4f31-83a2-ce3bccacd8a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55f2b406-c64e-4fbb-98de-422e472fb4a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c169614c-54de-477e-be81-31e1e3f8ef8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5a34e06-14dd-4ff0-9b64-ae0637ea1664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7da9f3b-3dd7-44d3-803a-859e14e3797d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e70e3f2-caa0-4a1f-a633-b9acac1451ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 053e9de4-3c59-406e-a2d5-4b6753ff29ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74f9cfb1-3d51-4927-83c1-06ca4f1a64bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d10a1459-4cc6-4ea8-9dae-1df541403802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 002d70bd-f63a-4544-9a5e-aa876f914a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee886b21-a944-42f2-b5bd-35762eca115a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ce0edbc-f31d-43cf-bd44-c36f1c811687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5943c2ce-6d43-483b-bcc2-6ca847294361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7204bd44-d101-4c43-8e44-d6f2996433ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d87c7d4f-2748-4e4a-90a6-ae7ff1748e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0c01222-5d15-4aec-abf2-9ade76ca7fdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07e6a06c-7f42-447a-8fa1-1380b46b9531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d83345e2-a25c-4305-8b3b-2f9e2787f3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2402395a-6e8b-466a-8485-35c01b7b775a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a7b2074-1e3a-40cd-b27b-b53976da5d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf2c59e4-a79f-4b3b-aec2-a3ed61f42e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02bb240b-85d4-4989-bb63-e9c3f65b63f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 123bc3d9-ed71-41b0-9329-eba1206b9eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a6c4ac-6080-4720-90ea-9144dd6a131f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0cde1e9-66f2-47ab-a11c-b2acc8c3626e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53f76225-fb17-4137-85ca-b983faeb4a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c26929b3-2a5c-4018-8467-9cf64acd4625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd7a2e80-5bbf-451c-8711-06919b41d6cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 925bf370-3694-4823-b085-9308916e2725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4a70264-dee3-4164-96bb-75a35f8f0fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39220cba-9c36-4f1d-b353-c6485994b119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73841f3f-45aa-45c3-bb91-e14e162ca218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41e4c0d9-b786-4e29-b8f3-78ef86ce1511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1e25cd3-5cdf-4ee0-b713-a6feb972c08f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bcd0595-b9a2-4d5a-a0d8-7ebd1d14c5e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32bd29a6-64ce-4869-bb67-1e5ac9f4ea96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e113a085-be61-48e1-bf76-9a802a688c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94932076-7911-4be4-8cf6-bf1371af4c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 171d75be-8b97-48a6-ada0-6fb7589f5412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27e11214-3257-46f3-abb4-ebf78ce3f4b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f511fe2-f99d-4459-908c-9690b386e135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be95535-e2e7-44a4-8443-8799284e855b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 102e329c-0631-4b78-ae02-dd3c633e0698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80fae846-c89a-4bf9-9a81-5435c62b1e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 092441de-8195-4b36-a17e-bbd8ec951b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43f309d4-da26-4299-a673-6f6af64a9d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12028b7d-0d29-4db5-9e2a-60eb5c19d4a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1647acc8-32b1-4ace-ac6a-15b66f3f5885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5edd3e7-2dde-4b16-ab64-742392889482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42d7d5a3-0dba-40f5-b15d-ff678f8eefe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b973f11-5bbd-40f8-8ea7-9efb6555de7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17aa7f70-4241-4bcd-aa4f-1c651f312a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdd92ca3-8eb0-4104-9304-7069c3cda276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b80f34e8-3943-470e-9071-abca0f9563c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e17be19-0e89-4eb1-ab9f-2d988987f280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfa36ad5-13bb-4b4b-b234-598cc0a87e6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ced46246-fa1e-4546-b788-8ce2570cee30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d486a11b-1d4d-4443-96b6-1e514051916e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be4e126a-ed1b-4a85-bae1-cce5659f8429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5ad9046-026e-4ef9-80a7-8aedcb892339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15c36d2e-1c32-43af-b645-166f49cb820f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01107918-c0d5-4733-84be-75f8f840ef99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dd2f9ff-ac56-494b-b02b-b7875c356479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f3d583e-8be8-43c2-847e-5088b5818b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9b1e63c-d150-4dd3-8287-462825180237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f952d0f-799d-45c7-bd83-c57f889df62a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd36a2e-9a29-450f-a8f2-9f29f942f305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e31d6b16-8d2a-4b2a-9dd0-e522de2376ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1220e0b-f726-4178-9d1d-ca8459a9bcc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5f84698-d7c5-4f5b-8862-8de80b94f3d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9651f077-53ad-43ce-8e45-f1e9fed2715b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2e44e82-e063-4064-9fae-b4262ad9b9d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8b5080f-ffed-46c0-9289-94dd4c58b514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bf2f85d-7dfe-4d93-88d5-4919a3ab37ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bb365cc-7802-438d-8380-ebf894db4f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e94fc83a-8294-4a49-86c2-eb8663cd9f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd284582-32e6-44af-a03f-878fadefae06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 627747b7-b396-4323-97d0-1def4b575cea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5057464c-d7d0-473a-96d1-5f8e5b132aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c15a26e-346e-4f76-99ee-03c8fb84a9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5364467-8075-44a6-948a-6b1b16c82442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9135fee-7b42-402b-8ff3-15df9eab3a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b6b3b9f-351a-4e3a-9f12-bc6b9695a9ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d92ec93d-18d8-4ab0-b0b1-03e7cec332ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19fc23c0-30b1-4928-b868-b9cc096617c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47eea684-c8d2-4218-b59e-7f5b0e180c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8269e615-ea60-424e-9e02-e07c394e9b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e9ea543-57a5-4865-83c0-82f4959cfa7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f872987-2025-4a5d-8e43-af02e837e09c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 239a6321-4507-459d-b874-b9f7ee97af96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4d78cd1-8dcf-488e-83e0-8a3074a08b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5621d6ae-d413-4c76-8a7c-b4f6db1fedf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04278ad5-85ca-40a1-bffa-ed959b4ac104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee9da342-b921-4a41-b3e6-9f8a8894b0f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dcd05c9-61db-46f7-b817-19dc34c0a6fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2807d1fb-93fc-4815-b501-ceee4d4e9db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d509379-b80d-4c19-8ae9-36ae4347f6fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f20bf589-c217-43ef-94c3-bcab5a8e5a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 789d0a02-1176-4328-8116-91f344d3c927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a6340f9-3156-4ef6-9933-ea943386f93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6c17f1a-6fd2-493f-92a4-2e59bd8f409e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 122817f9-38c8-419e-9d58-b95ea646cee6
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_21
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/test_labels.txt

📊 Raw data loaded:
   Train: X=(1494, 24), y=(1494,)
   Test:  X=(374, 24), y=(374,)

⚠️  Limiting training data: 1494 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  365 samples, 5 features
✅ Client client_21 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1327, val=0.0927 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0867, val=0.0777 (↓), lr=0.001000
   • Epoch   3/100: train=0.0859, val=0.0777, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0852, val=0.0779, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0851, val=0.0777, patience=3/15, lr=0.001000
   • Epoch  11/100: train=0.0844, val=0.0775, patience=9/15, lr=0.001000

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 2 Summary - Client client_21
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.001000 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0076
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0008
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.2093, RMSE: 0.4575, MAE: 0.3774, R²: -1.5728

============================================================
🔄 Round 5 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.001000 → 0.000500
   ✓ Epoch   1/100: train=0.1291, val=0.0986 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0834, val=0.0896 (↓), lr=0.000500
   • Epoch   3/100: train=0.0824, val=0.0909, patience=1/15, lr=0.000500
   • Epoch   4/100: train=0.0819, val=0.0908, patience=2/15, lr=0.000500
   • Epoch   5/100: train=0.0818, val=0.0909, patience=3/15, lr=0.000500
   📉 Epoch 9: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0814, val=0.0913, patience=9/15, lr=0.000250
   📉 Epoch 17: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 5 Summary - Client client_21
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0036
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0041
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1881, RMSE: 0.4337, MAE: 0.3552, R²: -1.3126

============================================================
🔄 Round 7 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1601, val=0.1406 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.1215, val=0.1065 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.0932, val=0.0871 (↓), lr=0.000125
   ✓ Epoch   4/100: train=0.0835, val=0.0856 (↓), lr=0.000125
   • Epoch   5/100: train=0.0835, val=0.0854, patience=1/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0829, val=0.0856, patience=7/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 7 Summary - Client client_21
   Epochs: 19/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0024
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0091
============================================================


============================================================
🔄 Round 11 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1496, val=0.1630 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.1386, val=0.1499 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.1282, val=0.1382 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.1191, val=0.1277 (↓), lr=0.000031
   📉 Epoch 5: LR reduced 0.000031 → 0.000016
   ✓ Epoch   5/100: train=0.1111, val=0.1183 (↓), lr=0.000016
   ✓ Epoch  11/100: train=0.0922, val=0.0967 (↓), lr=0.000016
   📉 Epoch 13: LR reduced 0.000016 → 0.000008
   📉 Epoch 21: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0851, val=0.0863, patience=1/15, lr=0.000004
   📉 Epoch 29: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0844, val=0.0847, patience=2/15, lr=0.000002
   📉 Epoch 37: LR reduced 0.000002 → 0.000001
   • Epoch  41/100: train=0.0842, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  51/100: train=0.0841, val=0.0840, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 11 Summary - Client client_21
   Epochs: 52/100 (early stopped)
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0029
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0405
============================================================


============================================================
🔄 Round 12 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1520, val=0.1539 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1516, val=0.1534 (↓), lr=0.000001
   • Epoch   3/100: train=0.1511, val=0.1530, patience=1/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1507, val=0.1525 (↓), lr=0.000001
   • Epoch   5/100: train=0.1503, val=0.1520, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1481, val=0.1497, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1452, val=0.1465, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.1426, val=0.1437, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1403, val=0.1411, patience=1/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1381, val=0.1386 (↓), lr=0.000001
   • Epoch  61/100: train=0.1360, val=0.1363, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1339, val=0.1340, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1319, val=0.1317 (↓), lr=0.000001
   • Epoch  91/100: train=0.1299, val=0.1295, patience=1/15, lr=0.000001

============================================================
📊 Round 12 Summary - Client client_21
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1284, RMSE=0.3583, R²=-0.4989
   Val:   Loss=0.1275, RMSE=0.3570, R²=-0.7111
============================================================


============================================================
🔄 Round 13 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1461, val=0.1547 (↓), lr=0.000001
   • Epoch   2/100: train=0.1459, val=0.1545, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1456, val=0.1542 (↓), lr=0.000001
   • Epoch   4/100: train=0.1454, val=0.1539, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1452, val=0.1537 (↓), lr=0.000001
   • Epoch  11/100: train=0.1438, val=0.1522, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1417, val=0.1498, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1397, val=0.1476 (↓), lr=0.000001
   • Epoch  41/100: train=0.1377, val=0.1453, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1357, val=0.1431, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1337, val=0.1409 (↓), lr=0.000001
   • Epoch  71/100: train=0.1318, val=0.1387, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1298, val=0.1366, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1279, val=0.1344 (↓), lr=0.000001

============================================================
📊 Round 13 Summary - Client client_21
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1259, RMSE=0.3548, R²=-0.4886
   Val:   Loss=0.1324, RMSE=0.3638, R²=-0.6813
============================================================


============================================================
🔄 Round 16 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1261, val=0.1344 (↓), lr=0.000001
   • Epoch   2/100: train=0.1259, val=0.1342, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1257, val=0.1340, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1255, val=0.1337 (↓), lr=0.000001
   • Epoch   5/100: train=0.1253, val=0.1335, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1242, val=0.1322, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1223, val=0.1300, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1204, val=0.1278 (↓), lr=0.000001
   • Epoch  41/100: train=0.1186, val=0.1256, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1167, val=0.1234, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1149, val=0.1212 (↓), lr=0.000001
   • Epoch  71/100: train=0.1130, val=0.1190, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1112, val=0.1168, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1094, val=0.1147 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_21
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1079, RMSE=0.3285, R²=-0.2750
   Val:   Loss=0.1128, RMSE=0.3358, R²=-0.4419
============================================================


============================================================
🔄 Round 17 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1209, val=0.1352 (↓), lr=0.000001
   • Epoch   2/100: train=0.1207, val=0.1349, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1205, val=0.1347, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1203, val=0.1345 (↓), lr=0.000001
   • Epoch   5/100: train=0.1202, val=0.1343, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1190, val=0.1330, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1171, val=0.1309, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1153, val=0.1288 (↓), lr=0.000001
   • Epoch  41/100: train=0.1135, val=0.1267, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1117, val=0.1247, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1099, val=0.1227 (↓), lr=0.000001
   • Epoch  71/100: train=0.1081, val=0.1207, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1064, val=0.1187, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1047, val=0.1167 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_21
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1033, RMSE=0.3215, R²=-0.2520
   Val:   Loss=0.1150, RMSE=0.3391, R²=-0.3211
============================================================


============================================================
🔄 Round 19 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0991, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0990, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0989, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0987, val=0.0963, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0986, val=0.0962 (↓), lr=0.000001
   • Epoch  11/100: train=0.0978, val=0.0953, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0965, val=0.0937 (↓), lr=0.000001
   • Epoch  31/100: train=0.0953, val=0.0923, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0942, val=0.0909 (↓), lr=0.000001
   • Epoch  51/100: train=0.0931, val=0.0896, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0921, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.0912, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0903, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0895, val=0.0850, patience=4/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_21
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0461
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0944
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0918, RMSE: 0.3030, MAE: 0.2572, R²: -0.1287

📊 Round 19 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2510, R²: -0.0490

============================================================
🔄 Round 21 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 21 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0241
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0054
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2497, R²: -0.0316

📊 Round 21 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2489, R²: -0.0228

============================================================
🔄 Round 23 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 23 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0052
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0041
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2486, R²: -0.0199

============================================================
🔄 Round 24 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 24 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0025
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0146
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2484, R²: -0.0173

📊 Round 24 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2482, R²: -0.0157

============================================================
🔄 Round 26 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 26 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0005
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0216
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: -0.0146

============================================================
🔄 Round 27 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 27 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0019
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0023
============================================================


============================================================
🔄 Round 29 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 29 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0016
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0029
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2478, R²: -0.0119

============================================================
🔄 Round 34 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 34 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0010
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0011
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2477, R²: -0.0110

📊 Round 34 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2477, R²: -0.0102

============================================================
🔄 Round 41 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 41 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0002
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0039
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2476, R²: -0.0101

📊 Round 41 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2476, R²: -0.0100

📊 Round 41 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2476, R²: -0.0098

============================================================
🔄 Round 46 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 46 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0015
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0021
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2476, R²: -0.0094

📊 Round 46 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2475, R²: -0.0092

📊 Round 46 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2475, R²: -0.0092

============================================================
🔄 Round 56 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 56 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0003
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0030
============================================================


============================================================
🔄 Round 59 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 59 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0001
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0025
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2475, R²: -0.0088

📊 Round 59 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2475, R²: -0.0088

============================================================
🔄 Round 65 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 65 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0008
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0075
============================================================


============================================================
🔄 Round 66 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 66 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0005
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0080
============================================================


============================================================
🔄 Round 67 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 67 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0003
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0022
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2475, R²: -0.0087

============================================================
🔄 Round 74 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 74 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0010
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0006
============================================================


============================================================
🔄 Round 75 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 75 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0013
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0159
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2474, R²: -0.0078

📊 Round 75 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2474, R²: -0.0079

============================================================
🔄 Round 79 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 79 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0003
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0001
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2474, R²: -0.0079

============================================================
🔄 Round 80 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 80 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0017
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0142
============================================================


============================================================
🔄 Round 81 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 81 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0001
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0024
============================================================


============================================================
🔄 Round 82 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 82 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0005
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0112
============================================================


============================================================
🔄 Round 85 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 85 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0031
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0386
============================================================


============================================================
🔄 Round 86 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 86 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0017
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0022
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2474, R²: -0.0079

============================================================
🔄 Round 87 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 87 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0005
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0016
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2474, R²: -0.0077

📊 Round 87 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2474, R²: -0.0076

============================================================
🔄 Round 90 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 90 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0024
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0306
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2474, R²: -0.0075

============================================================
🔄 Round 93 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 93 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0006
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0002
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0073

============================================================
🔄 Round 98 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 98 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0000
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0015
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2473, R²: -0.0074

📊 Round 98 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0073

============================================================
🔄 Round 101 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 101 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0009
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0006
============================================================


============================================================
🔄 Round 102 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 102 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0001
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0048
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0071

============================================================
🔄 Round 103 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 103 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0003
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0020
============================================================


============================================================
🔄 Round 104 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 104 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0032
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0040
============================================================


============================================================
🔄 Round 105 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 105 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0005
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0030
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0071

============================================================
🔄 Round 106 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 106 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0014
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0080
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0070

============================================================
🔄 Round 107 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 107 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0002
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0075
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0069

============================================================
🔄 Round 109 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 109 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0000
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0013
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0068

============================================================
🔄 Round 111 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 111 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0001
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0051
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0067

============================================================
🔄 Round 112 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 112 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0010
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0029
============================================================


============================================================
🔄 Round 113 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 113 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0010
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0065
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0068

📊 Round 113 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0069

============================================================
🔄 Round 116 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 116 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0012
   Val:   Loss=0.0868, RMSE=0.2945, R²=0.0037
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0068

============================================================
🔄 Round 117 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 117 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0012
   Val:   Loss=0.0947, RMSE=0.3078, R²=0.0015
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0069

============================================================
🔄 Round 118 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 118 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0003
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0025
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0068

============================================================
🔄 Round 119 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 119 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0008
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0006
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0068

============================================================
🔄 Round 120 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 120 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0003
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0023
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0067

============================================================
🔄 Round 123 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 123 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0009
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0051
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0068

============================================================
🔄 Round 124 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 124 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0009
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0062
============================================================


============================================================
🔄 Round 130 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 130 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0009
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0028
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2473, R²: -0.0066

============================================================
🔄 Round 131 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 131 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0008
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0055
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2473, R²: -0.0066

============================================================
🔄 Round 132 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 132 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0014
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0287
============================================================


============================================================
🔄 Round 139 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 139 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0002
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0080
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0063

============================================================
🔄 Round 142 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 142 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0011
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0075
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: -0.0063

============================================================
🔄 Round 143 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 143 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0013
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0046
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: -0.0064

============================================================
🔄 Round 144 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 144 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0009
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0028
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: -0.0065

📊 Round 144 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: -0.0066

📊 Round 144 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: -0.0065

📊 Round 144 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: -0.0065

============================================================
🔄 Round 148 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 148 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0002
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0030
============================================================


============================================================
🔄 Round 149 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 149 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0003
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0119
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: -0.0066

📊 Round 149 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: -0.0065

============================================================
🔄 Round 152 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 152 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0033
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0209
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: -0.0067

============================================================
🔄 Round 158 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 158 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0014
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0025
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: -0.0065

============================================================
🔄 Round 159 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 159 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0001
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0015
============================================================


============================================================
🔄 Round 161 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 161 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0017
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0048
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: -0.0064

============================================================
🔄 Round 165 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 165 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0018
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0030
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: -0.0063

============================================================
🔄 Round 166 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 166 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0012
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0037
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0063

📊 Round 166 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0062

📊 Round 166 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0062

============================================================
🔄 Round 169 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 169 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0013
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0040
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0060

============================================================
🔄 Round 174 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 174 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0005
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0008
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0061

============================================================
🔄 Round 175 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 175 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0006
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0079
============================================================


============================================================
🔄 Round 176 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 176 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0006
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0017
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0061

📊 Round 176 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0061

============================================================
🔄 Round 179 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 179 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0013
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0073
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0061

============================================================
🔄 Round 181 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 181 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0005
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0045
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0060

📊 Round 181 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0061

📊 Round 181 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0061

============================================================
🔄 Round 187 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 187 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0009
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0003
============================================================


============================================================
🔄 Round 188 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 188 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0012
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0038
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0061

📊 Round 188 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0061

============================================================
🔄 Round 193 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 193 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0005
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0010
============================================================


============================================================
🔄 Round 194 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 194 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0005
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0012
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2472, R²: -0.0059

============================================================
🔄 Round 197 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 197 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0006
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0035
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0061

============================================================
🔄 Round 205 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 205 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0001
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0159
============================================================


============================================================
🔄 Round 207 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 207 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0013
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0064
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2472, R²: -0.0059

============================================================
🔄 Round 210 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 210 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0008
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0017
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0060

❌ Client client_21 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
