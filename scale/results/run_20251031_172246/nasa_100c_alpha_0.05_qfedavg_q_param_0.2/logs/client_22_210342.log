[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6be76f11-93c9-4c47-9c40-eaf84d9d6cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 749e1874-3bf0-4ba8-a0ed-6ac3e893149c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60fdd3ac-3095-4a27-b7c2-584e466157ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04023c64-d546-4a5b-960a-a600dd32243b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a243fb4-1c6c-4a62-8324-4f92b2992b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d74f5d6f-5b08-49cc-a3e4-2c76a8d5728e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39f31c5e-e899-4a88-8e8a-e0c54a18ca75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57b66dee-363a-475a-ac81-6eee4695df80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0a21da2-43a2-44a8-adc4-65a5c40f3946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2307c345-16c7-4280-bfbc-3bd147c00eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4b81d8c-5d79-4e7c-b367-eed093cb177f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a4c575-6d8e-4aae-be80-414dd1846e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6884f754-bce9-4925-8334-015ad4f710ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a756ff9-1d52-45cb-86a3-cd37a3becac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 674240b7-dfc3-451b-878a-2d86c4963cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 069ed983-9af2-4818-9594-4f480a84eb88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e432cc1a-1b7f-446b-ae8d-d50b7e1ab7f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a755824f-09a9-49a1-a07b-1490e875826f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e780de9a-65d2-4366-b4b5-2fff6684c791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb845525-ab98-4c07-be65-5e7e6a636d4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 374ded9a-f223-4e1a-a3f6-80b3bd868b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f071dcc3-39e1-4997-a5b4-1620899c7b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47b6b2cd-4618-496d-ba84-bd050a54945c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 862ee7a1-61f8-401b-a4fc-289872ed0b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04968dc9-ebd8-40d4-8f57-198a074dd7a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48b2e65c-d22f-44e9-aff7-28dc87f2263f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25b9c83c-03b6-477f-b8da-76446bd99a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13a8b18c-46d9-4cb1-bf1b-92b780a5794f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b69f897-7435-4aae-8076-23f4d58f6672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e667aa3-57c0-444e-ae83-f6fc13e48d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bfb70f0-b8db-459b-bbcc-652fed82dd74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa1e9366-9e73-494b-ba80-e6307620c7d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3e84b05-66a4-49cf-835e-72c46bc468fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f8c4baf-0989-4413-8157-e0a9a014af85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48cb5e60-7302-4b1b-82a6-600da0a55146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbea6b1f-4020-481f-b4bd-00b0403e8ed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fe34846-7ba8-4a42-8286-2a4e93c2415b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d838e64-4d76-4613-b986-d0bb28b363be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 381cda69-eccd-41af-bbc0-d42f1efcfc7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bc853a7-7f71-4836-a00f-149621e71749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6acbf296-aec7-4886-8120-a3483fd9b6cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa6f6bc0-fce7-44a1-a14d-a00e6617c5bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e76fa5e-c2d8-43a2-aa29-cb10592076cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f28ab61c-9c98-422b-b7d5-178b0d168fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 611c6700-b17c-4f27-8aff-9570906ef245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c81e8b-8f90-4e6d-8ce1-c82ed39c66c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f43d618b-f2d0-4e6e-8de4-e1d71bcd0175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f17b071-dcaf-4655-b2e0-2e9bae936163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 447c1c85-efe6-49e6-afc1-1c61efbfcc54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dee3f6e7-379d-4361-8e5e-84b100f464f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a80ddf85-1986-4116-8515-3178585b15bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 366b9aa0-6fa5-4507-b176-d1037a05a8ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dded96e-dc36-40ab-880c-8300c887b5d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bafcc3eb-5a35-415f-8961-adc47fbcbe39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96a968fd-3c33-4d24-8867-e00c118e116c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcee60b4-a432-43fe-8a7c-c6ba1b3480ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8760112-8ca8-426e-aeea-e5316eb5a2a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92e393f8-59e9-4b27-9c63-3622e7d8325b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b9c63b1-b838-4294-9e0e-6ea5cf265508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a80b159-b96b-47aa-a414-f5567a49849f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f247579b-6e54-49b3-a597-255861be7afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13fcab38-5ce6-4c08-b094-f87578b8d74b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3eb8949-c4a2-462a-b227-161e6490ed17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee3dde5-7465-4822-a357-6a70cb0b7362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed5ca150-a05e-4947-bf29-3f3d2bf95bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2de2c23-5004-4820-8e31-7daeeb5a488d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17f142c6-08b7-4b82-b8d5-228de56123bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43c55b95-0ce3-444f-b59b-8d04d00078e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f09aafad-4afc-40fb-bd3c-91384f23051d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44957f7c-2d86-499d-97c1-9abc52a69a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3494312-b894-4623-8c51-d2fe70c2101b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a85a021a-c322-4da1-97cc-322b67926df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a7f181c-9cc8-480e-961d-56d8cd915e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77a1308a-33da-4d55-9510-83819b67b314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4092c83-6589-4871-8958-c1afc8ea3100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e6128f1-d24b-4eea-9de0-bba0b9408b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90973f6e-1d31-458a-bf9a-47e1bbbbfea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61e114fe-86a1-4918-9691-f3abc44a32ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bf92eec-34fc-4a5c-be28-ca6580ee5ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 214e140c-2fae-4b48-8aa6-7971031af0a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3322201b-fdd0-4c7b-b87e-e92de02f5d4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43870dd9-1fe3-448d-97b7-cfe7b598791f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acb2efeb-7f36-4e05-810b-7a1dec8804d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35c468b4-59cc-41b5-8908-cb6923db4f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d9d3763-5703-4711-9339-70ccc80fb218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a60809b0-3645-44f8-a5fe-26c0b73077ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaef4534-fd66-4320-9b6c-6c1ea35327d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d08d331f-48d0-4d82-a679-3661d85514eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43c31bec-e2a4-47bb-9a1d-c1fa75047c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6de6a001-c2c2-429e-83d6-04547d7bc8a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3220d94-e9fb-45eb-8daf-92c106704710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c9f4131-0126-4ffe-95e5-4b8072f1ccd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed36f60f-d0ac-4a39-b3e2-18b23cbc4c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77d77ed1-4174-4ef6-8598-f1239db8e20e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60691d7c-f83d-46a9-b409-9acdeb46809c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00cb9000-2a8c-4b6b-9423-e4be1a7bf511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4af259b-534b-43c2-934f-201b3e2270e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 601466c4-d225-4873-a345-3dcf464262eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18b76a13-47d6-4fc7-b119-dd9106ec7871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6528e8d-8640-4eea-8466-62be9efa19fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfd79914-2581-474b-9818-7d4898a9163b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f7237d-e319-4a71-887f-d94137cba1d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22dd0c72-6429-4c3e-bc92-a21285a65200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 701b6ce5-2c15-4dde-8641-077afc2cb57b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c67ffdfc-4b20-4980-bc29-90ddb9fd5877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5390865e-2ecf-451c-97aa-42cf051a5fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdeed9d5-873a-42e0-9615-3ed429028216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bbf747e-fe61-49fe-b2f8-a4eddf7b53bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95f95274-cb59-42b6-9187-f8e5ca19b991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2507aa8-2e4b-448d-8862-d0aea080701e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88057aab-96a0-4637-b8df-4fd6169ee932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbec3b09-3b4b-45d1-b684-9d6b97e9376d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c5f9c8d-17b1-47ef-85a7-4a91cdfb9590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bbd01f6-399c-4ce0-94ed-f566f8457914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34e99f03-c9b9-4676-8204-ee7418a852e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebc826a8-a9c8-4b08-b387-791231d9953c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88c38919-30e3-4115-9702-9f7e8b9d7673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23ecb2da-ba76-4a27-9634-9f0decd0e4f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 178482bf-aaa2-42a2-9edb-301578990ece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6965d3da-d944-46f4-acaf-191ca4e73213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e70a795-b63a-4914-ab14-ea7b7e1d7468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ae88229-e045-4b86-b528-c8d6cf896a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f24a9ff-5df3-40a9-81a6-938e60f4ac1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e2b34d5-6ece-4399-8662-ca3993fb4753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecd6d47e-fab4-49af-972f-301cf81e5880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cb61f6e-64d6-4683-9b61-1fe591b17d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 088159b1-0b2b-48eb-9fb6-280455f103ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d734c23-0f25-4fec-9a93-a77ce7f1ffd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54da8831-f614-49f0-9966-920db009b473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2511e953-c5a0-4478-81bd-84757b7152ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c4b3be1-f7f3-4767-8ae3-5d172e4e7d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52d08e1d-6378-49cb-8810-136611623dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdd346fc-3e1e-4aec-ae0c-c2282fa7f18a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b48c740-f603-47a3-964a-325c2d14f011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e98dfdf9-4b8b-465e-8fdf-ed414dedd4a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c2cda08-7b4f-41c0-b093-4ced0516e39e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2869971-ea13-4c57-a516-9b16156ef710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 076d98e3-b181-40bf-a8fc-bfc0bc147abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3993af46-6fa8-4ced-b9ce-4e0ba16212be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bcdafd3-6a4a-4df0-8359-03ea9c7e9be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fa71b39-6075-4b66-95f0-dd401125f493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee8fd9c-bcaa-4932-808d-4b7713b22f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ec57175-51ec-48e0-9be6-a98677c672f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f76ce801-b7ff-48d4-981e-cc5125c67f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e869d5b-7b4e-4993-81e8-cbe64086fa9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e25292e6-b97c-4547-8afd-f2582a503e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73cfb96a-e137-48a9-8bb0-82b9840cea18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28e05e22-0a60-4614-8e23-7236f6378cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61b28212-be38-414b-a3d8-744e5e579c20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd497e36-8015-47ce-b996-3813a5d07d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0cd3890-32b5-4130-aac1-51af0416d27e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87510c3d-2854-499c-9423-dac7ff58dbb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55e3fc55-8c41-4141-8d0f-95fae83f2f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93fb49cf-0617-4dd4-b256-74befe120ace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c81a6818-fede-467b-8801-151aa65af913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8b7d019-3176-49ff-a689-96f61b5bfab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e12a461-b4d0-4fbf-afe6-b6b4a8dd99ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62c3efe5-2f94-464e-99f2-e574ada80433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d34087f4-583e-4072-9161-b3e863ce28a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71857d12-8da2-445a-8f46-9a9ed1d015cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb6dd5b4-c7e0-4798-bc59-6ad9d1140464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc4afe8f-c1ba-41bf-a703-83c225b3140a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 365f8e61-f75a-4f19-868d-80be38826972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 568db5ab-393e-4190-83b7-9975f1c91322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c81f76c-40ab-49b3-94a8-86224a530a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baf14600-eb4f-4843-8e31-03c283113c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 696465db-87ab-4a61-8c7d-5a697000833d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ed68ce2-97ce-4af0-8c28-ba6151ce9423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4592f49-91ca-49fd-b17b-9bf837176161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f70b4e2-9a0e-4846-93d0-2333b9294a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d37cfeda-b811-450b-a11e-d5626dd6d6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5b686a1-4823-422a-9111-67b6fc3e3418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59c75d53-f4df-4e83-9c02-3948a9259fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b25d4be3-27c4-48d9-81b6-a4dacead7146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef19c6ba-e117-40c7-84e6-bffcb7ae2a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95af8da4-4f14-4d91-b889-dbda903d877f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db5be495-7402-4ee5-9cc1-74be3f968d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 272d5001-1cf4-40b6-8ee0-557517c1fa14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 865f0554-5f6f-4708-987b-c044ce324c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8de3ebee-169d-483a-ad9c-424b2ead2a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40cfe9bb-7dad-4ab3-987d-e9f2d216ce61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a80cff89-c613-4fbc-a3d4-9980c6590db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bebdbb9c-a5c0-4778-91c4-0e54db46e4af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 941bf798-4d54-4f08-a49e-e1b7e5ff9f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 108030c7-76f8-4de9-ad00-7ab8016c2182
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_22
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/test_labels.txt

📊 Raw data loaded:
   Train: X=(1312, 24), y=(1312,)
   Test:  X=(329, 24), y=(329,)

⚠️  Limiting training data: 1312 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  320 samples, 5 features
✅ Client client_22 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1234, val=0.0883 (↓), lr=0.001000
   • Epoch   2/100: train=0.0820, val=0.0883, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0822, val=0.0905, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0824, val=0.0884, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0818, val=0.0880, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0813, val=0.0880, patience=10/15, lr=0.001000

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 2 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.001000 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0621
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0316
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.1966, RMSE: 0.4434, MAE: 0.3639, R²: -1.4829

📊 Round 2 Test Metrics:
   Loss: 0.1826, RMSE: 0.4273, MAE: 0.3494, R²: -1.3062

============================================================
🔄 Round 6 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1164, val=0.0910 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0882, val=0.0800 (↓), lr=0.001000
   • Epoch   3/100: train=0.0844, val=0.0805, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0827, val=0.0798, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0831, val=0.0801, patience=3/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0823, val=0.0802, patience=9/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 6 Summary - Client client_22
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0009
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0004
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.1643, RMSE: 0.4054, MAE: 0.3303, R²: -1.0752

📊 Round 6 Test Metrics:
   Loss: 0.1615, RMSE: 0.4019, MAE: 0.3274, R²: -1.0400

============================================================
🔄 Round 9 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1209, val=0.0771 (↓), lr=0.000500
   • Epoch   2/100: train=0.0860, val=0.0784, patience=1/15, lr=0.000500
   ✓ Epoch   3/100: train=0.0846, val=0.0753 (↓), lr=0.000500
   • Epoch   4/100: train=0.0833, val=0.0755, patience=1/15, lr=0.000500
   • Epoch   5/100: train=0.0835, val=0.0753, patience=2/15, lr=0.000500
   • Epoch  11/100: train=0.0832, val=0.0752, patience=8/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 9 Summary - Client client_22
   Epochs: 18/100 (early stopped)
   LR: 0.000500 → 0.000500 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0006
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0035
============================================================


============================================================
🔄 Round 10 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1218, val=0.0874 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0848, val=0.0777 (↓), lr=0.000500
   📉 Epoch 3: LR reduced 0.000500 → 0.000250
   • Epoch   3/100: train=0.0822, val=0.0816, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0817, val=0.0801, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0816, val=0.0803, patience=3/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0814, val=0.0807, patience=9/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 10 Summary - Client client_22
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0142
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0034
============================================================


============================================================
🔄 Round 12 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1428, val=0.1024 (↓), lr=0.000125
   📉 Epoch 2: LR reduced 0.000125 → 0.000063
   ✓ Epoch   2/100: train=0.1001, val=0.0795 (↓), lr=0.000063
   • Epoch   3/100: train=0.0825, val=0.0805, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0817, val=0.0817, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0819, val=0.0814, patience=3/15, lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0817, val=0.0813, patience=9/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 12 Summary - Client client_22
   Epochs: 17/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0460
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0078
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1431, RMSE: 0.3783, MAE: 0.3082, R²: -0.8076

============================================================
🔄 Round 15 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.1329, val=0.1152 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1238, val=0.1096 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1175, val=0.1044 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1119, val=0.0999 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1068, val=0.0960 (↓), lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.0886, val=0.0833 (↓), lr=0.000008
   📉 Epoch 17: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0834, val=0.0807, patience=3/15, lr=0.000004
   📉 Epoch 25: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0827, val=0.0806, patience=13/15, lr=0.000002
   📉 Epoch 33: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 15 Summary - Client client_22
   Epochs: 33/100 (early stopped)
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0205
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0006
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1197, RMSE: 0.3460, MAE: 0.2836, R²: -0.5116

============================================================
🔄 Round 17 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1245, val=0.1287 (↓), lr=0.000001
   • Epoch   2/100: train=0.1242, val=0.1283, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1238, val=0.1280 (↓), lr=0.000001
   • Epoch   4/100: train=0.1235, val=0.1276, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1232, val=0.1273 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1214, val=0.1255 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1187, val=0.1227 (↓), lr=0.000001
   • Epoch  31/100: train=0.1163, val=0.1203, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1141, val=0.1180 (↓), lr=0.000001
   • Epoch  51/100: train=0.1120, val=0.1158, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1100, val=0.1137, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1080, val=0.1117 (↓), lr=0.000001
   • Epoch  81/100: train=0.1062, val=0.1098, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1044, val=0.1079, patience=2/15, lr=0.000001

============================================================
📊 Round 17 Summary - Client client_22
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1025, RMSE=0.3201, R²=-0.2596
   Val:   Loss=0.1063, RMSE=0.3261, R²=-0.2773
============================================================


============================================================
🔄 Round 18 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1084, val=0.1208 (↓), lr=0.000001
   • Epoch   2/100: train=0.1082, val=0.1206, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1080, val=0.1204, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1078, val=0.1202 (↓), lr=0.000001
   • Epoch   5/100: train=0.1076, val=0.1200, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1065, val=0.1188, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1047, val=0.1169, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1030, val=0.1150 (↓), lr=0.000001
   • Epoch  41/100: train=0.1013, val=0.1132, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0997, val=0.1115, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0981, val=0.1098, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.0966, val=0.1082 (↓), lr=0.000001
   • Epoch  81/100: train=0.0952, val=0.1067, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0938, val=0.1052 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_22
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0925, RMSE=0.3042, R²=-0.1570
   Val:   Loss=0.1039, RMSE=0.3224, R²=-0.1727
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2431, R²: -0.0230

📊 Round 18 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0051

📊 Round 18 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2420, R²: -0.0032

============================================================
🔄 Round 26 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 26 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0124
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0068
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2420, R²: -0.0027

============================================================
🔄 Round 28 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 28 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0052
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0061
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2420, R²: -0.0022

============================================================
🔄 Round 32 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 32 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0055
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0005
============================================================


============================================================
🔄 Round 34 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 34 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0022
   Val:   Loss=0.0952, RMSE=0.3086, R²=-0.0340
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2420, R²: -0.0017

============================================================
🔄 Round 37 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 37 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0042
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0004
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2420, R²: -0.0015

============================================================
🔄 Round 39 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 39 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0040
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0015
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2420, R²: -0.0014

============================================================
🔄 Round 42 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 42 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0050
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0021
============================================================


============================================================
🔄 Round 43 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 43 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0025
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0043
============================================================


============================================================
🔄 Round 44 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 44 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0028
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0041
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2420, R²: -0.0013

============================================================
🔄 Round 46 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 46 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0014
   Val:   Loss=0.0866, RMSE=0.2944, R²=-0.0163
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2420, R²: -0.0013

============================================================
🔄 Round 49 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 49 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0049
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0060
============================================================


============================================================
🔄 Round 50 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 50 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0015
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0073
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2420, R²: -0.0012

============================================================
🔄 Round 55 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 55 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0025
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0045
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2420, R²: -0.0012

📊 Round 55 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2420, R²: -0.0012

📊 Round 55 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2420, R²: -0.0012

============================================================
🔄 Round 58 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 58 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0041
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0029
============================================================


============================================================
🔄 Round 59 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 59 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0029
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0012
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2420, R²: -0.0011

============================================================
🔄 Round 62 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 62 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0037
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0020
============================================================


============================================================
🔄 Round 63 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 63 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0008
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0132
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0011

============================================================
🔄 Round 67 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 67 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0068
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0030
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0011

📊 Round 67 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0011

📊 Round 67 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0010

📊 Round 67 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0010

============================================================
🔄 Round 75 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 75 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0010
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0063
============================================================


============================================================
🔄 Round 76 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 76 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0004
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0134
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0010

📊 Round 76 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0010

============================================================
🔄 Round 79 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 79 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0020
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0846
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0010

============================================================
🔄 Round 82 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 82 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0039
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0052
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0010

📊 Round 82 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

📊 Round 82 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 86 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 86 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0015
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0402
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 87 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 87 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0022
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0021
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 88 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 88 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0027
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0007
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 89 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 89 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0018
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0033
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 90 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 90 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0038
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0003
============================================================


============================================================
🔄 Round 91 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 91 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0013
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0043
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 94 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 94 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0028
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0021
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 95 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 95 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0006
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0096
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 96 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 96 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0032
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0009
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 97 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 97 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0027
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0020
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 100 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 100 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0007
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0090
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 101 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 101 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0004
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0071
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 102 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 102 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0007
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0171
============================================================


============================================================
🔄 Round 103 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 103 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0021
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0001
============================================================


============================================================
🔄 Round 105 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 105 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0016
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0027
============================================================


============================================================
🔄 Round 106 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 106 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0011
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0085
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 107 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 107 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0067
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0162
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 109 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 109 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0016
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0025
============================================================


============================================================
🔄 Round 111 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 111 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0014
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0030
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

📊 Round 111 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

📊 Round 111 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

📊 Round 111 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

📊 Round 111 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 118 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 118 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0010
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0044
============================================================


============================================================
🔄 Round 120 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 120 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0021
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0219
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

📊 Round 120 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2421, R²: -0.0009

============================================================
🔄 Round 122 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 122 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0045
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0123
============================================================


============================================================
🔄 Round 123 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 123 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0006
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0060
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0009

============================================================
🔄 Round 124 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 124 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0014
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0023
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 130 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 130 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0007
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0089
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 132 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 132 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0009
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0056
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 133 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 133 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0018
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0014
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

📊 Round 133 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 136 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 136 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0003
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0098
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 138 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 138 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0011
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0035
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

📊 Round 138 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 144 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 144 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0007
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0081
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 145 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 145 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0031
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0051
============================================================


============================================================
🔄 Round 147 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 147 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0009
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0065
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

📊 Round 147 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 149 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 149 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0037
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0063
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 150 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 150 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0035
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0058
============================================================


============================================================
🔄 Round 153 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 153 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0034
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0022
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

📊 Round 153 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 156 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 156 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0020
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0170
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 157 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 157 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0077
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0192
============================================================


============================================================
🔄 Round 158 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 158 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0015
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0022
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 161 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 161 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0025
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0143
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

📊 Round 161 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 163 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 163 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0011
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0047
============================================================


============================================================
🔄 Round 164 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 164 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0007
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0221
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

📊 Round 164 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 166 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 166 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0018
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0123
============================================================


============================================================
🔄 Round 169 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 169 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0009
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0051
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 170 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 170 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0017
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0026
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 172 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 172 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0011
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0042
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 173 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 173 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0005
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0098
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 174 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 174 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0004
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0068
============================================================


============================================================
🔄 Round 175 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 175 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0015
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0056
============================================================


============================================================
🔄 Round 176 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 176 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0020
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0008
============================================================


============================================================
🔄 Round 177 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 177 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0009
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0297
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 178 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 178 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0004
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0084
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 180 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 180 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0022
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0013
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 185 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 185 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0017
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0366
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 187 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 187 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0007
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0340
============================================================


============================================================
🔄 Round 189 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 189 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0012
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0037
============================================================


============================================================
🔄 Round 191 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 191 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0027
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0030
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

📊 Round 191 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 194 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 194 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0019
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0033
============================================================


============================================================
🔄 Round 195 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 195 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0017
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0115
============================================================


============================================================
🔄 Round 197 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 197 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0024
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0011
============================================================


============================================================
🔄 Round 198 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 198 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0007
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0047
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 200 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 200 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0002
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0187
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 201 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 201 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0043
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0061
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

📊 Round 201 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

📊 Round 201 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 205 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 205 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0013
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0039
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

📊 Round 205 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2421, R²: -0.0008

============================================================
🔄 Round 209 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 209 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0003
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0068
============================================================


============================================================
🔄 Round 210 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 210 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0034
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0030
============================================================


❌ Client client_22 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
