[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84eba11e-fe97-44b6-b329-0db336adae21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd6c4939-795a-4b4f-b350-b78dcf224c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a165545d-e100-4c57-ae00-bbbad108283b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 826af2b7-97dc-4218-b803-a8eb2cf41b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54b15944-6582-47cd-8246-6f496182e1a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 941c6b10-81c7-4878-bad5-bfffca376f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2da6c351-63af-4854-abd2-b47e077f9a3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37ab8498-7844-4356-a670-590c16a7f09f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf3375a-5c0b-4ceb-ac95-a7e8884f0df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2de2075e-9930-4456-a010-eb22a5315f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e2a7dc6-85e0-46ad-a797-066e4055c52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08f35a55-52b7-41aa-9a7b-9d16ea29a187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f42ad213-2268-45d3-b66a-5d5fc318ea3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c9e0e60-0d90-4878-9971-2425a36c55e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcc907b4-ec47-4af6-8372-430c5d7ab6de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da540d68-6fb2-4aba-8eb4-dda3a1241170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b84895f2-a1c0-4cfe-9d78-cb5032788690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf870713-fc40-4997-b478-dd7bc898981b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bc2f433-aa9a-4584-a99c-93f4ec9cdb78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15446e6f-83da-4e35-97a0-dfc4460b2a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2164c567-94ed-488a-9ee0-0fe577d3e2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 827fc945-8727-47b2-9c49-5152a59127fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6a3f1ba-5c3b-49ec-acb8-9a2ef865cac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 087213ea-2e8f-481a-88f3-4e6c9bf551a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d48c5092-9f9b-45c2-9405-ec4be5477a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a600ef66-6978-45c8-94bc-b8a7705ecadd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe47e491-6532-470c-adde-d3014879d888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 264a1932-a102-471e-ad47-5b440043ce5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfb9757b-71af-4bab-a350-3da0e73996f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d97357cc-47d1-47b4-a68a-69987dee28db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac16850c-5363-4985-995b-f3f69ba1de17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e86283a-6b86-49b4-b27f-97a0a81202e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f607c72-cb7d-4b61-941b-e6671c2c62dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 481af8d0-59db-4e37-a9e3-89dc3a4a26cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5a8273d-7b0f-45c9-b02f-84ca1b768e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5418d73-a4b7-42b5-8455-0e0ac96c5cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9465a16-a2f3-4974-a032-7a6fd859a513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbfa3b28-1630-46d4-ab7f-41d2e2879d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89084e89-e337-4486-b3f9-f6d1bff795fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff67c7e0-590b-4426-97d3-c8fbbfd1a9ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a12cca21-928e-4c2a-9779-fec699131947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32d31520-b84f-4e0f-b2b0-df3adaf40845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd9f48db-63da-40f5-9a85-dd583fbcec30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e39b1b4-822d-438f-ac1b-6d1b68455b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2407c859-8bf1-422b-b2bf-956e2093d531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72f6cde7-acdc-480d-a9e2-459258a66247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0eec097-756d-4f93-95a2-acc383a46b41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e6bb3bd-1f39-4c7d-b073-3ab4efadb759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1ef5f26-9705-4fd3-b379-571b057410bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 310a2ce4-4bda-41e3-92bd-7c022f4fb6a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92b6eb0e-4936-4a08-8696-7e1158fb49fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36cc5a0a-4d16-4f7d-8cc1-1d915ac0755b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b0aebd7-9c57-4324-9567-5d4da9323018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ded91e89-c1f3-4366-815b-59280c19d4c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 081f25ef-8154-42b5-bc5d-68633e047a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 084ce33b-f07a-4850-8aa8-31c3b4154bc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c51ea49-2945-40a3-8aa7-4c9a75ea8d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c471c30a-72a4-4a1f-b8db-5af722470b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7e11656-77d2-40be-adc8-38241cde4512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2cc1b56-263c-4433-9e29-f186808dc533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1f424f3-367c-4756-b5a7-0cbe414f5fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c712f97f-2992-4ecb-82c3-a5f4e5cc2fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message def01b61-775c-4701-95ee-fa8d2c7d4b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7d91416-78fa-436d-81f7-7384fed8fb0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c728637e-7409-40bc-9f1f-c03893cb6d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10072a16-cd79-4dc1-a08b-7bf082d85f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65cf47b3-ee0c-42f9-964a-f8ca07fa6ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c4c847-d6f3-433a-bfce-8cf4d075fe2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b54f077-b4a6-4ea2-aee8-4db4fe9f0859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eef7d8df-4786-49a5-892c-52b7250ed37f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d04ffb34-4d37-4ca4-bddf-d751f01f56c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61ce7d0a-9195-479f-8212-e4123bc4601f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb5bc4cd-43e5-4b28-a684-885814c5fb7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa906ff3-5805-4c3d-bcfe-1105af20a44e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b4cb9dc-e8a8-4ab1-9574-32f3f116445d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e2dd990-f133-4a46-9ba0-941825b59022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c5374fe-ee75-4c7c-9bd3-df76758ead72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3476d3a-5b06-490a-a382-47f5ba861eb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aa4eab5-8afa-4a6f-b4be-9c759fefaafa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64931177-a591-404d-8045-1f7f3f1b81c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72f516aa-c413-42b1-87f3-f19176c97658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 028f1bb5-15fb-4b13-86c3-98798464da3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3db8db47-79ad-4c84-841c-39b4889a1b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e80fd79f-6f19-47b5-9972-9bca86520bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03cac931-bd52-4c05-88ef-91805227f574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 059c5396-5ced-468c-a7aa-9b3491658b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39042bba-e879-4a0f-89bf-fc637b00edfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf4e2788-b6fe-4e65-b320-4846325a1f36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3be630f9-1cf5-4f45-9c04-da9d48a79711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b208b62-0a69-45b7-86eb-6ad8e88a7af0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d1a03ba-18d4-4c36-aa78-0c27f848e96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd77efd3-bca8-470e-9f10-7dd94947b57d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a822117-3eb2-424d-b375-65498920cf2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a7dac2-7d8d-41f3-8d4d-90cb76df7bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47472b6f-a0b9-4ea1-a51e-b8d2ea833231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55623628-8340-4c3b-9524-bb413053fd1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 743e440b-9b58-44a5-bdef-fef08eb727be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d689eb25-6ae7-409f-bc4e-1a43c05b6226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69783a09-28e2-445a-9a45-d30a633c7b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15a5453f-71d2-4008-9259-780e5a5d4ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96b851f5-8938-4481-8642-81853ec1068e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3cfd08b-cd18-40f6-891f-6b8869cbbf6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45d7acff-190d-4f7b-89ea-86750b706f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53782ace-b4e1-4dc2-aecd-ea481d1729a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9ae6970-41f6-4f39-9011-8eaf91265064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa3d1352-c417-4b4a-bcb3-af05ebf7961a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c6260d5-492e-426a-96dc-487406614e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d87484a-0bf4-46bf-80cc-0e811d512dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85c23d25-0f0c-466a-95da-90ed9d40f353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3b2c831-3a98-4cab-b18d-5ae324d6c9a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ca1316-b54b-4fcd-bd24-e50d262a8f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aead4390-67d6-43d7-a50d-610d841d2dd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbeaa2f4-0c59-45ac-83c8-1486b17f651a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f85dab0-0afc-4e5f-b082-11f56959cbf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91a27840-fda5-4069-82ec-ccc15f20332c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2ad4249-e0cf-4819-a1da-89dd2db6c138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cfb253e-a822-420e-8839-4d41d54cc4a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f32bdda-add4-48dd-bfe3-cd69a0bf497f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a146149f-d7d9-4292-9bd8-964e8d81b811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e4ce602-7597-403f-8222-4d02ca938587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6d3dcd5-7335-4038-ad29-0457afbb75fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39af3535-d40f-49d4-b7ce-adcb89231992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfb8d437-68f3-4827-a87d-7a253f29a283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e77e225d-aceb-4caa-9054-941a88ef0adc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e247c84b-4e9b-4e92-8909-7df60cdf9082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59f9b67a-833e-406f-aafd-a7aa831404d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 191382bc-c8dd-48fd-9b99-318af73a2996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 617edf9c-fd63-454e-abf9-5f8c761bc58b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e71dabc9-c99c-48a0-be32-9b742bd7634a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff44ae5b-9140-4405-b95a-cb149bbebe80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 882c04a6-cbce-41bb-a14b-b0e358a58df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04ae00b9-e507-4488-81d3-34f3c86dc0ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64a0599f-5103-483f-b333-9975298c8dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ada20b1-5f03-44bd-8516-f4e73847d468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3a7b63c-c7c8-445d-ad15-fc4f4e856b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 469be2ec-d076-4cea-b5f4-91dd86ab2392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcc8789e-3642-4736-99f1-e03e53f31141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65658183-1fbc-4266-9033-49dbe4825718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f483d4e-da11-4f1f-90e8-ab9cdfdbc4cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75ad2ffc-4658-4064-8473-489b0445385a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56afaa4b-2398-4a6c-9aee-4b6a499938af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d411eb51-24f8-435e-ad3c-aa09d51b859d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5721ef71-fd70-4d54-90df-c1f6dbde3516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aab4aca2-e36a-4fa8-96e8-0136d6f17fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cd3ede6-e39b-4345-bbc0-4d81184e4821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da6086a0-8957-4b74-bfd6-11d8aba6baed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9c73d8a-4df8-49e0-a6b6-9505addb6b4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 547c1170-9b56-4bb8-bdab-4df2af1ee3f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddce4a35-f346-4c39-8a94-422e9ab5469e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b28b48e2-f1ff-4eb1-9c26-f8e19f2f3d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1888a1f-a192-45b6-813a-f80fb2f9c89d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 537d9ed9-48e3-4b56-a0d2-b57fd2b9677c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d0a0366-f7c7-4e08-b571-527a8df2b912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 182ce04e-286d-44ef-a98c-6a2763da2dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed9a7fda-f0b6-4366-af03-77890b3fd5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ceff30e-2243-49fc-b594-c1bdae3ce259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83c84bb4-a0f8-4ac4-a9ef-31f26a349995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37c5a9a0-f5d5-421d-ab6c-1e2b5acaf862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 992799e2-32b2-4778-9160-cd4346c4023f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7643cb2-db6b-46f8-bcf5-37ad63924a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ede03255-612a-4d42-82f4-fe41a9634d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b460ce3-21f9-45d9-85b7-61bf4f755565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63996040-6330-4a01-9a3c-4661299586a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02373ee9-8079-4be4-8546-814909726efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b45053db-2ade-4383-ba78-72f481719ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4754294-9c06-4978-8012-4a06349ebdea
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_24
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/test_labels.txt

📊 Raw data loaded:
   Train: X=(849, 24), y=(849,)
   Test:  X=(213, 24), y=(213,)

⚠️  Limiting training data: 849 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  204 samples, 5 features
✅ Client client_24 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1920, RMSE: 0.4382, MAE: 0.3666, R²: -1.5071

============================================================
🔄 Round 4 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1346, val=0.0716 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0887, val=0.0693 (↓), lr=0.001000
   • Epoch   3/100: train=0.0889, val=0.0698, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0895, val=0.0698, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0890, val=0.0701, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0875, val=0.0711, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 4 Summary - Client client_24
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0029
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0022
============================================================


============================================================
🔄 Round 5 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1655, val=0.1484 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1084, val=0.0933 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0849, val=0.0865 (↓), lr=0.000250
   • Epoch   4/100: train=0.0843, val=0.0878, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0840, val=0.0871, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0837, val=0.0873, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 5 Summary - Client client_24
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0067
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0033
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1664, RMSE: 0.4079, MAE: 0.3404, R²: -1.1717

📊 Round 5 Test Metrics:
   Loss: 0.1635, RMSE: 0.4044, MAE: 0.3374, R²: -1.1349

📊 Round 5 Test Metrics:
   Loss: 0.1542, RMSE: 0.3927, MAE: 0.3276, R²: -1.0135

📊 Round 5 Test Metrics:
   Loss: 0.1501, RMSE: 0.3874, MAE: 0.3232, R²: -0.9594

============================================================
🔄 Round 12 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1572, val=0.1230 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1340, val=0.1052 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1126, val=0.0919 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0959, val=0.0851 (↓), lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   • Epoch   5/100: train=0.0865, val=0.0855, patience=1/15, lr=0.000031
   • Epoch  11/100: train=0.0841, val=0.0875, patience=7/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 12 Summary - Client client_24
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=-0.0658
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0035
============================================================


============================================================
🔄 Round 13 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1546, val=0.1404 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.1486, val=0.1343 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1439, val=0.1315 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1410, val=0.1288 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1383, val=0.1263 (↓), lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1245, val=0.1140 (↓), lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.1158, val=0.1060, patience=1/15, lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.1124, val=0.1030, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1103, val=0.1010 (↓), lr=0.000001
   • Epoch  51/100: train=0.1084, val=0.0992, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1065, val=0.0975, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.1047, val=0.0958, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1030, val=0.0942 (↓), lr=0.000001
   • Epoch  91/100: train=0.1014, val=0.0927, patience=2/15, lr=0.000001

============================================================
📊 Round 13 Summary - Client client_24
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.1000, RMSE=0.3162, R²=-0.1624
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.1537
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1295, RMSE: 0.3599, MAE: 0.3004, R²: -0.6912

============================================================
🔄 Round 15 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1396, val=0.1337 (↓), lr=0.000001
   • Epoch   2/100: train=0.1393, val=0.1335, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1390, val=0.1332 (↓), lr=0.000001
   • Epoch   4/100: train=0.1387, val=0.1330, patience=1/15, lr=0.000001
   • Epoch   5/100: train=0.1384, val=0.1327, patience=2/15, lr=0.000001
   • Epoch  11/100: train=0.1368, val=0.1314, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1344, val=0.1293 (↓), lr=0.000001
   • Epoch  31/100: train=0.1321, val=0.1273, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1299, val=0.1254, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1277, val=0.1236 (↓), lr=0.000001
   • Epoch  61/100: train=0.1256, val=0.1218, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1235, val=0.1200, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1215, val=0.1182 (↓), lr=0.000001
   • Epoch  91/100: train=0.1194, val=0.1165, patience=1/15, lr=0.000001

============================================================
📊 Round 15 Summary - Client client_24
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1176, RMSE=0.3429, R²=-0.4168
   Val:   Loss=0.1150, RMSE=0.3391, R²=-0.2680
============================================================


============================================================
🔄 Round 16 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1345, val=0.1304 (↓), lr=0.000001
   • Epoch   2/100: train=0.1343, val=0.1302, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1340, val=0.1300, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1338, val=0.1298 (↓), lr=0.000001
   • Epoch   5/100: train=0.1336, val=0.1296, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1324, val=0.1284, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1303, val=0.1264, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1283, val=0.1244 (↓), lr=0.000001
   • Epoch  41/100: train=0.1262, val=0.1225, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1242, val=0.1205, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1222, val=0.1186 (↓), lr=0.000001
   • Epoch  71/100: train=0.1203, val=0.1167, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1183, val=0.1148, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1163, val=0.1129 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_24
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1144, RMSE=0.3383, R²=-0.3450
   Val:   Loss=0.1112, RMSE=0.3335, R²=-0.3392
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1209, RMSE: 0.3477, MAE: 0.2901, R²: -0.5779

============================================================
🔄 Round 17 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1262, val=0.1437 (↓), lr=0.000001
   • Epoch   2/100: train=0.1260, val=0.1435, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1258, val=0.1433, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1256, val=0.1431 (↓), lr=0.000001
   • Epoch   5/100: train=0.1254, val=0.1429, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1242, val=0.1415, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1223, val=0.1394, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1204, val=0.1372 (↓), lr=0.000001
   • Epoch  41/100: train=0.1185, val=0.1351, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1166, val=0.1329, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1147, val=0.1308 (↓), lr=0.000001
   • Epoch  71/100: train=0.1128, val=0.1287, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1110, val=0.1266, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1092, val=0.1245 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_24
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1074, RMSE=0.3277, R²=-0.2929
   Val:   Loss=0.1227, RMSE=0.3503, R²=-0.3518
============================================================


============================================================
🔄 Round 18 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1150, val=0.1166 (↓), lr=0.000001
   • Epoch   2/100: train=0.1148, val=0.1164, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1146, val=0.1162, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1144, val=0.1160 (↓), lr=0.000001
   • Epoch   5/100: train=0.1142, val=0.1158, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1131, val=0.1146, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1112, val=0.1127, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1094, val=0.1108 (↓), lr=0.000001
   • Epoch  41/100: train=0.1077, val=0.1089, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1059, val=0.1071, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1043, val=0.1053 (↓), lr=0.000001
   • Epoch  71/100: train=0.1026, val=0.1036, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1010, val=0.1019, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0995, val=0.1003 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_24
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0980, RMSE=0.3130, R²=-0.1553
   Val:   Loss=0.0989, RMSE=0.3144, R²=-0.1750
============================================================


============================================================
🔄 Round 22 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0994 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0994, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0994, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0994, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0994, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0993, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0994)

============================================================
📊 Round 22 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0213
   Val:   Loss=0.0994, RMSE=0.3153, R²=-0.0143
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2361, R²: -0.0180

📊 Round 22 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2356, R²: -0.0136

============================================================
🔄 Round 25 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 25 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0107
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0003
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2355, R²: -0.0123

============================================================
🔄 Round 27 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 27 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0017
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0400
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2351, R²: -0.0093

============================================================
🔄 Round 37 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 37 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0018
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0144
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2350, R²: -0.0088

============================================================
🔄 Round 38 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 38 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0021
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0108
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2350, R²: -0.0087

============================================================
🔄 Round 40 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 40 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0002
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0853
============================================================


============================================================
🔄 Round 43 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 43 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0062
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0065
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2349, R²: -0.0081

============================================================
🔄 Round 47 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 47 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0022
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0102
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2349, R²: -0.0079

📊 Round 47 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2349, R²: -0.0079

============================================================
🔄 Round 51 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 51 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0054
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0031
============================================================


============================================================
🔄 Round 54 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 54 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0111
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0022
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2349, R²: -0.0077

📊 Round 54 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2349, R²: -0.0077

============================================================
🔄 Round 57 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 57 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0049
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0089
============================================================


============================================================
🔄 Round 58 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 58 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0024
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0094
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2349, R²: -0.0076

============================================================
🔄 Round 59 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 59 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0005
   Val:   Loss=0.0929, RMSE=0.3049, R²=-0.0331
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2348, R²: -0.0076

============================================================
🔄 Round 61 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 61 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0015
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0129
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2348, R²: -0.0075

📊 Round 61 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2348, R²: -0.0074

📊 Round 61 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2348, R²: -0.0074

============================================================
🔄 Round 64 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 64 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0062
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0008
============================================================


============================================================
🔄 Round 66 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 66 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0049
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0051
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2348, R²: -0.0073

📊 Round 66 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2348, R²: -0.0073

============================================================
🔄 Round 69 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 69 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0007
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0104
============================================================


============================================================
🔄 Round 70 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 70 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0038
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0010
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0771, RMSE: 0.2778, MAE: 0.2348, R²: -0.0072

============================================================
🔄 Round 71 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 71 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0030
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0001
============================================================


============================================================
🔄 Round 73 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 73 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0050
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0105
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2348, R²: -0.0070

📊 Round 73 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2347, R²: -0.0069

============================================================
🔄 Round 76 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 76 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0026
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0009
============================================================


============================================================
🔄 Round 78 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 78 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0011
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0107
============================================================


============================================================
🔄 Round 79 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 79 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0006
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0263
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2347, R²: -0.0068

============================================================
🔄 Round 81 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 81 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0017
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0048
============================================================


============================================================
🔄 Round 83 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 83 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0034
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0028
============================================================


============================================================
🔄 Round 84 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 84 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0007
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0840
============================================================


============================================================
🔄 Round 85 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 85 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0025
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0046
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2347, R²: -0.0067

============================================================
🔄 Round 87 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 87 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0009
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0097
============================================================


============================================================
🔄 Round 90 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 90 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0005
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0154
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2347, R²: -0.0066

============================================================
🔄 Round 92 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 92 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0046
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0066
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2347, R²: -0.0065

📊 Round 92 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2347, R²: -0.0065

============================================================
🔄 Round 94 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 94 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0027
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0013
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2347, R²: -0.0064

============================================================
🔄 Round 98 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 98 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0016
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0046
============================================================


============================================================
🔄 Round 99 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 99 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0022
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0062
============================================================


============================================================
🔄 Round 100 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 100 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0038
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0056
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2347, R²: -0.0064

📊 Round 100 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2346, R²: -0.0064

============================================================
🔄 Round 102 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 102 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0003
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0086
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2346, R²: -0.0063

============================================================
🔄 Round 104 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 104 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0025
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0008
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2346, R²: -0.0063

📊 Round 104 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2346, R²: -0.0062

📊 Round 104 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2346, R²: -0.0062

📊 Round 104 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2346, R²: -0.0061

📊 Round 104 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2346, R²: -0.0062

============================================================
🔄 Round 116 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 116 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0024
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0009
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2346, R²: -0.0061

============================================================
🔄 Round 119 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 119 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0028
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0009
============================================================


============================================================
🔄 Round 120 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 120 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0037
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0083
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2346, R²: -0.0061

============================================================
🔄 Round 122 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 122 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0003
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0206
============================================================


============================================================
🔄 Round 126 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 126 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0001
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0109
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2346, R²: -0.0060

============================================================
🔄 Round 130 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 130 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0020
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0007
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2346, R²: -0.0059

📊 Round 130 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2346, R²: -0.0059

============================================================
🔄 Round 134 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 134 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0012
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0246
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2346, R²: -0.0059

============================================================
🔄 Round 137 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 137 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0022
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0006
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2345, R²: -0.0058

📊 Round 137 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2345, R²: -0.0058

============================================================
🔄 Round 139 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 139 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0014
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0016
============================================================


============================================================
🔄 Round 140 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 140 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0016
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0242
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2345, R²: -0.0058

============================================================
🔄 Round 141 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 141 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0014
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0036
============================================================


============================================================
🔄 Round 142 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 142 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0005
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0344
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2346, R²: -0.0058

📊 Round 142 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2346, R²: -0.0059

============================================================
🔄 Round 147 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 147 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0033
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0067
============================================================


============================================================
🔄 Round 150 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 150 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0026
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0013
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2346, R²: -0.0059

============================================================
🔄 Round 154 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 154 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0019
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0011
============================================================


============================================================
🔄 Round 155 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 155 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0004
   Val:   Loss=0.0960, RMSE=0.3098, R²=-0.0087
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2346, R²: -0.0058

============================================================
🔄 Round 157 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 157 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0001
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0072
============================================================


============================================================
🔄 Round 159 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 159 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0032
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0006
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2346, R²: -0.0058

============================================================
🔄 Round 160 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 160 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0020
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0046
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2346, R²: -0.0057

============================================================
🔄 Round 162 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 162 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0013
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0097
============================================================


============================================================
🔄 Round 165 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 165 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0031
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0004
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2345, R²: -0.0057

============================================================
🔄 Round 167 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 167 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0005
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0064
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0057

============================================================
🔄 Round 168 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 168 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0007
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0060
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0056

============================================================
🔄 Round 170 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 170 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0011
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0052
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0056

📊 Round 170 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0056

============================================================
🔄 Round 173 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 173 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0022
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0020
============================================================


============================================================
🔄 Round 174 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 174 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0024
   Val:   Loss=0.0758, RMSE=0.2752, R²=0.0033
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0056

📊 Round 174 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0055

============================================================
🔄 Round 176 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 176 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0020
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0035
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0056

============================================================
🔄 Round 178 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 178 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0014
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0155
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0056

📊 Round 178 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0055

============================================================
🔄 Round 181 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 181 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0025
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0436
============================================================


============================================================
🔄 Round 182 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 182 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0002
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0072
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0055

============================================================
🔄 Round 184 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 184 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0057
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0058
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0055

============================================================
🔄 Round 185 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 185 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0012
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0046
============================================================


============================================================
🔄 Round 188 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 188 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0007
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0112
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0055

============================================================
🔄 Round 190 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 190 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0026
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0013
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0055

============================================================
🔄 Round 191 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 191 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0012
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0027
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0055

============================================================
🔄 Round 194 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 194 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0047
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0003
============================================================


============================================================
🔄 Round 195 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 195 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0026
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0032
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0054

============================================================
🔄 Round 198 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 198 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0003
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0115
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0055

📊 Round 198 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0055

============================================================
🔄 Round 200 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 200 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0017
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0078
============================================================


============================================================
🔄 Round 203 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 203 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0033
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0072
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0054

📊 Round 203 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0054

📊 Round 203 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0054

📊 Round 203 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2345, R²: -0.0054

============================================================
🔄 Round 209 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 209 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0010
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0085
============================================================


============================================================
🔄 Round 210 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 210 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0003
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0398
============================================================


============================================================
🔄 Round 211 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 211 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0020
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0085
============================================================


❌ Client client_24 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
