[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 974303ce-085a-4bf4-b176-afcc1b85ad84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c252372a-cee9-402b-8fd8-e126ec8aac79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 783066e7-3d9c-4d47-b52f-9c8d7a957648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15d0ff71-1e16-4b31-8366-b39c6109d944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69599513-216c-40fc-b176-00e4ef80c283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44e61ed4-34dd-4891-9113-08ff76f5a9f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1860920-6a3f-44ad-b8f9-64366ba127a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08411187-af5f-48b4-99e4-560c36c524a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9477e269-c016-4527-9c15-44e64a6b5a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 810da08d-6499-4e32-9fa7-e5f40f11cd97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4596ceb-f288-4b80-811d-fdf30f8497e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 411f7330-7bd9-4fe2-8ec1-403d24a7c8b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79297a2b-18b3-463b-87d7-8994a4d25038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f77b5681-fda8-4462-8bc1-14ce96ff2795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddb1c8d5-1fe1-4b4d-831e-c31a5f6690b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d424b6a7-c57a-48cf-965a-bbe6163442e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d961994-fcb7-4dc2-8456-58efc8eb892d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7635305-55e3-4ae6-90d9-f0ed0779725c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9d055c3-0c36-41db-9b32-5c5f43f38515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 640f5c6d-a9bf-4c09-898e-e941d35e63c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c7b9481-d401-4490-a177-b7ab5a22c244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21991297-d463-40dc-93e2-6d1afe9e4fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5bc4d91-a435-43b5-a9da-934acbe2da24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94aa12f1-1c0b-45de-90f0-10585eafdf3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55b171d2-5bb3-4fbe-83a4-1a66346f0dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58d30688-b64b-49da-8fef-c225d3077601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d5b8084-b994-4067-adfc-5145abf37269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a4fba4b-4eab-4a70-96cb-4be26ed5322c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6de8548c-4588-441a-a866-726d8f31bee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d991fa71-2b5d-43fd-83cc-8e558dc8e332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e531ee1-6021-4a84-a37e-9b2c1b9e91b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 278d5ab2-81fe-4d5c-9c62-0633eca437ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b63c08e4-12cd-47fe-83c2-2c63a562b442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61c0aec1-8d07-4f47-8049-0e218e722bf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a29db180-c291-434c-be84-e48d07dafc0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd723322-0e56-4301-b338-0850a1255939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c3801e6-f313-45a1-bb61-595313d98cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f26e5b3-378e-4808-9203-54d46beec508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aa9753d-ceef-4019-afce-a538155cad1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21ae65e7-2776-4d8c-8481-e4ede265aa20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97862347-aa1a-4050-b0fc-f337afb64ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42e5006b-a2fd-4684-a620-10bb050ab5c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83d1e59e-747f-4823-8734-5a9c6ebe6c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 727c99ce-d284-49c8-bec7-c0bd47640870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4423d0f-7a58-427d-837c-34ae3c405e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e24f697f-5787-41b2-bdbd-ab7c81901a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aec5d80b-f2c1-42f1-bcae-03c2d155b8dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 806c08dd-8a0a-4617-90f0-ff56b2e16caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 719e8b3b-ff70-4d6b-bc3a-f9de343d435f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 727acc30-93e2-4144-a1dc-6cc884ce52c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2661de60-f2d0-4049-96dc-af11087bec3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a71d9e17-a257-4af9-b29a-61b9caf151a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70e9b65e-da86-4c3a-b18e-be51e8cea366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9666f57-57fa-47b7-b73b-746b8423c759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a687d0d4-5fde-407d-a100-24395ac345d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1545a509-3d1b-4e4c-bf2a-64b3e00f6846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88caf294-d2b0-4598-8132-1e222466cfa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56fb4167-0992-4889-b1f1-493a7560a9d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb72c421-5588-4281-99ae-f66aafa126f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34326f37-1c5d-4c89-be8a-a80ef92c10dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39dffbd0-ca41-42b0-8b45-4dca8eed92f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d49c1a4-8a15-48e2-bf8f-84142ff13780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac63fe3e-bb9b-4825-a53e-13f1ac904e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message becb3c94-5c04-4b90-a5b7-5ba4667d22f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a44d8353-a8ad-4c59-b495-20bca8a3101b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c538ac1c-de2f-4a78-9795-724366c16625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 965c05a7-42db-4f9c-8019-849b054fb4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cc4606b-3a37-4ed8-8c37-8c8206bd1467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a0a96a5-039b-4023-8d58-34659b0530d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62add814-2e19-44cc-b288-67e0777c91f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab440034-2ab6-4ef5-be6b-a33d6e578662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07195ed2-dd04-4d56-aa42-c7d97e7bd424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11017b8e-abd7-47b9-b856-6f62b9de3bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b05c1209-2464-4364-a047-bc98bdf97425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fccd9a38-976b-4904-931d-55ff11771e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25ab2ee4-5e0d-487d-a0d1-bc2c33ebd389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51da6acf-b660-4043-a62a-3a5de67cece3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f0b8ea3-8f0a-4757-b5d7-42e06910117b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1334b50a-4aea-4a23-83ad-0242a209b7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 336bb7b8-4bfe-40c2-ad42-d769b21afbe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 722a5990-3efc-4657-9ed5-baa37ae6a6b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9994dff-4466-4e43-ac59-49e0b265c246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a0e416c-f749-4def-9962-ec72a664f53a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de1663e2-1e62-451c-8fa6-21b5479696d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad526357-611b-43e4-bda5-f1b315b0e24f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 682dc46d-84a7-4433-9faa-627bd407b337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce4ffe9c-a18c-402f-91f0-95d4da913a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24728446-b8af-4d75-bec7-edd499ba81bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a0efb3e-9b8b-4ce9-b9c9-805cff6358a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb21abc8-83c2-47d4-a52e-580675f8a6ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36a93f84-372c-4f8b-9229-5ae13c6158fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f35cc48-af80-43a5-b70c-84e477e80c7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80a00041-8ca0-4c71-bd42-e903a254525b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34d32da9-5c1e-4bf7-a738-3e11349cf7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ea873b2-4be0-402e-80f1-92b7b43bd241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message addc8cf0-9ec3-4ca6-bdb2-c29f09908d75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f8f32a7-cb60-4c42-be57-bdb18c483d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fc24148-8ffe-4d10-a785-80419ad0e99b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af4524b0-83b1-4bd5-b286-3c5d8b568fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e6c976a-616d-43b7-a154-d810b6573cca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 446c23cb-4659-4592-bf1f-fb3004368b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9513febe-aba4-4392-9a74-b23dc58c74e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ced7285f-46b0-4d1a-b766-5b74b629ec82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4be182d1-fea5-412c-8e17-7f25305b2eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51a311cf-6dfb-4a77-9fe7-3432a678f22b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4deb85f-aa20-4e8b-9aac-649b14d0232d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 065e62ee-ff13-42d3-9536-e6bcfc419f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d573dbfe-de19-4e30-8097-078331c92c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c503445-38e3-4901-95e4-115e5679ec31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20214cda-b46a-43ac-8888-f13f8a16c0fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37e1baf5-0b8d-4dcf-838a-35efc3f1ab1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b8f0847-facb-4b05-a1fe-df31e6d088ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af0fece6-08ed-4dbc-a9e6-de66f81a4300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 836ce6be-a40b-432e-a8a7-606ea99d9cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a9ec435-400e-4925-a1c0-a58ad414909f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2b40422-fe8d-4b1c-917a-ebb00023d231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6afe2bce-0586-43d5-9b64-83a75c5ded4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ffc9361-7792-4b4c-9bbd-fa16a57f5865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b9b478-53f4-4511-bba8-aba2a9575a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed0ad76e-bbc2-49f7-8f0f-a1a1324f72de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 564f6c69-8a0f-4f90-a6b7-e59aa38b749d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0595244-0e8d-407e-8976-91b5db418474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e91e4cd-da18-492d-83be-06ce9c9c0eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1bd1a27-613b-4b4f-99b5-0a352ad74e6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e238c1d-11f0-472a-aa75-0b70aa15ca1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d875a98e-8c33-4f64-a03e-d456380c3c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f4b0e13-0078-4389-a30e-0899469a4f1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b774bcf4-3da3-4f56-878a-a8d5ea0b26a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2916bb30-ef00-4016-922c-86f89872beb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4908068f-e999-41cb-afd7-6cfcdb0f03fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12881ea2-f690-4ed2-95d0-40a6475be1e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f05fdad-a81a-4ac5-bb53-f300348ca59c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40fe6c46-3153-42ba-ae5b-46911e2a46e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1be18c5a-ad1d-40c6-851e-43ebb8c1516c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c7aeb96-bd0a-4b6f-9635-8a35c0159b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9717d834-aae0-4f4a-a613-1a67e331f7fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f87fd9be-e3ef-4832-a372-2010f33088b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ac1f81c-ccc7-4388-ba31-2852f52f5bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b359d662-53df-4465-809e-6f098d4d5c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e1d5eff-c651-4c9c-b9ca-3ea3c09bc0f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98465513-0d21-4724-83e6-b7a1d5037fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b78956b7-e855-44dc-b8f8-8e0601263277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a590e845-d2b7-4bbd-b8cb-49dfcad32f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fe9b719-76f1-43ff-a6f6-ecde388e923d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b6b000c-1261-4a8c-b876-685d7742d351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 800e164b-2417-4af8-b0e6-0bea4d75e913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b56294f-2e29-4dd3-ac90-f104a6612046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e158116-151e-4f0c-a68c-eb8d20424b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3694180-8932-45f8-b3fe-a9f7ba0e3f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9acece2-04f0-4d47-9738-a40817f01897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6699ae7-6519-4f15-85e7-81e08ce46ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dad1248-8e62-47d1-89cf-a7cdf583a8ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1327917a-6f5c-48ab-92f8-5b64746ed78d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c769b6ee-c204-4039-9379-458900bccbfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d83c9300-72a1-424b-94c5-aef73dce2a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2d59e1e-3124-42ab-a5f2-4670ff2a7f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3afcf82-3c9f-4812-9652-2a88b79ace5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00ef388f-98d9-4657-818e-a266b1777919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 717a6a62-c6ee-45d8-ae57-7e73c8695ed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e39606d-46d1-4bad-975e-40d577ae2afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1150456-63c1-4b60-9318-5ce978c31c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e1d16cb-c7c6-4c78-acd5-5127520fc92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 836e43a9-1b2b-4aa9-bcee-93eef2377dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68e25d77-f5bf-4a93-9758-eea8b224475b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 446d9fae-e125-4374-b216-b30e77755b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9e5f950-3e99-4cf5-a649-c5b5fc5c1664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01246b7f-d156-4a28-9982-b313692fbd71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebe0eb7c-5f80-42c8-886c-96929007d4ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80ef0c72-766e-406a-b495-7c3df3389883
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_25
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/test_labels.txt

📊 Raw data loaded:
   Train: X=(1671, 24), y=(1671,)
   Test:  X=(418, 24), y=(418,)

⚠️  Limiting training data: 1671 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  409 samples, 5 features
✅ Client client_25 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1267, val=0.0797 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0867, val=0.0789 (↓), lr=0.001000
   • Epoch   3/100: train=0.0872, val=0.0801, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0875, val=0.0788, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0869, val=0.0788, patience=3/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0861, val=0.0789, patience=9/15, lr=0.000500
   📉 Epoch 19: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0840, val=0.0785, patience=9/15, lr=0.000250
   📉 Epoch 27: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 3 Summary - Client client_25
   Epochs: 27/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0194
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0159
============================================================


============================================================
🔄 Round 4 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1774, val=0.1466 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.1347, val=0.1125 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.1010, val=0.0901 (↓), lr=0.000125
   • Epoch   4/100: train=0.0840, val=0.0904, patience=1/15, lr=0.000125
   ✓ Epoch   5/100: train=0.0838, val=0.0891 (↓), lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0830, val=0.0893, patience=6/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 4 Summary - Client client_25
   Epochs: 20/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0024
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0185
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.1943, RMSE: 0.4408, MAE: 0.3630, R²: -1.4586

📊 Round 4 Test Metrics:
   Loss: 0.1909, RMSE: 0.4369, MAE: 0.3596, R²: -1.4158

📊 Round 4 Test Metrics:
   Loss: 0.1815, RMSE: 0.4260, MAE: 0.3501, R²: -1.2971

============================================================
🔄 Round 9 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1698, val=0.1205 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.1561, val=0.1111 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.1436, val=0.1034 (↓), lr=0.000031
   📉 Epoch 4: LR reduced 0.000031 → 0.000016
   ✓ Epoch   4/100: train=0.1326, val=0.0968 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1249, val=0.0939 (↓), lr=0.000016
   ✓ Epoch  11/100: train=0.1007, val=0.0823 (↓), lr=0.000016
   📉 Epoch 12: LR reduced 0.000016 → 0.000008
   📉 Epoch 20: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0881, val=0.0809, patience=7/15, lr=0.000004
   📉 Epoch 28: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 9 Summary - Client client_25
   Epochs: 29/100 (early stopped)
   LR: 0.000031 → 0.000002 (4 reductions)
   Train: Loss=0.0939, RMSE=0.3065, R²=-0.1136
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0141
============================================================


============================================================
🔄 Round 10 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1585, val=0.1749 (↓), lr=0.000002
   ✓ Epoch   2/100: train=0.1578, val=0.1741 (↓), lr=0.000002
   ✓ Epoch   3/100: train=0.1571, val=0.1734 (↓), lr=0.000002
   ✓ Epoch   4/100: train=0.1564, val=0.1727 (↓), lr=0.000002
   ✓ Epoch   5/100: train=0.1558, val=0.1720 (↓), lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   ✓ Epoch  11/100: train=0.1532, val=0.1696 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1506, val=0.1669 (↓), lr=0.000001
   • Epoch  31/100: train=0.1482, val=0.1645, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1460, val=0.1622 (↓), lr=0.000001
   • Epoch  51/100: train=0.1439, val=0.1600, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1418, val=0.1579, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1398, val=0.1558 (↓), lr=0.000001
   • Epoch  81/100: train=0.1379, val=0.1538, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1360, val=0.1518, patience=2/15, lr=0.000001

============================================================
📊 Round 10 Summary - Client client_25
   Epochs: 100/100
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.1343, RMSE=0.3665, R²=-0.6249
   Val:   Loss=0.1500, RMSE=0.3873, R²=-0.6420
============================================================


============================================================
🔄 Round 14 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1447, val=0.1309 (↓), lr=0.000001
   • Epoch   2/100: train=0.1445, val=0.1307, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1443, val=0.1305, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1441, val=0.1303 (↓), lr=0.000001
   • Epoch   5/100: train=0.1439, val=0.1301, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1426, val=0.1288, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1406, val=0.1267, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1386, val=0.1247 (↓), lr=0.000001
   • Epoch  41/100: train=0.1366, val=0.1227, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1347, val=0.1207, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1327, val=0.1187 (↓), lr=0.000001
   • Epoch  71/100: train=0.1308, val=0.1167, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1288, val=0.1147, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1268, val=0.1127 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_25
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1251, RMSE=0.3537, R²=-0.4314
   Val:   Loss=0.1110, RMSE=0.3331, R²=-0.5320
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1360, RMSE: 0.3688, MAE: 0.3009, R²: -0.7215

📊 Round 14 Test Metrics:
   Loss: 0.1310, RMSE: 0.3620, MAE: 0.2955, R²: -0.6582

============================================================
🔄 Round 16 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1255, val=0.1394 (↓), lr=0.000001
   • Epoch   2/100: train=0.1253, val=0.1392, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1251, val=0.1390, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1249, val=0.1388 (↓), lr=0.000001
   • Epoch   5/100: train=0.1247, val=0.1386, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1236, val=0.1375, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1217, val=0.1355, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1198, val=0.1336 (↓), lr=0.000001
   • Epoch  41/100: train=0.1179, val=0.1317, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1160, val=0.1298, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1142, val=0.1279 (↓), lr=0.000001
   • Epoch  71/100: train=0.1123, val=0.1260, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1105, val=0.1242, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1087, val=0.1224 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_25
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1067, RMSE=0.3266, R²=-0.3029
   Val:   Loss=0.1207, RMSE=0.3475, R²=-0.2758
============================================================


============================================================
🔄 Round 17 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1259, val=0.1168 (↓), lr=0.000001
   • Epoch   2/100: train=0.1257, val=0.1166, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1255, val=0.1164, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1253, val=0.1162 (↓), lr=0.000001
   • Epoch   5/100: train=0.1251, val=0.1161, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1240, val=0.1150, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1220, val=0.1132, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1202, val=0.1115 (↓), lr=0.000001
   • Epoch  41/100: train=0.1183, val=0.1098, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1165, val=0.1081, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.1146, val=0.1064, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.1128, val=0.1047, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1111, val=0.1031, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.1093, val=0.1015, patience=1/15, lr=0.000001

============================================================
📊 Round 17 Summary - Client client_25
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1078, RMSE=0.3284, R²=-0.2638
   Val:   Loss=0.1001, RMSE=0.3164, R²=-0.2406
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1119, RMSE: 0.3345, MAE: 0.2758, R²: -0.4156

============================================================
🔄 Round 18 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1102, val=0.1121 (↓), lr=0.000001
   • Epoch   2/100: train=0.1100, val=0.1119, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1099, val=0.1118, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1097, val=0.1116 (↓), lr=0.000001
   • Epoch   5/100: train=0.1095, val=0.1114, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1085, val=0.1104, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1069, val=0.1087, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.1053, val=0.1071, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1038, val=0.1055, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.1022, val=0.1039, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1008, val=0.1024, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.0994, val=0.1009, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0980, val=0.0995, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0967, val=0.0981, patience=1/15, lr=0.000001

============================================================
📊 Round 18 Summary - Client client_25
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0955, RMSE=0.3090, R²=-0.1323
   Val:   Loss=0.0969, RMSE=0.3113, R²=-0.1427
============================================================


============================================================
🔄 Round 21 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 21 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0220
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0092
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2447, R²: -0.0276

============================================================
🔄 Round 22 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 22 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0109
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0009
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2437, R²: -0.0165

📊 Round 22 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2434, R²: -0.0141

============================================================
🔄 Round 26 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 26 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0038
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0012
============================================================


============================================================
🔄 Round 28 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 28 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0006
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0041
============================================================


============================================================
🔄 Round 29 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 29 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0016
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0006
============================================================


============================================================
🔄 Round 30 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 30 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0013
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0027
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2431, R²: -0.0101

============================================================
🔄 Round 31 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 31 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0010
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0137
============================================================


============================================================
🔄 Round 32 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 32 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0009
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0009
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2430, R²: -0.0092

📊 Round 32 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2429, R²: -0.0087

📊 Round 32 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2429, R²: -0.0083

============================================================
🔄 Round 38 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 38 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0009
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0091
============================================================


============================================================
🔄 Round 40 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 40 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0000
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0022
============================================================


============================================================
🔄 Round 41 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 41 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0007
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0137
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2428, R²: -0.0076

============================================================
🔄 Round 42 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 42 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0009
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0069
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2428, R²: -0.0073

============================================================
🔄 Round 46 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 46 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0005
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0067
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2428, R²: -0.0072

============================================================
🔄 Round 47 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 47 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0006
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0034
============================================================


============================================================
🔄 Round 48 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 48 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0001
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0091
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2427, R²: -0.0070

============================================================
🔄 Round 49 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 49 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0007
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0057
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2427, R²: -0.0069

============================================================
🔄 Round 54 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 54 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0003
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0171
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2427, R²: -0.0069

📊 Round 54 Test Metrics:
   Loss: 0.0796, RMSE: 0.2820, MAE: 0.2427, R²: -0.0068

============================================================
🔄 Round 57 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 57 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0009
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0053
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2427, R²: -0.0068

📊 Round 57 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2427, R²: -0.0067

============================================================
🔄 Round 59 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 59 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0010
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0080
============================================================


============================================================
🔄 Round 60 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 60 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0004
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0087
============================================================


============================================================
🔄 Round 61 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 61 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0017
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0089
============================================================


============================================================
🔄 Round 62 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 62 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0005
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0012
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2427, R²: -0.0065

============================================================
🔄 Round 63 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 63 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0008
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0081
============================================================


============================================================
🔄 Round 65 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 65 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0002
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0062
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2427, R²: -0.0063

📊 Round 65 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2427, R²: -0.0063

============================================================
🔄 Round 68 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 68 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0001
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0061
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2427, R²: -0.0063

============================================================
🔄 Round 70 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 70 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0003
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0035
============================================================


============================================================
🔄 Round 71 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 71 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0002
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0001
============================================================


============================================================
🔄 Round 73 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0983, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0983, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0983, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0983)

============================================================
📊 Round 73 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0002
   Val:   Loss=0.0983, RMSE=0.3135, R²=-0.0007
============================================================


============================================================
🔄 Round 75 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 75 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0004
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0006
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2426, R²: -0.0058

============================================================
🔄 Round 76 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 76 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0003
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0035
============================================================


============================================================
🔄 Round 77 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 77 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0006
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0144
============================================================


============================================================
🔄 Round 80 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 80 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0021
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0125
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2426, R²: -0.0056

============================================================
🔄 Round 81 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 81 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0008
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0022
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2426, R²: -0.0056

============================================================
🔄 Round 82 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 82 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0023
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0110
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0794, RMSE: 0.2819, MAE: 0.2426, R²: -0.0055

============================================================
🔄 Round 86 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 86 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0003
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0002
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2426, R²: -0.0056

============================================================
🔄 Round 87 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 87 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0008
   Val:   Loss=0.0884, RMSE=0.2972, R²=-0.0298
============================================================


============================================================
🔄 Round 88 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 88 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0013
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0070
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0794, RMSE: 0.2819, MAE: 0.2426, R²: -0.0054

📊 Round 88 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2426, R²: -0.0053

============================================================
🔄 Round 93 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 93 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0004
   Val:   Loss=0.0930, RMSE=0.3050, R²=0.0006
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2426, R²: -0.0052

============================================================
🔄 Round 97 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 97 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0004
   Val:   Loss=0.0799, RMSE=0.2828, R²=-0.0028
============================================================


============================================================
🔄 Round 98 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 98 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0009
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0001
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2426, R²: -0.0052

📊 Round 98 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2426, R²: -0.0051

📊 Round 98 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2426, R²: -0.0051

============================================================
🔄 Round 104 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 104 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0033
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0442
============================================================


============================================================
🔄 Round 107 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 107 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0005
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0083
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2425, R²: -0.0048

📊 Round 107 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2425, R²: -0.0047

📊 Round 107 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2425, R²: -0.0048

============================================================
🔄 Round 117 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 117 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0012
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0167
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2425, R²: -0.0048

📊 Round 117 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2425, R²: -0.0048

📊 Round 117 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2425, R²: -0.0047

============================================================
🔄 Round 121 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 121 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0002
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0044
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2425, R²: -0.0047

📊 Round 121 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2425, R²: -0.0047

📊 Round 121 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0046

📊 Round 121 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0046

============================================================
🔄 Round 127 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 127 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0005
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0058
============================================================


============================================================
🔄 Round 128 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 128 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0023
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0117
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0046

📊 Round 128 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0045

📊 Round 128 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0046

📊 Round 128 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0045

============================================================
🔄 Round 134 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 134 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0004
   Val:   Loss=0.0730, RMSE=0.2703, R²=-0.0035
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0044

============================================================
🔄 Round 138 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 138 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0003
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0028
============================================================


============================================================
🔄 Round 140 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 140 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0001
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0013
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0044

📊 Round 140 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0044

============================================================
🔄 Round 144 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 144 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0002
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0005
============================================================


============================================================
🔄 Round 145 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 145 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0003
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0022
============================================================


============================================================
🔄 Round 146 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 146 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0004
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0010
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0046

============================================================
🔄 Round 148 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 148 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0004
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0005
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0046

📊 Round 148 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0046

============================================================
🔄 Round 151 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 151 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0006
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0045
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2425, R²: -0.0047

============================================================
🔄 Round 152 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 152 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0007
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0083
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0046

📊 Round 152 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0046

📊 Round 152 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0046

📊 Round 152 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0046

============================================================
🔄 Round 157 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 157 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0017
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0012
============================================================


============================================================
🔄 Round 160 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 160 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0001
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0032
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0045

============================================================
🔄 Round 162 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 162 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0003
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0014
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0045

📊 Round 162 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0045

📊 Round 162 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0044

============================================================
🔄 Round 167 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 167 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0002
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0049
============================================================


============================================================
🔄 Round 168 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 168 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0000
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0049
============================================================


============================================================
🔄 Round 170 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 170 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0004
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0039
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2425, R²: -0.0042

============================================================
🔄 Round 175 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 175 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0001
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0128
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2425, R²: -0.0042

============================================================
🔄 Round 176 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 176 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0011
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0054
============================================================


============================================================
🔄 Round 177 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 177 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0011
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0039
============================================================


============================================================
🔄 Round 179 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 179 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0011
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0016
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0043

============================================================
🔄 Round 181 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 181 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0008
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0008
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2425, R²: -0.0042

📊 Round 181 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0043

============================================================
🔄 Round 184 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 184 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0004
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0112
============================================================


============================================================
🔄 Round 186 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 186 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0005
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0312
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0043

============================================================
🔄 Round 187 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 187 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0004
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0037
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0043

============================================================
🔄 Round 188 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 188 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0006
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0002
============================================================


============================================================
🔄 Round 192 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 192 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0018
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0034
============================================================


============================================================
🔄 Round 195 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 195 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0009
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0066
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2425, R²: -0.0042

📊 Round 195 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0043

============================================================
🔄 Round 199 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 199 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0029
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0080
============================================================


============================================================
🔄 Round 201 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 201 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0023
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0203
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2425, R²: -0.0042

============================================================
🔄 Round 202 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 202 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0041
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0091
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2425, R²: -0.0041

📊 Round 202 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2425, R²: -0.0042

============================================================
🔄 Round 205 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 205 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0004
   Val:   Loss=0.0979, RMSE=0.3129, R²=-0.0020
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2425, R²: -0.0042

📊 Round 205 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2425, R²: -0.0042

============================================================
🔄 Round 207 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 207 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0002
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0124
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2425, R²: -0.0041

============================================================
🔄 Round 208 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 208 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0003
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0001
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2425, R²: -0.0042

============================================================
🔄 Round 211 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 211 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0025
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0458
============================================================


❌ Client client_25 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
