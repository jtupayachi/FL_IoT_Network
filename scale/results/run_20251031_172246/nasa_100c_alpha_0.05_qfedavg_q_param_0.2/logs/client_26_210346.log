[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e971d8a3-e772-4a93-b73e-b59c8be2765d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b48c2ece-d3ad-44d4-9913-bf6fbe6b1b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9a2e6a1-b071-40ee-8060-19fdc02d8eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d27a33e8-b124-4cf5-9f45-ddfd4419f885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2deac0f9-7c62-486e-8922-17b7a62bcff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3794a87e-56c4-413d-8ebf-11a1c19e678d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bb25ff6-5908-4297-9222-0fbe2828efbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03942e44-8758-42df-9591-08047cf0ac42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57a6f08f-ef91-4f4b-9c41-411982228555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b96cebc9-e7a7-426e-862d-f511aa2f72ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c276f884-be2b-4e39-bf2e-0493efae825b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ce401f-4bca-4adf-a945-f9185de44981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4c7094d-5767-41b4-a74d-bb7c03e92902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fcac45b-2538-45d9-85a3-b6417c88f293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75344012-72b4-475c-84a0-144616d270db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0166186-a2bb-4983-85ec-ba15b05153ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2639f32-1522-47f6-a31d-8c0868a3e9ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b1cb0f9-fe30-4911-a608-a7f9013f728e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 982847f2-a5a1-492c-9515-d42702ff67c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c351e49-9389-45cf-9582-4e9577d88c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3a91180-91f4-49b2-a1f9-0e675ebed01d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57000841-189e-477e-b755-1f91cb08a5ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5abc6918-9a57-43db-b6de-6978fde47982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 834c32ed-cc5e-42ac-bd23-2bf1e06b52ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0af14f14-8090-4e5a-8562-434875e1cf4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7846e28c-c0a7-4a54-878a-0b25d21958ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 202cdc8d-4df4-4319-8464-865dc0fe0045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6607fd5d-04c3-4aab-8641-9ccc06ff643b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67bfe3df-65ac-485b-8e21-f620b31c0fd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1c6c32f-a142-4ae6-b2d2-86bd109fdef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e56f540-25eb-4cc9-9742-0543a73c65f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e76611c-d18a-4e57-ba4b-9bea63938da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c760caa2-1f0e-420c-baa8-2ed6597ed1b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cefefb2d-c072-4c80-92db-4c5939953aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85969a9f-6141-446e-906c-9daadf7d5aef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a07fd357-f407-480b-81de-b1cbcbf8c074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 551c7a35-6060-4d5a-b416-eb75d9f616d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65e40208-d95d-4281-afee-4055502b422e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 411cfa4f-4e65-4ac0-8cdb-2dab79393b4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2d7ae48-bb2c-4a7a-b03a-8e622e2e8443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a57d409-e11d-4428-be08-6f67ff5349eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ada2eb2-72c1-4879-aa53-5c26c6023195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 411c3013-b01d-41ad-926b-e4ed735f082b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36dd942a-3f06-4498-891f-bba3785826f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7289e615-a84d-4b21-85d8-a8df6ca7ea17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b5ca61f-49f4-41e8-b511-a35480b93d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aed66735-ead4-4e48-9364-f928a6bc2753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9dc52bf-25ef-4be9-9202-cc18c5d7fc71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94ce8cc9-65ec-4d77-a41b-04c2b543de2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3049f6d3-33a5-49bc-b68e-d8d6351720a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 223ffe9b-84ce-4937-ba4b-38fd6a8f8a42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1959430-d51b-42b0-ab9e-966a7ef9c239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea829ff9-416a-4c68-a6b1-1db8c0eddb49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ccb0154-d861-48ba-80a1-4c85591ffcd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 128fd2da-b85f-4dbb-af11-2611eadcc0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0a54929-3e2d-4297-b97d-6ed0f7d8325f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f89166c-9479-4f81-82d0-3c4d2a3c597e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efe77ac1-cbec-4dcc-a277-b560975b3acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61fb37c1-083a-4048-b6ee-7ecfb1f1dba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ab57ca6-1b78-41e5-b702-54a95f590d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76408f0f-9a89-48cc-b2bb-dfc1cf6f98c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23220bc2-7db1-43e6-88c1-d774f1c50590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b0d99c-2e6c-4f84-ae5d-a0cc0113d076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fba1ec0f-cdcb-41d3-909c-692cf93080ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da05a908-7ec7-4b06-ab3e-cd401265deb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fcadc8d-95d9-41d4-89f9-f5637d57e1f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 233caa45-c3a5-44be-b660-8f107e302041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ebed572-bde3-4eb9-9be0-c652b1a81fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeea7c4f-5a0b-4493-a8c3-58a7bac2e139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1cd95ea-9484-4075-b4ff-71d565661912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9abc153b-f3ce-4813-bf17-4e8cc24df27a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d50587-43b4-4452-a397-0fb8cd5d3358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61922660-f74c-42f4-8e80-748552b7a610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c151f2bc-b1a9-4df9-bb41-2a6f85067d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95fc563f-c8c7-4a9a-b70b-64d9bf747328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fad0826-a697-4725-9647-153e4a1bab8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7eee6f4-0a6d-4cdc-900e-ffdff70b285a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dab00a72-811f-4d2f-8861-5776efcef2e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0eefec4-d7a2-4a1d-8bae-e675be52d955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 700bc680-ddda-4e3f-820f-af16a07c0333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deffdd44-b4b9-4a4a-8bc6-ccf39806dc44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 081aa184-06cb-4ca3-a23d-45803025257f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 451ec868-e3d4-4f6d-9366-cea3592a07a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 493489f6-a8b6-42ad-b653-ffaa40002a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 467859f4-2e36-4ba8-8b0a-c398e74d419d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf7d6d80-0806-49a3-8e97-4bee8a437309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ba3fb7a-c151-47b6-a140-de0446038a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 595094fd-e0c0-4775-9af0-3311ba308e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4ec46a7-087e-4919-bc58-0a7159ded711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e6befa9-3c8a-449e-b88e-15b8163665af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc021cd3-6985-45ea-bbf4-24b5bb5105b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f6b8734-bbc2-4956-b9be-e51dbb461360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3c8c124-c696-4d9d-ba6c-49f741b272d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6dad5e6-c825-4209-add8-1b0eeb80c104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2fec906-f241-4a7f-abfa-075688ced30d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 191a3186-77f8-4581-aacf-6482525f6bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 057411e1-9934-4e13-b2f6-db994adf1025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faec9568-40a8-41aa-9239-0c0e9abbed36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a655e54-5374-4083-8e5e-72a9bba0187e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec1d43d8-0061-461d-92c9-8783fe40a984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4e25bc9-ba49-496c-a641-f5d2294df6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3423e21-f0a0-4a2e-b5db-8ed30e2fabe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b94fc09-02c8-4577-8391-8a0fdf072cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b08996c7-051b-4c8c-b4d8-8a81e20b3920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5197ef8-d8d8-4f2f-9a92-f00961201ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec44d8bf-54ec-4a41-90d0-c1a8d6eb3f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce011c2-88e7-4b6c-ae5f-07fa573d07b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6d80a1b-5b9f-438e-b0fc-2c44d5652755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88744eaf-e875-4aa7-9158-26451679bf3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d34bfdfb-b446-402b-9ca3-4a633f1f8ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d27ad2b2-61ea-4881-a344-c1e0354241d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00633bb7-c3b7-4a3a-9c25-f0c95f68dced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e32e400f-661b-4788-9566-1849061dcfbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81d3c8b8-67f5-4c9b-a0b4-311378fa39bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9321cb5b-e561-4532-8c97-4574acab6d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb71369-67a1-4683-851c-7ca510677da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e1d065d-729f-48c1-81ad-7d7f6c7c1a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 656bbe64-958b-4423-90fc-9f21580a6bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beec1406-6029-4f1e-b4f7-a671004b0632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8811ea0d-9f34-4d02-a416-3952060e1627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd68a180-9b27-45a0-a3c0-8cbc3729c509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae42aede-c14e-482e-a0a3-c394616e7661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91cd8ff9-47b1-4977-96b4-424efc23ae42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1071830a-32e6-4fd5-b7f8-a3a558a79005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e980d6d-2b21-478d-b0ba-398ecc291889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b32078d6-2823-4859-986e-c0c7106432ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 421ee948-c968-4bb5-b5ce-e547a0fbbcc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eed833a-2be5-4b28-bb8a-98e7510583c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 988509db-c5ae-4ff3-b386-d00af391a179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46ab8d59-3d08-4b61-8da5-625286bdf414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61960cba-daf7-4af4-8f0d-a2fcfc70a85c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db2694ba-08e1-4ae5-a287-dc552b6ff2c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55bf9ab4-dcb8-4179-b043-91b43c11285b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64f20d95-e1a8-476d-935a-6137a79152e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbf103f2-651f-43fa-b012-40304b274531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01ccc228-69f0-4431-9d0c-ade315709fd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62649462-5559-435d-84a5-9004678e7172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8f1414d-fba7-49d9-a2a4-796caf5706df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceae4e37-0828-4e1b-8705-d30e1ca9c4eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f7932e9-24d1-4863-8800-0d59b90b384f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3be8e270-c0a9-44a4-b4dc-e892dff58a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5c58816-134c-4a96-99df-f53dd5734c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99f7a53a-33ca-407c-9eff-b34d3e781d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b324d7f2-25eb-4aa7-9217-d3af592ba96f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4819108c-08cc-490e-a2e5-6b7a0bcca86f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db92c5fc-fb28-42d0-9f29-522b914891ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5a4bb46-b236-42e2-bd24-bc3b471daef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a987278f-adca-4956-be3d-55cc6f84530d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d1d9f30-3077-4008-9c1b-8c9caa1ba909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ac03cbe-0168-4306-a079-bdfa47aca307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4db3ed07-9b33-4235-9aa2-b6e44e05b3d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76fbedb9-6bb2-41b1-8a47-a2aac8d2d659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e5f35b1-aaf2-4f03-ac47-26ac702228a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63f25221-7d16-4182-9688-330fe6500f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17880e85-d43f-4d9d-8776-225eb79c1f38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8ab0c03-5be8-423c-8b90-bb93dd2b0c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38306430-5a30-4fb9-88a5-b4e082d371c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7de5d59d-b929-45de-927a-0152e3f39b3e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_26
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/test_labels.txt

📊 Raw data loaded:
   Train: X=(1231, 24), y=(1231,)
   Test:  X=(308, 24), y=(308,)

⚠️  Limiting training data: 1231 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  299 samples, 5 features
✅ Client client_26 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.2187, RMSE: 0.4677, MAE: 0.3858, R²: -1.5436

📊 Round 0 Test Metrics:
   Loss: 0.2116, RMSE: 0.4600, MAE: 0.3786, R²: -1.4607

============================================================
🔄 Round 4 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1178, val=0.0918 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0847, val=0.0805 (↓), lr=0.001000
   • Epoch   3/100: train=0.0843, val=0.0808, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0831, val=0.0807, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0829, val=0.0807, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0815, val=0.0809, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 4 Summary - Client client_26
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0003
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0002
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.2041, RMSE: 0.4517, MAE: 0.3709, R²: -1.3732

📊 Round 4 Test Metrics:
   Loss: 0.2007, RMSE: 0.4480, MAE: 0.3676, R²: -1.3341

============================================================
🔄 Round 6 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1568, val=0.1150 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1012, val=0.0770 (↓), lr=0.000250
   • Epoch   3/100: train=0.0848, val=0.0773, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0842, val=0.0774, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0839, val=0.0777, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0834, val=0.0781, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 6 Summary - Client client_26
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0061
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0070
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.1722, RMSE: 0.4150, MAE: 0.3391, R²: -1.0027

============================================================
🔄 Round 12 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1418, val=0.1435 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1232, val=0.1253 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1065, val=0.1107 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0936, val=0.1000 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0851, val=0.0941 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0800, val=0.0916, patience=1/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0798, val=0.0914, patience=11/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 12 Summary - Client client_26
   Epochs: 25/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0022
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0017
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1625, RMSE: 0.4032, MAE: 0.3295, R²: -0.8902

📊 Round 12 Test Metrics:
   Loss: 0.1567, RMSE: 0.3959, MAE: 0.3236, R²: -0.8226

============================================================
🔄 Round 14 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1410, val=0.1299 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1385, val=0.1273 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1358, val=0.1248 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1333, val=0.1225 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1309, val=0.1203 (↓), lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1229, val=0.1134 (↓), lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.1168, val=0.1079, patience=1/15, lr=0.000002
   📉 Epoch 22: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.1144, val=0.1058 (↓), lr=0.000001
   • Epoch  41/100: train=0.1125, val=0.1040, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1106, val=0.1022, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.1088, val=0.1006, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1071, val=0.0990 (↓), lr=0.000001
   • Epoch  81/100: train=0.1055, val=0.0974, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1038, val=0.0959 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_26
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.1025, RMSE=0.3202, R²=-0.2265
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.2322
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1218, RMSE: 0.3490, MAE: 0.2900, R²: -0.4169

============================================================
🔄 Round 18 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1122, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.1120, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1118, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1116, val=0.0902, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1113, val=0.0900 (↓), lr=0.000001
   • Epoch  11/100: train=0.1101, val=0.0892, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1082, val=0.0878 (↓), lr=0.000001
   • Epoch  31/100: train=0.1063, val=0.0865, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.1046, val=0.0853, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.1029, val=0.0842, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.1013, val=0.0832, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.0997, val=0.0822, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0982, val=0.0813, patience=5/15, lr=0.000001
   • Epoch  91/100: train=0.0968, val=0.0804, patience=3/15, lr=0.000001

============================================================
📊 Round 18 Summary - Client client_26
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0958, RMSE=0.3096, R²=-0.1493
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0520
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0978, RMSE: 0.3127, MAE: 0.2694, R²: -0.1373

============================================================
🔄 Round 21 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 21 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0180
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0283
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0894, RMSE: 0.2989, MAE: 0.2622, R²: -0.0394

============================================================
🔄 Round 22 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 22 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0075
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0231
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2610, R²: -0.0195

============================================================
🔄 Round 28 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 28 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0033
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0147
============================================================


============================================================
🔄 Round 29 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 29 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0056
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0153
============================================================


============================================================
🔄 Round 31 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 31 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0015
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0475
============================================================


============================================================
🔄 Round 32 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 32 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0051
   Val:   Loss=0.0917, RMSE=0.3029, R²=0.0010
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0874, RMSE: 0.2957, MAE: 0.2608, R²: -0.0166

============================================================
🔄 Round 33 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 33 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0008
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0099
============================================================


============================================================
🔄 Round 34 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 34 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0022
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0060
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2608, R²: -0.0161

📊 Round 34 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2608, R²: -0.0158

============================================================
🔄 Round 36 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 36 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0013
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0050
============================================================


============================================================
🔄 Round 37 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 37 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0013
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0052
============================================================


============================================================
🔄 Round 38 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 38 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0014
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0150
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2608, R²: -0.0150

============================================================
🔄 Round 39 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 39 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0016
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0039
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2607, R²: -0.0148

============================================================
🔄 Round 40 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 40 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0021
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0020
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2607, R²: -0.0144

📊 Round 40 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2607, R²: -0.0139

============================================================
🔄 Round 44 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 44 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0019
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0035
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2607, R²: -0.0139

============================================================
🔄 Round 45 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 45 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0027
   Val:   Loss=0.0708, RMSE=0.2662, R²=-0.0079
============================================================


============================================================
🔄 Round 46 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 46 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0029
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0040
============================================================


============================================================
🔄 Round 48 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 48 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0016
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0093
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2607, R²: -0.0135

============================================================
🔄 Round 49 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 49 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0024
   Val:   Loss=0.0697, RMSE=0.2640, R²=-0.0021
============================================================


============================================================
🔄 Round 51 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 51 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0002
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0083
============================================================


============================================================
🔄 Round 52 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 52 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0010
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0067
============================================================


============================================================
🔄 Round 53 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 53 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0037
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0409
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2607, R²: -0.0132

📊 Round 53 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2607, R²: -0.0131

📊 Round 53 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2607, R²: -0.0132

📊 Round 53 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2607, R²: -0.0130

============================================================
🔄 Round 59 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 59 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0031
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0022
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2607, R²: -0.0129

📊 Round 59 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2607, R²: -0.0129

📊 Round 59 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2606, R²: -0.0125

============================================================
🔄 Round 64 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 64 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0035
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0042
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2606, R²: -0.0123

============================================================
🔄 Round 68 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 68 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0036
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0219
============================================================


============================================================
🔄 Round 69 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 69 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0023
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0000
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2606, R²: -0.0123

============================================================
🔄 Round 70 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 70 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0007
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0061
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2606, R²: -0.0119

📊 Round 70 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2606, R²: -0.0116

============================================================
🔄 Round 76 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 76 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0025
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0003
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2606, R²: -0.0115

📊 Round 76 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2606, R²: -0.0113

📊 Round 76 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2606, R²: -0.0113

============================================================
🔄 Round 82 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 82 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0009
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0078
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2606, R²: -0.0112

📊 Round 82 Test Metrics:
   Loss: 0.0869, RMSE: 0.2949, MAE: 0.2606, R²: -0.0111

📊 Round 82 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2606, R²: -0.0113

============================================================
🔄 Round 90 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 90 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0038
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0006
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2606, R²: -0.0106

============================================================
🔄 Round 94 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 94 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0021
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0654
============================================================


============================================================
🔄 Round 95 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 95 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0023
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0070
============================================================


============================================================
🔄 Round 96 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 96 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0020
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0136
============================================================


============================================================
🔄 Round 97 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 97 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0014
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0165
============================================================


============================================================
🔄 Round 98 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 98 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0013
   Val:   Loss=0.0825, RMSE=0.2871, R²=-0.0038
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2606, R²: -0.0104

============================================================
🔄 Round 101 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 101 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0020
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0035
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2605, R²: -0.0101

============================================================
🔄 Round 105 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 105 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0037
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0306
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2605, R²: -0.0101

============================================================
🔄 Round 106 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 106 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0016
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0134
============================================================


============================================================
🔄 Round 109 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 109 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0042
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0261
============================================================


============================================================
🔄 Round 112 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 112 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0024
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0131
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2605, R²: -0.0098

📊 Round 112 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2605, R²: -0.0097

============================================================
🔄 Round 114 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 114 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0010
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0056
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2605, R²: -0.0097

📊 Round 114 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2605, R²: -0.0098

============================================================
🔄 Round 118 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 118 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0041
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0108
============================================================


============================================================
🔄 Round 119 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 119 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0011
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0052
============================================================


============================================================
🔄 Round 120 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 120 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0028
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0042
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2605, R²: -0.0095

============================================================
🔄 Round 122 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 122 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0004
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0081
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2605, R²: -0.0095

============================================================
🔄 Round 124 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 124 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0007
   Val:   Loss=0.0692, RMSE=0.2631, R²=-0.0103
============================================================


============================================================
🔄 Round 125 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 125 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0043
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0061
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2605, R²: -0.0093

============================================================
🔄 Round 129 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 129 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0028
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0081
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2605, R²: -0.0092

============================================================
🔄 Round 132 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 132 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0038
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0024
============================================================


============================================================
🔄 Round 133 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 133 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0017
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0026
============================================================


============================================================
🔄 Round 136 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 136 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0026
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0095
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2605, R²: -0.0090

============================================================
🔄 Round 139 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 139 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0018
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0061
============================================================


============================================================
🔄 Round 140 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 140 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0010
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0050
============================================================


============================================================
🔄 Round 142 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 142 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0006
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0234
============================================================


============================================================
🔄 Round 143 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 143 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0009
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0053
============================================================


============================================================
🔄 Round 144 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 144 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0032
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0041
============================================================


============================================================
🔄 Round 145 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 145 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0026
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0018
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2605, R²: -0.0092

============================================================
🔄 Round 150 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 150 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0019
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0176
============================================================


============================================================
🔄 Round 151 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 151 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0014
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0035
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2605, R²: -0.0091

============================================================
🔄 Round 152 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 152 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0047
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0018
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2605, R²: -0.0091

📊 Round 152 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2605, R²: -0.0091

📊 Round 152 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2605, R²: -0.0089

============================================================
🔄 Round 159 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 159 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0016
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0145
============================================================


============================================================
🔄 Round 160 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 160 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0024
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0011
============================================================


============================================================
🔄 Round 161 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 161 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0015
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0025
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2605, R²: -0.0088

============================================================
🔄 Round 162 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 162 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0025
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0030
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2605, R²: -0.0088

============================================================
🔄 Round 163 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 163 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0026
   Val:   Loss=0.0771, RMSE=0.2778, R²=0.0020
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2605, R²: -0.0088

📊 Round 163 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2605, R²: -0.0087

============================================================
🔄 Round 166 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 166 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0007
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0057
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2605, R²: -0.0084

============================================================
🔄 Round 171 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 171 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0029
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0090
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2605, R²: -0.0083

============================================================
🔄 Round 173 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 173 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0011
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0071
============================================================


============================================================
🔄 Round 175 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 175 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0021
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0220
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2605, R²: -0.0083

============================================================
🔄 Round 177 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 177 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0022
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0047
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2605, R²: -0.0083

📊 Round 177 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2605, R²: -0.0081

📊 Round 177 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2605, R²: -0.0083

============================================================
🔄 Round 186 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 186 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0024
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0015
============================================================


============================================================
🔄 Round 187 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 187 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0026
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0076
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2605, R²: -0.0082

============================================================
🔄 Round 191 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 191 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0021
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0051
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2605, R²: -0.0081

============================================================
🔄 Round 192 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 192 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0012
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0061
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2605, R²: -0.0079

============================================================
🔄 Round 196 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 196 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0032
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0011
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2605, R²: -0.0081

============================================================
🔄 Round 197 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 197 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0034
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0005
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2605, R²: -0.0082

============================================================
🔄 Round 198 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 198 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0031
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0148
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2605, R²: -0.0082

📊 Round 198 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2605, R²: -0.0081

📊 Round 198 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2605, R²: -0.0080

📊 Round 198 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2605, R²: -0.0079

============================================================
🔄 Round 204 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 204 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0012
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0159
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2605, R²: -0.0079

📊 Round 204 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2605, R²: -0.0079

❌ Client client_26 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
