[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1232e62e-b235-4cab-9b54-116799e14994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eb94d2a-a230-4599-9d47-ccd3ac6fa032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 680a06cf-6d5e-4083-b126-ce92d7c9b023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f35308d1-9049-4c25-92ac-68d34f221c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9916b83-54c4-41db-ad08-b58e187c8a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aa5033e-f12a-405a-aced-9861ae88cf42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee5a7b27-ac97-455e-bd23-6a7366b74e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0abfba71-e038-466a-a4fc-33a5055e2b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c784b0b6-67ac-4abc-b6a8-1148eb0a8475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 112fbead-8af3-4a6b-82b1-ddce9eb96a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a337ebe7-6fd4-4ae3-8ce5-25489e975911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac61806-7769-4a4a-b2db-f627d5450085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cb81c64-b354-4ae5-861f-0a3b072f47f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59681925-b304-4c79-a7c4-e56b34a0e5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed9dd1fb-7ccb-4f88-8f8f-df27ed7eeef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5918195-6739-45d8-9d13-e6c34e66ea38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b76f24e3-c43a-478f-8f46-232d6c17157f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 551f51a5-6c04-4d59-b7e3-6a752ebec7be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 120de051-93d3-47a4-b400-93377da5ad24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f908124-7afe-4861-9be6-9b2411ad8bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db03cb7a-6c6c-4ce1-a37e-9a25fef176f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 977fadc7-83ff-46c6-8c30-f37d3489c394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8abcdd5e-f54c-4e7f-938c-bd13089a2e9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d8c54ee-9f0f-4786-b6ae-8f8b21671499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e05bf89-b8ce-485b-ad95-85cbafea427b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35e23ded-51b3-4e11-9d81-02a159a66c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7581e1da-d1c0-41b0-a012-fcd681da695d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac99b346-b541-4f39-82c7-712d132578ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ae24085-72dc-4972-b5e5-749645910e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9d50570-a63b-424b-9292-4035eb9ead21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ad7044e-f17e-4ddc-a7d7-6e2a52d292d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b20520b4-ba91-40b5-bf1b-2a3a8190443f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1412e148-317e-4869-8590-8d3c8d3cced1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77172780-fb04-43aa-9e0c-4f9c55b887b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d63f251-f0b1-4375-b9f5-1347aa9bcd57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f0dad69-7902-439d-b337-5c66319cd798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44c69a0e-59a0-4a2e-9dc8-110187b971da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70081695-84b1-42f4-99b4-1de1a8b7aac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4123640-b712-466e-999a-c60f57b069a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc4cc7ab-3d0d-4d88-95de-7e5f99d18498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa79075e-79db-4c68-afef-8f8a95f6066b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97810bd0-a964-498a-befa-ee71a848ae8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0642e1dc-61d8-479f-99de-d04eaf26ad37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40cae864-b0f4-4397-8221-04f14e41ab7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af5b95c3-7477-4dc5-bf45-e962314e42e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d013e24-e7a9-4f38-b545-0d8c8fc33d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d397660e-3c46-446e-9d37-37c2e3b6078e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ea7e735-c2f5-4993-b2ca-57cdeecd91de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee457bfe-edc2-459b-a5be-60d61ad8209b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af5967eb-0b3f-4e3c-b18c-7ae56989aff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39097fd7-420e-4a13-b919-228343f53e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37d79e7e-e3a6-4ff9-988f-e91f82968574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86e00b50-ed88-407a-963e-e546914fe5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 762a1204-b9c4-4564-8e66-64f073ad1192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fe6314b-acdc-427b-b456-238bddf52c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de58013a-7188-4281-863f-d5db0f7c0b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b74b628-4c79-4d6e-8be3-265ca433b026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5660c7b6-c4a6-4625-a8fa-ea39ffd0ed3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5be9f0b3-cb1b-44b0-a4c5-045e92d1fd76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c64d4ba-395d-4563-be31-9ca5277e02c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac7835ec-0903-4812-9068-6b7d74641f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01450c57-f0d6-45c1-bf7b-5eb60c8325cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96b112cf-7d8c-47d3-95e3-e02c504ba330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc060f3d-2e08-4f3c-930b-32f13ab56fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 715b35d4-bc22-4333-8671-2ec34cbaf603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c92bebc-890c-4aac-947b-588121414668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 754bffb8-9a3e-4512-858d-fcc7607d9f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dc99c86-3ef0-432d-b5d8-f21c91598e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a80ebd2-9f23-4e2c-a257-3e155bd494fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d50703a-67b5-4333-b274-8416d9236324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 643ec25f-4f5b-4adb-adf9-14e05580bb71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 617f71df-24e9-4755-b45e-5de15717e435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c64ffdd-5cd6-4e2e-8a4d-fdf3b7d231cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1699d1eb-2296-4ccd-99c4-66e27ef2f32e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f480556-0398-4801-ab71-8d235d21f741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c04637c-42e8-4697-8e4a-62d0515d17d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18f34406-0f78-4478-8d86-c5a19fd5dbbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba40b383-5ff1-4e4a-a04e-1dd2ef5f586d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4039397-40b2-45d7-a86d-0678435f785b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3edf4b9-1c3e-4834-9932-c95f304dc8df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0c9991e-5fa3-4afd-bf04-f1b27a32bcd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f44e3bf-4352-4c13-a5b0-d7c83267fe27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f853b3d-6292-40c7-afe8-3e6f3c6e121d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 527b8969-1c37-4613-ad96-72fd34963d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b107e92f-bac0-43ea-951f-0c5b6d3dd361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7ed596f-bb53-4deb-81cb-2140040efbe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05200618-aebb-4ee9-b5bb-d27b469a44e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d0f5393-ccf7-4621-af55-985d26affe46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9696a08c-999b-43a0-8d9c-e83d9b1b8e57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eace7486-6148-49a1-9f9c-b25e96571d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4db1bc8f-e17f-476f-a325-7b93de90423d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97fa2ee6-9ccf-448e-b6be-ed31264234d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ad2e361-b7bf-4fa8-b952-c6dbb5210d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06174be3-4722-40d1-9cd2-5aec33230d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ca208bf-4c3b-47a8-b7a1-28bc6e1b5c1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46550122-ba35-4956-817c-e0ba77b62c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca874156-cf43-4c3e-8602-90ea7a23ac9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98a51875-b477-4fe5-979c-4aed2e310ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a8de347-94fb-4669-886d-842c05ceee3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc54a83-690f-4d43-9933-c4d409ac272b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7efab40-2317-4d65-be3c-17fe85bbb63a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d54cc88f-5b1a-45d8-9780-6d8e5a23177f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 276428d5-33ed-4742-a3f2-e0c5a413f67d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f8002e4-e2b5-4eba-9fe5-fd77bfdf9c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5894ce38-6e3f-43dd-ad1f-a39aa264df56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbfca046-2eb8-4996-9014-f0fde16cb27a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fced8c9e-2e1c-4f0b-8e22-465e84c031bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2ba2d43-8565-4a3a-8ad0-1e5eb5a1b245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7af2f25e-55a5-423f-a39a-d408c23aa686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be8672b6-7231-45f5-8a24-72cdbb99e61d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5515ee3-d3b9-41ac-8018-3d657065c74d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4e551e4-0fe3-40b2-8e63-ec0f4fdaff58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b718b6ea-b26f-4db1-a8ba-213a79e803c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6237fa08-f091-4614-ae58-56cb7531ba78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de2533c-b3d4-44c4-bb11-1193c0cd3ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 985dc84d-004e-4a5f-91e5-ce60a102dcec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c62cbfd7-43b2-4629-b8bc-07ed42769518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f471aee2-4296-4cf7-a02d-4921b645b3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99b2afe7-c434-4819-9371-253822588afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8666259b-a07e-45b3-b072-ac82d3830c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b1c9148-b5ce-47a5-a59a-1e525811917e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb939b7f-8be0-4518-a8b5-7992a792293d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93d9b422-4cc5-42d8-990e-f5739b0af34a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3a154be-5e82-46b5-ac52-707768545381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a951a114-696d-4e41-b530-b80a34978e45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c5d3af6-dd9d-4e76-b0fe-c92894906b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc70c484-ae5e-4fe6-9b55-a3490038055a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18d9428d-8554-4de4-ab17-d17de5ce9932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8557e1be-8717-4e39-8b07-4ad98b954524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39d6d502-4b2b-4adb-b994-3c9bc19337cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de422907-8ad4-4ece-9e61-52e4c9d32d5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7ad05af-7b10-4f8a-8e30-dc2541dc6eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bb62137-0656-4eb9-a0a0-829a565b8999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17823f49-43a5-4cc4-a4ae-81cec8a49e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ead5294d-6609-45ae-af6c-cdde33b91d50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67619d23-6b69-4ad7-bb46-709beb5ae237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecb64087-cabb-4c40-b789-d855353b941f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab699574-0c57-4937-9165-c1083fc18203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51dd1529-1b89-4500-af8d-5d0bd5e906ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6e8abd3-ef8d-40d3-9ba3-68ff126e446a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e06bb590-36e5-4c1f-ad56-b0ab6996be46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b5a6cd9-66fa-4146-ab7b-87f089936244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6d6f949-c27c-482a-8dde-0994b202391a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c875d74-def0-4248-9289-fec8fd301915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 164363a5-2940-4d29-92e0-68562eb2246e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06c8b22d-cc62-4e5a-a91a-df6816bdb141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e405b2f8-44d4-48c4-af49-72a316f35f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bbba18b-b686-4b81-8f0c-bdf5e77fcb4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f653412-9e30-4b86-b8ef-9aa7ba9f63a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78445669-cc07-4a6e-9662-6a83816e4d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 086688b2-dfd1-48b7-9a13-3873fc8b22e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7f97396-3df2-4b7f-beb5-663b8c9e6e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1be07bd9-854b-43f1-83cf-1f223b3e5106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b33201c5-ebd5-4023-9ca5-bb029adf95d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aefbd1d8-19ac-4a6c-82cf-cf0eb04b56d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 079e8191-4e6e-4395-8150-2d1607c982f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b363e12b-41f9-4b4b-b169-6d567720f3e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cad9b290-43b0-40e4-83a5-2b5223eb30c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2078fc43-7c1e-4d55-a644-7ffa94ef8c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd2387f-7164-41ed-8ef9-761df2d73d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fda4edfe-66a6-4cfe-90ee-6a9f4c07c066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9fe49a3-3a08-4e85-9ac0-8a32d859c04a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3c1b64f-129b-487b-84c8-446351c11ef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b1a148a-d470-473c-aa98-59d1c24ee25b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc51f9f4-5176-4bd3-9c2f-ac8e607741fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9b1ac4e-c3e0-4a85-a6ba-e3f163550414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce1fea8c-de33-4773-83c9-7411060c15ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b7ede8f-df6a-4982-8f71-9f93fbe5a3cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60be16d5-8067-4b6a-bfe0-2d78bd7aed84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c916a8a8-dfbe-4f77-bacf-d23e124aa49f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50e3adff-f480-434b-afd4-de92e460773f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0cf25d0-9f9a-46fd-a48b-3b61b3f7073d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe3e4856-78af-4820-bbe6-58e25dbe9d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e691a6a-e4b3-4e05-82bc-f8591681c0f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4518829-94b4-4049-94ac-a8e6ffa8a6a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2dcaade-5734-494c-85cc-b1726349c677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b567159-779d-487a-baeb-2f8b8bbe238e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7e21b23-bc25-4919-bb63-93fc3f33adad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a3af64c-0a02-4ffc-bb51-6fcd1c4b2ae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5247948a-d884-4156-89ce-15a6b6e570f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb07b729-828d-4642-b89e-a4eaa42ba777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3688571e-387d-4bf6-b99d-0124d0a54341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e13fb550-8992-43d6-8473-54d4c5db981b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b76ef917-22c6-48f1-8e6c-f839684475b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7b1e77f-9e5d-484c-881e-db8498ea76f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f72c3e8-3e8c-4a76-b1c5-0e0b4c9e6d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aac34cf-b18c-436a-83e4-077c5e035006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14b900ab-a3a9-40bb-9b41-a680230af247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d03e177-476c-46ad-84c2-3013f4f43d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c68c80f8-cd22-4144-9933-938383432c5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 289229b8-d58f-4c2f-9f2f-ef4030f04fcd
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_27
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_27
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_27/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_27/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_27/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_27/test_labels.txt

📊 Raw data loaded:
   Train: X=(999, 24), y=(999,)
   Test:  X=(250, 24), y=(250,)

⚠️  Limiting training data: 999 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  241 samples, 5 features
✅ Client client_27 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.2209, RMSE: 0.4700, MAE: 0.3856, R²: -1.4814

📊 Round 0 Test Metrics:
   Loss: 0.2137, RMSE: 0.4623, MAE: 0.3786, R²: -1.4008

📊 Round 0 Test Metrics:
   Loss: 0.2028, RMSE: 0.4503, MAE: 0.3677, R²: -1.2775

============================================================
🔄 Round 6 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1133, val=0.0780 (↓), lr=0.001000
   • Epoch   2/100: train=0.0819, val=0.0801, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0813, val=0.0809, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0812, val=0.0807, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0810, val=0.0808, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0801, val=0.0810, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 6 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0071
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0081
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.1839, RMSE: 0.4288, MAE: 0.3489, R²: -1.0654

============================================================
🔄 Round 10 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1345, val=0.1102 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0874, val=0.0774 (↓), lr=0.000250
   • Epoch   3/100: train=0.0825, val=0.0793, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0814, val=0.0791, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0813, val=0.0788, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0810, val=0.0790, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 10 Summary - Client client_27
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0089
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0076
============================================================


============================================================
🔄 Round 11 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1499, val=0.1348 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1275, val=0.1144 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1078, val=0.0985 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0927, val=0.0880 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0837, val=0.0841 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0803, val=0.0841, patience=6/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 11 Summary - Client client_27
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0074
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0027
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1698, RMSE: 0.4121, MAE: 0.3350, R²: -0.9079

📊 Round 11 Test Metrics:
   Loss: 0.1645, RMSE: 0.4055, MAE: 0.3297, R²: -0.8474

============================================================
🔄 Round 13 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1447, val=0.1475 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1391, val=0.1412 (↓), lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   ✓ Epoch   3/100: train=0.1335, val=0.1355 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1296, val=0.1328 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1271, val=0.1302 (↓), lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1145, val=0.1167 (↓), lr=0.000004
   📉 Epoch 19: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.1059, val=0.1081 (↓), lr=0.000002
   📉 Epoch 27: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.1028, val=0.1047, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1010, val=0.1027, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0993, val=0.1008 (↓), lr=0.000001
   • Epoch  61/100: train=0.0977, val=0.0990, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0961, val=0.0973, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0947, val=0.0956, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0933, val=0.0940 (↓), lr=0.000001

============================================================
📊 Round 13 Summary - Client client_27
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0919, RMSE=0.3031, R²=-0.1246
   Val:   Loss=0.0926, RMSE=0.3044, R²=-0.1770
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1586, RMSE: 0.3983, MAE: 0.3239, R²: -0.7816

📊 Round 13 Test Metrics:
   Loss: 0.1482, RMSE: 0.3850, MAE: 0.3138, R²: -0.6650

============================================================
🔄 Round 15 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1332, val=0.1262 (↓), lr=0.000001
   • Epoch   2/100: train=0.1329, val=0.1260, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1326, val=0.1257 (↓), lr=0.000001
   • Epoch   4/100: train=0.1323, val=0.1254, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1320, val=0.1252 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1304, val=0.1237 (↓), lr=0.000001
   • Epoch  21/100: train=0.1280, val=0.1216, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.1257, val=0.1195, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1235, val=0.1176 (↓), lr=0.000001
   • Epoch  51/100: train=0.1214, val=0.1157, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1193, val=0.1138, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1173, val=0.1120 (↓), lr=0.000001
   • Epoch  81/100: train=0.1152, val=0.1102, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1133, val=0.1085, patience=2/15, lr=0.000001

============================================================
📊 Round 15 Summary - Client client_27
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1116, RMSE=0.3340, R²=-0.3800
   Val:   Loss=0.1069, RMSE=0.3270, R²=-0.3033
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1432, RMSE: 0.3784, MAE: 0.3090, R²: -0.6082

============================================================
🔄 Round 16 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1289, val=0.1205 (↓), lr=0.000001
   • Epoch   2/100: train=0.1287, val=0.1203, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1285, val=0.1201, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1283, val=0.1199 (↓), lr=0.000001
   • Epoch   5/100: train=0.1281, val=0.1197, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1268, val=0.1185, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1247, val=0.1166, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1226, val=0.1147 (↓), lr=0.000001
   • Epoch  41/100: train=0.1206, val=0.1129, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1186, val=0.1110, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1166, val=0.1092 (↓), lr=0.000001
   • Epoch  71/100: train=0.1146, val=0.1074, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1126, val=0.1056, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1107, val=0.1039 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_27
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1089, RMSE=0.3300, R²=-0.3416
   Val:   Loss=0.1023, RMSE=0.3199, R²=-0.2659
============================================================


============================================================
🔄 Round 19 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0980, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0978, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0977, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0975, val=0.0951, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0974, val=0.0950 (↓), lr=0.000001
   • Epoch  11/100: train=0.0965, val=0.0941, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0951, val=0.0926 (↓), lr=0.000001
   • Epoch  31/100: train=0.0938, val=0.0912, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0925, val=0.0898 (↓), lr=0.000001
   • Epoch  51/100: train=0.0913, val=0.0885, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0901, val=0.0873, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.0890, val=0.0861, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0880, val=0.0851, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0871, val=0.0841, patience=3/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_27
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0535
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0726
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2643, R²: -0.0333

📊 Round 19 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2636, R²: -0.0246

============================================================
🔄 Round 25 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 25 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0075
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0064
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2629, R²: -0.0163

============================================================
🔄 Round 28 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 28 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0035
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0107
============================================================


============================================================
🔄 Round 30 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 30 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0018
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0124
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2628, R²: -0.0144

============================================================
🔄 Round 31 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 31 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0013
   Val:   Loss=0.0670, RMSE=0.2589, R²=-0.0014
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2627, R²: -0.0139

📊 Round 31 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2627, R²: -0.0136

📊 Round 31 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2627, R²: -0.0135

📊 Round 31 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2626, R²: -0.0131

📊 Round 31 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2626, R²: -0.0129

📊 Round 31 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2626, R²: -0.0125

📊 Round 31 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2626, R²: -0.0122

============================================================
🔄 Round 39 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 39 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0031
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0154
============================================================


============================================================
🔄 Round 40 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 40 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0022
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0164
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2625, R²: -0.0118

============================================================
🔄 Round 41 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 41 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0020
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0125
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2625, R²: -0.0116

📊 Round 41 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2625, R²: -0.0115

📊 Round 41 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2625, R²: -0.0112

📊 Round 41 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2625, R²: -0.0110

============================================================
🔄 Round 49 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 49 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0006
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0106
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2624, R²: -0.0106

============================================================
🔄 Round 53 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 53 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0037
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0231
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2624, R²: -0.0107

============================================================
🔄 Round 54 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 54 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0018
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0042
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2624, R²: -0.0107

📊 Round 54 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2624, R²: -0.0106

📊 Round 54 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2624, R²: -0.0106

📊 Round 54 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2624, R²: -0.0107

============================================================
🔄 Round 58 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 58 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0022
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0025
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2624, R²: -0.0105

============================================================
🔄 Round 59 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 59 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0010
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0001
============================================================


============================================================
🔄 Round 61 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 61 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0017
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0014
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0899, RMSE: 0.2999, MAE: 0.2624, R²: -0.0103

📊 Round 61 Test Metrics:
   Loss: 0.0899, RMSE: 0.2999, MAE: 0.2624, R²: -0.0102

============================================================
🔄 Round 63 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 63 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0006
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0061
============================================================


============================================================
🔄 Round 65 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 65 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0001
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0056
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0899, RMSE: 0.2999, MAE: 0.2624, R²: -0.0101

============================================================
🔄 Round 66 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 66 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0001
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0051
============================================================


============================================================
🔄 Round 67 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 67 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0003
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0052
============================================================


============================================================
🔄 Round 68 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 68 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0012
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0016
============================================================


============================================================
🔄 Round 69 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 69 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0016
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0018
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2624, R²: -0.0099

============================================================
🔄 Round 70 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 70 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0004
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0046
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2623, R²: -0.0097

============================================================
🔄 Round 71 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 71 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0004
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0046
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2623, R²: -0.0096

📊 Round 71 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2623, R²: -0.0095

============================================================
🔄 Round 74 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 74 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0011
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0054
============================================================


============================================================
🔄 Round 76 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 76 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0003
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0003
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0898, RMSE: 0.2997, MAE: 0.2623, R²: -0.0093

============================================================
🔄 Round 79 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 79 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0015
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0008
============================================================


============================================================
🔄 Round 80 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 80 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0001
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0021
============================================================


============================================================
🔄 Round 81 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 81 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0020
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0035
============================================================


============================================================
🔄 Round 82 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 82 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0005
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0018
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0898, RMSE: 0.2997, MAE: 0.2623, R²: -0.0090

============================================================
🔄 Round 83 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 83 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0007
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0079
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0898, RMSE: 0.2997, MAE: 0.2623, R²: -0.0090

============================================================
🔄 Round 84 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 84 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0022
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0075
============================================================


============================================================
🔄 Round 85 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 85 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0004
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0011
============================================================


============================================================
🔄 Round 86 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 86 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0010
   Val:   Loss=0.0765, RMSE=0.2767, R²=-0.0002
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0898, RMSE: 0.2997, MAE: 0.2623, R²: -0.0091

============================================================
🔄 Round 88 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 88 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0009
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0172
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0898, RMSE: 0.2997, MAE: 0.2623, R²: -0.0090

============================================================
🔄 Round 90 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 90 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0015
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0251
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0898, RMSE: 0.2997, MAE: 0.2623, R²: -0.0088

📊 Round 90 Test Metrics:
   Loss: 0.0898, RMSE: 0.2997, MAE: 0.2622, R²: -0.0087

============================================================
🔄 Round 93 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 93 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0000
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0013
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0898, RMSE: 0.2996, MAE: 0.2622, R²: -0.0085

📊 Round 93 Test Metrics:
   Loss: 0.0898, RMSE: 0.2996, MAE: 0.2622, R²: -0.0085

📊 Round 93 Test Metrics:
   Loss: 0.0898, RMSE: 0.2996, MAE: 0.2622, R²: -0.0086

============================================================
🔄 Round 98 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 98 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0013
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0002
============================================================


============================================================
🔄 Round 101 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 101 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0036
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0199
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0898, RMSE: 0.2996, MAE: 0.2622, R²: -0.0083

============================================================
🔄 Round 104 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 104 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0028
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0241
============================================================


============================================================
🔄 Round 109 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 109 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0016
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0010
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2622, R²: -0.0080

============================================================
🔄 Round 110 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 110 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0003
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0080
============================================================


============================================================
🔄 Round 111 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 111 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0025
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0026
============================================================


============================================================
🔄 Round 112 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 112 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0020
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0008
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2622, R²: -0.0080

============================================================
🔄 Round 113 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 113 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0006
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0083
============================================================


============================================================
🔄 Round 116 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 116 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0022
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0023
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2622, R²: -0.0079

📊 Round 116 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2622, R²: -0.0080

============================================================
🔄 Round 118 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 118 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0011
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0202
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2622, R²: -0.0080

============================================================
🔄 Round 120 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 120 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0002
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0039
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0078

📊 Round 120 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0077

============================================================
🔄 Round 126 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 126 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0013
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0012
============================================================


============================================================
🔄 Round 127 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 127 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0021
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0004
============================================================


============================================================
🔄 Round 128 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 128 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0014
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0035
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0077

============================================================
🔄 Round 129 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 129 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0027
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0028
============================================================


============================================================
🔄 Round 131 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 131 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0049
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0147
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0076

============================================================
🔄 Round 132 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 132 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0002
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0076
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0075

📊 Round 132 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0075

============================================================
🔄 Round 136 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 136 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0007
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0059
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0074

📊 Round 136 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0074

📊 Round 136 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0073

============================================================
🔄 Round 144 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 144 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0014
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0079
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0075

============================================================
🔄 Round 145 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 145 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0029
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0023
============================================================


============================================================
🔄 Round 147 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 147 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0007
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0033
============================================================


============================================================
🔄 Round 151 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 151 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0012
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0025
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0076

============================================================
🔄 Round 152 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 152 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0004
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0036
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0075

📊 Round 152 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0076

============================================================
🔄 Round 156 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 156 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0022
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0001
============================================================


============================================================
🔄 Round 157 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 157 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0029
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0403
============================================================


============================================================
🔄 Round 160 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 160 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0037
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0089
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0073

============================================================
🔄 Round 161 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 161 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0002
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0044
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0073

📊 Round 161 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2621, R²: -0.0073

============================================================
🔄 Round 165 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 165 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0016
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0047
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0897, RMSE: 0.2994, MAE: 0.2621, R²: -0.0072

============================================================
🔄 Round 167 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 167 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0004
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0019
============================================================


============================================================
🔄 Round 168 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 168 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0027
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0028
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0897, RMSE: 0.2994, MAE: 0.2621, R²: -0.0071

============================================================
🔄 Round 170 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 170 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0012
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0398
============================================================


============================================================
🔄 Round 171 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 171 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0014
   Val:   Loss=0.0866, RMSE=0.2944, R²=0.0033
============================================================


============================================================
🔄 Round 172 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 172 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0002
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0014
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0069

============================================================
🔄 Round 174 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 174 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0006
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0026
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0070

📊 Round 174 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0069

============================================================
🔄 Round 176 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 176 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0017
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0027
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2621, R²: -0.0070

📊 Round 176 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0070

============================================================
🔄 Round 180 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 180 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0026
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0107
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0069

============================================================
🔄 Round 181 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 181 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0032
   Val:   Loss=0.0765, RMSE=0.2767, R²=-0.0089
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0069

📊 Round 181 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0069

📊 Round 181 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0069

============================================================
🔄 Round 185 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 185 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0024
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0012
============================================================


============================================================
🔄 Round 186 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 186 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0013
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0041
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0070

============================================================
🔄 Round 188 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 188 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0028
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0021
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0070

============================================================
🔄 Round 189 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 189 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2828, R²=0.0033
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0043
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0069

📊 Round 189 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0069

📊 Round 189 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0069

============================================================
🔄 Round 193 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 193 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0035
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0079
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0067

📊 Round 193 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0067

============================================================
🔄 Round 196 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 196 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0025
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0010
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0068

============================================================
🔄 Round 197 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 197 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0001
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0284
============================================================


============================================================
🔄 Round 198 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 198 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0022
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0014
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0069

============================================================
🔄 Round 199 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 199 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0005
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0046
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0069

============================================================
🔄 Round 200 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 200 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0009
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0034
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0069

============================================================
🔄 Round 201 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 201 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0016
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0003
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0068

============================================================
🔄 Round 203 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 203 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0001
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0049
============================================================


============================================================
🔄 Round 204 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 204 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0030
   Val:   Loss=0.0713, RMSE=0.2669, R²=-0.0066
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0067

============================================================
🔄 Round 207 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 207 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0027
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0164
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0067

============================================================
🔄 Round 208 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 208 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0035
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0176
============================================================


============================================================
🔄 Round 210 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 210 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0025
   Val:   Loss=0.0766, RMSE=0.2769, R²=-0.0012
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2620, R²: -0.0067

❌ Client client_27 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
