[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22d6981c-337b-4c78-8146-fb9edcc71753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33dbbc36-653b-4555-9464-28ccde695bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07637951-3a14-4d9a-815b-040d4bbefe82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d50df2ab-76ba-4e64-aabb-8a7035b83b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12313b4f-c6b7-42f1-b9b1-15ba97127b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fea38ac0-5029-435a-9f95-880741b5ba45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e80ffb73-a6e1-442c-bc48-0732cbe93cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1c1910e-05c7-4c69-aa69-0939ec32295a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92680550-537c-45af-bec0-82ac5ac09909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 399b41dd-9161-4dee-aeb2-8df63805cb20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ea19f62-a126-4461-9c39-7478361ca026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5e3d416-2541-4192-85f7-5daf139ab037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 976e273c-0508-4ba0-a307-ad9876e84bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3db89a92-3e62-4b1a-b99b-6b54892bcd26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41735aee-c258-4fed-9f15-57f2d1594745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f373b78-9cd2-4540-8a10-dd6b68b143b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de43a4e2-08ef-4fdf-b55e-89dd2839d334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7a5f06b-ddcf-4f7b-b61f-8fb3f67a9f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8c46b9e-ce50-49a2-a626-4c0002388296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fecf8bb-1219-4685-87f7-64d26ae881b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82dd3158-2ce6-4c05-a0ad-e9a3960475e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83dcab61-b9e1-49c2-b60e-6424813f97a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8abe71f5-2e17-4096-836c-bd1157cea242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5bd1d1a-dd35-4463-be74-57d794c3177b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f7bd6d6-1c7d-484c-b2fc-b7133c5da95e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60a841a9-d974-4594-9908-ed2991a89020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d089b0f-0745-435f-aad7-2bd698f63d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9d8ef42-663a-4e76-861c-889deb5dbfd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 469c84de-cf57-4055-aa86-c0b7b473ca5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2afdf2-45d5-4d9d-8904-fdf1ccdf4500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 597c2bd9-4d1b-469b-99be-6492d51063b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c736952-a7a1-44c5-bf49-658ce40c0a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de1a0d77-bc13-434f-b218-0f989bf9afae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd73eb5e-74f6-4077-968b-3706ded9835a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcd866fa-06ec-4935-bd29-e6215c3a95f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f68a71f-ae65-46ce-8bb3-805cd9d20d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8de4cf1a-aba2-44a3-b013-6dc026e1849c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58872f4d-ed15-4efd-b4f5-5bcadaec617e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68cca286-8f48-4948-b3d6-6d4db075f9da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 452dfd87-223c-4065-aec3-a1e3c222fcbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5187e819-994d-4af3-b028-c13a53d0f48f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95e0c440-a0cc-4d31-a2f8-0a91427c04d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c33cd4a9-7f60-49bd-9be5-df16c9d434c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c41299-1bc1-4eee-88a4-7cfd67202ccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bc91141-2980-45df-bc0c-3951b73a3988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d58eab-3398-41e2-9cf0-12ac6a4c8595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37dce9b5-64fb-492e-b912-f6fe5fb244e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 847dcbe3-af73-465b-8e3c-d59705e79911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f001928-ada0-44ee-b44f-ef4990c63386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdec10e8-27ad-46fc-8e7a-766aa9e6f280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20829bab-4d24-4496-9903-d70af7e11a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d954ed14-6113-4b96-9acb-be9cb7602da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56febb9f-2a11-4a38-9403-d014cb5244c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 712f7a4d-065a-4a6c-9699-589d01b3ff4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60e51a5b-898a-4a0d-9c12-f029a134f756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf595ac0-df65-469a-af08-379bc11c125e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7f7b690-d602-4759-8049-f62b37c300fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 736718b4-3ff3-406a-aaef-4afd71894dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84641b39-a281-427d-ba82-7f60a1fd85ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 020d5844-a37e-460d-85e3-ee6bdd3cd89f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9e7b389-d220-435b-955c-eb6000230ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e67c2b0-300e-4b5d-8095-2da021fbdb40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7f1b36b-3c7d-4524-b1e9-24d4ed7887de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9608c37-3420-4825-8b29-6db9895febc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9093e79-2204-4da1-ba65-97e30de816f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7e350e5-0078-47b7-bf88-fb790ef02e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48a700b2-9d3a-4d01-afd0-6260746ac192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d73ecbc-9762-4a0c-a272-8c26fa8448fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dbf8a47-f147-4efb-be38-65b73504d319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0db7eae4-4172-4eb2-9160-33ae379237c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b3be316-9e2d-4872-b687-e6820fb6acca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 927d5f1b-9ef2-4f53-8bcc-9cff09a3ad97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0918c539-cc7f-4906-874e-6b81ea18fcef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcb7a6c4-edc9-4e62-ac4d-9ea839c2fa0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36102af0-a9db-4d4c-a79c-ef4234bb1d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff3c1c24-82c7-40d5-8fcf-b5c6261f28f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f33cac94-8a3c-46dc-b869-945d6a7eed3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51003409-96db-4809-9cad-2b8d27f5873e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2e880ef-b21b-408a-ae56-33c6753c93bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0df1d4d0-c3e9-4ecf-ba0e-2eedaa7de808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2db11691-95a7-436e-9514-1ee431bea1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11dfafde-4f17-4bba-93b5-aad1c6485ce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d44843a5-591d-4c8d-aaf0-120b76658c35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9772007a-f95d-453d-b81a-384e3172af31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb872abb-a597-4884-87dd-f3e1fe3f864a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 375a80bd-f0d2-4bdb-989f-66e5140142dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b972fe7d-35ca-4a3c-93d5-58d4840d555a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfaf4817-8215-4b85-9414-1b414233df37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d74502ce-6cff-4134-97eb-22f8c864ce13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb3d1f3c-4dcc-4e1e-95c5-ece9e81ebf18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 942e730d-5fb0-4eb1-a407-21c2a6e65321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92a5817d-33ec-4129-aa58-9e1f984ea339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b54e93-e5ad-4ce4-b19f-6ab3ce26013b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76a3455f-5c19-4c4e-b486-5b58a83d7f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d59f6ad-1926-451c-8c9b-cb90e77d688b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4885dac6-188b-4f3a-848c-34ce66543d21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b40b3271-98f6-427a-ade8-63f7e6ac225d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c19a537b-c84c-4f8a-a4cf-c07794cba1d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1bcbf18-547f-41c9-b6bd-4df7395854f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01813d3f-4005-4a0c-ab36-e70d2bd624ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4be83abc-8d81-498b-941f-db7a0d6394ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2c93dac-958a-4833-af59-b34ade141ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b0807ac-11b9-4661-a2da-dfa3fe0255d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74b10870-92c7-402a-be00-8b6ac0d4bdae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edb88e3b-c48e-492d-a3f2-cade36bd26d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c19805e-bb0d-49db-85f7-826b588fe9b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b9ad30-1f7e-4a2d-bf68-c4a95b4086a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfbbe046-fc3f-429e-9547-afbbda499d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be09891b-9e65-4151-8689-cc4ac6a54423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71811c05-1c3e-41c8-893c-6c76b6a99c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4ba0377-0a86-4602-8275-160a8641caf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76137fad-7d3d-41da-962b-874bbac7f5b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 794cf5b1-5c06-4ee5-85fb-3a0a3ff5ba1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8332a9f5-4e58-47b5-8db5-f130fa12526c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a67f4467-8d55-454d-b1b6-21f82f179680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65c22440-dea9-49db-8541-bfa366fd6e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15b11311-6c02-4506-a1f5-0c48473277a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d4e54c1-bf21-4142-86a7-879122c4d637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7deb0e4d-85a3-4e32-8819-30112ae0218c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b7544b5-4723-4eaa-a33c-5386f2f4e5cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89dca38d-776a-4982-9f74-58c638881497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5450aec0-e461-495f-82e3-ed73eabed761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29e2517e-1b78-4c50-b2ac-39352c44e832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b212dcf-293e-405f-b24a-99c02cc17fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e93edb95-3c95-493a-987b-5cc1eee14465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53244510-b4a4-4876-93ef-6f92ec3c66a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 383f75b2-b18b-4010-93fb-f1d59ba962fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8600d3d8-1b41-47e7-9d53-ef75b410533a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fc75e4d-91e8-419b-98b4-408b1803e1b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00c62b8d-1d90-421b-ae70-32a3f6916ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d56bf8ff-8d09-469c-bb41-37761da7e927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 840b8751-2f8f-482a-9156-4b29b4438ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8566e78c-755f-4fec-aa9e-cc552ef72292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32839dfa-0970-46c5-8a52-7bff2dd22f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7a1fb17-5747-4d3a-abce-ad022a2cfe66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db8fa91e-695b-4d93-984b-235334e3bea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4357033f-01b5-4b5e-8fb8-0e47389a5755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8821b5c-5e7e-47fc-a5e9-40d9fc82f3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ba6031c-82ca-415a-9473-fbc2fc7295fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab5bad48-4613-44de-ab13-ff6c8aeaaed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d281fa3-eb39-44d5-b4ca-9bfbd6474710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbf6a759-49d8-482b-9004-87c9b1ba5a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79cc5229-1536-4699-bf15-7e9562d00100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8076634e-ee4c-407b-a37e-29298a75dd4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3957d5b0-b967-4676-85d0-a9db371a9aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50fe47d8-b63b-48a8-b989-8947149acae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d66c8f87-e254-4e68-8942-54c3c15137db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe9bdbd9-dfd8-465b-b821-57f9479f039d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5798a42c-a7df-43d7-b2e0-168dac3f0bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e8cfda7-41ff-406f-8b77-f3915867f1af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b597bff8-b585-4cdd-9e90-3ec9840fc4d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 025d3460-46f4-4417-b4cd-f49da2bd3272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3fb9dd2-2844-425b-9b5f-928996f8d702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fd83f0f-4820-4b5d-884e-1443edc990d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0907a072-6ca7-4f2f-a211-42a2a5e62d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b534fdd5-c9f7-4ed8-a6d9-8f5472f2143c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6c21034-2cae-4679-82d7-328648e75917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab2ba57c-43be-41c9-8180-6fe84a5c4000
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_28
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/test_labels.txt

📊 Raw data loaded:
   Train: X=(1617, 24), y=(1617,)
   Test:  X=(405, 24), y=(405,)

⚠️  Limiting training data: 1617 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  396 samples, 5 features
✅ Client client_28 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.2010, RMSE: 0.4483, MAE: 0.3744, R²: -1.4887

============================================================
🔄 Round 5 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1146, val=0.0826 (↓), lr=0.001000
   • Epoch   2/100: train=0.0867, val=0.0944, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0874, val=0.0998, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0857, val=0.0941, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0853, val=0.0952, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0842, val=0.0931, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 5 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0923, RMSE=0.3038, R²=-0.0903
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0045
============================================================


============================================================
🔄 Round 6 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1649, val=0.1246 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1003, val=0.0933 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0850, val=0.0924 (↓), lr=0.000250
   • Epoch   4/100: train=0.0842, val=0.0925, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0840, val=0.0928, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0837, val=0.0929, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 6 Summary - Client client_28
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0021
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0043
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.1880, RMSE: 0.4336, MAE: 0.3613, R²: -1.3282

============================================================
🔄 Round 7 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1775, val=0.1552 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1527, val=0.1330 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1313, val=0.1146 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1133, val=0.0991 (↓), lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   ✓ Epoch   5/100: train=0.0991, val=0.0884 (↓), lr=0.000031
   • Epoch  11/100: train=0.0862, val=0.0832, patience=3/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016
   📉 Epoch 21: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0860, val=0.0832, patience=13/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 7 Summary - Client client_28
   Epochs: 23/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0037
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0054
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.1742, RMSE: 0.4174, MAE: 0.3475, R²: -1.1571

============================================================
🔄 Round 12 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1582, val=0.1710 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1554, val=0.1678 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1524, val=0.1648 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1496, val=0.1620 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1470, val=0.1595 (↓), lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1385, val=0.1514 (↓), lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.1318, val=0.1448, patience=1/15, lr=0.000002
   📉 Epoch 22: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.1291, val=0.1422 (↓), lr=0.000001
   • Epoch  41/100: train=0.1269, val=0.1400, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1248, val=0.1378, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1228, val=0.1356 (↓), lr=0.000001
   • Epoch  71/100: train=0.1207, val=0.1336, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1188, val=0.1315, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1169, val=0.1295 (↓), lr=0.000001

============================================================
📊 Round 12 Summary - Client client_28
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.1148, RMSE=0.3388, R²=-0.3727
   Val:   Loss=0.1277, RMSE=0.3574, R²=-0.3536
============================================================


============================================================
🔄 Round 13 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1591, val=0.1427 (↓), lr=0.000001
   • Epoch   2/100: train=0.1588, val=0.1424, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1585, val=0.1421 (↓), lr=0.000001
   • Epoch   4/100: train=0.1582, val=0.1418, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1580, val=0.1415 (↓), lr=0.000001
   • Epoch  11/100: train=0.1564, val=0.1400, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1540, val=0.1376 (↓), lr=0.000001
   • Epoch  31/100: train=0.1518, val=0.1354, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1497, val=0.1333, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1476, val=0.1312 (↓), lr=0.000001
   • Epoch  61/100: train=0.1455, val=0.1291, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1434, val=0.1270, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1413, val=0.1249 (↓), lr=0.000001
   • Epoch  91/100: train=0.1392, val=0.1228, patience=1/15, lr=0.000001

============================================================
📊 Round 13 Summary - Client client_28
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1375, RMSE=0.3708, R²=-0.5486
   Val:   Loss=0.1209, RMSE=0.3478, R²=-0.6403
============================================================


============================================================
🔄 Round 15 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1400, val=0.1400 (↓), lr=0.000001
   • Epoch   2/100: train=0.1398, val=0.1398, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1395, val=0.1396, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1393, val=0.1394 (↓), lr=0.000001
   • Epoch   5/100: train=0.1391, val=0.1392, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1378, val=0.1380, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1356, val=0.1361, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1334, val=0.1341 (↓), lr=0.000001
   • Epoch  41/100: train=0.1312, val=0.1322, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1290, val=0.1303, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1269, val=0.1284 (↓), lr=0.000001
   • Epoch  71/100: train=0.1247, val=0.1265, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1226, val=0.1246, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1204, val=0.1228 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_28
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1186, RMSE=0.3444, R²=-0.4242
   Val:   Loss=0.1211, RMSE=0.3480, R²=-0.2724
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1323, RMSE: 0.3637, MAE: 0.3039, R²: -0.6381

============================================================
🔄 Round 17 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1273, val=0.1441 (↓), lr=0.000001
   • Epoch   2/100: train=0.1271, val=0.1439, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1270, val=0.1436, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1268, val=0.1434 (↓), lr=0.000001
   • Epoch   5/100: train=0.1266, val=0.1432, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1255, val=0.1419, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1236, val=0.1397, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1217, val=0.1374 (↓), lr=0.000001
   • Epoch  41/100: train=0.1199, val=0.1352, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1180, val=0.1330, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1161, val=0.1308 (↓), lr=0.000001
   • Epoch  71/100: train=0.1143, val=0.1285, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1125, val=0.1263, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1107, val=0.1241 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_28
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1094, RMSE=0.3308, R²=-0.2857
   Val:   Loss=0.1222, RMSE=0.3495, R²=-0.3933
============================================================


============================================================
🔄 Round 19 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1041, val=0.1040 (↓), lr=0.000001
   • Epoch   2/100: train=0.1040, val=0.1038, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1038, val=0.1037, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1036, val=0.1035 (↓), lr=0.000001
   • Epoch   5/100: train=0.1035, val=0.1033, patience=1/15, lr=0.000001
   ✓ Epoch  11/100: train=0.1025, val=0.1023 (↓), lr=0.000001
   • Epoch  21/100: train=0.1010, val=0.1007, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0995, val=0.0992 (↓), lr=0.000001
   • Epoch  41/100: train=0.0981, val=0.0977, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0968, val=0.0963 (↓), lr=0.000001
   • Epoch  61/100: train=0.0955, val=0.0950, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.0943, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0932, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0922, val=0.0915, patience=4/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_28
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3020, R²=-0.0606
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0666
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0922, RMSE: 0.3037, MAE: 0.2596, R²: -0.1423

============================================================
🔄 Round 20 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0926, val=0.1009 (↓), lr=0.000001
   • Epoch   2/100: train=0.0925, val=0.1008, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0924, val=0.1007, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0922, val=0.1006, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0921, val=0.1005, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.1000, patience=4/15, lr=0.000001
   • Epoch  21/100: train=0.0902, val=0.0991, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0891, val=0.0984, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0882, val=0.0977, patience=7/15, lr=0.000001
   • Epoch  51/100: train=0.0874, val=0.0972, patience=9/15, lr=0.000001
   • Epoch  61/100: train=0.0867, val=0.0967, patience=9/15, lr=0.000001
   • Epoch  71/100: train=0.0860, val=0.0963, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 20 Summary - Client client_28
   Epochs: 79/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0351
   Val:   Loss=0.0966, RMSE=0.3108, R²=-0.0156
============================================================


============================================================
🔄 Round 21 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0832, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0886, val=0.0828, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0882, val=0.0825, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0878, val=0.0822, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 21 Summary - Client client_28
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0179
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0116
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2486, R²: -0.0280

============================================================
🔄 Round 23 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 23 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0142
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0027
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0245

============================================================
🔄 Round 25 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 25 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0053
   Val:   Loss=0.0970, RMSE=0.3115, R²=-0.0238
============================================================


============================================================
🔄 Round 26 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 26 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0083
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0021
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2477, R²: -0.0184

📊 Round 26 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2475, R²: -0.0165

============================================================
🔄 Round 30 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 30 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0039
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0097
============================================================


============================================================
🔄 Round 32 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 32 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0012
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0229
============================================================


============================================================
🔄 Round 35 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 35 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0122
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0268
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: -0.0144

============================================================
🔄 Round 36 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 36 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0049
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0028
============================================================


============================================================
🔄 Round 37 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 37 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0035
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0055
============================================================


============================================================
🔄 Round 39 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 39 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0042
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0021
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: -0.0133

============================================================
🔄 Round 40 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 40 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0037
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0081
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2471, R²: -0.0131

============================================================
🔄 Round 41 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 41 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0030
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0064
============================================================


============================================================
🔄 Round 42 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 42 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0042
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0059
============================================================


============================================================
🔄 Round 43 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 43 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0015
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0213
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2471, R²: -0.0125

============================================================
🔄 Round 46 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 46 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0022
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0072
============================================================


============================================================
🔄 Round 48 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 48 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0024
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0067
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2470, R²: -0.0121

============================================================
🔄 Round 49 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 49 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0084
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0101
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2470, R²: -0.0119

📊 Round 49 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2470, R²: -0.0118

============================================================
🔄 Round 53 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 53 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0013
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0105
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2470, R²: -0.0118

============================================================
🔄 Round 54 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0987)

============================================================
📊 Round 54 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0010
   Val:   Loss=0.0987, RMSE=0.3142, R²=-0.0250
============================================================


============================================================
🔄 Round 55 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 55 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0035
   Val:   Loss=0.0955, RMSE=0.3091, R²=-0.0014
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2470, R²: -0.0117

============================================================
🔄 Round 57 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 57 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0010
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0097
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2470, R²: -0.0118

============================================================
🔄 Round 58 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 58 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0078
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0085
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2470, R²: -0.0115

============================================================
🔄 Round 60 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 60 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0012
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0236
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2470, R²: -0.0115

============================================================
🔄 Round 61 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 61 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0055
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0019
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2470, R²: -0.0113

============================================================
🔄 Round 63 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 63 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0037
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0013
============================================================


============================================================
🔄 Round 66 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 66 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0021
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0100
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2469, R²: -0.0110

============================================================
🔄 Round 67 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0983, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0983, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0982, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0983)

============================================================
📊 Round 67 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0001
   Val:   Loss=0.0983, RMSE=0.3135, R²=-0.0315
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2469, R²: -0.0109

📊 Round 67 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2469, R²: -0.0107

============================================================
🔄 Round 72 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 72 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0025
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0031
============================================================


============================================================
🔄 Round 73 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 73 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0037
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0026
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2469, R²: -0.0105

📊 Round 73 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2469, R²: -0.0104

============================================================
🔄 Round 77 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 77 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0032
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0001
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2468, R²: -0.0101

📊 Round 77 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2468, R²: -0.0099

============================================================
🔄 Round 81 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 81 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0010
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0108
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2468, R²: -0.0100

============================================================
🔄 Round 82 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 82 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0015
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0074
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2468, R²: -0.0099

📊 Round 82 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2468, R²: -0.0096

📊 Round 82 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2468, R²: -0.0095

📊 Round 82 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2468, R²: -0.0094

============================================================
🔄 Round 94 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 94 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0013
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0187
============================================================


============================================================
🔄 Round 95 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 95 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0016
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0049
============================================================


============================================================
🔄 Round 96 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 96 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0027
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0010
============================================================


============================================================
🔄 Round 97 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 97 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0034
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0003
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2468, R²: -0.0094

============================================================
🔄 Round 99 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 99 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0047
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0063
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2468, R²: -0.0093

============================================================
🔄 Round 100 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 100 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0010
   Val:   Loss=0.0912, RMSE=0.3021, R²=-0.0092
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2467, R²: -0.0090

📊 Round 100 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2467, R²: -0.0089

============================================================
🔄 Round 107 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 107 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0036
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0043
============================================================


============================================================
🔄 Round 108 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 108 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0060
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0072
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2467, R²: -0.0087

📊 Round 108 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2467, R²: -0.0087

============================================================
🔄 Round 116 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 116 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0004
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0231
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2467, R²: -0.0087

============================================================
🔄 Round 120 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 120 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0016
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0040
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2467, R²: -0.0084

============================================================
🔄 Round 127 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 127 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0031
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0058
============================================================


============================================================
🔄 Round 129 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 129 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0024
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0002
============================================================


============================================================
🔄 Round 131 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0992 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0992, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0993, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0992)

============================================================
📊 Round 131 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0022
   Val:   Loss=0.0992, RMSE=0.3150, R²=-0.0011
============================================================


============================================================
🔄 Round 132 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 132 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0010
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0065
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2467, R²: -0.0082

============================================================
🔄 Round 133 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 133 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0040
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0335
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2467, R²: -0.0081

============================================================
🔄 Round 137 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 137 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0011
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0050
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2466, R²: -0.0079

📊 Round 137 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2466, R²: -0.0078

============================================================
🔄 Round 141 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 141 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0011
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0047
============================================================


============================================================
🔄 Round 146 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 146 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0022
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0010
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2467, R²: -0.0082

============================================================
🔄 Round 148 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 148 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0032
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0014
============================================================


============================================================
🔄 Round 155 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 155 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0026
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0004
============================================================


============================================================
🔄 Round 156 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 156 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0031
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0025
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2467, R²: -0.0081

============================================================
🔄 Round 157 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 157 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0029
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0025
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2467, R²: -0.0082

📊 Round 157 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2467, R²: -0.0081

📊 Round 157 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2467, R²: -0.0080

============================================================
🔄 Round 161 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 161 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0033
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0025
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2467, R²: -0.0081

📊 Round 161 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2467, R²: -0.0080

============================================================
🔄 Round 164 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 164 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0023
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0027
============================================================


============================================================
🔄 Round 165 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 165 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0018
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0088
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2466, R²: -0.0077

📊 Round 165 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2466, R²: -0.0077

============================================================
🔄 Round 170 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 170 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0010
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.0206
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2466, R²: -0.0076

============================================================
🔄 Round 171 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 171 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0011
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0171
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2466, R²: -0.0076

📊 Round 171 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2466, R²: -0.0075

📊 Round 171 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2466, R²: -0.0075

📊 Round 171 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2466, R²: -0.0077

============================================================
🔄 Round 178 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 178 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0025
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0001
============================================================


============================================================
🔄 Round 180 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 180 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0033
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0019
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2466, R²: -0.0076

============================================================
🔄 Round 182 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 182 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0033
   Val:   Loss=0.0962, RMSE=0.3102, R²=0.0023
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2466, R²: -0.0077

📊 Round 182 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2466, R²: -0.0077

============================================================
🔄 Round 189 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 189 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0021
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0093
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2466, R²: -0.0076

📊 Round 189 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2466, R²: -0.0075

📊 Round 189 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2466, R²: -0.0075

============================================================
🔄 Round 193 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 193 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0021
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0015
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2466, R²: -0.0074

============================================================
🔄 Round 194 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 194 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0013
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0095
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2466, R²: -0.0074

📊 Round 194 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2466, R²: -0.0073

============================================================
🔄 Round 197 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 197 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0024
   Val:   Loss=0.0948, RMSE=0.3078, R²=-0.0011
============================================================


============================================================
🔄 Round 198 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 198 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0031
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0081
============================================================


============================================================
🔄 Round 199 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 199 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0008
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0062
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2466, R²: -0.0076

📊 Round 199 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2466, R²: -0.0075

📊 Round 199 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2466, R²: -0.0075

============================================================
🔄 Round 202 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 202 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0028
   Val:   Loss=0.0939, RMSE=0.3064, R²=0.0013
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2466, R²: -0.0074

============================================================
🔄 Round 204 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 204 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0016
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0041
============================================================


============================================================
🔄 Round 205 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 205 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0019
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0060
============================================================


============================================================
🔄 Round 206 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 206 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0019
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0022
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2466, R²: -0.0073

============================================================
🔄 Round 208 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 208 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0005
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0205
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2466, R²: -0.0074

============================================================
🔄 Round 211 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 211 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0042
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0007
============================================================


❌ Client client_28 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
