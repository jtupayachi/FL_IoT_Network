[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9212c584-758a-4019-9612-ae27be21e2f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef4741be-7086-464b-a4cf-ebe3cffeba9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae8b087c-c7c7-499b-9407-3c528b7b9c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2425c57-beb9-4656-83fa-43beedb722fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 118b4570-eafc-4028-8e2f-829d1d00876e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b308f9f9-b89f-40b1-81ff-5ff552f45312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6552cfc1-0527-420d-ae74-6bc211924ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf8d122d-f9ca-4551-a46c-2771f4efa74a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 674f9c14-7ded-4f17-af28-eec90b777761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a5676b8-56d1-4d52-8c74-2dc6885ade35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 315993c3-5af8-4431-a36a-cb1375ae682c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 553c1ba1-baba-4026-8a08-f6276c362488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3b0fde6-bebd-4ff6-826a-06d2699ac8e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f0fef17-df62-441b-aa03-b8638461748a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c403e18f-01b4-4fd2-a36d-de95110e1379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06471544-769e-4d83-bd2f-29a3bd987e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2d3d5ff-00ea-4291-bf11-6aee82f0f61f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee43fdcb-5d0f-40b8-9f41-f3b59fe678bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 363dfa2c-df52-4bb6-b356-8694993fdf51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a00fb35-268f-4808-8b10-fed1e43dcee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message add30e5c-8aff-4872-ab7d-1c32b2a7174f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54e891bd-7e19-4c8d-b659-94f118e6a189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message add254c9-fd2b-4521-8ddc-c3e3953449dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37d93eb4-088d-4ab1-84e2-2625ce15b7a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1817783f-7c1a-4bbb-ac20-de0f2b485061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d350799-ba75-42b1-8d37-9519b4be24c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4214993e-5ecf-438c-a918-e6e8c1d0ee0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 225dbd70-0e83-4d41-90db-132cb415e254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb3730f7-fcf2-4360-8ec5-4790bdce37fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71870dfd-ad9b-4c60-a580-ffd3ece0f4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef2ed66e-0dce-4058-bf39-909c1aeb4a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce1fe483-ba52-4d5a-baed-e63f52f3fbc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c21a36d-c227-489c-be22-a5ba0e3dc9e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5a83482-cbba-4f75-b1ef-7b1b9b00af7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4006e156-5a9f-4921-a406-112b6c44cd3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60ae751b-03b2-4c1c-8d30-11ee78a79c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 599eb48e-cd74-44bb-9ab7-39abbce5822e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3724c95-61f2-44fd-bbf6-1835814b218d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84b2c141-f1e9-4aeb-9a51-8d2f3db04be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e9d2a24-4b2c-4acd-bc78-021c7d0285b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9049532-bf52-497b-b55a-a0b102a1af93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1fc35f6-f2e7-4f2f-b0df-a1ec70784bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e048f9fe-c84b-4214-9f6c-8cd489e024a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1463c33-e0a1-4af0-a8b5-5a6740bf5985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09427f5f-ad6e-4c92-8d61-3897d5af490a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ab67c9-cd75-4d29-9ff1-3f30c3fb8b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf3bb0f0-8dde-49bf-bf3f-d988123bc6b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60431f1f-7523-4561-9324-1127bc1c26a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e130b512-1933-4bc3-afe9-eae5ff2ec78d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6628b56a-adab-48d2-b8cf-f174eccf1366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 822b2ca9-3edb-4810-96ce-8d2408df03f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 974b8f4e-431e-42a7-a769-0b8accad72a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fd5b6b0-50a6-42f8-9af4-ca4842180bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 209e388d-4cf4-4220-8bd8-627df6fa30f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18a56e27-7f95-4e8e-ac45-a4517658266a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8497a56c-d899-41cd-90c0-192d984a0855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ec733e3-98cf-400b-a82f-48537a3bb73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 576623ae-a6d0-43c8-9194-2f831ec3086d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccb1e3b3-2cab-4250-a821-653daecf4c1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f11d7bcc-9616-42bf-80e7-4b781b253325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 444682fb-aff6-45a7-aad4-0d9a880ce4d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a64510c4-2567-4aa8-89ce-b341dac68e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dae2814-6757-4b6c-a1b7-93796fbcca85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b9ba74c-fbd0-4c65-8a2b-92fa30ecba99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51df5862-99d2-4a05-90cd-5af06a5f7b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 614efc83-22c7-4a25-a357-a5e683004d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aba66ab-ae6d-4252-9487-b30b06464acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc9eb755-203f-4445-b877-562bcbcb7817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 114829ff-2384-4408-9772-63ececda5654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a09428c-3717-4d0a-8ec6-9fac5e4d2939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f7c9521-50fe-4a31-8054-a86f66c6b8b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5754688-3f5b-4c68-8fb1-a14a0ee00568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c797a7da-ee85-4d92-916e-c1ae8789b715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d3ee39d-d8a9-4853-8e2c-eff04dcac3fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f154cbf7-1e1a-44cc-b957-36cada400d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abce58a8-3b59-4f8e-950f-ad362b4dc9c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc9f6a4d-54ce-477e-ae0f-8764be6cf6fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d946a93-6497-43ca-908f-9c367aedad2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccf42c10-37b2-423a-b6e1-2a21bcd41dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d1d7956-026a-4518-ab90-7698984c41b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f1ad968-8c3c-46a4-b14d-28e8cdbbbbe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18affd2f-2ebb-45bb-8f07-0a8daececcd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99d748b8-7b58-4729-84d7-7b982ab3f6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b28d3e0-a9c9-4aed-8219-f108c79a5b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c313b6b-e824-41a8-ad58-6c9b172fd9d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c0c6520-4b14-40d5-91c1-5d7f13c6918d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43230f62-d673-4867-b5cf-03f5a0f82057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42a5d068-870d-4243-8ea4-dfc123cd0137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3108454e-fc68-4ff6-b227-2e43d8aceb43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b27cf377-d01f-4c8b-8c8b-acda5b78a32a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72d5a726-3200-4a5d-8ba7-68676d99cdac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cf91255-8089-470c-9e36-7e95dbded8d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63ea8fab-e6d6-4ee9-98d1-960910e9dc80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5060dcf8-a005-450e-9f5d-c866babb2e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7255061-0067-44bf-a1bd-16665c19b06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92792e37-2d94-48c2-b801-94ede00b2c0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6467ab9-5c6b-4cb7-89d8-a9d6f5df8a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dd2b415-1473-44a5-a596-b4235b83b5ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e9e2e94-d1e2-4807-ad83-1d27a765a80e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe89f529-6d77-448c-90a2-9bc297a45585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55a144db-a81a-430b-919b-241eb750abf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6295617-e38d-4e92-a494-15b20ee6b35e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 537318ce-0618-49ad-aa6e-66d26aba8351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37f78f2f-e872-481c-8d12-e96ee752d828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25251681-a4fb-46cb-9173-d3bbbf522bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 497690bd-d7b3-4ffa-b4c3-6fd311d6c4c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34d4354c-92d7-4e24-98fd-e2828489ec49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3724778-4b5e-4892-9baf-e53f0361736d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4188d0f-18e0-417e-b329-71615818523c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b639aaf1-c8b6-4744-b44f-4c8623691b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 744c37c4-fdea-4699-9155-7518f29b4704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff37fb26-b8e2-4e94-86fa-66715f3dafd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad9ff4c4-b567-47cd-8f7b-2d7253d218e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06172920-6f88-45e8-a0f0-3d7e97855964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b7efec4-46b2-4774-bb23-3baef182dd23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63a7994b-c545-4e15-ae1e-2643ae19b0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e202d0a-7fd3-4582-ac42-afc1150a743d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f809c77-40e8-4356-9368-b971dcdc2061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14eecdcd-a630-4059-adf5-de1e021663e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cea9f83-f0ca-4ea6-bd22-dce0d67058cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9446a1a6-7109-4b17-b4a4-21fef1ed5f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9041a99b-598c-4af2-a930-ce9eae7dbf6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8579df61-32a7-4420-83e7-9130c7d036f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 229f61d1-0aff-4d3d-acae-0246d59e2f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caefe7d6-5046-4950-9b65-0f153a99c28a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c7e79fd-5e42-4b12-be2e-78ef6f2e8506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66213c29-15ea-4b17-bc98-6d27fe62e6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7f24048-b7ae-4407-b8fd-593c370b5b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0561e5fd-653e-40b5-8dbe-dc1a3f887cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70782f6d-dbca-4bf2-80f3-4fce3bfaef10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7518a370-e967-421d-8250-b406022a61f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37d87a74-538b-422a-9e14-01a4220d2f0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8365295-a632-459b-bd77-6ac01252ddb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7321026-27b7-4f14-8859-b89578cc8d51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16c7a585-4c65-4ce1-a79e-c51e1b0155a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caf6b046-8c2b-40d3-aed8-6a9de6d5cf0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4415e651-a397-470f-b91d-abefe63a69ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c399569-40c6-4723-98d2-10ed6b807512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 414190d4-32d6-4f8c-8ec7-15744a5eb965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4599cb92-96e0-4a58-8d22-1f47cfc6e9a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 462d924f-f089-40ab-83a6-792d59a9d1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bd612ba-40e0-48c8-b109-00d952406b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d70878d-d6ab-4257-8ba1-a98ca2b08f6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72d4ff93-34b1-4fe1-b7dd-a0d3f03e04cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 561e5c45-b691-47fe-b3dd-ebafe52072ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab54a5ce-066b-4e0d-bd05-b84e21ae2df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4275315-3e6f-44cc-86f7-5660109e6965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed3d8aeb-f9c4-4ef0-a9a7-4798098bf038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e149b471-393a-43a5-a250-4adc58e778ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5408cdaa-1432-4c88-bad9-b34021d965a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a98eed64-8a02-40df-8944-6922562a15d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1169862b-afc1-453f-8f39-85c73f8123a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdde1ee5-afaf-444a-982c-3847c759dfd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bb735b5-78a4-4436-af33-40870aab2272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab3502c5-d211-4b17-9219-185aea8fee47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 031f91a5-a5fd-4e91-a05b-d8d479bd94d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f45d9e08-fc9a-4c77-8260-c71f45971bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3e33ede-f251-4f1d-910a-bbe4646cbf34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a940bfc3-7ecb-435b-840d-8e17edab5141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c69493d1-2588-4499-9faf-7fab3c4f8224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d58151b-39a1-44a6-8113-58e2f75f66b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21e1067d-e443-4982-9d29-488da79d6be5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56bd473f-422d-4e29-abf2-8bc1997bcbf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c8e3135-dc5c-449a-b669-e2908d81acc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c46288ff-79a0-4070-bfeb-1d6dc94c8e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c2f2247-3640-4674-94b2-4b3d0c013abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f68d4bf7-1dae-4ba9-b9e8-708dd2ff787e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6055ab2-72ec-42fe-b0d6-b6a47b65ca8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6866d8c3-3f29-4df5-89bb-c4a365505bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62c1c599-a2dd-4f87-b803-d44e4e95d16b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_29
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/test_labels.txt

📊 Raw data loaded:
   Train: X=(2503, 24), y=(2503,)
   Test:  X=(626, 24), y=(626,)

⚠️  Limiting training data: 2503 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  617 samples, 5 features
✅ Client client_29 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1105, val=0.0862 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0902, val=0.0796 (↓), lr=0.001000
   • Epoch   3/100: train=0.0844, val=0.0796, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0837, val=0.0799, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0842, val=0.0799, patience=3/15, lr=0.001000
   • Epoch  11/100: train=0.0825, val=0.0791, patience=9/15, lr=0.001000
   📉 Epoch 17: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 5 Summary - Client client_29
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0113
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0070
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1670, RMSE: 0.4087, MAE: 0.3263, R²: -1.0383

============================================================
🔄 Round 8 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1287, val=0.0782 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0862, val=0.0776 (↓), lr=0.000500
   • Epoch   3/100: train=0.0847, val=0.0774, patience=1/15, lr=0.000500
   ✓ Epoch   4/100: train=0.0843, val=0.0770 (↓), lr=0.000500
   • Epoch   5/100: train=0.0841, val=0.0768, patience=1/15, lr=0.000500
   • Epoch  11/100: train=0.0836, val=0.0760, patience=3/15, lr=0.000500
   • Epoch  21/100: train=0.0827, val=0.0751, patience=2/15, lr=0.000500
   • Epoch  31/100: train=0.0813, val=0.0747, patience=2/15, lr=0.000500
   📉 Epoch 39: LR reduced 0.000500 → 0.000250
   • Epoch  41/100: train=0.0792, val=0.0749, patience=12/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 8 Summary - Client client_29
   Epochs: 44/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0420
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0379
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1547, RMSE: 0.3933, MAE: 0.3143, R²: -0.8876

============================================================
🔄 Round 10 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1397, val=0.0873 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0871, val=0.0846 (↓), lr=0.000250
   📉 Epoch 3: LR reduced 0.000250 → 0.000125
   ✓ Epoch   3/100: train=0.0848, val=0.0787 (↓), lr=0.000125
   • Epoch   4/100: train=0.0838, val=0.0793, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0836, val=0.0796, patience=2/15, lr=0.000125
   📉 Epoch 11: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0831, val=0.0797, patience=8/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 10 Summary - Client client_29
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0035
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0046
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.1494, RMSE: 0.3865, MAE: 0.3093, R²: -0.8231

============================================================
🔄 Round 11 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000063 → 0.000031
   ✓ Epoch   1/100: train=0.1575, val=0.1287 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.1365, val=0.1166 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.1236, val=0.1063 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.1125, val=0.0976 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.1030, val=0.0907 (↓), lr=0.000031
   📉 Epoch 9: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0839, val=0.0814, patience=3/15, lr=0.000016
   📉 Epoch 17: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0836, val=0.0815, patience=13/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 11 Summary - Client client_29
   Epochs: 23/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0170
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0122
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1455, RMSE: 0.3814, MAE: 0.3056, R²: -0.7752

📊 Round 11 Test Metrics:
   Loss: 0.1354, RMSE: 0.3680, MAE: 0.2960, R²: -0.6524

============================================================
🔄 Round 15 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1375, val=0.1329 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   ✓ Epoch   2/100: train=0.1345, val=0.1302 (↓), lr=0.000004
   ✓ Epoch   3/100: train=0.1320, val=0.1289 (↓), lr=0.000004
   ✓ Epoch   4/100: train=0.1305, val=0.1277 (↓), lr=0.000004
   ✓ Epoch   5/100: train=0.1290, val=0.1265 (↓), lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.1213, val=0.1207, patience=1/15, lr=0.000002
   📉 Epoch 18: LR reduced 0.000002 → 0.000001
   ✓ Epoch  21/100: train=0.1163, val=0.1169 (↓), lr=0.000001
   • Epoch  31/100: train=0.1138, val=0.1149, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1115, val=0.1132, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.1093, val=0.1115, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1072, val=0.1099 (↓), lr=0.000001
   • Epoch  71/100: train=0.1052, val=0.1084, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1032, val=0.1070 (↓), lr=0.000001
   • Epoch  91/100: train=0.1014, val=0.1057, patience=2/15, lr=0.000001

============================================================
📊 Round 15 Summary - Client client_29
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0998, RMSE=0.3159, R²=-0.2477
   Val:   Loss=0.1045, RMSE=0.3233, R²=-0.0994
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1218, RMSE: 0.3490, MAE: 0.2828, R²: -0.4866

📊 Round 15 Test Metrics:
   Loss: 0.1052, RMSE: 0.3244, MAE: 0.2669, R²: -0.2843

============================================================
🔄 Round 18 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1167, val=0.1037 (↓), lr=0.000001
   • Epoch   2/100: train=0.1165, val=0.1035, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1163, val=0.1033, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1160, val=0.1031 (↓), lr=0.000001
   • Epoch   5/100: train=0.1158, val=0.1029, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1146, val=0.1016, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1126, val=0.0996, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1107, val=0.0977 (↓), lr=0.000001
   • Epoch  41/100: train=0.1088, val=0.0959, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1070, val=0.0941, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1053, val=0.0924 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1036, val=0.0907 (↓), lr=0.000001
   • Epoch  81/100: train=0.1020, val=0.0891, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1004, val=0.0875 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_29
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0988, RMSE=0.3144, R²=-0.1516
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.1786
============================================================


============================================================
🔄 Round 20 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0925, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0924, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0923, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0922, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0921, val=0.0879, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0914, val=0.0873 (↓), lr=0.000001
   • Epoch  21/100: train=0.0904, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  31/100: train=0.0894, val=0.0855, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0886, val=0.0847, patience=5/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0878, val=0.0840 (↓), lr=0.000001
   • Epoch  61/100: train=0.0871, val=0.0833, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.0866, val=0.0828, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0860, val=0.0824, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0856, val=0.0820, patience=11/15, lr=0.000001

============================================================
📊 Round 20 Summary - Client client_29
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0139
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0126
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2491, R²: -0.0107

============================================================
🔄 Round 21 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 21 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0453
   Val:   Loss=0.0897, RMSE=0.2994, R²=0.0031
============================================================


============================================================
🔄 Round 22 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 22 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0265
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0084
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0008

📊 Round 22 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2493, R²: 0.0001

============================================================
🔄 Round 25 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 25 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0035
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0297
============================================================


============================================================
🔄 Round 26 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 26 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0032
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0155
============================================================


============================================================
🔄 Round 28 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 28 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0050
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0036
============================================================


============================================================
🔄 Round 29 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 29 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0021
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0133
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2494, R²: 0.0002

📊 Round 29 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2494, R²: 0.0001

============================================================
🔄 Round 31 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 31 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0017
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0190
============================================================


============================================================
🔄 Round 32 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 32 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0056
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0032
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2495, R²: 0.0001

📊 Round 32 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2495, R²: -0.0000

📊 Round 32 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2495, R²: -0.0001

📊 Round 32 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2495, R²: -0.0002

============================================================
🔄 Round 38 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 38 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0008
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0200
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2496, R²: -0.0003

============================================================
🔄 Round 43 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 43 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0021
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0101
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2496, R²: -0.0004

============================================================
🔄 Round 45 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 45 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0026
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0008
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2496, R²: -0.0004

============================================================
🔄 Round 46 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 46 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0015
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0032
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2496, R²: -0.0004

📊 Round 46 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2496, R²: -0.0005

============================================================
🔄 Round 49 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 49 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0001
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0095
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2496, R²: -0.0006

============================================================
🔄 Round 50 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 50 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0032
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0066
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2496, R²: -0.0006

📊 Round 50 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2496, R²: -0.0006

📊 Round 50 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2496, R²: -0.0006

============================================================
🔄 Round 56 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 56 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0021
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0000
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2496, R²: -0.0006

============================================================
🔄 Round 57 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 57 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0018
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0025
============================================================


============================================================
🔄 Round 58 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 58 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0064
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0203
============================================================


============================================================
🔄 Round 61 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 61 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0046
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0001
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2497, R²: -0.0007

============================================================
🔄 Round 65 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 65 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0021
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0038
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2497, R²: -0.0007

============================================================
🔄 Round 69 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 69 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0024
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0014
============================================================


============================================================
🔄 Round 70 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 70 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0013
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0010
============================================================


============================================================
🔄 Round 71 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 71 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0030
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0008
============================================================


============================================================
🔄 Round 73 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 73 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0001
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0121
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2497, R²: -0.0010

============================================================
🔄 Round 77 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 77 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0015
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0013
============================================================


============================================================
🔄 Round 78 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 78 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0014
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0004
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2497, R²: -0.0011

📊 Round 78 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2497, R²: -0.0011

============================================================
🔄 Round 81 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 81 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0005
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0087
============================================================


============================================================
🔄 Round 85 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 85 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0011
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0082
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2497, R²: -0.0012

============================================================
🔄 Round 91 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 91 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0029
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0066
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2498, R²: -0.0012

============================================================
🔄 Round 92 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 92 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0021
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0032
============================================================


============================================================
🔄 Round 93 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 93 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0008
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0007
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0013

============================================================
🔄 Round 94 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 94 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0010
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0241
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0013

============================================================
🔄 Round 97 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 97 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0005
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0071
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2497, R²: -0.0012

============================================================
🔄 Round 98 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 98 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0008
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0020
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0013

📊 Round 98 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0014

📊 Round 98 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0014

============================================================
🔄 Round 106 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 106 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0007
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0004
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0014

============================================================
🔄 Round 107 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 107 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0011
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0022
============================================================


============================================================
🔄 Round 110 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 110 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0006
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0004
============================================================


============================================================
🔄 Round 113 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 113 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0019
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0078
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0016

============================================================
🔄 Round 116 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 116 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0006
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0036
============================================================


============================================================
🔄 Round 117 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 117 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0013
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0184
============================================================


============================================================
🔄 Round 118 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 118 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0001
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0025
============================================================


============================================================
🔄 Round 119 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 119 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0008
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0053
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0015

============================================================
🔄 Round 123 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 123 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0012
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0067
============================================================


============================================================
🔄 Round 125 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 125 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0014
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0030
============================================================


============================================================
🔄 Round 126 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 126 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0019
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0133
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0016

============================================================
🔄 Round 127 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 127 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0005
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0084
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0016

============================================================
🔄 Round 130 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 130 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0013
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0040
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0016

📊 Round 130 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0017

============================================================
🔄 Round 134 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 134 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0005
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0025
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0017

============================================================
🔄 Round 135 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 135 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0043
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0137
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0017

📊 Round 135 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0018

============================================================
🔄 Round 140 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 140 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0015
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0001
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0019

📊 Round 140 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0018

============================================================
🔄 Round 143 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 143 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0014
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0043
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0016

============================================================
🔄 Round 145 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 145 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0011
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0028
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0015

📊 Round 145 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0016

============================================================
🔄 Round 147 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 147 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0001
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0038
============================================================


============================================================
🔄 Round 149 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 149 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0004
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0051
============================================================


============================================================
🔄 Round 150 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 150 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0013
   Val:   Loss=0.0927, RMSE=0.3044, R²=0.0034
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0016

📊 Round 150 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0015

📊 Round 150 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0015

📊 Round 150 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0014

📊 Round 150 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0015

📊 Round 150 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0015

============================================================
🔄 Round 156 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 156 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0004
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0063
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0016

📊 Round 156 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0016

============================================================
🔄 Round 161 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 161 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0005
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0009
============================================================


============================================================
🔄 Round 162 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 162 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0017
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0075
============================================================


============================================================
🔄 Round 163 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 163 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0008
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0014
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0016

📊 Round 163 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0016

============================================================
🔄 Round 166 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 166 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0011
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0033
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0017

📊 Round 166 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0018

📊 Round 166 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0018

============================================================
🔄 Round 171 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 171 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0010
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0016
============================================================


============================================================
🔄 Round 172 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 172 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0013
   Val:   Loss=0.0730, RMSE=0.2703, R²=-0.0356
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0019

📊 Round 172 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0018

📊 Round 172 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0018

============================================================
🔄 Round 179 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 179 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0010
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0017
============================================================


============================================================
🔄 Round 180 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 180 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0003
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0050
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0018

============================================================
🔄 Round 182 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 182 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0006
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0043
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0018

============================================================
🔄 Round 183 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 183 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0002
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0008
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0017

============================================================
🔄 Round 184 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 184 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0017
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0058
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0018

📊 Round 184 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0018

============================================================
🔄 Round 186 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 186 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0002
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0002
============================================================


============================================================
🔄 Round 188 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 188 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0013
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0035
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0016

============================================================
🔄 Round 189 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 189 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0004
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0006
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0017

============================================================
🔄 Round 191 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 191 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0016
   Val:   Loss=0.0696, RMSE=0.2639, R²=-0.0154
============================================================


============================================================
🔄 Round 194 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 194 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0004
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0024
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0018

📊 Round 194 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0017

============================================================
🔄 Round 197 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 197 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0002
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0010
============================================================


============================================================
🔄 Round 198 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 198 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0036
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0033
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0017

============================================================
🔄 Round 199 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 199 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0000
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0022
============================================================


============================================================
🔄 Round 200 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 200 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0012
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0043
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0017

============================================================
🔄 Round 203 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 203 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0001
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0003
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0017

📊 Round 203 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0018

============================================================
🔄 Round 208 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 208 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0019
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0027
============================================================


============================================================
🔄 Round 210 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 210 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0006
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0017
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2498, R²: -0.0018

============================================================
🔄 Round 211 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 211 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0001
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0022
============================================================


❌ Client client_29 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
