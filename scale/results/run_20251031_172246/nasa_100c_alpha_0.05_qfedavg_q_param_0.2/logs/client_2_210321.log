[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c66b4d3f-3bf5-482d-aa91-cf85b8fec0c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af6e29f4-6268-4cd2-a0f8-49d2177a050a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0842e53c-79a2-4202-8f26-8b761f82f285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 041725f2-d1fb-4b92-8c29-c9b39674e49e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9064efe-7d90-464b-8071-8a00ec32405f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a41d2c35-00bd-4212-ade4-eb870f156382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3404d8e3-103d-4995-a4e4-acb43f1546ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82ae19e5-9ab6-4937-8313-514764de7d2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd8a55b3-ec66-418b-8c86-77a3c8dc537e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39b272ce-6735-4026-9a14-b8788864416f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f15cf2e-4ab2-4a67-804d-a97dc903e52f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9a2cb77-af7a-439a-a50a-6a3bb8d110a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18fdd8fd-7ecf-487f-b888-ec0cee17ddc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ceb2ae6-09c2-4cc6-a866-717d54c867b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af7f7e9a-4ebe-494d-9aa6-89b3bbaf1242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac55b07-3e37-47d0-a40d-99d656252f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed423986-6f56-4f0d-b71b-c2dad9066039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 950ac9ad-32cf-46e7-9eb6-50851f3fa1ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b990669-17a6-4a11-846f-8b07aca25534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f5c64b0-bbe3-4be6-b2e7-31f7320e1558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 210eef55-94e2-4278-ace4-3211f6ddb849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f16c190d-0cb8-444e-bf5f-9762a037e48b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64d42221-924e-4834-bce1-813243e80cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2428ea6e-6387-4356-b189-d78a9fa9c6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aec8cfb8-9622-486c-b8ff-a4176cbb81f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 448bee00-bccf-4ec0-b97e-a1d9378c2ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 716551c5-f1a7-423e-b773-0db4e061d340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c986362-0ba0-4e1b-877c-3d5529ef617c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b563f269-b186-481f-8d05-0883f6a3c14e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c963a18-70aa-4464-8885-262cd581161e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd11fa66-71b0-43d2-af71-6d26a7f96db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 495d0c6d-1629-453e-add1-18e904a27980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f36bc8d-5194-4e8e-b4fd-aaf301b5ff83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07e444d2-a603-4273-a11b-f0833e82be04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e47c186-d315-4c21-8e5b-4c30863e9de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd5b1488-8b2c-412f-a165-7dde44f9853a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a366c149-3324-454a-8a8d-b65e138f38a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76dc5ec4-0921-4661-9d20-64261816839a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54bc04dc-352c-4cf3-a147-142d7882066b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2218e84f-d4ae-45b2-8b70-85a098283eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92448cae-009c-47f2-9aaa-a417fc6c40de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f3192ab-b8fa-48e8-b05e-990d9ced2d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f7a3659-5142-4877-b991-6650b54d7663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bba5259f-93d9-4e62-be1b-825c738d2809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d26d1116-f27c-4ffd-bda0-f8a4cf83fdec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb370699-1c04-4ccc-af84-9c2535a7dcb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fea23eda-9007-49c8-998f-2f688bc8fc98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d678acf-793f-4467-bfb3-00f460095469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 136f37fa-073e-4cfa-b379-d988b09a5626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49857077-6790-4d23-8519-d0d21117fb11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4be7b797-9ec6-4261-814e-3e3012800259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8aa565c-9399-4da2-8dbc-db17b4bed2b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee563afe-8c3a-4407-a863-034848ef6088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdade9c8-67e4-49d5-bcd4-a1923972e730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b2d28e6-4f35-49e4-8956-5888ed2bd124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b8a8273-56ab-4b7e-9267-5c6b5151554f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c55b2d3-9607-4476-b3e5-2574851b71d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8058ed36-954a-4a8f-a488-4a3066150bac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff80c2cb-f6b9-4dc9-b665-292d8d0a8c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03489fff-bc85-4887-a56d-9b164c5e80dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77058788-bcdf-4e5a-bb70-0abf2fb30784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 403637a8-d268-40d6-9a99-5e46a0406918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df2b31d1-b219-4b88-8df7-687489f74f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44151b51-e202-44db-a423-bc0c0d20cf80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 442dcff5-1616-47a0-8eb0-3f2867ae9da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5cbc5ba-8547-4335-8ef7-96e3e974b52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ff4964c-78c3-4be2-b91b-7a011ba62863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 378c2afc-f8a5-4d62-a565-ad26e93a0442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d512800d-e0e8-4f5c-bed8-47220f15fa83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02d4fe45-f150-414a-b183-6aad2621e6cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f9c8478-791a-4372-be34-a1bf47895b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d2f0b26-0134-43af-bbe0-d0041e5241bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19fd4aa6-ad93-4e56-9b5e-7716b13b0703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1d3f8d4-4a20-435a-88a2-cc722686a50a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 818f472a-b621-4248-8687-4be66cd92b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ddfbb26-83d6-4f7b-9897-f0d01fac5ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a23b8e9-6045-42e6-9990-ef2e23dd6e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bcad0d2-c3c3-44b5-b862-c20ba7a44bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f8dbdd9-f765-4a45-8c65-1abd6c2e02e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaaeae9c-4b2c-4a0a-a3c6-fc4f72153ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cb71e73-7e95-4d9d-a9a2-4186bf7a4453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff8d4c2-e9c4-4fe8-9d12-a7ff97a004f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68a68d38-51af-4757-a93c-952b99f28509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcf0e857-c760-4633-92c7-6233f9a751dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 258f2574-a9be-4dbf-b8fe-a607568a9313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d7fdc3-1948-43e9-b1c5-678bb049a838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55743107-d597-4b1f-80c3-f75e21584d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27eb6f7a-4e9d-4701-8013-0a88d1767eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a83e08f-196a-49e3-ade7-4fec2d2ab940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5c24cfb-becc-453a-a41c-4db1d3693ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca0318a3-8636-4e24-97a0-578589eaf5d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8096db6f-20e1-4c60-b62c-f45cce097787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb481a0f-1f1f-40b4-b049-d07ab3bb0e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a178b99a-ae39-44a8-b964-d240c2c5597c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c697b4b-42ef-4c4f-a754-ee1d13a8a045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed7c01cd-9e91-4f3f-9516-2edb2c211884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d1e271c-8640-49a2-a8d2-b4e6e61581c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79b2aa9c-ccae-4402-878e-9b23feb89a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b59a86b-ac35-4328-bf4b-883c1b46883c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afd0d97d-ee04-4e2a-b3c5-06d88884f752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 974d7b56-dc13-4d23-8d08-d43348720b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message addc1cd7-2f01-43e3-b98f-b3dd8ff1ee28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2c9d869-14b9-438b-8159-71ef00a5cf0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bd1043d-0cd9-4803-be86-6b651b0c49d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0184eea9-a950-44f3-87ca-53516e79fc12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bca48946-ae33-4123-8d1d-7193e0d4e0b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 820f61d2-f1ed-472c-965e-889022f8cd7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54d35c76-40aa-4698-a01c-d2c27affd06b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb11a695-2def-443b-ba4b-8daed8574fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d357be5-ffc8-40f2-a912-f73f4bf50296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f35e093f-7fb4-492f-a160-397e42fc5dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71a4a6a0-c127-4f15-9582-54c38717c6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e7ca659-5374-4dd4-a1b8-4b8a985a9252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37579bbf-add2-40d1-9987-180a86426f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ead9ec1e-3bf1-4d03-8590-32e37f52f935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3cddd7a-c65d-4d40-ae81-cff8878397f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e1c5415-66cd-429b-a2bb-0777a08611df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2fdd074-df1a-4415-adce-fe1eac6831a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5685ccb5-0c6b-41a9-b9a4-8ea54d7ab529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bd63d4c-4238-4d71-8678-cfee870dda7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ebf9eff-5376-4854-9f12-a993f3e84545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5438f13c-3a90-47bd-b604-0800da820231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9284600f-3f9c-4e7b-9cb4-7ec89d3bc37e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43532603-6fa9-4d8f-b4ca-fa6834893f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 777f15bc-418b-4e6d-ab7a-2c74069f3be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f38cd45-b0b7-4fcc-adc8-67869d3907a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 364d9fd7-ea4c-4576-b995-73925490fd0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbebed8d-ee55-4d5b-ba27-f0317158aea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af760990-b025-480b-9aa1-78ceeff8cad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfbd50b7-6a10-469a-978c-e65654d4e61b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e42a740e-4307-4c27-8142-1acab2ea4fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a3341d7-5351-4997-a353-ac826e848855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 891ba31a-c6da-40ef-88a0-3ec14feca751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a3b03ac-224f-448d-adce-a844950efd23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 926f2b6e-ed0a-45b2-8624-bfee78587d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e538ca89-b144-4a6b-881d-b41d6514883d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72a3caf6-16b4-4768-ae30-64e5a1c4ff0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b08324c2-398f-4bf6-a32d-3441125d267b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a39ad37-3a07-4d1b-800b-fa73d45166a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec2fab75-e81e-44c5-a831-f69612279252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 420b68f2-4ea7-479d-bf77-06cfd01c5049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07fa8f71-365c-4579-895b-d5ccced6ad64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e93ae26-30cb-43ac-9bc2-9a06e39a5492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26190732-b2d1-40b9-8248-b9e59932dd48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4443f50-f3ad-4d5a-aa51-102113fa4d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa145b1c-f75d-4633-953b-21f3fc2e2dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab6c7185-7748-47a1-a2a0-224b20fa9a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7db2775f-829a-4c18-9f65-4cce7d86171e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61215390-04cc-4333-8406-c02a3bd774dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eb5eb61-c4fc-46a8-b349-fb29b86b2460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a50cd381-68f2-451d-877c-8942d4c6b64d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72e70060-a0fd-42dd-99f9-46289d4d962d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_2
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_2
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_2/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_2/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_2/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_2/test_labels.txt

📊 Raw data loaded:
   Train: X=(848, 24), y=(848,)
   Test:  X=(212, 24), y=(212,)

⚠️  Limiting training data: 848 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  203 samples, 5 features
✅ Client client_2 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1288, val=0.0851 (↓), lr=0.001000
   • Epoch   2/100: train=0.0913, val=0.0851, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0886, val=0.0831 (↓), lr=0.001000
   • Epoch   4/100: train=0.0881, val=0.0830, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0882, val=0.0834, patience=2/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0869, val=0.0842, patience=8/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 3 Summary - Client client_2
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0037
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0200
============================================================


============================================================
🔄 Round 4 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1790, val=0.1345 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1189, val=0.0875 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0903, val=0.0839 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0874, val=0.0828 (↓), lr=0.000250
   • Epoch   5/100: train=0.0876, val=0.0829, patience=1/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0870, val=0.0830, patience=7/15, lr=0.000125
   📉 Epoch 18: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 4 Summary - Client client_2
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0007
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0018
============================================================


============================================================
🔄 Round 6 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1859, val=0.1763 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1632, val=0.1544 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1443, val=0.1364 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1284, val=0.1204 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.1143, val=0.1060 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0883, val=0.0825, patience=1/15, lr=0.000031
   • Epoch  21/100: train=0.0879, val=0.0820, patience=9/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 6 Summary - Client client_2
   Epochs: 27/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0030
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0046
============================================================


============================================================
🔄 Round 8 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1771, val=0.1661 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.1654, val=0.1546 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.1544, val=0.1450 (↓), lr=0.000031
   📉 Epoch 4: LR reduced 0.000031 → 0.000016
   ✓ Epoch   4/100: train=0.1448, val=0.1362 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1381, val=0.1321 (↓), lr=0.000016
   ✓ Epoch  11/100: train=0.1152, val=0.1107 (↓), lr=0.000016
   📉 Epoch 12: LR reduced 0.000016 → 0.000008
   📉 Epoch 20: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.0988, val=0.0965 (↓), lr=0.000004
   📉 Epoch 28: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0944, val=0.0925, patience=2/15, lr=0.000002
   📉 Epoch 36: LR reduced 0.000002 → 0.000001
   • Epoch  41/100: train=0.0928, val=0.0912, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0919, val=0.0904, patience=5/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0911, val=0.0896 (↓), lr=0.000001
   • Epoch  71/100: train=0.0904, val=0.0890, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0898, val=0.0885, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0892, val=0.0880, patience=2/15, lr=0.000001

============================================================
📊 Round 8 Summary - Client client_2
   Epochs: 100/100
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=-0.0220
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0104
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1458, RMSE: 0.3818, MAE: 0.3146, R²: -1.0487

📊 Round 8 Test Metrics:
   Loss: 0.1363, RMSE: 0.3691, MAE: 0.3036, R²: -0.9154

============================================================
🔄 Round 12 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1613, val=0.1655 (↓), lr=0.000001
   • Epoch   2/100: train=0.1609, val=0.1650, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1604, val=0.1646 (↓), lr=0.000001
   • Epoch   4/100: train=0.1600, val=0.1642, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1596, val=0.1638 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1574, val=0.1617 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1543, val=0.1587 (↓), lr=0.000001
   • Epoch  31/100: train=0.1516, val=0.1562, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1492, val=0.1538 (↓), lr=0.000001
   • Epoch  51/100: train=0.1469, val=0.1515, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1446, val=0.1494, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1424, val=0.1472 (↓), lr=0.000001
   • Epoch  81/100: train=0.1403, val=0.1451, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1382, val=0.1431, patience=2/15, lr=0.000001

============================================================
📊 Round 12 Summary - Client client_2
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1360, RMSE=0.3688, R²=-0.5937
   Val:   Loss=0.1412, RMSE=0.3758, R²=-0.5358
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1313, RMSE: 0.3623, MAE: 0.2978, R²: -0.8451

📊 Round 12 Test Metrics:
   Loss: 0.1259, RMSE: 0.3548, MAE: 0.2913, R²: -0.7698

📊 Round 12 Test Metrics:
   Loss: 0.1120, RMSE: 0.3347, MAE: 0.2750, R²: -0.5748

📊 Round 12 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2429, R²: -0.1862

============================================================
🔄 Round 19 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1048, val=0.1104 (↓), lr=0.000001
   • Epoch   2/100: train=0.1046, val=0.1102, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1044, val=0.1100, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1043, val=0.1097 (↓), lr=0.000001
   • Epoch   5/100: train=0.1041, val=0.1095, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1032, val=0.1083, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1017, val=0.1063, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1003, val=0.1044 (↓), lr=0.000001
   • Epoch  41/100: train=0.0990, val=0.1025, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0978, val=0.1008, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0966, val=0.0991 (↓), lr=0.000001
   • Epoch  71/100: train=0.0955, val=0.0974, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0945, val=0.0959 (↓), lr=0.000001
   • Epoch  91/100: train=0.0936, val=0.0945, patience=2/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_2
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0923, RMSE=0.3038, R²=-0.0514
   Val:   Loss=0.0932, RMSE=0.3054, R²=-0.1555
============================================================


============================================================
🔄 Round 21 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0924, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0887, val=0.0921 (↓), lr=0.000001
   • Epoch  21/100: train=0.0883, val=0.0916, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0879, val=0.0912, patience=9/15, lr=0.000001
   • Epoch  41/100: train=0.0875, val=0.0909, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0873, val=0.0906, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 21 Summary - Client client_2
   Epochs: 51/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0181
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0160
============================================================


============================================================
🔄 Round 23 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 23 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0118
   Val:   Loss=0.0950, RMSE=0.3083, R²=-0.0283
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2280, R²: 0.0013

📊 Round 23 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2279, R²: 0.0019

============================================================
🔄 Round 25 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 25 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0110
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0098
============================================================


============================================================
🔄 Round 27 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 27 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0104
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0026
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0710, RMSE: 0.2664, MAE: 0.2278, R²: 0.0024

============================================================
🔄 Round 32 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 32 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0081
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0043
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0710, RMSE: 0.2664, MAE: 0.2278, R²: 0.0024

============================================================
🔄 Round 36 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 36 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0068
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0057
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0710, RMSE: 0.2664, MAE: 0.2277, R²: 0.0023

📊 Round 36 Test Metrics:
   Loss: 0.0710, RMSE: 0.2664, MAE: 0.2277, R²: 0.0023

============================================================
🔄 Round 40 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 40 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0042
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0221
============================================================


============================================================
🔄 Round 41 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 41 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0109
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0145
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0710, RMSE: 0.2664, MAE: 0.2277, R²: 0.0022

============================================================
🔄 Round 43 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 43 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0081
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0031
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0710, RMSE: 0.2664, MAE: 0.2277, R²: 0.0022

============================================================
🔄 Round 44 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 44 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0075
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0050
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0710, RMSE: 0.2664, MAE: 0.2277, R²: 0.0022

============================================================
🔄 Round 47 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 47 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0036
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0198
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0710, RMSE: 0.2664, MAE: 0.2277, R²: 0.0021

============================================================
🔄 Round 50 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 50 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0066
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0044
============================================================


============================================================
🔄 Round 51 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 51 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0028
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0225
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2277, R²: 0.0021

📊 Round 51 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2277, R²: 0.0021

============================================================
🔄 Round 55 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 55 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0063
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0008
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2277, R²: 0.0021

============================================================
🔄 Round 57 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 57 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0051
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0103
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0710, RMSE: 0.2664, MAE: 0.2277, R²: 0.0021

📊 Round 57 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2277, R²: 0.0021

============================================================
🔄 Round 59 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 59 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0024
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0301
============================================================


============================================================
🔄 Round 61 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 61 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0037
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0115
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2277, R²: 0.0020

============================================================
🔄 Round 63 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.1014 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.1013, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.1013, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.1013, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.1013, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.1013, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1014)

============================================================
📊 Round 63 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0035
   Val:   Loss=0.1014, RMSE=0.3184, R²=-0.0096
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2277, R²: 0.0020

📊 Round 63 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0019

============================================================
🔄 Round 68 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 68 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0018
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0257
============================================================


============================================================
🔄 Round 69 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 69 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0042
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0071
============================================================


============================================================
🔄 Round 70 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 70 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0065
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0028
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0019

📊 Round 70 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0019

============================================================
🔄 Round 72 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 72 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0048
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0038
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0018

📊 Round 72 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0018

============================================================
🔄 Round 75 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0995 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0995, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0995, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0995, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0995, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0994, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0995)

============================================================
📊 Round 75 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0028
   Val:   Loss=0.0995, RMSE=0.3155, R²=-0.0182
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0018

============================================================
🔄 Round 78 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 78 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0050
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0062
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0017

📊 Round 78 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0017

============================================================
🔄 Round 81 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 81 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0056
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0030
============================================================


============================================================
🔄 Round 83 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 83 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0029
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0102
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0017

📊 Round 83 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0017

📊 Round 83 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0016

📊 Round 83 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0016

============================================================
🔄 Round 94 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 94 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0051
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0005
============================================================


============================================================
🔄 Round 95 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 95 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0037
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0098
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0015

============================================================
🔄 Round 101 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 101 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0034
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0158
============================================================


============================================================
🔄 Round 104 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 104 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0070
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0054
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0014

📊 Round 104 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0014

============================================================
🔄 Round 108 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 108 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0030
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0084
============================================================


============================================================
🔄 Round 109 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 109 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0034
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0045
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0013

📊 Round 109 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0013

============================================================
🔄 Round 111 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 111 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0032
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0080
============================================================


============================================================
🔄 Round 112 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 112 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0045
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0037
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0013

============================================================
🔄 Round 116 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 116 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0068
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0022
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0013

📊 Round 116 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2278, R²: 0.0014

============================================================
🔄 Round 118 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 118 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0041
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0013
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0710, RMSE: 0.2666, MAE: 0.2278, R²: 0.0013

============================================================
🔄 Round 119 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 119 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0078
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0039
============================================================


============================================================
🔄 Round 121 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 121 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0057
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0080
============================================================


============================================================
🔄 Round 122 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 122 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0017
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0125
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0013

📊 Round 122 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0012

📊 Round 122 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0012

📊 Round 122 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0012

📊 Round 122 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0012

============================================================
🔄 Round 131 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 131 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0056
   Val:   Loss=0.0915, RMSE=0.3026, R²=0.0043
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0012

============================================================
🔄 Round 133 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 133 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0037
   Val:   Loss=0.0914, RMSE=0.3022, R²=-0.0020
============================================================


============================================================
🔄 Round 134 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 134 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0014
   Val:   Loss=0.0957, RMSE=0.3093, R²=-0.0191
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0011

📊 Round 134 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0011

============================================================
🔄 Round 142 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 142 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0051
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0033
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0011

📊 Round 142 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0012

📊 Round 142 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0013

============================================================
🔄 Round 146 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 146 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0025
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0067
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0012

📊 Round 146 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0012

============================================================
🔄 Round 148 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 148 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0037
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0055
============================================================


============================================================
🔄 Round 149 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 149 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0039
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0027
============================================================


============================================================
🔄 Round 150 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 150 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0027
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0059
============================================================


============================================================
🔄 Round 151 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 151 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0029
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0065
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0013

📊 Round 151 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0013

📊 Round 151 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0013

============================================================
🔄 Round 155 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 155 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0027
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0067
============================================================


============================================================
🔄 Round 157 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 157 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0049
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0012
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0013

📊 Round 157 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0012

📊 Round 157 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2278, R²: 0.0012

============================================================
🔄 Round 165 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 165 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0035
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0025
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0011

📊 Round 165 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0010

📊 Round 165 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0010

📊 Round 165 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0010

============================================================
🔄 Round 175 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.1059 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.1059, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.1059, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.1059, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.1059, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.1059, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1059)

============================================================
📊 Round 175 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0020
   Val:   Loss=0.1059, RMSE=0.3255, R²=-0.0195
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0011

============================================================
🔄 Round 178 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 178 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0031
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0033
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0011

============================================================
🔄 Round 181 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 181 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0011
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0156
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0010

============================================================
🔄 Round 183 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 183 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0040
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0000
============================================================


============================================================
🔄 Round 184 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 184 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0065
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0012
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0011

📊 Round 184 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0010

📊 Round 184 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0011

📊 Round 184 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0011

============================================================
🔄 Round 191 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 191 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0012
   Val:   Loss=0.0952, RMSE=0.3085, R²=-0.0268
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0011

============================================================
🔄 Round 192 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 192 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0026
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0058
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0011

============================================================
🔄 Round 197 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 197 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0020
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0088
============================================================


============================================================
🔄 Round 198 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 198 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0026
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0055
============================================================


============================================================
🔄 Round 199 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 199 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0036
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0624
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0011

📊 Round 199 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0011

============================================================
🔄 Round 202 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 202 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0017
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0088
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0010

============================================================
🔄 Round 205 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 205 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.0063
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0197
============================================================


============================================================
🔄 Round 208 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 208 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0035
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0006
============================================================


============================================================
🔄 Round 209 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 209 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0067
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0023
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2279, R²: 0.0010

============================================================
🔄 Round 211 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 211 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0030
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0051
============================================================


❌ Client client_2 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
