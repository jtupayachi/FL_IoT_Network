[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2b76020-d906-47ee-8985-80035d53fde4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8b26b92-0ca7-42d4-b26f-503d83ffbb57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99db4fb1-0046-4bce-9110-f0f295349542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 214448f4-c796-430e-a94a-e2601f44fa51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 383d16a4-8285-42c4-85d5-e20bab02048f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c520275-38b5-4400-979a-cc021e0ec2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 968d06c5-1216-475d-b48c-ac4e0cab52a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18bcb1db-4ea7-4ae8-bb97-8592d5f258e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89ba4202-92c8-4533-b791-be447845753e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d0892bd-2b3c-457e-b25b-608bf05e9fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0d0d1ff-c608-4cd1-8131-d2b49d52ee52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0e27665-a167-4477-8df7-94b2ac07b39e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9deed3e-d2ac-4642-bdb8-823d153c39e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1822422a-8837-4003-9efe-80d188c83d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ead461a-197e-4031-8be7-e0dd3ed6b34e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0035d351-4418-49ce-9afd-3e0ad960efbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e2930a-e533-4439-84c8-ee95b5ed01b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4677a1b4-1aea-45fc-85fc-82f50c111ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81cb9fe8-4b4c-4170-bc34-a0fda8827425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4ea2a12-1778-493d-9a99-ba50dbab6f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd25654d-b870-4dd3-b762-31f667822399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad0285d-443a-45d6-a139-325bb73faf5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 705f05de-89a3-4b95-97e6-6e6f5fba0d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71a1bfe7-5b52-42d3-8271-f3adc68afab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42acc1d2-3939-41da-a13c-8a8ee06c799d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28ed5a81-6473-426a-b863-61c134657cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bf58099-59f4-4839-9d88-64bf51c22248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e91261b-f788-4555-9e9e-a6b8c8a70993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b0ae8f2-2c9d-4f43-bf24-2f1e97303ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bb7033b-68e4-41a7-8dc2-2cd31b914d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14fbd134-f133-4051-a246-3ba9f2462c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0fcd1bf-df3b-4ea0-8a08-e92cf975383a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e6e37b4-3d67-4a7e-bb62-ea647988cf3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c957f7a3-fb2c-45c6-b9bc-54c0429932d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd070be1-ab2f-4134-a669-3ad2e2d9d993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96cfd964-11b8-447e-b9ae-17be776f6c6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54504bae-f726-449b-b9b5-9b99cb21455f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5f7f20b-40c5-49dc-ae62-9313af9bb358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2721dc7-7557-4ed6-8154-103e1a98fbb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dba03a34-8d96-410b-b8be-5f43a56c676b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16a46110-545c-4cc9-ac44-e72efb7aeb28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ee5727d-a3cd-46b9-bec4-03aa281f23c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91445bb7-7bf9-4bc6-8294-04b71809cc65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab1c7d9f-8d06-40bb-9ac9-2b1d6f83cb39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 520e26f9-f376-43a6-b520-643bbb94be23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53595e85-d964-484a-b9ec-a982f18e9a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33482be9-0798-4ef1-a0e7-ae3518cb1d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e724f6b-6a21-41ee-a724-92f5f8ba6541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28c3e62e-0744-4648-941f-bcdddf71b8a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dabb81da-1215-4c86-8b8c-8cd73623f09f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7614bbe8-9667-476b-b0a1-dccc4fe624f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aad7c52c-a502-40e0-88fc-1f8c15cd1510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e5339b3-769a-4f6e-b0e1-d8c713155f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46b12259-c9b7-4d76-89c0-138b52a3f055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c32d4cb-563a-4018-8d0b-0de62c28a4e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d97d4607-a8c5-4a67-9a3f-163c0feed11f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afe4c039-a399-486c-8942-8e93516d73bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffd53a59-8d93-49d7-82a4-439ba5b01168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ab07f79-390f-4000-b59e-c6e2fbb50fbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 918f6c9f-26a2-4fba-87e6-20f0876cd7ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afcd4e2f-0e37-48c6-a9bb-10c6cb083b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0aed231-1cd1-48d3-8890-1aced07c8863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f5f8310-c40f-4d73-8df0-d419fc7f96fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ea13bb6-5de6-42eb-a651-5396f2025ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5055ea23-1e05-4b03-bfcf-26e3599bcf8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f7e4163-6c90-43c9-b9c5-6e7be3b78263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aecccb0-f3ce-4b17-86a2-436b2dcb883d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b09374cc-3d16-4009-8240-bab283ba0880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b05dd8ac-aaca-4a0c-bd9c-13fbf449735d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dfc966a-ee00-4502-8ef5-ec1c3f1e8b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ed80f1f-2e8d-4f0f-b94e-f27bd00161df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5cd8d68-1ab8-440a-add0-5867e5141da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 982bd009-279c-4bde-b4ef-1201bed3239d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3ed1009-96fb-4544-b74b-d4b4333fedea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2efbf02e-ba4d-452d-af74-37da9e1e22a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3dede58-82e9-476e-b378-98746090dc86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 142b64f8-f60a-47f4-882e-186de3f481b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4900adc1-01fe-4fb3-bf99-60aeb7813e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 963e15bf-847e-4359-bc62-b54123e83a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7354bc91-3883-4e2e-ae90-53a657f16803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb862ef9-63dc-44b9-960d-42260f6014df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03764e99-617d-4820-81ee-f5cbaac73401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1e60258-4fb8-45b6-98e8-8d4e942dc6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff5d76c1-c33b-42c5-8ecb-c7f539d450e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84cd18af-9a43-447c-baf1-ead496186c40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4da6dcbd-72ea-4c1d-9696-ccea084538d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad56870c-7752-4280-b38e-7c7f78120172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f7ed586-6a55-4c3c-a321-e1bf558d65f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7efa84a0-f118-4e4d-98b3-c6a4a13ee07b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bbced4e-02e9-44a2-9d19-18b1f4889299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d17001e0-b9fa-4c7a-92ed-138081c68fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67602a5a-18d8-43cf-ba46-b19eb5ef4a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0fc12c8-e293-4a5b-b4eb-f9cdbf7565e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bad2c960-88c8-4d1a-95fb-afe6936aad33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c192113b-7cb1-4566-a9ea-d020239bf023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19c1c6ce-2056-4177-9ac4-04fb05d6c7de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 710f4141-8107-4bd7-b02b-425724797de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 931a3653-aaf2-4ae2-b390-9a6c1f35a71d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32e90194-a402-4bb4-be46-0269e344675b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1551967-6ed3-4408-a8f8-55dc3da80014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 714f2403-72c0-40b2-b3c8-58af4d557da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a185aa9-24ac-461c-aee0-c794d0c3d09d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33505f50-68b8-4a2a-9c23-d58631f88f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76b2e179-db38-48b1-a147-77f51a32057d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 347b7bfb-af35-49fd-bd20-fb179ee1fe97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb3df987-ce24-4a15-bbae-d073902e110b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891b5a8e-32b9-417e-ad43-2cb878c9b500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d045c0d6-b93e-4c0a-8856-7c23d3618a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f041e2a5-3d03-4eb5-a887-7685201aa7e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab1b8c76-7b1f-44ed-ba0b-e3831b0a9acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c54319b-018d-4c27-a7fe-823455731680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 027d7b18-d650-4d68-be6f-d1b99284061d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67444b99-ac8a-4c6f-addc-23b11d13bc6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 773337fe-536e-4ba1-a330-bc68f1134649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2f4081d-0a2d-4627-8d6f-a97ad9821061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa3cbe0d-6fd5-4b98-8bfe-3022651166f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7bdc269-711d-4879-afa6-055b804555e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5aa6654-5240-4bdb-8bf2-69cceb150d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1e25d01-59d0-431a-98a5-8499ccc19084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee56cc3d-8e2c-41de-9a90-b2ef8b8e7004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f7f9cb0-7620-4f43-9910-bb986335e253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ab88fb1-ef4c-4d3a-91c0-32f1dffb24fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d453edce-3da2-4add-9957-d5bb7f974491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22cf7faf-b96d-4e2c-97a3-4bd1cb194d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3cd9a8e-0512-4106-8cb3-f0d22a189d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 140d6eb6-c07c-4167-b4df-7fe79117bb2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4e9b6ff-1cb5-49a5-8552-c21691e80b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8280d87d-e2ee-455b-92d7-24b18b2e4f80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69c3d882-206c-4c18-8df5-6eef112aa545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48318f19-1041-4928-aa9b-49239fbe19a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30082aeb-9c25-433f-ab9f-ffcfaf4c0d30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4be1e17-4cf7-4377-9957-d985d268f446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90becaf3-1fe1-4a31-abf1-f76bc89ffe6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba9c6e6d-66f8-4375-8b62-5093bcdb770d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f9fff13-d6cb-4f35-9083-0fc9d54641a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 959293e3-66a4-4bf3-b573-105b78a11127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54627b7a-1cf2-4d22-9760-9e7ad2b88bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73577f89-e012-489b-adba-837cc7fd3268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dfc32f0-d445-4702-9cb6-9a09a5808fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 220fa470-9945-4f70-9cd9-c1dcad9e46f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc2e012e-fd15-4ed5-87da-55a61ac9689b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ea8710-22fe-4cbf-b63f-cc0a468b1b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ede20891-8604-4587-be90-d4af26d26ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8ab9c0e-b8e1-4f9c-933d-5a104fc58197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62f46f2d-ad11-4d92-b0a3-277c29a3925d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81789b18-cd0d-45d7-8a3a-181570dff6d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3ced649-6b0a-41bd-83ed-df5b4666cd09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b070c62b-d47d-4ce2-80f5-9663559c4611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1d99439-8e63-4b6d-a909-7afa6b5830a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af2d9d03-d427-4aa0-bbc8-d901f6bc7f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5695e041-99de-4cd1-807b-a8d1975b87ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f97339f7-3565-49ec-9ac8-60ddbce15717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6585c5c-b43b-4b8b-8f6b-7493b59e7030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73d694f4-c36b-45fb-a23a-7b68ab658710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 982e66de-4dca-4af5-bab0-01ac12f77309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bf7b47f-5c68-4d66-9b3c-c562152f96f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8148ff82-90fd-4282-8f21-5d704dde0c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e19cc450-2bab-4422-b081-27fd57720d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2e2bc23-2293-40c1-b044-5464d6bc1ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 343c0fa6-772f-423e-9c2f-5847dd97fd5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ce37bea-598e-4146-b8f4-5c689b495c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62543428-2333-4a39-a828-9a7e33a7ff79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55bc1312-0e9f-4c42-b6ab-e77d9c059284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a890c2fe-5c77-4480-80fc-1c10e40d0152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a28602e0-5735-4fb5-bc71-d565c5f2718a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_30
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_30
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_30/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_30/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_30/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_30/test_labels.txt

📊 Raw data loaded:
   Train: X=(1432, 24), y=(1432,)
   Test:  X=(358, 24), y=(358,)

⚠️  Limiting training data: 1432 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  349 samples, 5 features
✅ Client client_30 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 4 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1130, val=0.0825 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0825, val=0.0762 (↓), lr=0.001000
   • Epoch   3/100: train=0.0801, val=0.0761, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0795, val=0.0760, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0796, val=0.0760, patience=3/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0790, val=0.0757 (↓), lr=0.001000
   • Epoch  21/100: train=0.0771, val=0.0755, patience=10/15, lr=0.001000
   📉 Epoch 22: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 4 Summary - Client client_30
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0151
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0039
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.1791, RMSE: 0.4232, MAE: 0.3404, R²: -1.1823

============================================================
🔄 Round 8 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1185, val=0.0831 (↓), lr=0.000500
   • Epoch   2/100: train=0.0797, val=0.0856, patience=1/15, lr=0.000500
   ✓ Epoch   3/100: train=0.0802, val=0.0826 (↓), lr=0.000500
   📉 Epoch 4: LR reduced 0.000500 → 0.000250
   • Epoch   4/100: train=0.0784, val=0.0833, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0783, val=0.0831, patience=2/15, lr=0.000250
   • Epoch  11/100: train=0.0779, val=0.0831, patience=8/15, lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 8 Summary - Client client_30
   Epochs: 18/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0019
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0208
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1698, RMSE: 0.4120, MAE: 0.3309, R²: -1.0690

📊 Round 8 Test Metrics:
   Loss: 0.1660, RMSE: 0.4074, MAE: 0.3270, R²: -1.0229

============================================================
🔄 Round 10 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1385, val=0.1290 (↓), lr=0.000125
   📉 Epoch 2: LR reduced 0.000125 → 0.000063
   ✓ Epoch   2/100: train=0.1045, val=0.0971 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0855, val=0.0877 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0799, val=0.0838 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0782, val=0.0829 (↓), lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0778, val=0.0829, patience=6/15, lr=0.000031
   📉 Epoch 18: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 10 Summary - Client client_30
   Epochs: 20/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0025
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0080
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.1603, RMSE: 0.4004, MAE: 0.3213, R²: -0.9542

📊 Round 10 Test Metrics:
   Loss: 0.1509, RMSE: 0.3885, MAE: 0.3118, R²: -0.8395

📊 Round 10 Test Metrics:
   Loss: 0.1453, RMSE: 0.3812, MAE: 0.3063, R²: -0.7709

============================================================
🔄 Round 14 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1324, val=0.1317 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1274, val=0.1260 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1221, val=0.1208 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1174, val=0.1159 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1130, val=0.1114 (↓), lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.0994, val=0.0985 (↓), lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.0907, val=0.0896 (↓), lr=0.000004
   📉 Epoch 22: LR reduced 0.000004 → 0.000002
   📉 Epoch 30: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.0879, val=0.0868 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.0868, val=0.0856 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.0858, val=0.0846 (↓), lr=0.000001
   • Epoch  61/100: train=0.0849, val=0.0836, patience=5/15, lr=0.000001
   • Epoch  71/100: train=0.0841, val=0.0827, patience=3/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0834, val=0.0818 (↓), lr=0.000001
   • Epoch  91/100: train=0.0828, val=0.0811, patience=3/15, lr=0.000001

============================================================
📊 Round 14 Summary - Client client_30
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0372
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0502
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1354, RMSE: 0.3680, MAE: 0.2968, R²: -0.6500

============================================================
🔄 Round 15 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1242, val=0.1267 (↓), lr=0.000001
   • Epoch   2/100: train=0.1239, val=0.1263, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1236, val=0.1260 (↓), lr=0.000001
   • Epoch   4/100: train=0.1233, val=0.1257, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1230, val=0.1254 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1214, val=0.1238 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1190, val=0.1213 (↓), lr=0.000001
   • Epoch  31/100: train=0.1168, val=0.1191, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1147, val=0.1170, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1127, val=0.1149 (↓), lr=0.000001
   • Epoch  61/100: train=0.1108, val=0.1130, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1089, val=0.1110, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1071, val=0.1092 (↓), lr=0.000001
   • Epoch  91/100: train=0.1053, val=0.1074, patience=1/15, lr=0.000001

============================================================
📊 Round 15 Summary - Client client_30
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1036, RMSE=0.3218, R²=-0.3159
   Val:   Loss=0.1058, RMSE=0.3252, R²=-0.3442
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1306, RMSE: 0.3614, MAE: 0.2923, R²: -0.5915

📊 Round 15 Test Metrics:
   Loss: 0.1266, RMSE: 0.3558, MAE: 0.2886, R²: -0.5431

============================================================
🔄 Round 17 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1164, val=0.1154 (↓), lr=0.000001
   • Epoch   2/100: train=0.1162, val=0.1152, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1160, val=0.1150, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1158, val=0.1148 (↓), lr=0.000001
   • Epoch   5/100: train=0.1156, val=0.1146, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1144, val=0.1134, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1125, val=0.1115, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1106, val=0.1097 (↓), lr=0.000001
   • Epoch  41/100: train=0.1087, val=0.1079, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1069, val=0.1061, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1051, val=0.1043 (↓), lr=0.000001
   • Epoch  71/100: train=0.1034, val=0.1026, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1016, val=0.1009, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1000, val=0.0993 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_30
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0988, RMSE=0.3143, R²=-0.2538
   Val:   Loss=0.0979, RMSE=0.3128, R²=-0.2476
============================================================


============================================================
🔄 Round 18 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1037, val=0.1015 (↓), lr=0.000001
   • Epoch   2/100: train=0.1035, val=0.1013, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1033, val=0.1011, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1032, val=0.1009 (↓), lr=0.000001
   • Epoch   5/100: train=0.1030, val=0.1008, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1020, val=0.0997, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1004, val=0.0980, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0989, val=0.0963 (↓), lr=0.000001
   • Epoch  41/100: train=0.0974, val=0.0946, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0959, val=0.0931 (↓), lr=0.000001
   • Epoch  61/100: train=0.0945, val=0.0915, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.0932, val=0.0901 (↓), lr=0.000001
   • Epoch  81/100: train=0.0919, val=0.0886, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0906, val=0.0873 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_30
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.1219
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.1627
============================================================


============================================================
🔄 Round 19 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0939, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0937, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0936, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0934, val=0.0870, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0933, val=0.0868 (↓), lr=0.000001
   • Epoch  11/100: train=0.0924, val=0.0861, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0910, val=0.0849, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0897, val=0.0839, patience=1/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0885, val=0.0829 (↓), lr=0.000001
   • Epoch  51/100: train=0.0874, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  61/100: train=0.0864, val=0.0812, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0854, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0845, val=0.0798, patience=6/15, lr=0.000001
   • Epoch  91/100: train=0.0837, val=0.0792, patience=8/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_30
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0506
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0254
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2571, R²: -0.1030

📊 Round 19 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2528, R²: -0.0348

📊 Round 19 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2512, R²: -0.0140

============================================================
🔄 Round 23 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 23 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0062
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0044
============================================================


============================================================
🔄 Round 26 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 26 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0030
   Val:   Loss=0.0743, RMSE=0.2727, R²=-0.0121
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2508, R²: -0.0081

============================================================
🔄 Round 27 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 27 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0043
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0149
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2507, R²: -0.0075

============================================================
🔄 Round 29 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 29 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0046
   Val:   Loss=0.0692, RMSE=0.2631, R²=-0.0094
============================================================


============================================================
🔄 Round 33 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 33 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0048
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0096
============================================================


============================================================
🔄 Round 36 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 36 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0024
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0064
============================================================


============================================================
🔄 Round 37 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 37 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=-0.0071
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0018
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2506, R²: -0.0054

============================================================
🔄 Round 40 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 40 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0025
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0061
============================================================


============================================================
🔄 Round 41 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 41 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0026
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0091
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2506, R²: -0.0050

============================================================
🔄 Round 45 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 45 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0027
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0115
============================================================


============================================================
🔄 Round 46 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 46 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0042
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0047
============================================================


============================================================
🔄 Round 47 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 47 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0047
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0024
============================================================


============================================================
🔄 Round 48 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 48 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0029
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0070
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2506, R²: -0.0048

============================================================
🔄 Round 52 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 52 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0040
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0039
============================================================


============================================================
🔄 Round 53 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 53 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0044
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0015
============================================================


============================================================
🔄 Round 55 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 55 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0039
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0004
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2506, R²: -0.0046

📊 Round 55 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2506, R²: -0.0046

============================================================
🔄 Round 59 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 59 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0017
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0095
============================================================


============================================================
🔄 Round 62 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 62 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=-0.0040
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0087
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2505, R²: -0.0044

============================================================
🔄 Round 67 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 67 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0031
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0045
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2505, R²: -0.0043

📊 Round 67 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2505, R²: -0.0043

📊 Round 67 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2505, R²: -0.0041

📊 Round 67 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2505, R²: -0.0041

📊 Round 67 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2505, R²: -0.0041

============================================================
🔄 Round 74 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 74 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=-0.0020
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0085
============================================================


============================================================
🔄 Round 75 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 75 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0038
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0078
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2505, R²: -0.0040

============================================================
🔄 Round 76 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 76 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0040
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0028
============================================================


============================================================
🔄 Round 78 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 78 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=-0.0051
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0060
============================================================


============================================================
🔄 Round 79 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 79 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=-0.0065
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0030
============================================================


============================================================
🔄 Round 80 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 80 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=-0.0025
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0109
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2505, R²: -0.0038

============================================================
🔄 Round 83 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 83 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0052
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0195
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2505, R²: -0.0038

📊 Round 83 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2505, R²: -0.0038

============================================================
🔄 Round 85 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 85 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0039
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0024
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2505, R²: -0.0038

============================================================
🔄 Round 87 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 87 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0031
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0076
============================================================


============================================================
🔄 Round 88 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 88 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0051
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0031
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2505, R²: -0.0038

📊 Round 88 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2505, R²: -0.0037

📊 Round 88 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2505, R²: -0.0037

============================================================
🔄 Round 92 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 92 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=-0.0037
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0054
============================================================


============================================================
🔄 Round 93 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 93 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0047
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0004
============================================================


============================================================
🔄 Round 94 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 94 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0019
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0119
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2505, R²: -0.0036

============================================================
🔄 Round 96 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 96 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0037
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0082
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2505, R²: -0.0036

============================================================
🔄 Round 99 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 99 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=-0.0043
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0093
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2505, R²: -0.0035

📊 Round 99 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0035

📊 Round 99 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0035

📊 Round 99 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0034

============================================================
🔄 Round 105 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 105 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0039
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0046
============================================================


============================================================
🔄 Round 110 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 110 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0031
   Val:   Loss=0.0694, RMSE=0.2635, R²=-0.0162
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0033

📊 Round 110 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0033

============================================================
🔄 Round 117 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 117 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=-0.0054
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0017
============================================================


============================================================
🔄 Round 118 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 118 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0058
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0045
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0033

📊 Round 118 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0032

📊 Round 118 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0032

============================================================
🔄 Round 126 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 126 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0035
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0106
============================================================


============================================================
🔄 Round 129 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 129 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0048
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0003
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0031

============================================================
🔄 Round 130 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 130 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=-0.0028
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0098
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0031

============================================================
🔄 Round 132 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 132 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=-0.0034
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0074
============================================================


============================================================
🔄 Round 134 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 134 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0029
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0165
============================================================


============================================================
🔄 Round 136 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 136 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0068
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0071
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0030

📊 Round 136 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0030

============================================================
🔄 Round 141 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 141 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0052
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0087
============================================================


============================================================
🔄 Round 142 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 142 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0038
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0095
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0030

============================================================
🔄 Round 146 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 146 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0030
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0073
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0031

============================================================
🔄 Round 147 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 147 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0028
   Val:   Loss=0.0729, RMSE=0.2701, R²=-0.0207
============================================================


============================================================
🔄 Round 149 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 149 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0073
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0168
============================================================


============================================================
🔄 Round 150 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 150 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0118
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0589
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0031

📊 Round 150 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0031

============================================================
🔄 Round 153 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 153 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0061
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0075
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0031

============================================================
🔄 Round 154 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 154 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0032
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0111
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0030

============================================================
🔄 Round 156 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 156 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=-0.0032
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0098
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0030

============================================================
🔄 Round 157 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 157 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=-0.0029
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0068
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0030

📊 Round 157 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0030

============================================================
🔄 Round 159 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 159 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0021
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0194
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0030

📊 Round 159 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0030

📊 Round 159 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0030

📊 Round 159 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0030

📊 Round 159 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0029

============================================================
🔄 Round 167 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 167 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0094
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0341
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0029

============================================================
🔄 Round 169 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 169 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0012
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0176
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0029

============================================================
🔄 Round 170 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 170 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0039
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0045
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2505, R²: -0.0028

============================================================
🔄 Round 173 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 173 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0046
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0027
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2505, R²: -0.0028

============================================================
🔄 Round 175 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 175 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0050
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0009
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2505, R²: -0.0028

📊 Round 175 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0028

📊 Round 175 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2505, R²: -0.0028

📊 Round 175 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2505, R²: -0.0028

📊 Round 175 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2505, R²: -0.0028

============================================================
🔄 Round 184 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 184 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0034
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0156
============================================================


============================================================
🔄 Round 191 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 191 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0070
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0002
============================================================


============================================================
🔄 Round 192 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 192 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0038
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0051
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2505, R²: -0.0027

============================================================
🔄 Round 194 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 194 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0034
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0090
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2505, R²: -0.0027

============================================================
🔄 Round 195 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 195 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0061
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0059
============================================================


============================================================
🔄 Round 196 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 196 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0038
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0045
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2505, R²: -0.0028

============================================================
🔄 Round 198 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 198 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0048
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0028
============================================================


============================================================
🔄 Round 199 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 199 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0057
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0012
============================================================


============================================================
🔄 Round 200 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 200 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0037
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0045
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2505, R²: -0.0027

============================================================
🔄 Round 201 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 201 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0041
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0040
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2505, R²: -0.0027

============================================================
🔄 Round 203 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 203 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0071
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0096
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2505, R²: -0.0027

============================================================
🔄 Round 204 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 204 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0034
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0100
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2505, R²: -0.0027

📊 Round 204 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2505, R²: -0.0027

============================================================
🔄 Round 206 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 206 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0037
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0051
============================================================


============================================================
🔄 Round 207 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 207 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0034
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0072
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2505, R²: -0.0027

📊 Round 207 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2505, R²: -0.0027

============================================================
🔄 Round 209 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 209 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0053
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0009
============================================================


============================================================
🔄 Round 211 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 211 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0059
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0026
============================================================


❌ Client client_30 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
