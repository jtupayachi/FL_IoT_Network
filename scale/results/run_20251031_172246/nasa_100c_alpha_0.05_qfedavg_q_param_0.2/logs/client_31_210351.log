[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19813af0-fe11-4570-bab5-82dec9a97310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68eee9ac-b8c6-4cf3-bf48-ca1f33d57598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4caa742a-7b04-4492-a322-061f2064dde0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec01045e-b32e-40c7-984e-634bc885005a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42f00f32-3934-46b8-94fb-a47ebee307d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7305a20-c7e2-4253-971a-6d63aca7b5dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 316c5a5c-963e-434d-8dce-da41ecf6ff33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1755599d-89d6-41be-b161-c680683061e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ada091dc-13a7-47a2-be1d-ea55581a6a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffbe2f2f-85ab-4d27-b3a4-ba525c86ce8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 077224f2-2a19-4cc1-bab8-34e9f0958cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99f0fea5-a4f0-4749-ac0e-ba53cc6d977b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e3be240-a272-4f5d-b68d-78d3d46f3cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89f4dd5c-6a70-4d66-a14e-806242e59865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b120f619-4a4d-4020-a781-e040f7153c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f4536d6-f437-48f8-bd52-bbd747c9de77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 036c8e3c-ec28-4bb9-aff2-174b7d4f335c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c358b0ca-19f6-4c57-bab0-18677e272e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf4dcc4c-15ab-4625-8147-34232d14dd39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44f89b46-64d8-46df-8b54-04490a97bc44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 067bbfb0-6691-4b8a-b3b7-07126f8ca178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2003e5ec-5b13-421c-9cc5-3fb5f4335a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d4c5fbc-09ee-44c8-b21a-d2a2139ba7f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 456d5eaf-42f1-4942-9fb8-4794181d9af1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a121c6e-321b-4ba4-8477-4c1b201c0abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06e971e5-77a3-40f7-9ab9-c127839c1fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40d0471c-4f4a-4826-94ab-c0f78140028b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5933a45-8476-4e60-b419-2a4fa9c8d787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca2727a5-dce8-4549-a1e4-c0841d8244ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0835b913-b3f2-42ed-a872-66d05287486b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 901a7f25-c74e-4e58-b131-0a7d0a47bf72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c630de2-b241-41d7-b4fd-c65b84c19ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 468c4e1d-826d-4a68-ac6f-86b124354086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 012a5e22-007c-4cb7-a576-e1c21545e7ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a43d4cc-7726-4cfa-8702-a8bbf15c3b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 128a011c-6c5a-4b3b-b0e0-50353e2db6ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c4f6200-a47f-48bb-bee2-9a45a1c76cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b09d889e-3295-4256-8d93-aee1eebee5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c75ad1f-c2d5-4fb9-bd11-6ff22854b4c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c713087a-25eb-4a5a-bf13-b79f8f37f431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37a134a6-adb2-415f-896a-add036731ccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 664d3884-3181-44cf-ad36-22c3ad802161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b58ed62e-fff7-4a1c-b35d-2877315fc660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d578cd0-c6ee-46c4-b081-11712b919457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d504107a-7d3f-4f14-b821-72639fdca369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3973882-005a-4308-882e-82f1d3639136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3da3f617-4c34-450e-a5cb-15332a78916c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 071f93c4-b7d8-4410-8c0d-4dfd191a5280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e795f2ea-9897-49be-ba44-4a1083662451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f43d7891-4efd-4073-8622-a95d7d143448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bacf3acc-9fcd-4628-871a-75d1bf4a86e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4440470-a542-4a68-b434-18710640027a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9c88ab4-9ab5-44a3-bab6-0f305258287e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3680f8c9-a867-43f3-8dde-8b3022c187b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00f6f7cb-1d3e-4d2a-ad32-738b0c6c6519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 343d9509-ca4c-4a3d-b22f-805dfc15cc47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b709afe-2c8b-4d96-b01b-9f97049e48f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d71c2bdf-fbd2-4848-a78e-1e4209357ba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f34a3c4-0793-4bfd-9aad-c4b31201b1b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f82ea51-974b-46f4-87b4-ef28bc128351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e244709-b7e1-4e8a-a9f9-fda862304cd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d699e05-6130-4a5e-b4cc-47a9ad299153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b820f09-dbf9-4e78-8990-18b05259d410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48b773fe-b6ee-4d56-a9c5-05bdddc7b5ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcbeb4fb-bb0e-4cb3-b924-8447316adc3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f693fa9-4da2-45d4-b31c-e72c936b817b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20db2b98-715e-4c77-a2f6-a3db4305fd5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a90b688c-5193-48c4-9dc6-e008c7fde66f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c6d1700-e83d-4ce9-ae04-8aa173d1ac64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d54e1935-4f30-46cf-b3b7-93f4b6cbfedb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1beafff9-ee05-45a3-ae6d-7e08f68fba68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d8562a2-67ce-4282-b04f-3cfcf1e93396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b11244a0-4421-4830-a720-645cd58028e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd8c8e99-1037-4885-a21a-e34af407dfa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc343fb4-0739-438f-b710-da40ea9b6016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8690b26-ac7e-4dc6-92b8-93e963581f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aebcbd5f-5f92-4069-a881-70db64059a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12e2ab72-ca01-43f7-bde5-0fa85bc98451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a22d40f-1101-44fe-960d-c6689b1e717d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27629a03-5a98-4af1-9dc4-3d94a6cec830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 633caad5-7577-455c-9aa1-07b11cc12a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bad6761d-3e2d-4759-bc1e-0c8b1290101b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac2ad01f-4fb5-4e38-9519-a0b1b173e393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5ff517b-de6c-4dee-ad1d-3226fbc50e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e52599b-e0e6-45a9-8357-6c1524e580d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2848d3ff-b469-471e-afd7-e56a67019cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24bc2876-0984-4c07-831a-7bec10cadd3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aa3c0f1-dc0b-425b-8ae9-86a5de981b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f576c16-4862-4875-8016-9dbda4ce84bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eedb3ee-1915-42d6-adb6-790250ff7426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cd6c2ee-27dd-4e0f-bd6d-624bc9201271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09b4ef6d-71ac-460a-88da-262aa070b0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 959ddba1-45a8-4889-a6ac-b70788f90e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40a0d200-c141-4a02-b3fd-c24c1960be7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f52ac598-a170-46ce-8a65-3e26843282d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5af01f4a-1c22-4b62-9b00-242e9989869e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb7944c-c4be-4d30-93d0-9cb145d14ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d71aa9c-c049-4e5f-bf54-edbbd1b1610d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c36d27b9-a7e4-4449-826a-0bf7dba98592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57086307-d4a7-4617-a8aa-e74f1f09c15d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae9a0b7a-a467-46be-b4d2-2ca453adc573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe264611-187a-4eee-8eb1-fb88aac5733e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b44ae99-c26b-4bd6-9026-0fc180b88a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66968a7a-3d39-4da4-b70b-4754671362fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3da629c6-b4a6-4a65-a48d-b8a259c03c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b3e195d-289f-4d1b-896f-df4bb58795b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2cd0699-6753-4c1f-920b-a3fff3d54eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f072ea5-d5d6-4cf7-bfb0-4bbef7301f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0537bd2f-e6b5-4804-bb21-ea45d016fd41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff78d536-3601-4e66-81ff-9ad388311157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b457cbfc-6891-42f9-af65-9175bbac743f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cd46970-3f1b-490d-a164-62fc01618a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38adf2ca-558b-4b36-9464-489e26ce58c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1f04d3f-4b4a-4f0a-94f1-652ce86aceed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57bb882b-fe55-4336-be6a-462eb680eb1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b0728de-e442-4d19-9161-eb96a1694683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abe74de5-55c6-4a60-ab23-f68886c17ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f2c33d6-07b8-4afe-9ac5-fa27776c38c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 433e3aeb-85ba-4448-9ffb-a6366e14af4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 598c360d-5576-48c1-9ff8-f2ae3f792af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f478c9d-8ff9-425e-90ae-44efacabb323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ba80b5-0647-410e-b5d8-24ff8a43c70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de9b2b33-70f2-42ca-b7e5-7b734a0aa86c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 540469e4-a011-4bab-a717-f8dc07ff0bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20c217a7-fd5d-4ac2-a5ac-23f46c8dbdd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51ae3ea0-b639-43b9-8815-c549324ed459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d086fb01-ab68-4227-a10f-15f9efbe0405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d18d2fd7-f1c0-4301-9f6d-fceba88d1335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81db2434-c8c5-4b62-aa19-3eb6edf8f46f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdc80de5-6a8b-4cf4-8679-b3013c621898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bdc931a-fc50-4768-a2a9-2cb8d479d370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f51dda4b-ca07-41df-b00d-aa608be4d1f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b052e2c5-3b6d-470f-9c54-bef52eb82c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3070c4b2-8fc4-4770-9fca-59d62e6f4d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57c94e75-2ee7-496a-aa20-e707b49fcbf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 671d974f-d310-4b75-bd06-2091dbd679c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1476109-b714-40a0-85ea-a07a05050664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c0aaac7-823e-476f-a27f-e0f91b359625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77d55b13-ac44-47fb-8791-99495b1c31a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cc46744-ae49-42be-aafa-e5158269738b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1567a044-5956-4406-bff0-7fdadd0c98de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 757ed13b-dc0d-473b-9788-ce63d7b77b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e948952c-012d-4afc-a148-d8de43f3d6ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89fdefc9-6591-43b9-a780-39afac64b1d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62a62248-f98e-49c4-8fad-561ffa143f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21a1cd84-ad4d-40bd-b314-31574b6b703a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cb5dc35-0135-4cf1-983f-de8910ad660b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4022a6e4-6f88-4535-93e2-dc59f0838bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99db76d5-b72d-49e8-a00d-cd10210e73f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 091c97e2-a3b3-4e26-9410-1b9d71c87452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bc42482-5f02-4941-99a8-1d03554c6974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e14733d1-d63a-4754-b4fd-075218151c45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86c82542-0132-489b-b489-e7fe81d9369c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a717bb3-0e33-40d0-afb9-2f3b4de3dc70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e5082ef-46d9-4592-aee3-81e520e95449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aff4eb41-0cbe-47a5-a774-3685f9238bd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d964a610-cd2e-43c5-a045-c0231fec1a98
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_31
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/test_labels.txt

📊 Raw data loaded:
   Train: X=(1351, 24), y=(1351,)
   Test:  X=(338, 24), y=(338,)

⚠️  Limiting training data: 1351 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  329 samples, 5 features
✅ Client client_31 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1133, val=0.0873 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0869, val=0.0819 (↓), lr=0.001000
   • Epoch   3/100: train=0.0853, val=0.0822, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0843, val=0.0821, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0842, val=0.0822, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0828, val=0.0830, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 5 Summary - Client client_31
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0024
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0012
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.2003, RMSE: 0.4475, MAE: 0.3687, R²: -1.3902

📊 Round 5 Test Metrics:
   Loss: 0.1839, RMSE: 0.4288, MAE: 0.3531, R²: -1.1948

============================================================
🔄 Round 8 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1371, val=0.1268 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0895, val=0.0861 (↓), lr=0.000250
   • Epoch   3/100: train=0.0833, val=0.0896, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0828, val=0.0892, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0827, val=0.0888, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0824, val=0.0890, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 8 Summary - Client client_31
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0135
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0073
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1768, RMSE: 0.4205, MAE: 0.3464, R²: -1.1105

============================================================
🔄 Round 10 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1629, val=0.1172 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1390, val=0.1009 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1179, val=0.0889 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1008, val=0.0821 (↓), lr=0.000063
   • Epoch   5/100: train=0.0894, val=0.0817, patience=1/15, lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0838, val=0.0854, patience=7/15, lr=0.000031
   📉 Epoch 19: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 10 Summary - Client client_31
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0935, RMSE=0.3057, R²=-0.1176
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0146
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.1664, RMSE: 0.4079, MAE: 0.3363, R²: -0.9854

============================================================
🔄 Round 13 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1471, val=0.1455 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1419, val=0.1395 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1367, val=0.1339 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1318, val=0.1288 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1273, val=0.1240 (↓), lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.1091, val=0.1053 (↓), lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.0983, val=0.0935 (↓), lr=0.000004
   📉 Epoch 24: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0948, val=0.0895, patience=1/15, lr=0.000002
   📉 Epoch 32: LR reduced 0.000002 → 0.000001
   • Epoch  41/100: train=0.0935, val=0.0880, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0925, val=0.0868, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0916, val=0.0856, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.0908, val=0.0846, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0900, val=0.0836, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0893, val=0.0827 (↓), lr=0.000001

============================================================
📊 Round 13 Summary - Client client_31
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0887, RMSE=0.2977, R²=-0.0366
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0703
============================================================


============================================================
🔄 Round 15 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1344, val=0.1298 (↓), lr=0.000001
   • Epoch   2/100: train=0.1341, val=0.1295, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1338, val=0.1293 (↓), lr=0.000001
   • Epoch   4/100: train=0.1335, val=0.1290, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1332, val=0.1287 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1315, val=0.1273 (↓), lr=0.000001
   • Epoch  21/100: train=0.1290, val=0.1251, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.1267, val=0.1232, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1245, val=0.1213 (↓), lr=0.000001
   • Epoch  51/100: train=0.1223, val=0.1195, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1203, val=0.1177, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1183, val=0.1160 (↓), lr=0.000001
   • Epoch  81/100: train=0.1163, val=0.1144, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.1144, val=0.1128, patience=1/15, lr=0.000001

============================================================
📊 Round 15 Summary - Client client_31
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1127, RMSE=0.3358, R²=-0.3727
   Val:   Loss=0.1113, RMSE=0.3337, R²=-0.2399
============================================================


============================================================
🔄 Round 16 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1306, val=0.1239 (↓), lr=0.000001
   • Epoch   2/100: train=0.1304, val=0.1237, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1302, val=0.1235, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1300, val=0.1233 (↓), lr=0.000001
   • Epoch   5/100: train=0.1298, val=0.1232, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1285, val=0.1221, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1264, val=0.1204, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1243, val=0.1187 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1223, val=0.1170 (↓), lr=0.000001
   • Epoch  51/100: train=0.1203, val=0.1153, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1183, val=0.1137 (↓), lr=0.000001
   • Epoch  71/100: train=0.1163, val=0.1121, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1143, val=0.1106 (↓), lr=0.000001
   • Epoch  91/100: train=0.1124, val=0.1090, patience=2/15, lr=0.000001

============================================================
📊 Round 16 Summary - Client client_31
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1103, RMSE=0.3322, R²=-0.3452
   Val:   Loss=0.1077, RMSE=0.3281, R²=-0.1975
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0949, RMSE: 0.3081, MAE: 0.2609, R²: -0.1329

============================================================
🔄 Round 20 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0897, patience=4/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0896, val=0.0889 (↓), lr=0.000001
   • Epoch  31/100: train=0.0889, val=0.0882, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0882, val=0.0875, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0876, val=0.0869, patience=6/15, lr=0.000001
   • Epoch  61/100: train=0.0870, val=0.0864, patience=7/15, lr=0.000001
   • Epoch  71/100: train=0.0865, val=0.0860, patience=6/15, lr=0.000001
   • Epoch  81/100: train=0.0861, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0857, val=0.0853, patience=14/15, lr=0.000001

============================================================
📊 Round 20 Summary - Client client_31
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0149
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0117
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0882, RMSE: 0.2970, MAE: 0.2536, R²: -0.0524

📊 Round 20 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2511, R²: -0.0247

============================================================
🔄 Round 24 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 24 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0078
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0023
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2506, R²: -0.0187

============================================================
🔄 Round 26 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 26 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0047
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0046
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2503, R²: -0.0148

============================================================
🔄 Round 30 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 30 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0004
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0373
============================================================


============================================================
🔄 Round 31 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 31 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0020
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0046
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2502, R²: -0.0128

============================================================
🔄 Round 33 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 33 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0028
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0001
============================================================


============================================================
🔄 Round 36 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 36 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0028
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0020
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2501, R²: -0.0116

============================================================
🔄 Round 37 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 37 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0026
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0017
============================================================


============================================================
🔄 Round 38 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 38 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0007
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0088
============================================================


============================================================
🔄 Round 41 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 41 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0047
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0208
============================================================


============================================================
🔄 Round 43 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 43 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0027
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0023
============================================================


============================================================
🔄 Round 45 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 45 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0017
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0007
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2500, R²: -0.0102

============================================================
🔄 Round 46 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 46 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0026
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0023
============================================================


============================================================
🔄 Round 47 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 47 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0015
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0004
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2500, R²: -0.0099

📊 Round 47 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2500, R²: -0.0098

📊 Round 47 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2500, R²: -0.0097

============================================================
🔄 Round 51 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 51 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0032
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0045
============================================================


============================================================
🔄 Round 53 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 53 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0012
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0023
============================================================


============================================================
🔄 Round 54 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 54 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0015
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0002
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2499, R²: -0.0096

============================================================
🔄 Round 55 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 55 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0001
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0127
============================================================


============================================================
🔄 Round 56 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 56 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0009
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0017
============================================================


============================================================
🔄 Round 57 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 57 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0002
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0064
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 60 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 60 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0015
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0003
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2499, R²: -0.0093

📊 Round 60 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2499, R²: -0.0092

📊 Round 60 Test Metrics:
   Loss: 0.0845, RMSE: 0.2908, MAE: 0.2499, R²: -0.0089

============================================================
🔄 Round 65 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 65 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0009
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0022
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2499, R²: -0.0087

============================================================
🔄 Round 67 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 67 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0051
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0037
============================================================


============================================================
🔄 Round 68 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 68 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0013
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0092
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2499, R²: -0.0087

📊 Round 68 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2499, R²: -0.0084

============================================================
🔄 Round 72 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 72 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0014
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0014
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2499, R²: -0.0083

============================================================
🔄 Round 74 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 74 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0005
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0038
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2498, R²: -0.0082

============================================================
🔄 Round 76 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 76 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0006
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0161
============================================================


============================================================
🔄 Round 78 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 78 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0006
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0113
============================================================


============================================================
🔄 Round 79 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 79 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0007
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0080
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2498, R²: -0.0079

============================================================
🔄 Round 80 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 80 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0013
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0016
============================================================


============================================================
🔄 Round 82 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 82 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0005
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0016
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2498, R²: -0.0077

📊 Round 82 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2498, R²: -0.0076

============================================================
🔄 Round 84 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 84 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0026
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0328
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2498, R²: -0.0078

============================================================
🔄 Round 87 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 87 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0001
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0030
============================================================


============================================================
🔄 Round 92 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 92 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0010
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0004
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2498, R²: -0.0073

============================================================
🔄 Round 95 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 95 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0003
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0023
============================================================


============================================================
🔄 Round 97 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 97 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0002
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0038
============================================================


============================================================
🔄 Round 101 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 101 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0013
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0045
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2498, R²: -0.0069

📊 Round 101 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2498, R²: -0.0069

============================================================
🔄 Round 103 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 103 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0010
   Val:   Loss=0.0909, RMSE=0.3014, R²=0.0013
============================================================


============================================================
🔄 Round 106 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 106 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0003
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0015
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2497, R²: -0.0066

============================================================
🔄 Round 108 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 108 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0006
   Val:   Loss=0.0690, RMSE=0.2626, R²=0.0003
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2497, R²: -0.0065

============================================================
🔄 Round 110 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 110 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0010
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0051
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2497, R²: -0.0064

============================================================
🔄 Round 112 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 112 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0016
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0111
============================================================


============================================================
🔄 Round 114 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 114 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0002
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0180
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2497, R²: -0.0065

============================================================
🔄 Round 116 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 116 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0003
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0011
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2497, R²: -0.0064

📊 Round 116 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2497, R²: -0.0064

============================================================
🔄 Round 121 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 121 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0009
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0177
============================================================


============================================================
🔄 Round 122 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 122 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0003
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0047
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2497, R²: -0.0063

============================================================
🔄 Round 123 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 123 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0006
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0042
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2497, R²: -0.0063

📊 Round 123 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2497, R²: -0.0062

📊 Round 123 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2497, R²: -0.0061

📊 Round 123 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2497, R²: -0.0061

============================================================
🔄 Round 135 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 135 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0019
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0092
============================================================


============================================================
🔄 Round 137 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 137 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0015
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0267
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2497, R²: -0.0058

📊 Round 137 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2497, R²: -0.0058

============================================================
🔄 Round 139 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 139 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0007
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0046
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2497, R²: -0.0058

============================================================
🔄 Round 143 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 143 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0013
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0066
============================================================


============================================================
🔄 Round 144 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 144 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0002
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0021
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2497, R²: -0.0060

📊 Round 144 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2497, R²: -0.0061

============================================================
🔄 Round 146 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 146 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0006
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0004
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2497, R²: -0.0059

📊 Round 146 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2497, R²: -0.0061

📊 Round 146 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2497, R²: -0.0060

============================================================
🔄 Round 153 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 153 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0005
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0038
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2497, R²: -0.0061

📊 Round 153 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2497, R²: -0.0060

📊 Round 153 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2497, R²: -0.0059

============================================================
🔄 Round 157 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 157 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0009
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0160
============================================================


============================================================
🔄 Round 158 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 158 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0000
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0083
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2497, R²: -0.0059

📊 Round 158 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2497, R²: -0.0058

============================================================
🔄 Round 162 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 162 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0012
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0019
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2497, R²: -0.0059

📊 Round 162 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2496, R²: -0.0058

📊 Round 162 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2496, R²: -0.0057

============================================================
🔄 Round 166 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 166 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0019
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0209
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2496, R²: -0.0056

============================================================
🔄 Round 168 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 168 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0001
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0127
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2496, R²: -0.0055

============================================================
🔄 Round 169 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 169 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0013
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0091
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2496, R²: -0.0054

============================================================
🔄 Round 170 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 170 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0010
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0130
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2496, R²: -0.0054

============================================================
🔄 Round 171 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 171 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0011
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0024
============================================================


============================================================
🔄 Round 172 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 172 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0014
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0001
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2496, R²: -0.0053

============================================================
🔄 Round 176 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 176 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0002
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0003
============================================================


============================================================
🔄 Round 177 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 177 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0002
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0033
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2496, R²: -0.0053

============================================================
🔄 Round 179 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 179 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0001
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0036
============================================================


============================================================
🔄 Round 181 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 181 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0012
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0061
============================================================


============================================================
🔄 Round 183 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 183 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0017
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0049
============================================================


============================================================
🔄 Round 184 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 184 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0016
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0036
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2496, R²: -0.0053

📊 Round 184 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2496, R²: -0.0052

============================================================
🔄 Round 186 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 186 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0017
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0175
============================================================


============================================================
🔄 Round 187 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 187 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0001
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0011
============================================================


============================================================
🔄 Round 190 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 190 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0013
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0042
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2496, R²: -0.0053

============================================================
🔄 Round 192 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 192 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0002
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0145
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2496, R²: -0.0052

📊 Round 192 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2496, R²: -0.0051

============================================================
🔄 Round 195 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 195 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0008
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0001
============================================================


============================================================
🔄 Round 201 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 201 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0007
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0058
============================================================


============================================================
🔄 Round 203 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 203 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0007
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0029
============================================================


============================================================
🔄 Round 204 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 204 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0023
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0134
============================================================


============================================================
🔄 Round 205 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 205 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0012
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0023
============================================================


============================================================
🔄 Round 208 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 208 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0031
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0605
============================================================


============================================================
🔄 Round 209 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 209 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0007
   Val:   Loss=0.0718, RMSE=0.2679, R²=-0.0083
============================================================


============================================================
🔄 Round 210 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 210 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0010
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0031
============================================================


❌ Client client_31 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
