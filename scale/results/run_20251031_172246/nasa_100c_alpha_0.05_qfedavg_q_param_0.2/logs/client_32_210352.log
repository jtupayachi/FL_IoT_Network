[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cfe136b-dbfb-4018-beea-b3ce4ad6e067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09197e3d-5eb4-43e7-89a8-38f8e6ec2597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88d9af4c-d307-4f8c-8857-bd26daf6d814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccd1b2eb-9f89-45be-8432-1354e98e66dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a4f7495-d1ff-47cd-ae31-bd6ca8edacb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81b9ff32-d34e-48c8-b082-ca82bc30a2f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf79c4f2-7151-432d-ba9f-9a4f715b40cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af9153c2-905e-4201-8e3d-077982fb75f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb6d5839-8fc8-4c27-8773-297d9a2cd915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07177da1-be20-4602-ab1b-a790f5841b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55b413fb-8392-4f06-b6e6-728bb3379781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fdb3b2f-6326-4736-9769-0ab11b9c5932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56eb3d60-7faa-4b83-b756-bef54720acff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bedc3e85-cec5-4a23-9b73-ce2bd9b00f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c2c7b7f-e902-44f2-8422-4f5e85334fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29e0beb8-8050-4b07-900d-7ced169bc7ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f857f0c-3399-468c-915b-db48a7ad8ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 146f5c5b-77f1-45b6-8c9b-e8384707a194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 554093de-871a-4709-ab0b-92ba8f11e5c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ee02543-8c87-4118-97af-5f3aab9d6b49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 059d5990-6b4e-4336-b959-6109ab460a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b652d0-3a6f-4c31-813d-c1f156013eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71cd571b-fadb-4721-9ef1-9020600a8c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c473b9de-1dad-44c7-a41e-09a8c705b397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b755e850-7e5a-41a1-83d7-43643e476637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b85b205-60da-4ceb-85a8-2ef540bf97f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bda07280-5b8f-4dc5-8f84-96fb717fcb71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73ec15c2-497d-4625-9cc9-577cfae27e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e2a28c7-0421-4adb-b285-4dcb1b5dabda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0892cc23-daf3-4e2f-8a50-3fc9847c7051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b894c5b-3af6-4858-9c3e-dc5b7c2217bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba0f09af-b397-40fa-a014-364a1dd49855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cbb7480-e75b-40f0-af6b-3a542d693562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abc8072e-7ff4-4854-bb25-ed0f98892467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d07834da-3eb3-4069-81a5-6697ab632dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message febdf708-06cb-410c-a9f2-13075f9a3e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acb713be-1623-4fbd-a2be-d33fc3dcb31d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 937553b1-87fc-4b20-9878-81cb601b4511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68273929-f514-436e-91c1-ba408623763e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8915df2d-dd1b-4c51-b5f6-ccea7bcbe4f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0862551-50aa-485a-beb4-9e998ccb20a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca64c546-4b11-413d-b44f-afaa280f1287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 195db420-1e66-4cc1-a7a2-ec1dc469a427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aea763f-3232-4887-ae38-32c61d3bbf3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9769c363-3bf8-482c-8b2b-7c82cc5f2794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d42ea465-e0ba-41a9-a104-1fe07b69d324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0c6e02c-ebde-473f-8784-5e9cca34a1fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc6758d8-06e5-49cc-a48a-040c5b10bcdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3293ed9-b89a-4960-98da-8c008f100e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df3ffaa6-7d41-4144-971a-fb41681cb7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e5acc3c-012c-47c3-af0d-6d017125867d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96e376d1-55b3-4b6b-a1fd-db52a3799de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed0b6306-2991-4612-a8b6-c000ea814562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 756f9126-1592-4403-86cb-eede77db3c60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f3a1c4-697d-473e-869b-8f2790a4df15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c20cb91-22b5-44fb-9cfe-94afe34fa156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8428ab7d-e1e6-4f99-b376-cab68282d9f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45bdd4fc-b08f-40e2-ab0c-29d3ef6fc3c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fc002c7-72c4-453e-bd53-b2c7f0237825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 847afe57-5b8a-4c78-91ef-757a0a02f60f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba9ac36c-8f11-483a-b8c2-c6d7f08a9449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8628d496-3226-495a-9a6c-d62bf29c7842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 216aa2d7-742c-451b-9da2-1d9e5793d9cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b7f9550-6a97-49b0-9324-16175b70dbf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9854a7bf-21d1-4c89-a493-7de79e285e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a14487c-7417-43db-a4a8-74b6a3c90249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48eb4282-b70b-43b4-9dfe-3ec0ab1e48d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddbe6f09-49fb-43f3-aa3f-8120fc155581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c99a307d-e3d8-460b-bb95-eb94fb09b3ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cea1e337-0d86-4348-93a1-c72fa4774786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4187767e-4377-4187-9c00-fcdf3fc24823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a03335-ec44-426b-8ad6-a01d34c49159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeb3c69c-0760-423b-a066-f6a3cb5c1360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6f4ce0d-e471-4a16-a386-38ed5e99492d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bcba3c6-e11e-4110-ae4f-72d1eeb8f8d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 406f3ce3-028e-48e0-a9a8-7212bc0b691f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd8055cb-92d1-42c5-bdae-27858ae41171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53cc50c0-5c16-4d52-b3e5-7e41f54c69ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ff2a474-2159-4701-91e9-b000a0bde04c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 104ccf6b-91e8-404f-aeb2-5fbb2b7f2a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e6b1da9-e617-437e-94e9-ff90c11ee694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8983ad1-051c-4cc2-be02-52132f98c9d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5b01360-e26d-44ca-82a5-04ac62e74d75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84663725-1bdc-4ef9-a403-ac73482caa79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e499183-cb2d-42d4-b6b1-071ccaaf5062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bffbf89c-cb3e-4bc4-868a-302dc7d105fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 155ff117-0993-4faf-b1f5-dbf486318677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1fdf840-320c-4567-b38a-9b65508ff1d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b17ead6-c82d-4896-b137-200bb9539be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4c58a7c-fb3a-4a8f-90f3-65d3922e7ec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8724240-2d6b-4c53-936b-48256a5f524a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd3d2ce5-166a-48f6-8b5e-e83bbcfc97e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6811394-9b10-4749-b62c-1cb4330243e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c1d99e8-2696-435e-bd6c-1f0615eebbd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23aeeed0-99ca-4c63-86e4-cdf42b35c123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beb65963-58bd-4797-9003-d612c576dfe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd5ac614-7b54-451e-826f-d9df8d10b6e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3a4fb33-f662-4735-8c4c-ede97135b8ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4678d86c-a23b-4b2a-941a-1adb987927f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fea29d88-a974-4546-b016-d991423ee4dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deeb3619-7920-40b3-8efb-aba75c649abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eac669e-d881-4fa5-8f49-39906130985b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e427d3b3-76bd-4886-815d-8c0d30e42e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3702c7a3-2738-411d-a2ac-9e63c698a925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46ba3fa0-48f9-4e0c-840f-84758f83785e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3a3d822-ab26-47e9-bbc0-8537a763bb28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 057e0b1a-b66c-4338-afa9-e85ea1a68549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 041f96f0-13fc-44db-a33c-7ee832f60787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc004bff-2886-4496-a6c4-1abf989c6a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5efcb10-70bd-4ae8-9754-63f9bc948b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffad3abd-97c0-4aa5-9f49-fcd7a894ba56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8049ec2d-82c7-4268-b7b2-3a5c4bff5f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ab0e266-8291-4851-bd0e-2251a6fea480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bde37e28-77d3-4ed0-b530-14c27f979e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de29cd5a-3687-4d92-b700-38048048c19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e96ef4e-eba6-4a2f-99aa-1dfd447764bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c81c16c-055d-46d6-83ba-fa3b39cbf48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df42d013-1de2-433a-9ef0-ba2135253b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abeac264-1389-4925-b713-55018c7b8b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62789bc2-9f77-44a2-a511-27cd0eac4bfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c337664-763e-4f9b-9d14-7efdce1a46bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f06c90-4621-4f72-bad1-429ddc0ce375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8ab717d-f6a9-4608-865a-e04d2e946276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d70e4fb5-1887-4d84-82d9-497fd2ea1eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14568fac-ccb4-431a-9712-b325a16b510c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02dbbee9-a4c3-4999-b9d6-68f62199b145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e087e8a5-8ec4-453d-8640-8a18f477510b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f806a507-50b4-4b50-85f9-65f61f54013c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70bd1898-c32f-4f20-be56-3f1669adebbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c52b841-cc02-40b2-ac78-1e8b9462f60d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a74e8a99-b1eb-45de-b709-187b8f720ebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 556af6b4-a03e-491d-9f1a-e8a55114e68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f69e0915-f8d6-4c5a-b8d1-4d641781911e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11883ea3-0056-4f45-bb1b-1bc991f977ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96a45049-6800-4da2-aba3-9b0b551c9f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce884a13-6602-4fd0-b2f3-b7561c59f874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 096ca661-294a-4b3e-a2d1-9aa8b69e0a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d48cfa60-4dea-4c83-82e5-014d427eddb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 049f1f06-566d-4338-8106-b3182872655e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4a710c3-f7c8-4f0e-bfb6-6a0e167b5b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cda8bff-8d5d-454d-82b7-6e570de28a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b46b2ff6-6509-42d4-9222-46a7595d4a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d33acdaa-e692-41b6-95f5-546690e234d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 849d0c08-35e9-42b7-811b-d990ac018de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c3dfa0f-4d8f-4383-ae6b-85814eaa0223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f621d5fe-ac1a-41b4-833a-e24e2bf262bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9b720a5-f5fe-49c7-93fc-957e4055c807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b68ac5c-b778-4b34-bd6f-370ed9aee8d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dca3a2c7-e778-43e7-b635-bbef8bb5af9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 288ddc63-bd23-4cd6-b33d-465b075da6bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b216c086-b226-4e69-94f1-20e7cd8296d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8043abad-2848-4c3d-81cd-53e1d7cf33ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad6ca91e-e6a1-4382-ba22-75e45e116722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 437d0669-8a20-4f62-84d4-ca7cf3efbf40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34193eda-0217-4959-b52d-44b5d5cc183f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa0aa155-5ca0-49ba-a933-85e060cd9672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71b24b4e-045c-4c40-92d5-0e907b06834f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84563419-3649-48b6-971e-f9050ad1d732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9c74c1b-adca-49f1-819e-b0de8ef1b518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5fd3355-b7ce-4dd7-8eae-b6c67f54030a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 603f7124-0a5d-466e-96c8-ee423e1cb77e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4cbe9c8-b03d-438d-8e14-7e8e6efe7ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 528a04c6-26d7-46c3-bdf0-e4c2efc777ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d436fcf-d51d-4b7e-8c22-efedad0ab187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b762a78-54ed-4442-8391-ae67921f111d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b87a15f-1235-4d77-930c-9ead0e9f8e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e11ba732-ddeb-447a-9503-ff0b81bc4ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e9acaf7-0206-490b-96ff-2bafc901b9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d300b5b5-b3e4-40c6-b037-a8f046b2e825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df60f91f-a415-44cc-af62-fb52892c512e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37d7def6-9e25-4064-9f40-942908a7f5c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aed50431-b781-4f5b-95fa-084bfd905fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b8cc5c2-4629-47b5-8cb8-5c50f9f59df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdd4daa2-044a-4a70-870a-51d8ded91e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dca822fc-f5e5-4c4e-baf4-d9ace4f61370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a46dc5da-4cb6-4a04-8255-1a274e305c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 239bca9d-26f7-47de-8748-f4e32d4304a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 048844a0-5184-4bf2-a5cd-3e283807ddb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96683608-d3c3-49db-8cad-b5566e2c5b0c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_32
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/test_labels.txt

📊 Raw data loaded:
   Train: X=(620, 24), y=(620,)
   Test:  X=(155, 24), y=(155,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 611 samples, 5 features
   Test:  146 samples, 5 features
✅ Client client_32 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1807, RMSE: 0.4250, MAE: 0.3470, R²: -1.4822

📊 Round 0 Test Metrics:
   Loss: 0.1704, RMSE: 0.4128, MAE: 0.3355, R²: -1.3411

📊 Round 0 Test Metrics:
   Loss: 0.1616, RMSE: 0.4020, MAE: 0.3258, R²: -1.2207

============================================================
🔄 Round 7 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1142, val=0.0983 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0875, val=0.0971 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0834, val=0.0928 (↓), lr=0.001000
   • Epoch   4/100: train=0.0834, val=0.0932, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0832, val=0.0934, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0819, val=0.0938, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 7 Summary - Client client_32
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0079
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0025
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.1554, RMSE: 0.3942, MAE: 0.3190, R²: -1.1353

============================================================
🔄 Round 9 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1565, val=0.1148 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1023, val=0.0860 (↓), lr=0.000250
   • Epoch   3/100: train=0.0899, val=0.0865, patience=1/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0878, val=0.0847 (↓), lr=0.000250
   • Epoch   5/100: train=0.0878, val=0.0848, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0875, val=0.0844, patience=7/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 9 Summary - Client client_32
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000250 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0009
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0127
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1436, RMSE: 0.3790, MAE: 0.3064, R²: -0.9732

============================================================
🔄 Round 11 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1442, val=0.1114 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0968, val=0.0832 (↓), lr=0.000250
   • Epoch   3/100: train=0.0865, val=0.0837, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0850, val=0.0840, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0849, val=0.0844, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0845, val=0.0850, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 11 Summary - Client client_32
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0003
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0028
============================================================


============================================================
🔄 Round 13 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1530, val=0.1094 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1371, val=0.0962 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1214, val=0.0856 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1084, val=0.0780 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0987, val=0.0741 (↓), lr=0.000063
   • Epoch  11/100: train=0.0882, val=0.0756, patience=5/15, lr=0.000063
   📉 Epoch 12: LR reduced 0.000063 → 0.000031
   📉 Epoch 20: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0878, val=0.0758, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 13 Summary - Client client_32
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0900, RMSE=0.3001, R²=-0.0216
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0015
============================================================


============================================================
🔄 Round 14 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1480, val=0.1389 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1445, val=0.1349 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1405, val=0.1309 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1366, val=0.1271 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1329, val=0.1235 (↓), lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.1193, val=0.1109 (↓), lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.1098, val=0.1018 (↓), lr=0.000004
   📉 Epoch 23: LR reduced 0.000004 → 0.000002
   📉 Epoch 31: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.1062, val=0.0984 (↓), lr=0.000001
   • Epoch  41/100: train=0.1048, val=0.0971, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1035, val=0.0958 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1023, val=0.0945 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1011, val=0.0934 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.0999, val=0.0922 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.0988, val=0.0911 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_32
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0985, RMSE=0.3139, R²=-0.1248
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.1558
============================================================


============================================================
🔄 Round 15 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1398, val=0.1287 (↓), lr=0.000001
   • Epoch   2/100: train=0.1396, val=0.1285, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1394, val=0.1283, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1392, val=0.1281 (↓), lr=0.000001
   • Epoch   5/100: train=0.1389, val=0.1279, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1376, val=0.1266, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1356, val=0.1247, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1338, val=0.1230 (↓), lr=0.000001
   • Epoch  41/100: train=0.1320, val=0.1213, patience=1/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1302, val=0.1196 (↓), lr=0.000001
   • Epoch  61/100: train=0.1285, val=0.1180, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1269, val=0.1164 (↓), lr=0.000001
   • Epoch  81/100: train=0.1252, val=0.1148, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1236, val=0.1133 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_32
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1228, RMSE=0.3504, R²=-0.4107
   Val:   Loss=0.1119, RMSE=0.3345, R²=-0.3976
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1153, RMSE: 0.3396, MAE: 0.2744, R²: -0.5845

============================================================
🔄 Round 16 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1360, val=0.1387 (↓), lr=0.000001
   • Epoch   2/100: train=0.1359, val=0.1385, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1357, val=0.1383, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1355, val=0.1382 (↓), lr=0.000001
   • Epoch   5/100: train=0.1353, val=0.1380, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1342, val=0.1370, patience=1/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1325, val=0.1353 (↓), lr=0.000001
   • Epoch  31/100: train=0.1307, val=0.1337, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1290, val=0.1321 (↓), lr=0.000001
   • Epoch  51/100: train=0.1273, val=0.1305, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1257, val=0.1289 (↓), lr=0.000001
   • Epoch  71/100: train=0.1240, val=0.1274, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1223, val=0.1259 (↓), lr=0.000001
   • Epoch  91/100: train=0.1207, val=0.1243, patience=2/15, lr=0.000001

============================================================
📊 Round 16 Summary - Client client_32
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1157, RMSE=0.3402, R²=-0.3801
   Val:   Loss=0.1230, RMSE=0.3507, R²=-0.3244
============================================================


============================================================
🔄 Round 17 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1319, val=0.1146 (↓), lr=0.000001
   • Epoch   2/100: train=0.1318, val=0.1145, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1316, val=0.1143, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1315, val=0.1142, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1313, val=0.1140 (↓), lr=0.000001
   • Epoch  11/100: train=0.1304, val=0.1131, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1289, val=0.1117 (↓), lr=0.000001
   • Epoch  31/100: train=0.1274, val=0.1102, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1259, val=0.1088 (↓), lr=0.000001
   • Epoch  51/100: train=0.1244, val=0.1073, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1229, val=0.1059 (↓), lr=0.000001
   • Epoch  71/100: train=0.1215, val=0.1045, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1200, val=0.1031 (↓), lr=0.000001
   • Epoch  91/100: train=0.1186, val=0.1017, patience=2/15, lr=0.000001

============================================================
📊 Round 17 Summary - Client client_32
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1180, RMSE=0.3435, R²=-0.3364
   Val:   Loss=0.1005, RMSE=0.3169, R²=-0.3388
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2426, R²: -0.1996

============================================================
🔄 Round 19 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1018, val=0.1257 (↓), lr=0.000001
   • Epoch   2/100: train=0.1016, val=0.1255, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1015, val=0.1254, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1014, val=0.1252, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1013, val=0.1251 (↓), lr=0.000001
   • Epoch  11/100: train=0.1007, val=0.1242, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0997, val=0.1227 (↓), lr=0.000001
   • Epoch  31/100: train=0.0987, val=0.1212, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0978, val=0.1198 (↓), lr=0.000001
   • Epoch  51/100: train=0.0968, val=0.1184, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0960, val=0.1171 (↓), lr=0.000001
   • Epoch  71/100: train=0.0951, val=0.1158, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0943, val=0.1145 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.0936, val=0.1132 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_32
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0750
   Val:   Loss=0.1122, RMSE=0.3349, R²=-0.1810
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0736, RMSE: 0.2714, MAE: 0.2307, R²: -0.0118

📊 Round 19 Test Metrics:
   Loss: 0.0733, RMSE: 0.2708, MAE: 0.2307, R²: -0.0075

📊 Round 19 Test Metrics:
   Loss: 0.0732, RMSE: 0.2706, MAE: 0.2307, R²: -0.0062

============================================================
🔄 Round 25 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 25 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0072
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0186
============================================================


============================================================
🔄 Round 26 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 26 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0079
   Val:   Loss=0.0956, RMSE=0.3091, R²=-0.0095
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2307, R²: -0.0045

============================================================
🔄 Round 30 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 30 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0058
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0109
============================================================


============================================================
🔄 Round 32 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 32 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0049
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0129
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2308, R²: -0.0040

📊 Round 32 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2308, R²: -0.0040

============================================================
🔄 Round 34 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 34 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0046
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0246
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2308, R²: -0.0040

============================================================
🔄 Round 36 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 36 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0049
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0137
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2308, R²: -0.0039

📊 Round 36 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2308, R²: -0.0039

============================================================
🔄 Round 38 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 38 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0048
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0148
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2308, R²: -0.0039

============================================================
🔄 Round 39 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 39 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0045
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0096
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2309, R²: -0.0038

============================================================
🔄 Round 42 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 42 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0087
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0058
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2309, R²: -0.0038

============================================================
🔄 Round 45 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 45 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0047
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0058
============================================================


============================================================
🔄 Round 48 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 48 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0029
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0266
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2309, R²: -0.0038

📊 Round 48 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2309, R²: -0.0038

============================================================
🔄 Round 55 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 55 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0075
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0057
============================================================


============================================================
🔄 Round 56 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 56 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0079
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0062
============================================================


============================================================
🔄 Round 57 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 57 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0067
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0030
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2309, R²: -0.0038

============================================================
🔄 Round 59 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 59 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0037
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0410
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2309, R²: -0.0039

============================================================
🔄 Round 60 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 60 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0048
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0038
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2309, R²: -0.0038

============================================================
🔄 Round 61 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 61 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0035
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0096
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2310, R²: -0.0039

📊 Round 61 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2310, R²: -0.0039

============================================================
🔄 Round 67 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 67 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0066
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0054
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2310, R²: -0.0039

============================================================
🔄 Round 68 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 68 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0033
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0155
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2310, R²: -0.0039

============================================================
🔄 Round 70 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 70 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0052
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0013
============================================================


============================================================
🔄 Round 71 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 71 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0045
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0081
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2310, R²: -0.0039

============================================================
🔄 Round 73 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 73 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0059
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0040
============================================================


============================================================
🔄 Round 74 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 74 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0035
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0140
============================================================


============================================================
🔄 Round 76 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 76 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0061
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0017
============================================================


============================================================
🔄 Round 77 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 77 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0039
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0150
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2310, R²: -0.0040

📊 Round 77 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2310, R²: -0.0039

📊 Round 77 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2310, R²: -0.0039

📊 Round 77 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2310, R²: -0.0040

📊 Round 77 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2310, R²: -0.0040

============================================================
🔄 Round 82 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 82 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0056
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0012
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2310, R²: -0.0040

============================================================
🔄 Round 83 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 83 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0034
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0222
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2310, R²: -0.0039

============================================================
🔄 Round 85 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 85 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0051
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0142
============================================================


============================================================
🔄 Round 86 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 86 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0041
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0239
============================================================


============================================================
🔄 Round 87 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 87 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0097
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0289
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2310, R²: -0.0039

============================================================
🔄 Round 88 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 88 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0040
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0035
============================================================


============================================================
🔄 Round 89 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 89 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0036
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0185
============================================================


============================================================
🔄 Round 91 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 91 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0037
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0046
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0040

📊 Round 91 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0040

============================================================
🔄 Round 95 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 95 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0035
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0045
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0040

============================================================
🔄 Round 97 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 97 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0031
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0083
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0040

📊 Round 97 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0040

============================================================
🔄 Round 101 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 101 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0061
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0057
============================================================


============================================================
🔄 Round 103 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 103 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0024
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0637
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0041

============================================================
🔄 Round 104 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 104 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0034
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0148
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0041

📊 Round 104 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0041

============================================================
🔄 Round 108 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 108 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0029
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0406
============================================================


============================================================
🔄 Round 109 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 109 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0037
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0045
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0042

📊 Round 109 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0041

📊 Round 109 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0041

============================================================
🔄 Round 114 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 114 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0071
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0234
============================================================


============================================================
🔄 Round 115 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 115 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0041
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0014
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0041

📊 Round 115 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0041

============================================================
🔄 Round 120 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 120 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0034
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0048
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0041

============================================================
🔄 Round 122 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 122 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0040
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0160
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0042

============================================================
🔄 Round 124 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 124 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0039
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0015
============================================================


============================================================
🔄 Round 126 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 126 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0018
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0463
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0042

📊 Round 126 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2312, R²: -0.0042

============================================================
🔄 Round 129 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 129 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0042
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0064
============================================================


============================================================
🔄 Round 130 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 130 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0050
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0044
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2312, R²: -0.0042

📊 Round 130 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2312, R²: -0.0042

📊 Round 130 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0042

📊 Round 130 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0042

============================================================
🔄 Round 135 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 135 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0035
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0038
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0043

============================================================
🔄 Round 139 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 139 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0039
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0143
============================================================


============================================================
🔄 Round 142 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 142 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0032
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0301
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0042

============================================================
🔄 Round 143 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 143 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0028
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0059
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2312, R²: -0.0042

============================================================
🔄 Round 145 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 145 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0036
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0333
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2312, R²: -0.0042

============================================================
🔄 Round 146 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 146 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0032
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0025
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2311, R²: -0.0041

📊 Round 146 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2312, R²: -0.0042

============================================================
🔄 Round 150 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 150 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0029
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0090
============================================================


============================================================
🔄 Round 151 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 151 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0041
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0015
============================================================


============================================================
🔄 Round 152 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 152 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0065
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0053
============================================================


============================================================
🔄 Round 155 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 155 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0026
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0090
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2312, R²: -0.0042

📊 Round 155 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2312, R²: -0.0042

============================================================
🔄 Round 159 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 159 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0036
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0059
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2312, R²: -0.0042

📊 Round 159 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0042

============================================================
🔄 Round 162 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 162 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0023
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0052
============================================================


============================================================
🔄 Round 163 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 163 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0026
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0070
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2312, R²: -0.0042

============================================================
🔄 Round 167 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 167 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0034
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0016
============================================================


============================================================
🔄 Round 168 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 168 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0035
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0019
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0043

============================================================
🔄 Round 169 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 169 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0023
   Val:   Loss=0.0975, RMSE=0.3122, R²=-0.0064
============================================================


============================================================
🔄 Round 170 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 170 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0022
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0055
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0043

============================================================
🔄 Round 175 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 175 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0017
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0315
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0043

============================================================
🔄 Round 176 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 176 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0027
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0050
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0043

============================================================
🔄 Round 177 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 177 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0034
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0084
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0043

============================================================
🔄 Round 178 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 178 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0073
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0291
============================================================


============================================================
🔄 Round 179 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 179 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0049
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0095
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0043

============================================================
🔄 Round 180 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 180 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0043
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0071
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0043

============================================================
🔄 Round 182 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.1006 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.1006, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.1006, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.1006, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.1006, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.1006, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1006)

============================================================
📊 Round 182 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0046
   Val:   Loss=0.1006, RMSE=0.3172, R²=0.0036
============================================================


============================================================
🔄 Round 183 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 183 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0023
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0048
============================================================


============================================================
🔄 Round 184 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 184 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0023
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0059
============================================================


============================================================
🔄 Round 185 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 185 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0012
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0085
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0043

============================================================
🔄 Round 188 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 188 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0019
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0188
============================================================


============================================================
🔄 Round 189 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 189 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0032
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0004
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0043

📊 Round 189 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0043

============================================================
🔄 Round 193 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 193 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0024
   Val:   Loss=0.0695, RMSE=0.2636, R²=-0.0052
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0043

============================================================
🔄 Round 198 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 198 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0018
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0064
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0042

============================================================
🔄 Round 200 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 200 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0043
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0037
============================================================


============================================================
🔄 Round 201 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 201 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0017
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0064
============================================================


============================================================
🔄 Round 203 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 203 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0020
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0050
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0043

============================================================
🔄 Round 204 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 204 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0018
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0076
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0043

============================================================
🔄 Round 208 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 208 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0029
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0191
============================================================


============================================================
🔄 Round 209 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 209 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0043
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0013
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0731, RMSE: 0.2704, MAE: 0.2312, R²: -0.0043

============================================================
🔄 Round 211 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 211 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0026
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0024
============================================================


❌ Client client_32 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
