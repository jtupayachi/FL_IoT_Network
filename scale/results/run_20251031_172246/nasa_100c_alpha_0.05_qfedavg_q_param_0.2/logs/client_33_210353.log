[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb2f2d5c-3e5d-46ea-90d9-6fef73f72e3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab91f9bb-0627-4ff2-9fe1-97cc7beaed6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9cfa81b-46f4-482a-868f-3830a2e8ab9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3b16327-3ac4-460a-94cc-304201586c6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2657927-68be-4836-9bee-d8a0d33eae8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 391c9bd2-ae6d-4a89-9847-19c0b7e71246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ce09c65-1655-4952-99ba-ab23afd7e053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6bd06cb-ab3a-4f0e-9fee-36e4706ad68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c99efd56-0320-4eb3-8dc2-ba1deec72b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6171c50-3ed3-4f2f-935b-73fd7f928e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9e5ebb9-cdd6-4797-86a9-a1fefb2d56db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4f17a4d-828e-4c84-b668-cca275686214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 122c60bf-c6f2-4875-ab2a-9e4379a4162e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65dcf562-8bd6-4e0e-9b5a-ac4843e8f6f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a7fac5a-2d45-41ec-8183-c0db9cd4de01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f5cc287-ce4f-4bd0-b8e7-f0312b739e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c883bfbf-f508-4d24-84b1-09f62d2614bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cfd66b1-38f2-4c6f-9ca3-63ddf45d9595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9339236b-cb25-4767-beca-65849644ba95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd1a2456-322f-474e-b0ce-768db102bf13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82d50861-6e61-4d7a-b0a2-96c9a30ffda7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 209b87c6-789e-4207-b774-e5492ec5e21a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1891020d-a184-4849-96e5-c3955d696fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11d9af53-2491-4dba-b8b6-813793a8a7ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98915428-62f8-42a4-a8c4-fe34d5ddc756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 919704c6-4415-49a0-93db-24a9863ffec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 737d48f3-3d9b-439b-a959-01a8e7156f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fdb9c72-eccd-4d35-b7e9-619d5e7bc7b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98375248-3f5c-4b79-b5f8-465cdf33b0b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cbcb629-3981-4205-8aae-f1aba07435b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88a50934-decc-4bc4-9ae0-f0d628fc6cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c21ac88-2cfb-4ffe-8420-793f027ada50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7551580-8fe1-423d-89ad-8e5517e9ca01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 170f71e3-3651-45a0-ac48-64c462e49ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42019976-aba0-46b6-96e0-c7152213303b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33eef9ca-365b-4ead-a3e2-37bc19cbef62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e609898-e41b-4679-935b-69d6ff9a1bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2b16ba0-0812-41f6-ba79-15ab7bab9b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87e7687a-6964-4e72-967c-fd43fcd08656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42142b17-1042-4ca1-ada4-48b635646fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53dc77d1-23c6-46a9-a258-12b08ba2cb72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a87884d-0de5-42b9-8493-4fb854b57e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e326dbc2-3027-4dc2-9750-9654ba1604ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08dabc02-0eaa-45c6-a7ca-2d1bed276dd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9ba0b63-0546-4302-8394-a4f246dc997b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 854270a1-a420-437a-b558-bedcebebb80b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68ae73ec-2311-4d50-9f1b-961e49ea602e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d0ea019-9b65-473a-b387-7db9e811ba13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a4100e7-3b6e-4475-8788-0c4d3e26b82f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bce92a3e-a38e-4581-bf9c-b0531c417342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc8a79fd-c0fa-4931-b054-d86bd88d6af0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2e2481d-1013-45ed-a7cd-8b1a727df8ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7ddf368-7cd9-45f8-a56f-bb25f138a13b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de5a2b8a-1129-45b4-ac2d-1aa9b89e68d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a02e2f26-ef4b-4e7c-98a3-aa791dda4b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2648ebbd-2761-4851-8c47-ff1efab18e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6247efbe-17cc-427f-ad61-ec6901418de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eff0075d-d62d-4d70-8498-1201dca88e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efca5719-1d00-4360-86f5-8c935a3f4489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c3a204e-c25d-4ea0-9738-2a4885bf5425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80589375-6bf1-448e-acae-2334968477e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa2b79e8-5276-4672-af0c-b74c9f752d37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcf52890-564d-4342-baa7-3f12bdf4a2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1146999c-cec1-45a0-80f1-bc39e76cf343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 817ce33f-cc92-4fac-85ca-093c8387fca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02f40058-e5e7-4315-9653-2e14e2ac3535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5aa80c4-4ae8-491c-ace6-bdebb508f8fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2b0b15d-cd54-4c59-9945-22a1e9ee5357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d203c56e-feb2-4937-a4c9-2ee523e1fb42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0613173e-e0ea-4a3b-bfcc-31d42c585533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98ad15d0-ef02-4e54-af02-88e847a5ecfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 783cc5a2-54a5-4799-9814-d19549a417e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac68f0d9-a766-4e38-9de5-c09709d27ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d82b70df-5324-45a6-bebe-c8d85e01b37b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85375231-db7a-4447-b3b0-f776d3f0047a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc05ed9f-2be1-4fe5-a0d3-db29def89b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ae35486-0170-4fb2-976c-255f2f3550c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76444ddb-50d6-4949-b194-959a4b46782b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message befdebe1-7f4b-4fed-b213-0323e42ee70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f767bf9-f114-49fc-9568-5c5b300321c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9803292e-bf75-4ccf-969f-bd8f2d3da80b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d0d7640-5371-43d4-935c-3abd83db9f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd0fb9f1-d890-49f5-92f2-517fa793bb32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70cddc88-3eb3-40f5-bb04-8e3b514020ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9daa7d48-52cc-458c-84c3-7e0c281d1a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbd6ebac-dda0-4170-89c4-d0f7db2bf66d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6919b200-8ee9-422f-98a0-f4f2a28d2aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a901ad6d-8a0e-46a2-9328-9f076ba1b89f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ae629fa-9b9b-44a1-9148-5262188c3d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2b6dae4-a399-4126-bac5-2ecff5b5a077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6519bd4-7e3a-4f98-9c3e-e0124c76350e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a17f077-e3f5-4f92-a28c-a7d9618e4fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36a3d2bd-a25c-490f-9653-3b9051f31afa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29a392b4-fc1d-46a6-9a4b-4af1c2429711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ccefaf6-3834-49ee-8e59-923562ba88db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 892ca260-dedf-4ac7-bc46-50b6dc1d6316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01c24312-cef5-4fa9-8f9d-2e417d59f860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dcb17d6-0bec-4879-98e8-b1a0844a0979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22a653e1-6c32-42a2-99b2-1f74eb2163d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70706dac-aec0-40e1-81f5-7322ddc4a303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff420dd3-c03a-464d-8cf5-9496e792b0a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88c7d31a-5ed5-47fc-a550-6d4343dd5d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38f0e5b4-376c-4974-aa52-7363cfb33262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e175715-8f71-4b9d-aa83-5c63748b8b9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cbecb26-a821-4de4-b78c-6f64d6f8e4eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e9d6c6a-8612-4819-baff-9496788c6efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7b0ba1b-744b-44bc-94c5-e233fbc21bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 491bbf3b-2ca4-4a40-99ad-e86f43cabe58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6fb8a54-1f37-4e83-b24a-c980e521dd36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b94aea6e-babd-4298-9909-42fe6309983d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a2547a-464d-4df2-89da-fd07a02dc192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54abac05-d0f0-4ead-9498-56788156c47f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bb4d504-e4f4-4af1-b558-b9641cb4427a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6628e527-aff9-4f80-8038-46642eadea83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d60b0a1-86eb-4823-8df1-b66b2e6864de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce08267f-83f5-46d6-8b37-a23f70f61a4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd0083eb-3fd8-4ff5-bc12-208b55b97fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec6dafbc-a3d3-4bce-a0b3-c576c4ce3135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94835f02-9ef3-4d68-b994-76b97b5a87de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2414b34c-93ac-424f-bace-88d41b50a49b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95d72ce5-653a-48a1-a1ee-4790694fd660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e1b59d2-f02f-4495-9e26-84a1329d7936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4a9dc6d-8df6-449e-a57c-e05cd2c3cae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd7bc035-1ebc-4a89-8a23-13dabf32a851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59eafde0-79d5-401a-8078-cd219dfe01b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f65e1274-3bbc-4397-9ea0-1e0bdab77dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 619a735c-b7f7-41f2-b407-3fec21cac884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d15f462-2228-44b4-a42b-785a9879fd80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bb3941b-a176-4e16-a4aa-68aaf3a78a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ba471c8-6a15-4c35-86ba-095060d3379d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68d9e098-b81e-443e-b53f-bba92d5689f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b1f104f-c7d6-4142-9733-1f69aee23909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0070d3af-6cde-4aac-b51e-5232c443a893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b25b068f-f4d4-44bb-8647-807a51195836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8a18835-0e3c-4d65-b0de-edad03bfbe9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8cf2f3e-149b-43ad-a5da-7cd9e5a5f67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86d37e31-dfe1-41cc-94dc-6816cab6ab85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eed9c71-be24-4085-8a4b-cde2278c3edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1816fe88-6600-453d-9d19-f438cd4aa722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 759d94d8-5b5f-4d9f-843c-80e883a15d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b918a18-b732-47b3-8b5c-bead4c489fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d771a57d-90fd-4a46-b9a1-d9474deb8808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c31335a8-3a8d-44f6-af46-e2f601eab7dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36895195-d580-4c26-b66e-9eeb652fcba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0badd44b-c780-4c87-b40d-ae32cb745516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f648b79-bf12-4217-9d57-c3126a81b662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eef7611-273b-477c-b171-2c086ce96e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1e89e86-1eaf-443f-a3d4-a483cd94e74b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4725a87b-054c-4640-b150-424ca32e8021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0c37e8a-aeae-422b-8235-e98ad2c8bddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edd2aa36-f309-44d7-be02-01ae35c5ae56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae688969-272b-4357-9e9e-b2b99c885341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f01d806-1ffc-4fa8-ad33-7f55f6caaecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a58a0cbc-81eb-4d9f-93b2-6a2030cc8c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c92fe08c-3adf-411b-a8ab-b5baba50955a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afe5d4e9-d90d-4e95-99db-b002be0c9f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59c9b53e-53f5-4839-acee-77813f4dbb18
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_33
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/test_labels.txt

📊 Raw data loaded:
   Train: X=(2282, 24), y=(2282,)
   Test:  X=(571, 24), y=(571,)

⚠️  Limiting training data: 2282 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  562 samples, 5 features
✅ Client client_33 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1227, val=0.0867 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0832, val=0.0775 (↓), lr=0.001000
   • Epoch   3/100: train=0.0836, val=0.0771, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0834, val=0.0772, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0829, val=0.0772, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0815, val=0.0776, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 6 Summary - Client client_33
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0039
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0062
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.1848, RMSE: 0.4298, MAE: 0.3489, R²: -1.1459

📊 Round 6 Test Metrics:
   Loss: 0.1782, RMSE: 0.4221, MAE: 0.3428, R²: -1.0698

📊 Round 6 Test Metrics:
   Loss: 0.1753, RMSE: 0.4187, MAE: 0.3400, R²: -1.0362

============================================================
🔄 Round 10 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1489, val=0.1202 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0968, val=0.0815 (↓), lr=0.000250
   • Epoch   3/100: train=0.0835, val=0.0814, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0820, val=0.0817, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0822, val=0.0815, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0818, val=0.0815, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 10 Summary - Client client_33
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0020
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0089
============================================================


============================================================
🔄 Round 11 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1614, val=0.1449 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1394, val=0.1235 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1194, val=0.1057 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1027, val=0.0916 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0904, val=0.0829 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0822, val=0.0800, patience=5/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0821, val=0.0803, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 11 Summary - Client client_33
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0066
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0090
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1504, RMSE: 0.3878, MAE: 0.3160, R²: -0.7469

📊 Round 11 Test Metrics:
   Loss: 0.1314, RMSE: 0.3625, MAE: 0.2978, R²: -0.5267

============================================================
🔄 Round 18 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1169, val=0.1074 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.1122, val=0.1024 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1083, val=0.1000 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1060, val=0.0978 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1038, val=0.0958 (↓), lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.0936, val=0.0868 (↓), lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.0886, val=0.0823 (↓), lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0870, val=0.0809, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0862, val=0.0802, patience=6/15, lr=0.000001
   • Epoch  51/100: train=0.0854, val=0.0795, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0848, val=0.0790, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0844, val=0.0786, patience=11/15, lr=0.000001
   • Epoch  81/100: train=0.0840, val=0.0783, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 18 Summary - Client client_33
   Epochs: 88/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0152
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0120
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.1047, RMSE: 0.3235, MAE: 0.2726, R²: -0.2157

============================================================
🔄 Round 21 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0810, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0849, val=0.0806, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0843, val=0.0803, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 21 Summary - Client client_33
   Epochs: 34/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0370
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0059
============================================================


============================================================
🔄 Round 23 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0924, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0808, val=0.0918, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0806, val=0.0913, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0805, val=0.0909, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0804, val=0.0905, patience=11/15, lr=0.000001
   • Epoch  61/100: train=0.0803, val=0.0902, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 23 Summary - Client client_33
   Epochs: 69/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0044
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0436
============================================================


============================================================
🔄 Round 25 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 25 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0213
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0065
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2576, R²: -0.0085

📊 Round 25 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2575, R²: -0.0078

============================================================
🔄 Round 28 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 28 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0170
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0037
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2574, R²: -0.0072

============================================================
🔄 Round 29 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0788, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0834, val=0.0786, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0832, val=0.0783, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 29 Summary - Client client_33
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0068
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0167
============================================================


============================================================
🔄 Round 30 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0820, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0828, val=0.0816, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 30 Summary - Client client_33
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0062
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0266
============================================================


============================================================
🔄 Round 31 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 31 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0181
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0029
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2574, R²: -0.0062

============================================================
🔄 Round 33 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 33 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0116
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0117
============================================================


============================================================
🔄 Round 34 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 34 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0177
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0035
============================================================


============================================================
🔄 Round 35 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 35 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0153
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0014
============================================================


============================================================
🔄 Round 36 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0908, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0806, val=0.0904, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0805, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0805, val=0.0898, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 36 Summary - Client client_33
   Epochs: 42/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0023
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0542
============================================================


============================================================
🔄 Round 37 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 37 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0107
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0100
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2573, R²: -0.0053

============================================================
🔄 Round 38 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 38 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0163
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0036
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2573, R²: -0.0052

============================================================
🔄 Round 39 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0887, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0810, val=0.0884, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 39 Summary - Client client_33
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0042
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0196
============================================================


============================================================
🔄 Round 40 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0764, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0838, val=0.0761, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0837, val=0.0759, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 40 Summary - Client client_33
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0020
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0328
============================================================


============================================================
🔄 Round 41 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 41 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0108
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0058
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2572, R²: -0.0048

============================================================
🔄 Round 42 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 42 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0083
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0149
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2572, R²: -0.0046

============================================================
🔄 Round 45 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 45 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0085
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0114
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2572, R²: -0.0045

============================================================
🔄 Round 52 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 52 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0092
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0075
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0865, RMSE: 0.2940, MAE: 0.2572, R²: -0.0043

============================================================
🔄 Round 55 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 55 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0099
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0046
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0865, RMSE: 0.2940, MAE: 0.2572, R²: -0.0042

============================================================
🔄 Round 56 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 56 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0088
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0072
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0865, RMSE: 0.2940, MAE: 0.2572, R²: -0.0041

============================================================
🔄 Round 60 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 60 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0123
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0027
============================================================


============================================================
🔄 Round 61 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 61 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0082
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0092
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2572, R²: -0.0039

📊 Round 61 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2572, R²: -0.0039

📊 Round 61 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2572, R²: -0.0039

============================================================
🔄 Round 71 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 71 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0031
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0555
============================================================


============================================================
🔄 Round 74 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 74 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0027
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0383
============================================================


============================================================
🔄 Round 76 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 76 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0042
   Val:   Loss=0.0771, RMSE=0.2778, R²=-0.0227
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2571, R²: -0.0034

============================================================
🔄 Round 77 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 77 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0011
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0649
============================================================


============================================================
🔄 Round 78 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 78 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0094
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0023
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2571, R²: -0.0034

============================================================
🔄 Round 79 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 79 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0049
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0219
============================================================


============================================================
🔄 Round 80 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 80 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0036
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0285
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2571, R²: -0.0034

============================================================
🔄 Round 86 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 86 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0080
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0033
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2571, R²: -0.0034

============================================================
🔄 Round 87 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 87 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0061
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0108
============================================================


============================================================
🔄 Round 89 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 89 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0148
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0038
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2571, R²: -0.0032

📊 Round 89 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2571, R²: -0.0032

============================================================
🔄 Round 91 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 91 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0092
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0047
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2571, R²: -0.0031

📊 Round 91 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2571, R²: -0.0031

📊 Round 91 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2571, R²: -0.0031

============================================================
🔄 Round 98 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 98 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0059
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0089
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2571, R²: -0.0031

============================================================
🔄 Round 99 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 99 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0018
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0399
============================================================


============================================================
🔄 Round 100 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 100 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0052
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0223
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2571, R²: -0.0030

============================================================
🔄 Round 101 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 101 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0040
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0196
============================================================


============================================================
🔄 Round 102 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 102 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0063
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0078
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0029

============================================================
🔄 Round 104 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 104 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0046
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0134
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0029

📊 Round 104 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0029

📊 Round 104 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0029

============================================================
🔄 Round 108 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 108 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0040
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0166
============================================================


============================================================
🔄 Round 109 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 109 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0127
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0011
============================================================


============================================================
🔄 Round 110 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 110 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0023
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0289
============================================================


============================================================
🔄 Round 111 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 111 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0033
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0379
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0028

============================================================
🔄 Round 112 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 112 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0028
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0225
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0028

📊 Round 112 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0028

============================================================
🔄 Round 116 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 116 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0090
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0050
============================================================


============================================================
🔄 Round 120 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 120 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0076
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0013
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0028

============================================================
🔄 Round 121 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 121 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0022
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0311
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0027

============================================================
🔄 Round 123 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 123 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0059
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0062
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0027

============================================================
🔄 Round 126 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 126 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0033
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0329
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0027

============================================================
🔄 Round 127 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 127 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0044
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0118
============================================================


============================================================
🔄 Round 128 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 128 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0001
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0469
============================================================


============================================================
🔄 Round 131 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 131 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0084
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0029
============================================================


============================================================
🔄 Round 133 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 133 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0103
   Val:   Loss=0.0689, RMSE=0.2625, R²=0.0074
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0026

============================================================
🔄 Round 137 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 137 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0055
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0054
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0025

============================================================
🔄 Round 138 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 138 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0078
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0032
============================================================


============================================================
🔄 Round 139 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 139 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0060
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0019
============================================================


============================================================
🔄 Round 140 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 140 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0062
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0020
============================================================


============================================================
🔄 Round 141 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 141 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0056
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0034
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0026

📊 Round 141 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0026

📊 Round 141 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0026

📊 Round 141 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0026

📊 Round 141 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0027

📊 Round 141 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0027

============================================================
🔄 Round 150 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 150 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0048
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0104
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0026

============================================================
🔄 Round 151 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 151 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0070
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0002
============================================================


============================================================
🔄 Round 153 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 153 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0039
   Val:   Loss=0.0752, RMSE=0.2741, R²=-0.0141
============================================================


============================================================
🔄 Round 154 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 154 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0064
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0033
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0026

============================================================
🔄 Round 156 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 156 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0022
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0214
============================================================


============================================================
🔄 Round 159 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 159 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0038
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0193
============================================================


============================================================
🔄 Round 161 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 161 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0061
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0032
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0026

============================================================
🔄 Round 163 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 163 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0030
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0190
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0025

📊 Round 163 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0025

============================================================
🔄 Round 169 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 169 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0026
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0245
============================================================


============================================================
🔄 Round 170 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 170 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0093
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0022
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0024

============================================================
🔄 Round 179 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 179 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0074
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0006
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0024

📊 Round 179 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0024

============================================================
🔄 Round 182 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 182 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0047
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0096
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0024

============================================================
🔄 Round 184 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 184 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0138
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0059
============================================================


============================================================
🔄 Round 185 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 185 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0214
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0656
============================================================


============================================================
🔄 Round 189 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 189 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0039
   Val:   Loss=0.0954, RMSE=0.3088, R²=-0.0111
============================================================


============================================================
🔄 Round 190 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 190 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0019
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0282
============================================================


============================================================
🔄 Round 191 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 191 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0055
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0033
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0024

============================================================
🔄 Round 193 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 193 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0065
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0008
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0023

📊 Round 193 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0023

============================================================
🔄 Round 199 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 199 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0063
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0007
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0024

============================================================
🔄 Round 200 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 200 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0061
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0007
============================================================


============================================================
🔄 Round 202 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 202 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0027
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0133
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0023

============================================================
🔄 Round 204 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 204 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0077
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0056
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0024

============================================================
🔄 Round 206 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 206 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0057
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0029
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0023

============================================================
🔄 Round 209 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 209 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0070
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0024
============================================================


============================================================
🔄 Round 210 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 210 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0098
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0013
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2571, R²: -0.0023

============================================================
🔄 Round 211 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 211 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0152
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0237
============================================================


❌ Client client_33 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
