[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd34c37-6cfc-4eed-b7fd-b5f19c3eab4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e2789d4-504d-4f2f-aa7f-790765a4aca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 431a071b-8f25-4f58-bd83-338b5ba6e54e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 651b2db5-0fde-4a6b-ae4d-e204e90e2029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99e06b21-82c7-43d6-b98b-493a20264e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e07e3983-c57e-489f-8f43-9b363f73ca01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ec63698-7939-4428-b9a8-b75c42d4211c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c2f5444-afb4-411c-90b9-717fede3311f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0ce0c13-b25c-4815-9631-2bd3de125e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff252f24-9369-470e-a54e-06bc27bdea6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32d2d158-bd59-475f-ab6d-c04d4cd8b707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dea689fc-b378-4c56-82db-b425b04f5620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bf33192-4951-4a56-98e9-3050c9741f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aa13394-9e4b-487d-b16d-1e47baa6ed02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbae7e37-b314-428d-bf1d-fba521b1f2d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27976022-e51c-40a9-b59a-3a1e6e1c92bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71bab6f8-4dc7-42f8-88bf-de833f085e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b77bbc9-98e4-4056-a0c0-7a14733ba927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53210aa2-7721-4708-84e0-cca8279aaf8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3fc53a9-c48d-4153-94b3-f109afbe39a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1809c35c-6c4c-483d-895e-29d72b76e04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19c6a5f7-17d0-43a5-8bd3-e8a857cea1a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dac836d2-8e1f-48f7-ae5a-8cfc9669bb11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d35921b-a600-4555-87bd-44020bf55629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 793aef1e-f335-4e37-9eea-e42fa40dd48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6907744-3102-4702-bce9-07ddf1e52d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd648b0c-9da7-44b4-9469-eeb576c0b228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff37250d-a00f-4106-9c9d-9a369976b668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b37bfde-b568-4f3a-8d8d-bd85c7a424f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8300ca4d-b5c9-4b25-bab9-e66d595a608c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebe6b082-6690-4db0-bfd5-eb670554665a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85aa7b3b-5bbd-4e56-af4d-bd18d9c7de46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c2a18c3-757d-4789-a975-825011f59d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fd8a31f-2d83-4ae6-ae2f-ee83b4cf5cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36c8d440-2ec7-4719-a948-b2388e2307b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e2e0ef7-335c-44e1-89bd-827faf83cfdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4d8451e-299d-4ff5-8952-6ee0c76b7841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1545b9e9-075b-48b0-9d4e-c50aa5d3747f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86bef3f5-c77c-4ac2-a049-d64b347e0dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c80423f0-4b35-4e32-8351-268d4f8d16cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be9ece85-663f-495a-85e6-9a2b32b61172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3663d0a8-7a09-4ba7-a483-f2a67c49f68c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bb0d0c3-d822-4321-ab6d-f583a8e5106c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0482e453-3a24-4cde-8d02-4b8328a94059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7575ccb9-3d85-4088-8ac1-6bfe8947baa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eda136d8-7a02-4025-9b7b-6ee4061070d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73b15840-27d2-4cac-8a85-db1160adfc28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c523e0a9-4ad8-4c52-a77a-12a37ca3d960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fea2e62d-ff3a-4aa3-9a80-0983bd048a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2240e8d8-5367-49dd-a611-455fbba32ba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f8ffe77-692a-4141-a69a-b516f6f72653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1545f0c1-ccf6-47c1-af35-34fb7b293f70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message affcc674-6901-46cf-8fca-dafee7efdd6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56c00a88-1c9f-49f3-9c5a-c4f1b4c9b667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abecefc2-6f06-45f1-bf7f-7fdbd349af10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9abcb61f-9da5-4f75-878d-e5ebd6a949db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2158dff-3789-474e-af25-58b380c5413a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f679be34-6e46-42da-8b43-3268fb16c26a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab181f88-6e04-4a17-8a89-6597292ebba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee596fb1-e9c1-4ef5-a877-3606dce069f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eeae2ca-dc51-460e-b81c-19affee1d81f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c04e9fc4-23b2-4c85-b291-f6e1be11db4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bc1b1f3-09b1-4a57-b0bb-0e144e555874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac1c30c8-94d2-4002-8037-b3d4aaeb16a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f110e95-262f-4cfa-9e9b-6e800ef43355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7939b125-5601-4855-b0e4-814b73a7d162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c33682c-a543-4cc5-b3cc-b3fee1c222e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d1e1662-0a37-4ddc-9e5a-791081619139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a43ef213-fb41-49bf-9099-45a13ef2cc53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eafb9220-e49e-47a8-8d21-41ea666f2a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f2f90f7-52d2-49de-95e1-b7c348660008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a3b49b1-842d-4c18-b53a-ede14c757aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04c04b70-d0df-4a23-b51e-7384e2ddf068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3175c4ad-b0c9-4679-a8dd-fa500e145e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e36fe881-4f67-41e2-acd1-a40c2c9a4336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af0a6a53-63aa-4e48-8824-22d4ae35ebfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27a01b6f-3ede-40ab-9562-bba34cd5090a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a524f68-ee7d-4a94-a93b-49774e2d9280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8df48ef-9b6a-41df-b8b9-50e106e9c94b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2db19b6-c462-4edc-9848-1a46c8cc346e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 158d6e39-0559-4dee-b533-ec8f3591c2e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed7ae999-07ff-46e6-93f6-fba0ccf95249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf284aba-b63d-431c-ba38-4e2b059f0e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d0e75a5-3608-4719-85ea-a7fb6145e62d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1f81fa1-1e71-49e3-b46e-15df548c3f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f82eea26-2e4f-4e21-a44d-5b07bc89cf90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01c7ea91-9dfe-41f5-b94f-9bc676a8510d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee229dbf-dc77-411e-8fb8-643e741aae37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86ec2238-63a8-4f43-88ee-c4bed7c50e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5feeb864-7f74-4db3-90cc-ef425890810e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1eb7e24-d7bd-4cc1-b0d5-973805e46d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f57a435-7601-413e-9120-1a16820695f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b590ebc-3a7e-46e9-b4d2-0d1e8d342476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98c23b05-4baf-4ef9-b316-305144dc62e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed922cae-de65-4134-8b9e-e8f92c965d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a0ee58b-7d50-4836-ac86-0f1cb61a75fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e13e472-a44d-414c-8955-359d040432cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38ba7c5a-0560-4603-bfc3-5c058be7dade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09a9e6ed-902c-4dd1-82c9-a10938bcc7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ebb7b2b-e29b-4c04-88ab-49f17c621a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76262a8f-3225-4620-8374-d633ccd4a203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7776d277-2bcd-4bff-8ebc-4e923f14a24c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3863ed53-6440-480e-953e-642d108decdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd7505ce-8c19-4c49-8042-13b043c31260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9435c50c-cfa6-45d2-8a56-8d57b36a9fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f4db238-bee2-4aec-8be5-e7fdedfe4957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f32cca10-041b-4498-912e-206151d360c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6329e24e-48c2-4339-91cd-fa61968c07b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69cb4b33-6393-4a00-a7f3-cf57e3d74038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d853bc-05ea-4d49-8384-2801fb20d962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bcc7cca-ce88-42e2-92ab-4ccc30ca5d75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0af6583f-4e4f-4a05-9bc1-6886db4dc1f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1264d87e-6ab4-4eab-9096-b0dc98886c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c1f03b6-f10a-4a53-8beb-bf302dedfa58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c6c7358-08db-47a8-9167-f75b25cc9d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b241bea1-5f4d-4369-b634-7fdfd5b44e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42bdc5e0-0f1e-4648-9cd7-4b99d309956c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ccf0912-4bd0-4768-800e-6f28469c5dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f8b8dd9-56fb-4ead-aea3-43b590fc0df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25c6d237-2fab-45d6-892f-f954562f5b13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f733b47-ca1b-4445-bf7a-aab6eb01020a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59ce176e-78e7-4e50-8dc8-b89b76bdb18a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c076104-7c96-4dff-8b9a-cc4ae3b4b191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ece70cb-e235-4f7a-b318-1299bb44f1e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dc89dc1-928e-4f6e-884c-bd94ccd88a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9381140b-60d6-4496-8141-ec2698027f1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 413be343-6e23-434f-962c-293be386a5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59faf966-38da-4c39-ab74-c4196362f456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c710f095-50ca-4544-bb23-128aac189486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f56df41-1ef1-4cb5-a1f6-78b777ee0a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13800f18-ba9b-4925-9a09-a427c3e25f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54ab097a-2aa6-4516-959a-8f7ffd9e778f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f7b8272-d133-44be-9368-d2bd3b0be31b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce625d44-8479-4668-8cb0-b4da4eba486d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16e7e51a-54ed-4859-aca2-76479f1e87e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a20bc5e7-29cb-4668-b76e-f16be0532bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 782d733c-0467-41a6-93a0-e94a5036ac03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87fbb24-388c-41b1-93f3-37edae91309a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdf9fbb1-12d2-458a-9925-d9617daca3eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41f71090-b044-4bef-b395-1f033ae5a75d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d3d9d87-3935-4d9b-99d1-c2340d31cb0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9184cc16-0dc5-4297-9200-de7a5f2fbb38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd8fb755-5c80-42c8-86c6-a3e7fb0efa01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e002cb9-4d20-47b2-9e27-eead859c3821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26da1fce-168d-4f45-8f98-717fd9154fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe197747-dfd3-49a1-a2e0-b8f699e6db58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f6d6aa0-8d47-4529-be87-7125deec8b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b881bb3-e1b7-47f0-bd6f-b9fe17a7a2da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03e4ff15-e0a8-403d-bdaf-f8c12b9d7a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 531dd293-6dca-42ae-99b8-3687a7dd5905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b63175ee-5079-4f10-a425-783546e984a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92358694-4cf2-468c-b383-4b4d1082349b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0548d214-56a6-4103-82c9-bbaad7a16f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f83c1dc-efce-451f-b9b6-981cadac461d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fb19d01-80fa-4a63-8400-84d458972452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ff30d81-ed87-4de4-ada5-7d82f49170bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bf615c7-4232-43e8-9f06-84f596af9cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dedd6dc2-d53b-4335-884f-19be0fbbb3eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7607f1ca-fd52-40fd-9ef3-0f42a734739c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e78d2d35-f1ee-4289-997f-352fc7bbabe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5a51a6d-8b97-4e0e-b8b4-9116232ae191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43d09ff2-c385-4583-846a-be7440d4261c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a461479-db98-4a58-9224-77261931bfc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 903a2694-31aa-42c0-ab07-dd204f497e53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46549237-798c-498e-ad94-135b18c2e384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea99c347-b016-4ee5-9a8d-b0ce9268fff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbbfcc2f-b629-48a0-bb02-367e210fd31a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51c834d6-dd87-4bd7-8f5c-e2bfd1fedf35
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_34
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/test_labels.txt

📊 Raw data loaded:
   Train: X=(1148, 24), y=(1148,)
   Test:  X=(287, 24), y=(287,)

⚠️  Limiting training data: 1148 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  278 samples, 5 features
✅ Client client_34 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1835, RMSE: 0.4284, MAE: 0.3492, R²: -1.2112

📊 Round 0 Test Metrics:
   Loss: 0.1768, RMSE: 0.4204, MAE: 0.3422, R²: -1.1297

============================================================
🔄 Round 8 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1139, val=0.0740 (↓), lr=0.001000
   • Epoch   2/100: train=0.0859, val=0.0741, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0847, val=0.0740, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0846, val=0.0741, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0843, val=0.0741, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0826, val=0.0747, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 8 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0012
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0008
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1738, RMSE: 0.4169, MAE: 0.3391, R²: -1.0938

============================================================
🔄 Round 11 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1398, val=0.1026 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0894, val=0.0920 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0815, val=0.0888 (↓), lr=0.000250
   • Epoch   4/100: train=0.0814, val=0.0892, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0811, val=0.0897, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0803, val=0.0903, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 11 Summary - Client client_34
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0051
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0192
============================================================


============================================================
🔄 Round 12 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1512, val=0.1451 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1305, val=0.1246 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1119, val=0.1079 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0972, val=0.0954 (↓), lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   ✓ Epoch   5/100: train=0.0874, val=0.0885 (↓), lr=0.000031
   • Epoch  11/100: train=0.0816, val=0.0861, patience=4/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016
   📉 Epoch 21: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0814, val=0.0860, patience=14/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 12 Summary - Client client_34
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0035
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0092
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1481, RMSE: 0.3848, MAE: 0.3129, R²: -0.7843

📊 Round 12 Test Metrics:
   Loss: 0.1328, RMSE: 0.3644, MAE: 0.2976, R²: -0.5996

============================================================
🔄 Round 16 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1349, val=0.1205 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1322, val=0.1179 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1291, val=0.1154 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1263, val=0.1131 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1235, val=0.1109 (↓), lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1133, val=0.1034 (↓), lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.1064, val=0.0982 (↓), lr=0.000002
   📉 Epoch 23: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.1037, val=0.0963 (↓), lr=0.000001
   • Epoch  41/100: train=0.1018, val=0.0948, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1000, val=0.0935 (↓), lr=0.000001
   • Epoch  61/100: train=0.0982, val=0.0923, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0966, val=0.0911, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0951, val=0.0901, patience=1/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0937, val=0.0891 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_34
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0924, RMSE=0.3040, R²=-0.1286
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0450
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1014, RMSE: 0.3184, MAE: 0.2668, R²: -0.2212

📊 Round 16 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2528, R²: -0.0332

============================================================
🔄 Round 24 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 24 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0140
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0031
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0086

============================================================
🔄 Round 27 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 27 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0083
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0031
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2506, R²: -0.0061

📊 Round 27 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2506, R²: -0.0056

============================================================
🔄 Round 30 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 30 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0033
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0167
============================================================


============================================================
🔄 Round 31 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 31 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0041
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0137
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2505, R²: -0.0048

============================================================
🔄 Round 35 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 35 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0080
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0009
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0834, RMSE: 0.2887, MAE: 0.2504, R²: -0.0044

============================================================
🔄 Round 36 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 36 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0071
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0011
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2504, R²: -0.0042

📊 Round 36 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2504, R²: -0.0041

📊 Round 36 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2504, R²: -0.0039

📊 Round 36 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2504, R²: -0.0038

============================================================
🔄 Round 41 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 41 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0041
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0017
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2503, R²: -0.0036

============================================================
🔄 Round 44 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 44 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0051
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0036
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2503, R²: -0.0035

============================================================
🔄 Round 48 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 48 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0044
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0006
============================================================


============================================================
🔄 Round 50 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 50 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0015
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0098
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2503, R²: -0.0031

============================================================
🔄 Round 53 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 53 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0045
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0039
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2503, R²: -0.0031

============================================================
🔄 Round 57 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 57 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0043
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0019
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2503, R²: -0.0030

============================================================
🔄 Round 59 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 59 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0050
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0006
============================================================


============================================================
🔄 Round 60 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 60 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0045
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0017
============================================================


============================================================
🔄 Round 62 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 62 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0027
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0043
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2502, R²: -0.0028

============================================================
🔄 Round 66 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 66 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0045
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0029
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2502, R²: -0.0027

📊 Round 66 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2502, R²: -0.0027

📊 Round 66 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2502, R²: -0.0027

============================================================
🔄 Round 70 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 70 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0022
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0038
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2502, R²: -0.0026

📊 Round 70 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2502, R²: -0.0025

============================================================
🔄 Round 73 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 73 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0003
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0136
============================================================


============================================================
🔄 Round 74 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 74 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0052
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0029
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2502, R²: -0.0024

============================================================
🔄 Round 75 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 75 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0006
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0143
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2502, R²: -0.0023

============================================================
🔄 Round 77 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 77 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0013
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0068
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2501, R²: -0.0023

📊 Round 77 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2502, R²: -0.0023

============================================================
🔄 Round 80 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 80 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0017
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0107
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2501, R²: -0.0022

📊 Round 80 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2501, R²: -0.0022

📊 Round 80 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2501, R²: -0.0022

============================================================
🔄 Round 85 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 85 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0021
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0014
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2501, R²: -0.0022

📊 Round 85 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2501, R²: -0.0022

📊 Round 85 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2501, R²: -0.0021

📊 Round 85 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2501, R²: -0.0020

============================================================
🔄 Round 91 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 91 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0003
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0072
============================================================


============================================================
🔄 Round 92 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 92 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0053
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0020
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2501, R²: -0.0020

📊 Round 92 Test Metrics:
   Loss: 0.0831, RMSE: 0.2884, MAE: 0.2501, R²: -0.0019

============================================================
🔄 Round 97 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 97 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0067
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0023
============================================================


============================================================
🔄 Round 98 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 98 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0011
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0042
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0831, RMSE: 0.2884, MAE: 0.2501, R²: -0.0019

📊 Round 98 Test Metrics:
   Loss: 0.0831, RMSE: 0.2884, MAE: 0.2501, R²: -0.0018

📊 Round 98 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2501, R²: -0.0017

📊 Round 98 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2501, R²: -0.0017

============================================================
🔄 Round 104 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 104 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0004
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0108
============================================================


============================================================
🔄 Round 105 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 105 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0004
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0208
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2501, R²: -0.0017

============================================================
🔄 Round 106 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 106 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0002
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0136
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2501, R²: -0.0017

============================================================
🔄 Round 107 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 107 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0018
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0003
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2501, R²: -0.0016

📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2501, R²: -0.0016

📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0015

📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0015

============================================================
🔄 Round 112 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 112 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0034
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0025
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2501, R²: -0.0015

============================================================
🔄 Round 113 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 113 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0028
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0041
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0015

📊 Round 113 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0015

============================================================
🔄 Round 117 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 117 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0004
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0052
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0015

📊 Round 117 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0015

📊 Round 117 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0014

============================================================
🔄 Round 122 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 122 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0005
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0132
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0014

============================================================
🔄 Round 125 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 125 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0024
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0002
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0013

📊 Round 125 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0013

📊 Round 125 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0013

============================================================
🔄 Round 131 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 131 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0036
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0062
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0012

============================================================
🔄 Round 134 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 134 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0028
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0038
============================================================


============================================================
🔄 Round 135 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 135 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0017
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0004
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0012

============================================================
🔄 Round 137 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 137 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0007
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0082
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0011

============================================================
🔄 Round 139 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 139 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0035
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0045
============================================================


============================================================
🔄 Round 140 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 140 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0007
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0118
============================================================


============================================================
🔄 Round 141 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 141 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0010
   Val:   Loss=0.0722, RMSE=0.2688, R²=-0.0016
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0012

📊 Round 141 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0012

📊 Round 141 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0011

📊 Round 141 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0012

📊 Round 141 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0012

============================================================
🔄 Round 150 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 150 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0026
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0033
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0011

============================================================
🔄 Round 151 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 151 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0001
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0112
============================================================


============================================================
🔄 Round 152 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 152 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0006
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0084
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0011

============================================================
🔄 Round 153 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 153 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0018
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0031
============================================================


============================================================
🔄 Round 155 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 155 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0001
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0078
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0011

============================================================
🔄 Round 158 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 158 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0016
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0031
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0010

============================================================
🔄 Round 160 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 160 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0013
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0026
============================================================


============================================================
🔄 Round 164 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 164 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0014
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0029
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0010

============================================================
🔄 Round 165 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 165 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0016
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0008
============================================================


============================================================
🔄 Round 166 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 166 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0010
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0120
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0009

============================================================
🔄 Round 169 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 169 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0044
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0046
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0008

============================================================
🔄 Round 171 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 171 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0002
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0057
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0008

📊 Round 171 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0008

============================================================
🔄 Round 174 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 174 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0016
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0015
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0008

============================================================
🔄 Round 175 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 175 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0021
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0017
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0008

============================================================
🔄 Round 176 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 176 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0047
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0065
============================================================


============================================================
🔄 Round 178 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 178 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0006
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0329
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0008

============================================================
🔄 Round 180 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 180 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0026
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0005
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0008

============================================================
🔄 Round 181 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 181 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0011
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0096
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0008

============================================================
🔄 Round 182 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 182 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0004
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0184
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0008

============================================================
🔄 Round 186 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 186 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0004
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0064
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0008

============================================================
🔄 Round 188 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 188 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0006
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0133
============================================================


============================================================
🔄 Round 192 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 192 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0007
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0055
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2500, R²: -0.0007

============================================================
🔄 Round 195 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 195 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0010
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0020
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2500, R²: -0.0006

============================================================
🔄 Round 199 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 199 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0008
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0025
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0007

📊 Round 199 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2500, R²: -0.0007

============================================================
🔄 Round 201 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 201 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0005
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0058
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2500, R²: -0.0006

📊 Round 201 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2500, R²: -0.0006

📊 Round 201 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2500, R²: -0.0006

📊 Round 201 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2500, R²: -0.0006

============================================================
🔄 Round 209 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 209 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0015
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0012
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2500, R²: -0.0006

📊 Round 209 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2500, R²: -0.0006

============================================================
🔄 Round 211 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 211 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0012
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0002
============================================================


❌ Client client_34 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
