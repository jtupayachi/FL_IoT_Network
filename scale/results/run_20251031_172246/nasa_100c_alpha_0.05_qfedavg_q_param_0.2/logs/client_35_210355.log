[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 922325a0-65bc-420f-913a-bd02fc37112f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99a4eb0f-ada9-471f-ac53-0b9a3861be3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3db7a7b9-263a-4bc9-8de0-d8e82f0f0ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9aafeae-f363-49b3-b03f-6eff95555a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaea90fc-4d34-4d19-bb68-fc706abd8143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 249476ef-cf9d-4b74-95b5-a516bcd864ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df27308c-33ef-4ab7-b129-c279d330e12c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d4c15ea-f277-4b32-b70f-98579ee721dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31614d50-4c88-40d2-9d74-3984b5a22bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 884823bb-8696-4020-9e7c-801057d53074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9b9ce5f-d888-4e04-a4c2-142ff7c3c4fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31714aa4-b379-4e23-b508-782ca0f4343a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdc983b9-58be-4a32-9064-945bf959ccb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1db18ab2-99bf-4025-8d05-48dd11c921e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c6ab56d-fcc4-45bb-8bbb-1e9585871b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0b5cb26-dedf-426f-bbcd-fdbb9bda6c02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6b4b772-7dff-4803-9cea-7d371bb592e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de6f8025-0aba-4752-9132-963ed02773b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d3f2a08-6e0d-428f-9bad-f0c67abe27f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 982a66ed-ac0f-49ff-a1f1-1039d7223bab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f1b614-a3d7-4566-bef6-2fea3dfea41b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd6c99b8-6461-4e32-a7f6-f6cefcd76e10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcadb6d1-e644-496e-9436-43522644d350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 925e6c4a-42dd-4583-8bea-418d316df2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d46cf598-14f6-4413-b26f-193c8738500d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06435a39-e582-478c-9acf-611b747cc2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 353a8ce3-1866-411e-9ccd-a83ce26f114b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc1bd0ed-81a1-4bab-aec7-131d53eb7ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23471da1-34d2-461a-83d7-3666fa1a8280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dbde64b-e97f-4144-b818-8c3b276661fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c859db68-957d-48ea-bb88-fff4266758eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 427f5c04-e86e-4ef3-948c-39b07661ca26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa0755db-06fe-4c79-9c41-c4e3beacc026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f3e01eb-8dd3-4160-9f32-46bd7c54bf3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 504263e6-0b1c-47b4-bea6-3e09dd6dcfae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4ff671c-efe2-41b7-82e4-0268f95da532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0b70c7f-7b2d-4141-b0a4-392341d24ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71ab678a-8f72-448a-a796-ce83bcade486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e8136ac-4a29-4147-93f8-20b2742493e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac4951f-6211-4ab5-ae19-27f5c9017f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f58b993-8719-4875-b5b9-11517f397a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ddf327f-4ddf-4a89-9e94-7f4788266d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 810be916-fee5-4f41-ac07-b27f8680522f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b786458c-aed8-4465-933f-9f89f5f95c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c24439d-e2c2-48b5-afe0-cfdae2b857ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9012e523-0af8-4dff-86de-944e16fca60b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cc7ed23-12a7-4844-bbba-5c121c76e5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2440acf-2070-45c5-bf3f-b7a3454302ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61a3a598-3e68-4a2c-bc41-859f9359cdd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79256655-6e1e-4769-b7a0-df03534a3cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14c32c40-6443-43f5-9dfc-fefe5ee4e90e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 510b697c-1b9d-4835-9734-9e878113fb17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7febb367-442f-4472-9428-5a46956b46b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea516bc9-a4d1-4a52-9537-876945000f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd3644d5-febb-4b73-90f8-b0601b94af82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ded3f74e-7de7-4abd-9cf1-123ca8af68be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b27445c-ce67-411b-a4eb-4b9aea87a885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a4babe0-18bd-4106-85b0-1cf4ec8819a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35a2652b-abba-47de-89e9-da39119d41b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24798e10-b914-4fb2-bb91-9cf47e1a3ac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b16a22f1-80ad-41ae-9548-fe14db058b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caa247b6-6d3d-4896-87e0-67026fa87cee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63c8c7ac-61b7-4fe2-9050-254f6d5719d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21b90bd5-a555-44df-aa2d-40b396f57bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc65dbcc-f89f-408b-abf2-df0afa2dff3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7920de6f-fef7-448c-8c10-19c15387439b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88b3acb0-a67f-47b7-afba-0d30760228fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c85789ca-d1b4-4d3f-a233-77b9f26973df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 446d8241-1710-4e1b-88af-8ad876278c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b032b3c0-c534-46da-8c78-038a73d7e71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c0d798a-9088-43c6-9b38-37065bacc4f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 052c541c-95d3-4029-929c-9ddf6cbb2a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e1206a8-1fcf-4f3e-8b26-5a85c5ed1fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a5a80b-fd76-48ee-9279-71ae210d6345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60957b3e-bae9-4eca-8e1a-f79803d4752d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ea76871-8097-4b30-b204-439f460e6b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87caff9-69c7-4b82-9713-f16cd0a59cb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77307326-f427-49a1-b434-7d7cd3c3b330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ccf5c7-39fa-4f8b-8fe7-e2e2231c505e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25e1877f-cbc1-4328-a9d3-22766ae1d61d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08a84cea-948f-4f1c-a017-020456283314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99a0a082-ef57-41aa-add2-e641f921acaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cad78cf-8a4a-4d8f-b797-f5d3cb8f60d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16c7842c-047b-4137-920a-17d20d9cc55f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2dbf095-22e0-4e58-b0a4-1abf25f9f9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2d3c19e-2b46-4112-8614-e2bdd3deda70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 084fe1d0-4ede-4207-9b93-396f57db9ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 379fab19-4efb-4928-9a28-ee9b74c7131a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 881a5eb0-0e96-4eb8-ae36-2d4e64c7fa5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 953f3f08-e799-461d-897d-a0fc63945a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f7c8bf1-1851-4b90-aea0-f70769f630ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4604e45-5617-4579-8d17-d66a6e940bc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c26fe6fa-7a0b-4cb7-9279-3d61908e74f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e52f7233-4445-4a4f-8416-68110838b7e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f789a071-f417-4978-8c3b-8d5b2005a710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4767fdbc-98cf-4656-9582-3f98977e0b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a39fc5-a639-4658-9eb0-ce2e0ed68a3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1533c90-ea76-4657-82e5-a16338173059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fe683db-370e-487c-b7bb-cbe9833afd50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38255708-9358-498b-a823-2e20d84642e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56f52ed2-1f88-4acd-a175-1f79b0714867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f667d76-476b-4bf5-86df-672d4567641b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33af90b4-1217-4cb0-89d9-ccaefdac8f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc4f7aea-299a-4577-9a4a-41c6148c3868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a00c4387-6177-4d3a-942f-79b1ea4af0ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 604086fa-42db-4508-8be6-87f8d4c1451e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f53d2fb4-6c4f-4a76-89fc-b15aaeddc129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3569eda1-beb5-4124-a50a-ddf95e844d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 298e67c0-fda4-40f9-bf89-d03cb4edf65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1ea9e9f-eff3-4958-99ea-81e1790648e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ba52a13-1018-40bc-88a9-4040c3862ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6faf710-80e9-41e9-b716-a70e9e3052a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a73ecc0-413f-4564-aa0e-a692153fd009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d00b7db-c4d1-4fda-8b2b-22f374c4a0fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31065a8b-f1eb-49a7-b932-11cc84cb23c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92a7296a-0a44-419a-963c-b983ace2ba8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7aec7a5-924e-4450-b76a-7860d1ca0812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61f32bd5-b826-4fab-869f-59971fe3e696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5898b5e-5eb0-4dd3-90d9-c37afec9c7f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cebdf984-92f7-42f0-bf1f-e06b13f36da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1100db9f-a899-4497-87f3-745a55f2d3ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d0fbf19-c938-4212-b0d5-1b0d69cc6b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cb95dbd-24a3-4ec1-9a0f-5c3ad14bbf8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0a88728-f679-435a-b340-422f20a6a241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a3f9da5-1a43-42d0-8734-e4060a87ffa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 586d50c1-498a-400d-91f4-d7ee510ca5b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a0414cf-051e-4565-b260-ee61e5eef7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5a84ce4-384d-437a-9bf6-2d9739474097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 164595ad-65a1-4e72-b089-6ddd65623d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce93dde2-560a-402b-b780-412ca5c3ddef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c72bfce-b660-4457-9036-72e6ac632754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0ae24af-a36c-421c-bc79-fd0459a429e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 878390d6-978d-4e02-91d2-6841eb6d6408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ee1ac46-ba70-4975-9b61-aac757666ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b56b524-5085-444c-ae1d-9cb76fb7532f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07d2bec7-3468-4ed5-b619-22c6934592e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 636e3deb-653d-4a16-a3e6-f5a6df0a7082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3afce679-faa2-4541-aca5-162c39e0a2be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b619ef2c-9f92-4270-b630-07487d768830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 318e79c4-fe83-4389-9e3c-a6cf4f685c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ec6c52e-438e-47ad-a872-3b9d3e0d7e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5c3d28c-1fc8-493e-ad75-cff5f0c3d566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c73c9846-46ad-499c-8a59-ca9b3c98d2b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d72516d7-7f18-453e-b822-915422686d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa144a8a-4397-46ff-9171-f90da7dec806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5c08e2d-dc0b-4684-809a-22dfa393c9dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 561c06db-aa2e-4d2a-9a26-43e8b6cdd699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 360ea3a8-521b-49fb-b149-a51ebb90a660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0f6bc60-be17-4009-b7a2-4bb33d86827e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0507b133-b852-4925-8041-41befc720709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b505edc-d59e-46b4-93b0-695d8a75556c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4bb4c62-6c6d-46dd-a1f6-e958d6d8c32c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a97fd38-31a1-4deb-aef9-f5df1ce17465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b33c9e3-6f4a-444d-b4af-3729fb2c1c96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba80c098-7ae1-4128-9b30-46b45c103b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40c55511-6af3-4714-8105-93eda80a63d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed465021-7f08-4f6f-b87c-0dcd1707ef34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5621e97a-e889-4a94-84a1-ee766f995857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e584bf58-5fc2-44bb-bbfd-674180181db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10e8562e-7e7a-4816-a5a4-662eeff0fd82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6258c778-8680-470d-b43a-67a6be52a134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efeeaa52-7f13-45f5-a9bf-29c3f1807d1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5c8d967-5d37-4464-9dfb-dcc382430504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aff51be1-9fea-465a-b395-8838bd2b36c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e638c80a-fa02-4514-971d-97bedc34442b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abb1c994-a81f-454c-84e2-a82dbfc910d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2e19648-f555-41be-8751-7a13538e2432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0931f4d4-828d-4999-b909-9d6df1f124eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f851a8b-43de-474b-a00b-da88bd95ac0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 634a55e5-a9d3-4fbf-a4b5-05287f37925a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a0b160a-36be-4e82-b4a9-bd426460de27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 904f417f-bba1-4c32-bbdb-788fa565a5bb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_35
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/test_labels.txt

📊 Raw data loaded:
   Train: X=(1627, 24), y=(1627,)
   Test:  X=(407, 24), y=(407,)

⚠️  Limiting training data: 1627 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  398 samples, 5 features
✅ Client client_35 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1967, RMSE: 0.4435, MAE: 0.3639, R²: -1.4390

============================================================
🔄 Round 6 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1136, val=0.0869 (↓), lr=0.001000
   • Epoch   2/100: train=0.0865, val=0.0867, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0858, val=0.0869, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0854, val=0.0867, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0853, val=0.0866, patience=4/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0846, val=0.0871, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 6 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0147
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0111
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.1771, RMSE: 0.4208, MAE: 0.3441, R²: -1.1954

============================================================
🔄 Round 11 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1198, val=0.0829 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0899, val=0.0782 (↓), lr=0.000500
   • Epoch   3/100: train=0.0878, val=0.0785, patience=1/15, lr=0.000500
   • Epoch   4/100: train=0.0877, val=0.0779, patience=2/15, lr=0.000500
   • Epoch   5/100: train=0.0876, val=0.0780, patience=3/15, lr=0.000500
   • Epoch  11/100: train=0.0874, val=0.0779, patience=9/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 11 Summary - Client client_35
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0074
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0015
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1625, RMSE: 0.4031, MAE: 0.3297, R²: -1.0144

============================================================
🔄 Round 14 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1228, val=0.0855 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0898, val=0.0770 (↓), lr=0.000250
   • Epoch   3/100: train=0.0884, val=0.0773, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0880, val=0.0769, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0879, val=0.0771, patience=3/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0875, val=0.0775, patience=9/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 14 Summary - Client client_35
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0082
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0049
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1402, RMSE: 0.3744, MAE: 0.3079, R²: -0.7383

============================================================
🔄 Round 15 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.1214, val=0.1055 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0968, val=0.0931 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0878, val=0.0886 (↓), lr=0.000063
   • Epoch   4/100: train=0.0853, val=0.0883, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0850, val=0.0883, patience=2/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0847, val=0.0885, patience=8/15, lr=0.000031
   📉 Epoch 17: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 15 Summary - Client client_35
   Epochs: 18/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0021
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0132
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1350, RMSE: 0.3674, MAE: 0.3030, R²: -0.6737

📊 Round 15 Test Metrics:
   Loss: 0.1307, RMSE: 0.3615, MAE: 0.2990, R²: -0.6202

============================================================
🔄 Round 17 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1221, val=0.1315 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1168, val=0.1257 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1113, val=0.1205 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1064, val=0.1160 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1023, val=0.1120 (↓), lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.0898, val=0.1010 (↓), lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0851, val=0.0967, patience=1/15, lr=0.000004
   📉 Epoch 23: LR reduced 0.000004 → 0.000002
   📉 Epoch 31: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0842, val=0.0959, patience=7/15, lr=0.000001
   • Epoch  41/100: train=0.0840, val=0.0957, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0838, val=0.0955, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 17 Summary - Client client_35
   Epochs: 51/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0113
   Val:   Loss=0.0958, RMSE=0.3095, R²=0.0050
============================================================


============================================================
🔄 Round 18 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1102, val=0.1190 (↓), lr=0.000001
   • Epoch   2/100: train=0.1099, val=0.1186, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1096, val=0.1183 (↓), lr=0.000001
   • Epoch   4/100: train=0.1093, val=0.1180, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1090, val=0.1176 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1074, val=0.1159 (↓), lr=0.000001
   • Epoch  21/100: train=0.1051, val=0.1133, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.1032, val=0.1110, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1014, val=0.1090 (↓), lr=0.000001
   • Epoch  51/100: train=0.0997, val=0.1071, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0982, val=0.1053, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.0968, val=0.1036, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0954, val=0.1020, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0942, val=0.1005, patience=3/15, lr=0.000001

============================================================
📊 Round 18 Summary - Client client_35
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0930, RMSE=0.3050, R²=-0.0898
   Val:   Loss=0.0993, RMSE=0.3151, R²=-0.1416
============================================================


============================================================
🔄 Round 19 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0977, val=0.1108 (↓), lr=0.000001
   • Epoch   2/100: train=0.0976, val=0.1106, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0974, val=0.1104, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.0972, val=0.1102 (↓), lr=0.000001
   • Epoch   5/100: train=0.0971, val=0.1100, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.0962, val=0.1088, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0949, val=0.1071, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0936, val=0.1054, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0924, val=0.1038, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0913, val=0.1023, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0903, val=0.1009, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0894, val=0.0996, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0886, val=0.0983, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0879, val=0.0972, patience=4/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_35
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0320
   Val:   Loss=0.0963, RMSE=0.3103, R²=-0.0783
============================================================


============================================================
🔄 Round 20 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0958, patience=5/15, lr=0.000001
   • Epoch  21/100: train=0.0884, val=0.0949, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0877, val=0.0942, patience=6/15, lr=0.000001
   • Epoch  41/100: train=0.0870, val=0.0935, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0865, val=0.0930, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0861, val=0.0925, patience=11/15, lr=0.000001
   • Epoch  71/100: train=0.0857, val=0.0922, patience=9/15, lr=0.000001
   • Epoch  81/100: train=0.0854, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0852, val=0.0916, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 20 Summary - Client client_35
   Epochs: 92/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0092
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0194
============================================================


============================================================
🔄 Round 21 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 21 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0152
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0130
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2501, R²: -0.0279

📊 Round 21 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2489, R²: -0.0159

📊 Round 21 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0134

📊 Round 21 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2484, R²: -0.0107

============================================================
🔄 Round 27 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 27 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0009
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0033
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: -0.0105

============================================================
🔄 Round 28 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 28 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0006
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0030
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2483, R²: -0.0098

📊 Round 28 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: -0.0088

📊 Round 28 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2481, R²: -0.0083

============================================================
🔄 Round 33 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 33 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0023
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0077
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2480, R²: -0.0079

📊 Round 33 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2480, R²: -0.0076

============================================================
🔄 Round 38 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 38 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0006
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0007
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2478, R²: -0.0065

============================================================
🔄 Round 40 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 40 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0011
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0015
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2478, R²: -0.0063

============================================================
🔄 Round 41 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 41 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0001
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0030
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2478, R²: -0.0060

📊 Round 41 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2477, R²: -0.0058

============================================================
🔄 Round 44 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 44 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0005
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0102
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2477, R²: -0.0058

============================================================
🔄 Round 47 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 47 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0001
   Val:   Loss=0.0930, RMSE=0.3050, R²=0.0002
============================================================


============================================================
🔄 Round 49 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 49 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0003
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0014
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2477, R²: -0.0053

============================================================
🔄 Round 51 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 51 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0000
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0020
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2477, R²: -0.0052

============================================================
🔄 Round 52 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 52 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0006
   Val:   Loss=0.0881, RMSE=0.2967, R²=0.0004
============================================================


============================================================
🔄 Round 54 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 54 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0004
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0005
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2477, R²: -0.0052

============================================================
🔄 Round 56 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 56 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0006
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0029
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2477, R²: -0.0052

📊 Round 56 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2477, R²: -0.0053

📊 Round 56 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2477, R²: -0.0051

📊 Round 56 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2476, R²: -0.0050

============================================================
🔄 Round 60 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 60 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0006
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0049
============================================================


============================================================
🔄 Round 62 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 62 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0006
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0105
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2476, R²: -0.0048

📊 Round 62 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2476, R²: -0.0047

============================================================
🔄 Round 66 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 66 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0004
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0013
============================================================


============================================================
🔄 Round 67 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 67 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0013
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0030
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2476, R²: -0.0047

============================================================
🔄 Round 68 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 68 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0004
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0002
============================================================


============================================================
🔄 Round 69 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 69 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0006
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0072
============================================================


============================================================
🔄 Round 72 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 72 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0002
   Val:   Loss=0.0965, RMSE=0.3106, R²=-0.0003
============================================================


============================================================
🔄 Round 73 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 73 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0010
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0055
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2475, R²: -0.0042

============================================================
🔄 Round 75 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 75 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0011
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0077
============================================================


============================================================
🔄 Round 77 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 77 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0012
   Val:   Loss=0.0951, RMSE=0.3083, R²=-0.0218
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2475, R²: -0.0039

📊 Round 77 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2475, R²: -0.0039

📊 Round 77 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2475, R²: -0.0039

============================================================
🔄 Round 82 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 82 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0007
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0440
============================================================


============================================================
🔄 Round 85 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 85 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0008
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0014
============================================================


============================================================
🔄 Round 86 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 86 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0012
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0109
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2475, R²: -0.0039

============================================================
🔄 Round 88 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 88 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0001
   Val:   Loss=0.0876, RMSE=0.2961, R²=0.0004
============================================================


============================================================
🔄 Round 89 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 89 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0002
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0010
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2474, R²: -0.0037

============================================================
🔄 Round 90 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 90 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0002
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0130
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2474, R²: -0.0036

📊 Round 90 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2474, R²: -0.0034

📊 Round 90 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2474, R²: -0.0034

📊 Round 90 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2474, R²: -0.0034

============================================================
🔄 Round 98 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 98 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0009
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0245
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2474, R²: -0.0035

📊 Round 98 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2474, R²: -0.0034

============================================================
🔄 Round 100 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 100 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0013
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0046
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2474, R²: -0.0033

📊 Round 100 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2474, R²: -0.0033

============================================================
🔄 Round 102 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 102 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0004
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0129
============================================================


============================================================
🔄 Round 104 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 104 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0019
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0088
============================================================


============================================================
🔄 Round 105 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 105 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0003
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0071
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0030

============================================================
🔄 Round 109 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 109 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0008
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0078
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0029

============================================================
🔄 Round 110 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 110 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0004
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0025
============================================================


============================================================
🔄 Round 111 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 111 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0005
   Val:   Loss=0.0971, RMSE=0.3117, R²=-0.0056
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0028

============================================================
🔄 Round 113 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 113 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0024
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0007
============================================================


============================================================
🔄 Round 114 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 114 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0011
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0169
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0029

============================================================
🔄 Round 116 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 116 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0028
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0232
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0029

============================================================
🔄 Round 117 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 117 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0000
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0003
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0030

📊 Round 117 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0029

============================================================
🔄 Round 120 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 120 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0001
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0083
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0029

============================================================
🔄 Round 122 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 122 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0007
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0026
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0028

============================================================
🔄 Round 123 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 123 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0011
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0054
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0029

============================================================
🔄 Round 124 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 124 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0000
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0009
============================================================


============================================================
🔄 Round 125 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 125 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0005
   Val:   Loss=0.0935, RMSE=0.3057, R²=0.0016
============================================================


============================================================
🔄 Round 127 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 127 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0004
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0315
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0027

📊 Round 127 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0027

📊 Round 127 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0026

============================================================
🔄 Round 134 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 134 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0012
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0048
============================================================


============================================================
🔄 Round 135 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 135 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0003
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0098
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0025

📊 Round 135 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2473, R²: -0.0024

============================================================
🔄 Round 141 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 141 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0009
   Val:   Loss=0.0935, RMSE=0.3057, R²=-0.0007
============================================================


============================================================
🔄 Round 142 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 142 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0016
   Val:   Loss=0.0840, RMSE=0.2897, R²=0.0033
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0025

============================================================
🔄 Round 143 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 143 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0011
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0056
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0026

📊 Round 143 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0026

📊 Round 143 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0027

============================================================
🔄 Round 146 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 146 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0008
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0025
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0028

============================================================
🔄 Round 149 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 149 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0012
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0041
============================================================


============================================================
🔄 Round 150 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 150 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0028
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0166
============================================================


============================================================
🔄 Round 154 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 154 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0012
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0034
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0027

============================================================
🔄 Round 155 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 155 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0000
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0008
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0027

============================================================
🔄 Round 158 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 158 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0020
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0060
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0026

============================================================
🔄 Round 159 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 159 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0007
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0326
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0026

📊 Round 159 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0026

============================================================
🔄 Round 162 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 162 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0000
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0128
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2473, R²: -0.0025

============================================================
🔄 Round 167 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 167 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0022
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0053
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2473, R²: -0.0024

============================================================
🔄 Round 168 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 168 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0005
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0008
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0022

============================================================
🔄 Round 174 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 174 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0015
   Val:   Loss=0.0915, RMSE=0.3024, R²=0.0038
============================================================


============================================================
🔄 Round 176 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 176 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0016
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0045
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0022

============================================================
🔄 Round 180 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 180 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0011
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0195
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0022

============================================================
🔄 Round 183 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 183 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0011
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0013
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0024

============================================================
🔄 Round 188 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 188 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0004
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0026
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0023

📊 Round 188 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0023

📊 Round 188 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0022

📊 Round 188 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0022

📊 Round 188 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0021

============================================================
🔄 Round 196 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 196 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0008
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0041
============================================================


============================================================
🔄 Round 197 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 197 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0005
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0020
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0023

📊 Round 197 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0023

============================================================
🔄 Round 200 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 200 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0009
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0019
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0022

============================================================
🔄 Round 204 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 204 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0008
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0104
============================================================


============================================================
🔄 Round 206 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 206 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0022
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0102
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0021

============================================================
🔄 Round 207 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 207 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0004
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0115
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0022

============================================================
🔄 Round 209 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 209 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0006
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0172
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0022

📊 Round 209 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2472, R²: -0.0021

============================================================
🔄 Round 211 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0996, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0996)

============================================================
📊 Round 211 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0004
   Val:   Loss=0.0996, RMSE=0.3157, R²=-0.0004
============================================================


❌ Client client_35 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
