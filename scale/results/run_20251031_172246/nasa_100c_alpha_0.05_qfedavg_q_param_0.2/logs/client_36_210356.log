[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04ca13b8-b243-4f94-9171-5396c325580a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60d881f2-04ab-4843-a452-9561f62befd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c7df860-5919-41ff-abb6-85af6c37b128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ec14cd-9ff3-47ad-bbc2-0b133460cd88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acbe81a4-4163-4fdf-b3cb-c14b08234efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 522f3040-4b1b-440a-84f4-c7478f6b4ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a2cea2-511c-4ec5-820c-c4517fad243a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43fb7bf4-697e-4612-98c9-b78e3e993593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f22544db-e62d-42b8-b664-03f1764bedd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 870616dd-9e5b-4c7d-9696-beb67f45340b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68f83dd7-f719-47ae-828d-554af54493fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54f99e83-e9e3-4e99-a812-88ae4e887aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed20d7de-b8fb-4fec-945c-6c7b0013ac13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3fcf22f-2294-4ab4-bf86-a5a59b0bb7d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b1116fa-f1d5-4f59-8519-ad35beade5b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 667b6c66-cef9-4747-bfe5-1987f73d35e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42bdf0aa-41a5-493a-ab42-dc780f04ec19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 632d6b50-cd6d-4821-9eab-b442addd55aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31fcca5f-7a57-432d-9852-fcd1b4d96196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06ba58e0-3b41-4d8a-a9e2-2f66a0cc8ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 361bbcd3-fcb9-4c2e-b1f6-9b40c647d882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce8a0be0-5f51-4b5c-9009-41a745aecaf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bfd35e1-605a-4ae3-810e-57af62f1b1bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8fdec3b-90a3-4e5c-abd7-74c683f164b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bed55691-bd98-4b97-8b4a-40d309ffd663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 497a05e4-8200-468b-b349-4b7752d50854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cefc9ed5-eb0c-4cea-957d-407dbf6891d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f65e69c-c166-43af-90e1-4285639d16a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed749748-9180-420d-8d61-e62ea8f0e71f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d92460ff-2219-454b-808f-0026a852d3ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccafb9d3-3d0b-4e7b-a528-3dc0a052f7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6590945e-cf74-4ede-925f-0485cfe31678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a174c937-ecb2-4b51-aa1f-3f66f400e429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d4002f3-fdd2-4fc9-a0b8-d375c7864f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52389f87-94cb-4cd6-b8c5-ff64f0543696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c68b4960-713e-4c51-a4d6-1e30b9d95f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ada9c23e-8dff-4341-8b96-d194c83c10e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3d9e7f5-42e8-4fa6-adf0-d0249be0b3b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa2f85ab-1ca1-4302-8aad-1da0b2441b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49d205a9-9339-4a14-b400-8ebcf51436a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 957d427b-1378-4c49-9185-f1be56b3816f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d2bc16b-66f9-42bc-ba35-35b15dd54220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17b7d454-14c1-41dc-b44e-6b4936085475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e65d899-fde1-45f3-82d1-70ee467f18b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a483162e-0ed1-4be8-ab97-6cf80ee03f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fd9e249-234a-4870-a326-53224e207bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfa91891-b775-479c-a2d5-5153799a3f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22a4ea3e-5a26-448b-8578-6d91df6be460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed083745-d391-479c-a1b9-24d2871fe5e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ce4827c-dc75-4f2e-a604-94ccc66caae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9275d12-17f9-475f-a671-211eeada8447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 192bf26e-da67-4a48-9883-dc63a311c17c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f3c178e-7269-49e0-9640-b99afac2515b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3450c952-b1b3-499c-a488-99413cc0d58f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91f5dc9e-d0e8-41ea-91b4-2ba2b25c5494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b83813e3-d931-46c1-9731-16d3b05a6ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b83b41f2-c7e2-4b76-bdad-e666ddd68441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91342aa1-1e3f-4bbc-9804-e254c92475de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 597331bd-e5c1-4293-8182-f37bb21e67d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff3e15f7-f611-45a8-afb8-1d48d7df51d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 556c7209-9083-4e3b-b6f9-410287d151a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e799c607-7c9f-4e9e-bdcf-674094c1f611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 393e69cd-65a0-4298-967e-9c1ba1e9014c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d104baa-18c3-4038-833c-f058bada5398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d79839a8-1fec-4589-8cba-98786f07e535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e687af5-1a06-4c93-8872-f3d24f6c1f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cae98f9-db66-4a8e-8014-be0a81e15855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22bc640f-d775-4aeb-926d-bbf0985c26af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82e25a49-2b55-4370-a09e-3262800b1848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fa45d2d-d12c-4bd2-b33a-72ee0cf7c59e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc772921-9756-442a-82d4-5625d89c4f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41ba4a68-edbb-49f4-bdac-83ce0bec1307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9c03725-bb30-4a38-98c1-b4c8e965e1d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f535c547-9964-421a-8c16-62dfe95375cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 321b4257-ddd0-46a1-b542-4c3f31818b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 223bd317-7bae-426e-bea1-3a06336e73f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c170d271-b976-4b53-81a3-d202d8cf3311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 652d13f4-5bbd-45df-9f3e-e2556ca84dad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3726a65-dd9d-400e-9708-fb7d5652c4c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b277bfc3-022a-49eb-9640-cd0f977c03ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba957d46-8005-4bad-ac9c-91a1cdfeb491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1323a95a-3ba5-40a1-aee9-346250b1fb62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6bdf72b-09c4-469f-b834-8cb9776d804b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e182820-3a80-41bc-98a0-fca6c4375836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31200bf4-984b-4419-bb77-a9fc04e15f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2943043-fdfd-41c4-93de-01f4c978e849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 088be106-e677-4a25-a398-c659b9013d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22924809-1f9d-4ad5-9f5d-6d00f114e49a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a8e487c-16e3-4b7d-9f9f-2921a7906b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e8604e0-6a98-4fb6-8c4a-21b191fcc107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 292dda47-a756-4083-956b-f6bb3c02a768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebaf3d09-caa7-4fca-a469-7f429d2d6233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de4e6535-4075-4ba4-bd58-fdeda44df0ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 413e80d8-c78b-426f-aa1c-566dd126a672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d34a1b50-4dfb-4998-88da-5d317db5f057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5fb0583-c5de-4ea1-a7e6-8ede01279627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7b3d74f-9fa8-4bd9-9022-bda41aa6e29b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2fd5949-74ab-462c-aaec-aba103d06abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4ff24b0-9bad-4a0d-b312-7337027a94cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daf09ea4-1a10-4db8-b3d5-a519b5c794f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 797a6f42-0568-4097-8a66-06b6c5bce57e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a2b6753-f12e-464e-9de0-0649165092fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04b107b3-8816-44cb-80e4-c5572a1a1547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f73c6265-9cf8-416f-880b-757254db89f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7149c58-e902-49fc-b95a-b40d8135b5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa404d15-05e2-4ac6-8d08-de0b5b971e76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7d5c28a-1ec1-491d-8652-49e8d9de1c17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f1fe0c-b18d-407c-a9be-581abaa55918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 933cfb51-2fde-413e-969f-e64b0d4bbb9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 007a3dcf-3760-4fd0-84b7-5677a8238ccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df5077ef-c437-45f4-ba10-6a7effba7a3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8874e36b-446a-47b6-adf7-83cc9a84e1b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fc9636a-6dbf-4829-a22d-760a4e1fdb08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33840bef-1bc2-4aca-a18d-16e03454a76c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71ee37db-4ece-49b3-ae31-d3abe8521f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc6e6392-72c5-4b3f-b8cc-5c081dc49c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad64b400-ae5c-491d-81e3-de38f24c429f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d3ac00d-13ae-46a6-8277-52bbfba1747b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3915e1be-049f-4d7b-b729-6e906300712e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2b19687-e253-40a2-8de5-868875b4913c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2db445d-d8bf-4859-8586-f6e15767b3f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6929745a-0006-45e6-be9f-e12e816152d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d0aea80-a064-488e-b7f1-d0dd5909485a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7e66200-dfd9-4351-bcef-9d67cd669e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c153f73-d5dd-4306-9417-d0f838e24d96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b423d03-c3ff-4152-9af5-5b677b053a1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49bbe50f-22bc-44c9-9dfb-90fde299ab1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73cf5ea6-f36d-4834-a73d-43a689c5d495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a51daa34-09fd-4855-91be-3f89ddc26d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00ba838d-39af-49a0-b8ed-2fbaeb58fccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce259754-aa20-437e-b2ab-464c6c9b9b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81ff1c5e-14a9-46f6-8325-69eb83c60178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16efd8d1-7a8b-4e90-a7fe-165d048f4d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46c40992-fc7f-4f90-92a2-893ff7763fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69cca830-9b9c-467e-8750-57f84141db16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a635c9d3-300a-40fa-ae1d-c7c33211c249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fc00823-2e3e-4968-96db-f1a68d258a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63036558-54b2-4de2-89e0-9c03522ae7b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10718ffa-34ee-4e74-b30a-eb10c3646f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25f0a78c-0e9e-4350-ab7c-f436fd9b99b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c83e3806-1e06-4d3a-8d55-cdf68db0d401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31cc0e4b-e73f-43e7-9c7e-0bb2f20c2c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e45a57d-12d6-46f9-beec-2fd42dc5e680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f21bc99-aac0-4606-ac0f-9c5beeb3374b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25ecb9fc-f6d6-41b2-870c-72e3ebd97484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dcd147d-823d-42f5-aeed-fb51e9cef9ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1c7a162-2292-4654-a53d-1fa7c0ac21fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c17f10d-71a7-48e8-96d6-4a5e108eeedb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e52c639-62cc-4156-8650-bbb2f4d6a1df
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_36
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_36
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_36/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_36/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_36/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_36/test_labels.txt

📊 Raw data loaded:
   Train: X=(1354, 24), y=(1354,)
   Test:  X=(339, 24), y=(339,)

⚠️  Limiting training data: 1354 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  330 samples, 5 features
✅ Client client_36 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1835, RMSE: 0.4284, MAE: 0.3476, R²: -1.1968

============================================================
🔄 Round 5 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1134, val=0.0918 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0870, val=0.0823 (↓), lr=0.001000
   • Epoch   3/100: train=0.0818, val=0.0825, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0816, val=0.0832, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0820, val=0.0829, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0803, val=0.0827, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 5 Summary - Client client_36
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0037
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0058
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1803, RMSE: 0.4246, MAE: 0.3444, R²: -1.1586

📊 Round 5 Test Metrics:
   Loss: 0.1715, RMSE: 0.4141, MAE: 0.3357, R²: -1.0530

============================================================
🔄 Round 7 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1490, val=0.1249 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0916, val=0.0926 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0803, val=0.0913 (↓), lr=0.000250
   • Epoch   4/100: train=0.0791, val=0.0911, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0790, val=0.0910, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0787, val=0.0913, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 7 Summary - Client client_36
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0005
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0029
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.1588, RMSE: 0.3985, MAE: 0.3229, R²: -0.9007

📊 Round 7 Test Metrics:
   Loss: 0.1533, RMSE: 0.3915, MAE: 0.3174, R²: -0.8353

============================================================
🔄 Round 11 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1526, val=0.1480 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1320, val=0.1247 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1136, val=0.1053 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0991, val=0.0898 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0892, val=0.0798 (↓), lr=0.000063
   • Epoch  11/100: train=0.0834, val=0.0734, patience=4/15, lr=0.000063
   • Epoch  21/100: train=0.0831, val=0.0733, patience=9/15, lr=0.000063
   📉 Epoch 25: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 11 Summary - Client client_36
   Epochs: 27/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0029
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0098
============================================================


============================================================
🔄 Round 12 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1473, val=0.1708 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.1376, val=0.1584 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.1282, val=0.1472 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.1199, val=0.1372 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.1126, val=0.1279 (↓), lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   ✓ Epoch  11/100: train=0.0920, val=0.1018 (↓), lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008
   ✓ Epoch  21/100: train=0.0838, val=0.0883 (↓), lr=0.000008
   📉 Epoch 22: LR reduced 0.000008 → 0.000004
   📉 Epoch 30: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0826, val=0.0856, patience=2/15, lr=0.000002
   📉 Epoch 38: LR reduced 0.000002 → 0.000001
   • Epoch  41/100: train=0.0823, val=0.0848, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0822, val=0.0844, patience=11/15, lr=0.000001
   • Epoch  61/100: train=0.0821, val=0.0840, patience=8/15, lr=0.000001
   • Epoch  71/100: train=0.0820, val=0.0837, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0819, val=0.0834, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 12 Summary - Client client_36
   Epochs: 83/100 (early stopped)
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0039
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0705
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1442, RMSE: 0.3798, MAE: 0.3082, R²: -0.7264

============================================================
🔄 Round 15 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1370, val=0.1285 (↓), lr=0.000001
   • Epoch   2/100: train=0.1366, val=0.1281, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1362, val=0.1277 (↓), lr=0.000001
   • Epoch   4/100: train=0.1358, val=0.1273, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1354, val=0.1269 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1333, val=0.1249 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1303, val=0.1219 (↓), lr=0.000001
   • Epoch  31/100: train=0.1276, val=0.1194, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1252, val=0.1170 (↓), lr=0.000001
   • Epoch  51/100: train=0.1228, val=0.1147, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1206, val=0.1125, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1184, val=0.1104 (↓), lr=0.000001
   • Epoch  81/100: train=0.1163, val=0.1084, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1143, val=0.1064, patience=2/15, lr=0.000001

============================================================
📊 Round 15 Summary - Client client_36
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1126, RMSE=0.3356, R²=-0.3606
   Val:   Loss=0.1046, RMSE=0.3234, R²=-0.3615
============================================================


============================================================
🔄 Round 16 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1329, val=0.1236 (↓), lr=0.000001
   • Epoch   2/100: train=0.1327, val=0.1233, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1324, val=0.1231, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1322, val=0.1229 (↓), lr=0.000001
   • Epoch   5/100: train=0.1320, val=0.1227, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1307, val=0.1214, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1285, val=0.1193, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1264, val=0.1172 (↓), lr=0.000001
   • Epoch  41/100: train=0.1243, val=0.1152, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1223, val=0.1131, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1202, val=0.1111 (↓), lr=0.000001
   • Epoch  71/100: train=0.1182, val=0.1092, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1162, val=0.1072, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1142, val=0.1053 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_36
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1120, RMSE=0.3347, R²=-0.3482
   Val:   Loss=0.1035, RMSE=0.3218, R²=-0.3692
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0888, RMSE: 0.2979, MAE: 0.2533, R²: -0.0626

============================================================
🔄 Round 21 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0870, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0830, val=0.0864, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0828, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0826, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  51/100: train=0.0824, val=0.0849, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0823, val=0.0845, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0822, val=0.0841, patience=11/15, lr=0.000001
   • Epoch  81/100: train=0.0820, val=0.0838, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 21 Summary - Client client_36
   Epochs: 89/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0073
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0783
============================================================


============================================================
🔄 Round 23 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 23 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0157
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0170
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0005

============================================================
🔄 Round 26 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 26 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0166
   Val:   Loss=0.0733, RMSE=0.2706, R²=-0.0039
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2486, R²: -0.0004

============================================================
🔄 Round 28 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 28 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0149
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0019
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2486, R²: -0.0003

📊 Round 28 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2486, R²: -0.0003

============================================================
🔄 Round 30 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 30 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0090
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0073
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0003

📊 Round 30 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0004

============================================================
🔄 Round 34 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 34 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0111
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0056
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0004

📊 Round 34 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0004

============================================================
🔄 Round 37 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 37 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0074
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0078
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0005

============================================================
🔄 Round 39 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 39 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0064
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0109
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0005

============================================================
🔄 Round 41 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 41 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0070
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0075
============================================================


============================================================
🔄 Round 42 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 42 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0061
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0100
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0006

============================================================
🔄 Round 43 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 43 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0069
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0060
============================================================


============================================================
🔄 Round 47 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 47 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0124
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0034
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0006

📊 Round 47 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0007

📊 Round 47 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0007

============================================================
🔄 Round 51 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 51 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0094
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0008
============================================================


============================================================
🔄 Round 52 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 52 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0063
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0066
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0007

============================================================
🔄 Round 53 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 53 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0036
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0182
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0007

📊 Round 53 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0007

📊 Round 53 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0007

📊 Round 53 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0008

============================================================
🔄 Round 63 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 63 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0089
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0011
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0008

📊 Round 63 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0008

============================================================
🔄 Round 65 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 65 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0085
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0084
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0008

📊 Round 65 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0009

============================================================
🔄 Round 67 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 67 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0055
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0071
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: -0.0008

============================================================
🔄 Round 69 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 69 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0059
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0071
============================================================


============================================================
🔄 Round 70 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 70 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0091
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0035
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2487, R²: -0.0010

📊 Round 70 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2487, R²: -0.0010

============================================================
🔄 Round 77 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 77 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0036
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0169
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2488, R²: -0.0011

============================================================
🔄 Round 79 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 79 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0085
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0078
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2488, R²: -0.0011

============================================================
🔄 Round 82 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 82 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0038
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0149
============================================================


============================================================
🔄 Round 86 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 86 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0074
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0060
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2488, R²: -0.0011

============================================================
🔄 Round 87 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 87 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0036
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0128
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2488, R²: -0.0011

============================================================
🔄 Round 89 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 89 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0043
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0096
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2488, R²: -0.0012

============================================================
🔄 Round 93 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 93 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0104
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0077
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2488, R²: -0.0013

📊 Round 93 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2488, R²: -0.0012

📊 Round 93 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2488, R²: -0.0012

📊 Round 93 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2488, R²: -0.0013

============================================================
🔄 Round 105 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 105 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0023
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0139
============================================================


============================================================
🔄 Round 106 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 106 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0069
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0002
============================================================


============================================================
🔄 Round 108 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 108 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0034
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0097
============================================================


============================================================
🔄 Round 110 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 110 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0048
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0043
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2488, R²: -0.0015

📊 Round 110 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2488, R²: -0.0015

📊 Round 110 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2488, R²: -0.0015

============================================================
🔄 Round 113 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 113 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0116
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0292
============================================================


============================================================
🔄 Round 115 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 115 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0048
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0055
============================================================


============================================================
🔄 Round 116 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 116 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=-0.0037
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0110
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2488, R²: -0.0015

============================================================
🔄 Round 120 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 120 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0032
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0109
============================================================


============================================================
🔄 Round 125 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 125 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0039
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0066
============================================================


============================================================
🔄 Round 127 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 127 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0033
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0083
============================================================


============================================================
🔄 Round 128 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 128 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0046
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0233
============================================================


============================================================
🔄 Round 130 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 130 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0045
   Val:   Loss=0.0805, RMSE=0.2836, R²=-0.0104
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0016

============================================================
🔄 Round 134 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 134 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0039
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0087
============================================================


============================================================
🔄 Round 136 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 136 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0023
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0156
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

============================================================
🔄 Round 139 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 139 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0043
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0036
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

📊 Round 139 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0016

============================================================
🔄 Round 146 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 146 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0047
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0027
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2489, R²: -0.0015

📊 Round 146 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2489, R²: -0.0015

📊 Round 146 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2489, R²: -0.0015

📊 Round 146 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2489, R²: -0.0015

============================================================
🔄 Round 154 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 154 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0050
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0040
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2489, R²: -0.0015

📊 Round 154 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2489, R²: -0.0015

============================================================
🔄 Round 162 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 162 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0041
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0053
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2489, R²: -0.0015

============================================================
🔄 Round 163 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 163 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0046
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0020
============================================================


============================================================
🔄 Round 164 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 164 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0037
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0280
============================================================


============================================================
🔄 Round 166 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 166 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0054
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0144
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0016

============================================================
🔄 Round 167 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 167 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0070
   Val:   Loss=0.0729, RMSE=0.2699, R²=-0.0018
============================================================


============================================================
🔄 Round 168 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 168 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0028
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0078
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

📊 Round 168 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

============================================================
🔄 Round 170 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 170 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0037
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0069
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

============================================================
🔄 Round 171 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 171 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0030
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0285
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

📊 Round 171 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

============================================================
🔄 Round 173 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 173 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0053
   Val:   Loss=0.0952, RMSE=0.3085, R²=-0.0041
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0018

============================================================
🔄 Round 177 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 177 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0045
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0016
============================================================


============================================================
🔄 Round 178 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 178 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0023
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0292
============================================================


============================================================
🔄 Round 179 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 179 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0041
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0048
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

📊 Round 179 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

============================================================
🔄 Round 183 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 183 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0044
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0017
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

📊 Round 183 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

📊 Round 183 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

📊 Round 183 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

============================================================
🔄 Round 191 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 191 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0042
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0015
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

📊 Round 191 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

📊 Round 191 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

============================================================
🔄 Round 196 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 196 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0064
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0060
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0016

============================================================
🔄 Round 198 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 198 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0056
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0039
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

📊 Round 198 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

============================================================
🔄 Round 205 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 205 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0058
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0010
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

📊 Round 205 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

============================================================
🔄 Round 208 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 208 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0047
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0009
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

📊 Round 208 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2489, R²: -0.0017

============================================================
🔄 Round 211 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 211 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0028
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0145
============================================================


❌ Client client_36 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
