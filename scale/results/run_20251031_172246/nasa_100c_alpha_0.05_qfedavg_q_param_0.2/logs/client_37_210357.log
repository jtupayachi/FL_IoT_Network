[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2e3d603-9772-4983-8160-115a8bc62bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0fcbf5f-af54-4a70-996c-88a9f6f90669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0724257b-8d74-43ee-98b8-d38e20d89d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 675f033b-f907-4dc0-9985-dd96c21b6a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00d39f4b-3fa6-4fe4-8f40-d15852234906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d76aa2b6-bb3c-4963-9f8f-e7d2d0fc6414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee328b3a-e5f3-4a17-aae8-492f6f3f75e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 816a6b54-cbd0-494a-be4b-901fc240a1c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fb3419a-060b-4999-9c55-441b4af0b2f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 148152f9-2cf7-46be-85af-edde97d54f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d25cc157-09ff-48f2-b190-490a26c4cbfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08d4844e-8434-44fe-b18d-9936d010a146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a530ff2-ad71-4a3f-bd9e-104b5a51d484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c4eff6d-0cfc-4e12-9575-807c65c0e656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4918a563-597d-4faf-94ba-8d6b07097ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81a4c1c8-5eaa-45ec-922e-5cbddd272c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f07b7fef-e917-4b7c-a342-303a924ffd6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5537a89-434a-42a4-8585-184803e9ff4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff523080-5cbe-42e6-9fca-6e0ce5e33c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb4c689c-eb8d-4e09-ab03-de4a612519a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6702f80-efa9-4968-a0f4-eb6bf7313ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9ef1f63-e78b-4f1d-88b6-539f4fc51eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d568f9b5-47a4-48e2-a00d-19c2f3f87647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eae37c33-e9f4-465e-900c-5ba79c0300ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d6e0037-a1b8-45d7-8fdd-e138909dc254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c43bf96-8aae-4ebc-9ce8-32448e65396f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faee5cf6-c049-4ef4-a48c-8a3f698339b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33208bfc-8164-4e22-b73b-926d43e086b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53c82039-0976-4d33-9877-e4b41982338a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b11b53c9-a3b8-4fec-b868-6995c84c8bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e324d79-4609-44d6-afb4-e99377a8bab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 378b8896-8bcb-455c-97c7-f19a3ec76bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7604be54-762d-4759-ad44-28f22619b774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88026a18-fbf6-4fb4-ad06-0a5745c94883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e6645e4-227d-47bb-a9a6-16ec88e7f11b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6438f547-4bd6-4cd4-80ae-1b4c3caf7ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14357e92-bb09-4d55-a13f-8dd98ac4acd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a33b9903-e330-40ef-836b-563987712244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6077fb47-86d9-4925-b89e-a264c6ad62c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fcbc17e-c627-4e98-9536-a0d6019476b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 677ce234-112a-40cd-ac71-0d29efaae99d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5017c2b8-fb48-422e-b36c-0487d2374d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f31c787-6474-4bdd-8f10-cd1cce726c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d771975-558e-4abe-8114-1b62dd99cfeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c34b736a-c6fe-4575-a8c2-cba196a03fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94408a2b-24b2-4075-ae99-f1160ec87081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 021140cb-6ead-45d1-b2f3-8388afb40a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93f4bd3d-b1ee-4241-a1e7-5f9494576b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52446d32-f142-4882-8842-464a3905f806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a51ea512-4a76-4988-9c1c-c13ca0460ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d139939-971b-46da-88dd-0725378498db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f8bf2e8-7f95-4e1d-8e14-5ce625ba0a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 371ea2a8-2bc1-48ec-b727-42ef2aacfff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8b280f0-7723-4ee9-a47a-cdab326b948d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f51348a0-879c-4448-8dcc-c7213f2167bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f9df914-323c-4085-989e-6d75c0183700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79d21e5a-e754-408d-a01a-fce4d51444c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9101578d-838e-43f6-9a3a-9d2f3edfd926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa23598c-39c7-4db2-bd43-6fb89e373a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afa627ce-66fb-42ca-acdf-da21df5556b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 472d0426-c50d-479d-9be2-7e5f174d7221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7af4cf61-8f48-4ffa-8964-1a4298900460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b70637cb-352f-4f41-bd07-664067077428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a936fb0-c91f-4e90-9de7-64ca693b66b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aa7e129-d976-4b92-bb93-e017156f2af3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d740b73-9fbd-4a16-a9ca-a52249c17609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5c212bc-b751-40e6-9ccb-edc193d275b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5256f194-6872-4a48-914c-2d853cff76eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfbfecd0-0583-4efe-ba61-3cbebffdae78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82d670f9-862c-472c-b3f9-6e897a27cd4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d2d48c6-8621-479f-b0ff-f20d174d2377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cd36d0c-0fa9-4732-9246-652f3bb1e1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13e6c14f-720b-4c38-9049-094e09a0345b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70b388dc-0937-480d-b491-e9e2801340a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5974ed7-7842-46c2-b5ac-c0eece353498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86c097ac-5c7f-40f3-84f4-346f033a5bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 545eaf02-7358-40c9-8a23-5df2eefc00d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0487caeb-def8-4bed-a3f2-f053e13fcdd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39309fb9-7f94-4ea1-9d79-ca08fc27197e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbfc9ecc-efce-4184-87d6-66b2b9fdb192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 475e5522-3b6f-4faa-b520-b8c3493e2320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d065273-b246-4570-bcc7-f81bcf6cae6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81a704ac-0177-4532-9018-f01039061809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f6b7dcd-b342-4f43-b74c-d40e9560ef94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0efa1c1b-9942-4bcc-9461-b1c7e9cd724d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83737d5d-03e1-4eff-b7fe-d76c72a76fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fe9cc32-272f-44b5-973b-da1e437a5036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccb4eb2d-b2e5-40fd-bd4e-f7f64ac7fb81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 196625c7-ba0e-4a95-810e-7a167704f193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2c3562a-739f-464a-ae5b-5ef3d7cfd165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8294727c-b6c7-41ac-9479-4af3424ec8ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88a5d795-2450-4cac-b1db-b5ff95dce1ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3555980c-8fce-46eb-96e0-a0da613893fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3005d5e4-e14d-44ef-b27c-f3737fe056ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 494916c4-7e61-4ce3-b306-04f39259c337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d422ccf-1a51-4135-a96e-98f301ac62d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0a573d8-ae92-4ee9-bc68-d6eb15269fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d092b4e5-46a4-4c90-a1b7-070915ba72cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2178e253-a7b2-4f30-ad34-e1a55dbeacad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0647b5b4-6dc2-4275-b5e4-5a88b368cf6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38c6a2cc-10f1-4afc-80b2-4b1d0c732fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 441186f7-4f26-41bf-acd5-b27bc63a28e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8710ecaa-6505-4eca-b2a2-49e29e39b772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1276100-76fc-4f1f-9632-3528c208f0b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a6a786b-7c3b-480a-a2a1-baab6163ff6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1629d1e1-791c-450c-9662-57e8983de931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a56334a-b8ce-437d-8445-16ef64cf7817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9990ea7d-ee2a-4037-80e9-19ecf9e61709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bacc90f0-b177-44f4-b84a-6b853f87dc67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2705f6-f61f-482a-b618-ce83581be24d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bf41151-d9ef-4e64-9e85-0f7f4d366db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01a3fdfa-1fbd-447a-97c2-38e1e6cc5c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d09b2a00-7c93-4842-9065-7ae1b6847e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f66142d9-5473-4baf-8199-6d4502958882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3665146d-0dd1-4ffd-abe7-e234dfc2051c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 535fbf9a-edf1-43a6-a4a9-03111d72b3a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c546adf7-8547-4427-9a40-7eeae8672d0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec0163b7-435c-4245-990b-7f678f72617d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ce50da2-54e5-47b8-ae4b-08dcf58c17af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d59ee9c-3ab3-4e46-aaa4-bd39bb4722c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5b4a5cd-5256-456d-99cd-1350b0a025cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b317dd1-4c69-4e60-8979-9cc81e133e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a118b376-a78a-4ec1-b4db-adcf0815250d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7feec5f7-0409-44ca-b951-3f134d345e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4ca785f-9854-4d29-9df1-58f40a0fe159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59a145cb-3432-4556-8995-45dbb3725cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74192f7e-971a-401a-83bd-87c6bc1603b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f280aaca-b1ca-4d03-9ee9-b11fc7dafd81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3484a09-e9d6-489a-8a6e-0b666ed2186e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89918eb0-7692-40ca-a14a-51fe627dbf42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a38e1425-3719-4290-921a-1e19ad8efdb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c7c9665-dd5d-44c9-a23f-11419acbc194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1ef1646-bd53-4c98-8433-e69e33e1ac5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1d07937-e9f5-4c93-a956-51151c1be805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb8c0980-85d2-462b-9d98-0a1166519e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dea825cc-c4d5-40f9-9f16-0c5e59a45cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1c9aebe-f791-44f7-a63f-fa983e1bae78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ffb7f25-62ca-453f-b931-332072031b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebcbe926-dd72-4162-b0c2-1348fbd646d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3940dd4-ca8e-41eb-a325-252daddd2a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2da8fcd1-679a-453e-9f33-8587628ea4b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7528c960-d4b6-4dc4-bc9d-fd2549178085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 407147ec-eb45-42d7-9320-3ada9dd5c35d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ffeaaf4-6000-4445-869d-e54e0c3de928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2308b196-cc62-4e02-be0a-f50f713b5bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4deb29c2-7853-4528-bb24-d008eedad716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82b55015-a5f3-4c3b-b3a2-a70f0c29ebc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b5afda1-8050-4a8b-8eb0-5bf7647ff7ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 451fe6f5-a9fb-406a-bc3a-fe11942aaa02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47ad5cd5-2d1d-4911-bb71-51e685a5bb52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb923e39-9248-4f0d-a9e4-acfc58f5ab64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1760f8e-64c6-46ef-9781-12d0b0f2ed3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ba7e6b-3825-48f8-a252-a96e8cce5013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82a9927c-ed2b-4191-a47e-82504bf20e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91a9fe81-3671-4033-aaa7-8423007290fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8b5ba82-5b52-41b1-8df2-515d1487a448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f232b96-e348-4443-b0c7-32558c478b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 661b283b-3626-4315-a18f-c384f9fac756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be5e4c31-f43b-495b-b817-e44c5bebbe60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16696e4e-00d1-4ffd-8e5e-2407efbc17cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0d1b29f-71e6-40ed-9441-7ecffbab8fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c66fa36-8bf3-4f98-bac6-8dca415e44a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8996ab00-5772-47e2-9214-395bbb8466f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 297e6a65-01a0-41b3-bced-a89b4a73517b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_37
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/test_labels.txt

📊 Raw data loaded:
   Train: X=(1276, 24), y=(1276,)
   Test:  X=(319, 24), y=(319,)

⚠️  Limiting training data: 1276 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  310 samples, 5 features
✅ Client client_37 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1982, RMSE: 0.4452, MAE: 0.3680, R²: -1.4667

============================================================
🔄 Round 12 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1040, val=0.0784 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0862, val=0.0768 (↓), lr=0.001000
   • Epoch   3/100: train=0.0843, val=0.0773, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0844, val=0.0777, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0844, val=0.0778, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0834, val=0.0777, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 12 Summary - Client client_37
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0060
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0058
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1576, RMSE: 0.3970, MAE: 0.3266, R²: -0.9621

📊 Round 12 Test Metrics:
   Loss: 0.1407, RMSE: 0.3750, MAE: 0.3081, R²: -0.7507

============================================================
🔄 Round 15 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1118, val=0.0900 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0838, val=0.0873 (↓), lr=0.000250
   • Epoch   3/100: train=0.0820, val=0.0876, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0818, val=0.0878, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0817, val=0.0879, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0814, val=0.0881, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 15 Summary - Client client_37
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0043
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0006
============================================================


============================================================
🔄 Round 16 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1234, val=0.1065 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1041, val=0.0905 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0902, val=0.0829 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0846, val=0.0819 (↓), lr=0.000063
   • Epoch   5/100: train=0.0837, val=0.0821, patience=1/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0834, val=0.0818, patience=7/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 16 Summary - Client client_37
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0005
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0071
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1310, RMSE: 0.3619, MAE: 0.2974, R²: -0.6307

📊 Round 16 Test Metrics:
   Loss: 0.0906, RMSE: 0.3010, MAE: 0.2534, R²: -0.1275

============================================================
🔄 Round 20 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0888 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0879, val=0.0865 (↓), lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   ✓ Epoch   3/100: train=0.0865, val=0.0846 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.0857, val=0.0839 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.0854, val=0.0833 (↓), lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0843, val=0.0811, patience=1/15, lr=0.000004
   📉 Epoch 19: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0840, val=0.0806, patience=6/15, lr=0.000002
   📉 Epoch 27: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 20 Summary - Client client_37
   Epochs: 30/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0028
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0197
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2440, R²: -0.0110

📊 Round 20 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2437, R²: -0.0076

============================================================
🔄 Round 29 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 29 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0005
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0294
============================================================


============================================================
🔄 Round 30 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 30 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0012
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0035
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2436, R²: -0.0058

📊 Round 30 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2436, R²: -0.0056

📊 Round 30 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2436, R²: -0.0053

📊 Round 30 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2435, R²: -0.0046

============================================================
🔄 Round 37 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 37 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0002
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0060
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2435, R²: -0.0043

============================================================
🔄 Round 39 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 39 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0000
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0054
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2434, R²: -0.0041

============================================================
🔄 Round 40 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 40 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0025
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0058
============================================================


============================================================
🔄 Round 42 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 42 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0018
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0029
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2434, R²: -0.0035

📊 Round 42 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2434, R²: -0.0033

============================================================
🔄 Round 44 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 44 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0002
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0043
============================================================


============================================================
🔄 Round 45 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 45 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0008
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0090
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2434, R²: -0.0034

============================================================
🔄 Round 49 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 49 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0004
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0018
============================================================


============================================================
🔄 Round 51 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 51 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0015
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0181
============================================================


============================================================
🔄 Round 52 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 52 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0024
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0000
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2433, R²: -0.0027

============================================================
🔄 Round 53 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 53 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0007
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0054
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2433, R²: -0.0028

============================================================
🔄 Round 54 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 54 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0007
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0008
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2433, R²: -0.0029

📊 Round 54 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2433, R²: -0.0026

📊 Round 54 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2433, R²: -0.0025

📊 Round 54 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2433, R²: -0.0023

📊 Round 54 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2433, R²: -0.0022

📊 Round 54 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2433, R²: -0.0023

============================================================
🔄 Round 69 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 69 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0007
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0203
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2433, R²: -0.0022

📊 Round 69 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2433, R²: -0.0020

📊 Round 69 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2433, R²: -0.0020

============================================================
🔄 Round 73 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 73 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0014
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0014
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2433, R²: -0.0018

📊 Round 73 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2432, R²: -0.0017

============================================================
🔄 Round 76 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 76 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0005
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0137
============================================================


============================================================
🔄 Round 81 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 81 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0004
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0193
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2432, R²: -0.0015

============================================================
🔄 Round 82 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 82 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0004
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0002
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2432, R²: -0.0014

============================================================
🔄 Round 84 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 84 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0012
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0237
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2432, R²: -0.0015

============================================================
🔄 Round 85 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 85 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0015
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0042
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2432, R²: -0.0014

============================================================
🔄 Round 89 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 89 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0012
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0053
============================================================


============================================================
🔄 Round 90 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 90 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0001
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0020
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2432, R²: -0.0013

============================================================
🔄 Round 93 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 93 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0007
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0074
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2432, R²: -0.0011

📊 Round 93 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2432, R²: -0.0010

============================================================
🔄 Round 95 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 95 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0006
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0001
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2432, R²: -0.0010

============================================================
🔄 Round 96 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 96 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0016
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0045
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2432, R²: -0.0011

📊 Round 96 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2432, R²: -0.0012

📊 Round 96 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2432, R²: -0.0011

============================================================
🔄 Round 99 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 99 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0008
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0014
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2432, R²: -0.0011

============================================================
🔄 Round 100 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 100 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0017
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0213
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2432, R²: -0.0009

📊 Round 100 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2432, R²: -0.0009

📊 Round 100 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2432, R²: -0.0008

============================================================
🔄 Round 107 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 107 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0015
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0027
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0007

============================================================
🔄 Round 109 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 109 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0007
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0076
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0006

📊 Round 109 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0005

============================================================
🔄 Round 113 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 113 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0005
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0011
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0006

============================================================
🔄 Round 114 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 114 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0015
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0053
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0007

📊 Round 114 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0007

============================================================
🔄 Round 117 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 117 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0018
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0311
============================================================


============================================================
🔄 Round 118 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 118 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0004
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0037
============================================================


============================================================
🔄 Round 121 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 121 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0010
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0191
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0006

============================================================
🔄 Round 122 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 122 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0004
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0004
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0007

============================================================
🔄 Round 124 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 124 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0005
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0013
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0006

============================================================
🔄 Round 125 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 125 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0005
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0028
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0006

📊 Round 125 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0005

📊 Round 125 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0005

============================================================
🔄 Round 130 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 130 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0003
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0096
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0005

============================================================
🔄 Round 134 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 134 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0008
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0018
============================================================


============================================================
🔄 Round 135 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 135 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0031
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0154
============================================================


============================================================
🔄 Round 136 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 136 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0002
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0000
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0003

============================================================
🔄 Round 138 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 138 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0009
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0120
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0003

📊 Round 138 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0002

============================================================
🔄 Round 140 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 140 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0001
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0122
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0002

============================================================
🔄 Round 141 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 141 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0001
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0072
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0004

============================================================
🔄 Round 142 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 142 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0006
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0047
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0003

📊 Round 142 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0006

============================================================
🔄 Round 145 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0614 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0614, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0614, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0614, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0614, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0614, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0614)

============================================================
📊 Round 145 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0002
   Val:   Loss=0.0614, RMSE=0.2477, R²=-0.0017
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0007

📊 Round 145 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0007

============================================================
🔄 Round 149 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 149 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0001
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0005
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0007

📊 Round 149 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0007

📊 Round 149 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2432, R²: -0.0008

============================================================
🔄 Round 156 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 156 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0002
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0026
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0007

============================================================
🔄 Round 158 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 158 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0006
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0045
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0007

📊 Round 158 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0006

============================================================
🔄 Round 160 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 160 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0001
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0005
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0006

📊 Round 160 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0007

============================================================
🔄 Round 164 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 164 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0005
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0002
============================================================


============================================================
🔄 Round 165 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 165 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0001
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0016
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0005

============================================================
🔄 Round 166 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 166 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0009
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0109
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0004

============================================================
🔄 Round 172 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 172 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0009
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0009
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0003

📊 Round 172 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0003

============================================================
🔄 Round 174 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 174 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0001
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0017
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0003

📊 Round 174 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0003

📊 Round 174 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0005

📊 Round 174 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0004

============================================================
🔄 Round 181 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 181 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0019
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0136
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0004

============================================================
🔄 Round 185 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 185 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0008
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0096
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0004

📊 Round 185 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0006

📊 Round 185 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0004

============================================================
🔄 Round 192 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 192 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0006
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0005
============================================================


============================================================
🔄 Round 196 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 196 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0012
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0040
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0006

📊 Round 196 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0006

============================================================
🔄 Round 199 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 199 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0012
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0059
============================================================


============================================================
🔄 Round 200 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 200 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0006
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0017
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0005

============================================================
🔄 Round 201 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 201 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0009
   Val:   Loss=0.0923, RMSE=0.3037, R²=-0.0091
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0004

============================================================
🔄 Round 203 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 203 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0001
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0220
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0003

============================================================
🔄 Round 204 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 204 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0006
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0270
============================================================


============================================================
🔄 Round 206 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 206 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0011
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0013
============================================================


============================================================
🔄 Round 207 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 207 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0005
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0027
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2432, R²: -0.0005

📊 Round 207 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2431, R²: -0.0005

============================================================
🔄 Round 211 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 211 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0012
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0037
============================================================


❌ Client client_37 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
