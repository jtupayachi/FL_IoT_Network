[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b071d214-32b5-4304-8224-6eb4711352d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85b01e78-6858-4e31-9848-ef89b3ab711a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a806ff05-c989-42cb-9ad6-b4c4fd793a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed1f45d1-fe60-4763-a42f-587ca7191038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d6a5f06-fc21-40fb-9179-4d503261a6bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10a19497-70c6-4f0f-a238-aa874a5d0980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8042465f-4d3a-4ed2-b183-55d8988bd614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b0de18-0c13-4ac3-96b8-ba94be0f6d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19936bae-b207-4eb1-8521-33adb7f7424a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 617959f0-ee98-4bd5-b059-4b7f60931efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fcc8da5-9120-48cd-9844-41b7140f0bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95958c27-26b7-4a37-ba01-b2bffe7cad5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6536cdc-b069-4fcd-be17-a219daaed986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b3522d-154e-405f-a3ff-5caf5993f0db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5644e5d4-e765-4aae-ab85-6a80a538a4e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3d7a448-646c-45ed-b17f-acf21bf935a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a78b3259-69a9-4939-8c87-1f80604261a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f12d95de-f011-4b67-9e2f-5c8595c3029d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dac0dd2d-8268-44eb-b9a9-db2df87c87a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98a73f01-f062-457c-b3e0-c7d0b9fb6184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfe3eb26-acd2-4a40-aebc-155aa83639f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee4ada5-f91a-4f45-888e-3bab5a794d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8915d581-2369-474c-b60a-d264ef9257a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26bfe484-097c-40a5-8e22-698534faf623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f73e16f-c016-4f18-94f7-c37294fa8412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3dad0b6-3c0c-4bae-be8e-d42245dcc12d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 255298a1-e040-4f1c-ae4d-681422f74d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27852b4c-02c9-4743-ac6e-28e1306ec18e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db02b398-af49-4b66-992d-add1246d49da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d07836f2-c498-4c54-bfe2-9e4b5c66698e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41014671-0e29-4c75-8e88-d875cf373cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cc33432-c451-4cdb-9120-72767e2339f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 315725d8-ca7e-40f5-b0b7-fc90947ce35d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9963e01b-64ca-4cc4-b7ce-cbaec4c8046a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf63344b-2ac4-4af9-a257-0d0fb8abcf97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75dc7ff9-cbe8-4e1c-ab36-5ace21037ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f09eb2ea-d5de-42d6-ac9c-60d9bdb7562e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfc9ace5-2bee-448f-9887-12bb21203e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07ef5127-0640-4d2d-9e65-f3157c02d605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2f3f51b-471a-495b-9588-fac086627e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ed0e25a-0f40-42a7-ba84-dc911c41d75a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef94ea4c-0b87-4ee5-b73a-25c5c12d4fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4b9d3fd-5cfe-46c5-bedb-8d98194a0d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48da5edd-556b-4e17-8d93-c5ac9a420452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d326cb27-bae7-4f40-8ee5-4a34c20c0a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b2bc8b7-d21d-4f55-b51c-367bb7ce17b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c86667a7-e6fd-40ac-889f-e2e9e1adb56b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3117285-817f-42b8-8735-16aee9980633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5101bfd8-90e6-4878-ad48-64d932f7ec32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a40aae9-fb04-4d0a-aea8-63b4048ea0f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b51f55af-1133-4613-ab06-507968e9f021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4affec16-37c2-46e7-a70e-3057bf42b062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad60d07f-9adc-4667-81a7-180b0b37e383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d121cfbb-364b-4d24-8eae-055258a77a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 247b39a8-289b-4f35-ade4-6b8952c0c11f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b8e2ea5-8cce-4398-a576-b2682726615d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7e5b2c2-32b5-4037-9470-d1a740b3a49f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 382c0ddc-c48e-4398-8e48-052eb9f169d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b331c14b-0dab-4e9a-8db6-afa3baadcc83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc250315-480e-4374-a1c5-2910cdc02ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44cc7f43-2d58-42b4-96e5-b7f99a2ea37d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dda5ac25-6815-4526-a1fc-16391c3d2340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e999e4a7-eb92-4e18-b465-e44b2dfac824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad9b41ba-b7a8-4457-a850-85c9904775d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2e4f350-464e-41c6-a59e-bcf74acbe75b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6f6b49e-402d-446d-9580-a09a310ba99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7f69f4f-6321-4a68-9269-ba1b5042dab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21858ebd-4509-496f-a448-c444bf78337b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5d0c085-5ae4-4573-9b57-41292ec81a02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 031ef44e-a3a6-47cb-9007-fcb28d50f250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91ef5738-f99e-4be5-b1fd-fa4d3829bbe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dceb8589-f0f4-49b1-93e0-450b4195a8d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27fec28f-8171-48b5-a072-93e5cd815f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b0332e4-3aae-416f-a3c6-f8b4626c29db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f98e757-8de8-46b7-a5ff-9a3beff6dc52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b7bc54e-e3f1-41bf-b6ee-9df8054733b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message accd7f46-4174-4677-87b9-3ca7459fa84e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a872ba33-4b1c-4213-8193-1213f367bad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01900872-3b08-4447-9826-8362dc687f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f294b3ea-50f0-4142-8f9d-aa51e2b75f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5e371b8-c8b7-4672-a1ce-1aff9741fd8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df93e960-6a27-4ca8-88c6-cef175bbc541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d6eed8f-e316-421d-acf1-55e6461634ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7315d59d-73b3-4d8f-8496-7c406e04b46c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4749a64f-e2e9-45af-9fa2-bd9160ac97fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b203ad1e-a218-4987-836e-cc7dc4556f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bbe61c2-dde3-4de7-87a8-17315e3b538c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4aaf38e-032b-48bd-ac49-8f6acea6ecea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eab7974-5f70-494b-a073-b9d6dc8ed76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e79b95f6-dc02-4e65-8c23-6c0f304eef01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef897690-5ee4-4aec-804e-431830ea1a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdb785eb-fb05-4c6d-939f-b4218f3b0ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bfb3cda-92bc-4ae5-a734-0355a02e2111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd946d02-8972-4559-91b1-ae1db2e112a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50586b0e-8b2b-41c7-9a1b-b414ffd425b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 819cc022-3b66-4c43-b55e-fdae829ac61f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed95c09c-90f7-40c6-ba95-81cfc8e5d342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2474942a-74d9-4ad7-9a00-546d43d4062b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6c17f3a-fc5e-4aa7-b6f2-bf0de1cbb52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eba0bdb-0579-4633-9a65-5bd6f3abf290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 134fe93b-06c4-4313-b293-f6ee5eae7955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b5a33cb-f0d8-4ed5-abbb-ab54297180af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed084c11-0a31-46ff-9603-c70f70ca21bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4fbe7da-0668-42e5-84ec-7aa1dd28e08b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2010211f-6445-4ca7-855d-600ec17b506a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82b2869b-0dc3-41af-92e1-ad0238f41429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfc92028-d988-423c-9f67-fe1c15c1744e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0fd0449-7074-49e4-aaac-d9f63fe24c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf599fde-365d-4feb-8a58-350e6944c1fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e3face0-edc5-40da-b17b-b327c90064dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6d1a8fa-69b2-4ff7-9dee-2184e28284ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1726c5a-8da7-4dac-87fe-c26ebb1e4bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db384562-5b82-453d-9e82-e2dc4e0d6be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da55cf10-4784-47ff-89c4-f43455739a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f37b0fe-a73f-484c-8ddb-d310e72f6618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ad435c7-0589-481c-94a6-27e1ff953cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3f955d3-9db5-4fef-b26f-80a4eb21b1c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f1067bd-80e7-43a9-bc41-45f6d6fc7411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de7faa06-db9c-4b04-b361-4a67661c151a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04275f49-2415-4234-9afe-d42435facccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a463d035-fa38-495e-92f0-8d387df40150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b1c34e6-6b2e-4a65-8854-67d7f76031bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a72f50a2-4444-4bb4-8cb4-a19c6a12227a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95482cd2-d2f6-4049-9e69-a0d58815712d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33a7cbea-b2c2-4850-afdb-f951331ccadf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f406a343-4cd0-4c43-9570-19d94c7de9ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 123adfc6-a074-415d-badb-c0b07ae034a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26954041-f9e6-42a4-8c8d-a581dcc747ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 946002d0-d55a-4846-b207-3f93fe9b3f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43c414e6-832b-44a2-a07f-3b7a8bfa9273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8a9885d-b9b3-4a2d-9f0f-73a398e5fbff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2c497f-38f3-4dee-af2c-e91da2b2f648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f179df1-0bec-4e51-ac55-e50c08bc9b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62461fe4-7090-4a74-8966-e91f2c3c1df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ddff660-c7fc-499c-8285-9ff26f55f05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66ecc76d-be47-47cd-8619-7a86e8d0903b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40141560-113e-4027-b84e-2162d97b611a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5daa616a-1528-4c18-955e-c5df79ec4b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcbca0f6-0327-406c-a37b-1b1ea12fa063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5e3fbf3-af03-4602-b654-cd892607e3e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6d591ef-c947-4a22-9a8d-c85fbf64bba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ef71e02-b945-404c-9b38-077d3cc82d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff368824-91ab-4e06-9989-9900a88e7a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50059e80-923b-4609-8ea4-ac672e6d7abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45fbf814-c558-46ec-9575-638120ce2b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43e7be0a-db4d-44b4-9eee-e64b14cfc2bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c90de62d-83e1-49b3-b857-f6bf4bbd8fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f34942-eac2-48a1-9e57-d4d7a03c3fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bc342ae-b263-4001-ad0d-e9276c86f643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13c8a334-38b8-4dd7-aba9-31ede2b54c6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44bb5fd2-567a-4d17-ab00-916d63dad285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32478a5f-332a-4c34-baf9-f3e831a80946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac4d44fd-d9ab-47f8-9604-5d875049b77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 117299eb-1bf2-4df7-810f-c25db5f0bc81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82aef660-9c69-4a8e-8cb2-0d9651de5767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1d06988-adb8-417e-b44e-e141f1cf9d63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8daea17c-9b78-4e7b-bcc8-cea1b9c06cf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d06ced15-cba6-434d-b891-21b0ce493b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73b78ee4-ba97-44ce-a86d-f85d3cf51de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 960bfb9c-dc67-4f30-a9c6-63583aabac81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a04e4e69-e595-42c2-9ddd-c90e657f9609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16329c6a-a48e-43f4-996a-be91f9b22463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88ecb437-8dca-4f0a-9d6e-77920859871f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_38
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/test_labels.txt

📊 Raw data loaded:
   Train: X=(847, 24), y=(847,)
   Test:  X=(212, 24), y=(212,)

⚠️  Limiting training data: 847 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  203 samples, 5 features
✅ Client client_38 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1770, RMSE: 0.4207, MAE: 0.3357, R²: -1.0224

📊 Round 0 Test Metrics:
   Loss: 0.1687, RMSE: 0.4107, MAE: 0.3271, R²: -0.9280

============================================================
🔄 Round 7 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1120, val=0.0824 (↓), lr=0.001000
   • Epoch   2/100: train=0.0826, val=0.0823, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0817, val=0.0844, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0818, val=0.0840, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0815, val=0.0839, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0798, val=0.0831, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 7 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0008
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0037
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.1628, RMSE: 0.4035, MAE: 0.3213, R²: -0.8608

============================================================
🔄 Round 8 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1562, val=0.1025 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0930, val=0.0846 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0833, val=0.0815 (↓), lr=0.000250
   • Epoch   4/100: train=0.0823, val=0.0810, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0820, val=0.0816, patience=2/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0816, val=0.0811, patience=8/15, lr=0.000125
   📉 Epoch 18: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 8 Summary - Client client_38
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0094
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0199
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1479, RMSE: 0.3846, MAE: 0.3071, R²: -0.6902

============================================================
🔄 Round 12 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1557, val=0.1425 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1335, val=0.1200 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1135, val=0.1014 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0978, val=0.0878 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0877, val=0.0806 (↓), lr=0.000063
   • Epoch  11/100: train=0.0825, val=0.0786, patience=5/15, lr=0.000063
   📉 Epoch 13: LR reduced 0.000063 → 0.000031
   📉 Epoch 21: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0822, val=0.0787, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 12 Summary - Client client_38
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0075
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0047
============================================================


============================================================
🔄 Round 14 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1545, val=0.1310 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1484, val=0.1251 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1421, val=0.1196 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1362, val=0.1146 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1307, val=0.1099 (↓), lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.1088, val=0.0923 (↓), lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.0959, val=0.0823 (↓), lr=0.000004
   📉 Epoch 24: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0919, val=0.0794, patience=1/15, lr=0.000002
   📉 Epoch 32: LR reduced 0.000002 → 0.000001
   • Epoch  41/100: train=0.0905, val=0.0784, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0894, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  61/100: train=0.0884, val=0.0770, patience=7/15, lr=0.000001
   • Epoch  71/100: train=0.0875, val=0.0764, patience=9/15, lr=0.000001
   • Epoch  81/100: train=0.0868, val=0.0760, patience=9/15, lr=0.000001
   • Epoch  91/100: train=0.0861, val=0.0756, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 14 Summary - Client client_38
   Epochs: 99/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0245
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0298
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1251, RMSE: 0.3537, MAE: 0.2854, R²: -0.4294

============================================================
🔄 Round 16 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1366, val=0.1333 (↓), lr=0.000001
   • Epoch   2/100: train=0.1363, val=0.1330, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1359, val=0.1326 (↓), lr=0.000001
   • Epoch   4/100: train=0.1356, val=0.1323, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1352, val=0.1319 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1333, val=0.1301 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1305, val=0.1275 (↓), lr=0.000001
   • Epoch  31/100: train=0.1279, val=0.1250, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1254, val=0.1227 (↓), lr=0.000001
   • Epoch  51/100: train=0.1231, val=0.1205, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1208, val=0.1184, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1186, val=0.1163 (↓), lr=0.000001
   • Epoch  81/100: train=0.1164, val=0.1143, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1143, val=0.1124, patience=2/15, lr=0.000001

============================================================
📊 Round 16 Summary - Client client_38
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1123, RMSE=0.3351, R²=-0.3783
   Val:   Loss=0.1107, RMSE=0.3326, R²=-0.2910
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1092, RMSE: 0.3305, MAE: 0.2716, R²: -0.2481

============================================================
🔄 Round 18 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1135, val=0.1286 (↓), lr=0.000001
   • Epoch   2/100: train=0.1133, val=0.1284, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1131, val=0.1281, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1128, val=0.1279 (↓), lr=0.000001
   • Epoch   5/100: train=0.1126, val=0.1277, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1114, val=0.1264, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1093, val=0.1244, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1073, val=0.1223 (↓), lr=0.000001
   • Epoch  41/100: train=0.1053, val=0.1203, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1034, val=0.1184, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1016, val=0.1165 (↓), lr=0.000001
   • Epoch  71/100: train=0.0998, val=0.1147, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0980, val=0.1129, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0963, val=0.1112 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_38
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0947, RMSE=0.3078, R²=-0.1938
   Val:   Loss=0.1097, RMSE=0.3312, R²=-0.1623
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0918, RMSE: 0.3030, MAE: 0.2583, R²: -0.0493

📊 Round 18 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2592, R²: -0.0028

📊 Round 18 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2593, R²: -0.0026

📊 Round 18 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2596, R²: -0.0028

📊 Round 18 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2596, R²: -0.0028

📊 Round 18 Test Metrics:
   Loss: 0.0878, RMSE: 0.2962, MAE: 0.2597, R²: -0.0029

============================================================
🔄 Round 29 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 29 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0022
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0603
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2598, R²: -0.0033

============================================================
🔄 Round 32 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 32 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0092
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0092
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2598, R²: -0.0033

📊 Round 32 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2599, R²: -0.0036

📊 Round 32 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2599, R²: -0.0037

============================================================
🔄 Round 37 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 37 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0088
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0033
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2599, R²: -0.0037

============================================================
🔄 Round 39 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 39 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0113
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0060
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2600, R²: -0.0041

============================================================
🔄 Round 43 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 43 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0013
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0601
============================================================


============================================================
🔄 Round 44 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 44 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0036
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0318
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2600, R²: -0.0041

📊 Round 44 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2600, R²: -0.0042

============================================================
🔄 Round 47 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0758, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0846, val=0.0755, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0846, val=0.0752, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 47 Summary - Client client_38
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0016
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0456
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2601, R²: -0.0043

📊 Round 47 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2601, R²: -0.0044

============================================================
🔄 Round 53 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 53 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0039
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0196
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2601, R²: -0.0044

📊 Round 53 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2601, R²: -0.0044

📊 Round 53 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2601, R²: -0.0044

📊 Round 53 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2601, R²: -0.0044

============================================================
🔄 Round 57 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 57 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0034
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0314
============================================================


============================================================
🔄 Round 58 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 58 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0084
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0019
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2601, R²: -0.0044

============================================================
🔄 Round 59 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 59 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0084
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0051
============================================================


============================================================
🔄 Round 60 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 60 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0090
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0071
============================================================


============================================================
🔄 Round 61 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 61 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0047
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0094
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2601, R²: -0.0045

============================================================
🔄 Round 62 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 62 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0048
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0099
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2601, R²: -0.0046

============================================================
🔄 Round 63 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 63 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0058
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0118
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2601, R²: -0.0046

📊 Round 63 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2601, R²: -0.0046

📊 Round 63 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2601, R²: -0.0047

📊 Round 63 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2601, R²: -0.0047

📊 Round 63 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2601, R²: -0.0046

📊 Round 63 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2601, R²: -0.0047

📊 Round 63 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2602, R²: -0.0048

📊 Round 63 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2602, R²: -0.0048

============================================================
🔄 Round 72 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 72 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0086
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0093
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2602, R²: -0.0049

============================================================
🔄 Round 74 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 74 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0085
   Val:   Loss=0.0947, RMSE=0.3078, R²=0.0065
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2602, R²: -0.0050

📊 Round 74 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2602, R²: -0.0050

============================================================
🔄 Round 76 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 76 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0055
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0014
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2602, R²: -0.0051

============================================================
🔄 Round 77 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 77 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=-0.0061
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0002
============================================================


============================================================
🔄 Round 78 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 78 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0078
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0042
============================================================


============================================================
🔄 Round 80 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 80 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0019
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0157
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0879, RMSE: 0.2966, MAE: 0.2603, R²: -0.0052

============================================================
🔄 Round 81 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 81 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0028
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0116
============================================================


============================================================
🔄 Round 83 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 83 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0047
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0033
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0879, RMSE: 0.2966, MAE: 0.2603, R²: -0.0052

============================================================
🔄 Round 88 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 88 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0011
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0309
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2603, R²: -0.0052

============================================================
🔄 Round 89 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 89 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0017
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0268
============================================================


============================================================
🔄 Round 90 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 90 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0017
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0311
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2603, R²: -0.0053

📊 Round 90 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2603, R²: -0.0054

============================================================
🔄 Round 101 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 101 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0046
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0023
============================================================


============================================================
🔄 Round 106 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 106 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0021
   Val:   Loss=0.0768, RMSE=0.2770, R²=-0.0176
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2604, R²: -0.0057

📊 Round 106 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2604, R²: -0.0057

📊 Round 106 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2604, R²: -0.0058

📊 Round 106 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2604, R²: -0.0059

📊 Round 106 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2604, R²: -0.0058

📊 Round 106 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2604, R²: -0.0057

============================================================
🔄 Round 116 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 116 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0021
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0094
============================================================


============================================================
🔄 Round 117 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 117 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0030
   Val:   Loss=0.0698, RMSE=0.2641, R²=-0.0092
============================================================


============================================================
🔄 Round 118 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 118 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0007
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0162
============================================================


============================================================
🔄 Round 120 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 120 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0029
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0098
============================================================


============================================================
🔄 Round 121 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 121 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0055
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0037
============================================================


============================================================
🔄 Round 124 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 124 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0032
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0065
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2604, R²: -0.0059

📊 Round 124 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2604, R²: -0.0059

📊 Round 124 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2604, R²: -0.0060

📊 Round 124 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2604, R²: -0.0059

============================================================
🔄 Round 133 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 133 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0038
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0034
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2604, R²: -0.0060

============================================================
🔄 Round 136 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 136 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0027
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0062
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0061

📊 Round 136 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0062

📊 Round 136 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0062

============================================================
🔄 Round 140 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 140 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0013
   Val:   Loss=0.0879, RMSE=0.2966, R²=-0.0126
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0062

============================================================
🔄 Round 142 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 142 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0014
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0116
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2604, R²: -0.0060

============================================================
🔄 Round 144 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 144 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0001
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0239
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2604, R²: -0.0059

============================================================
🔄 Round 151 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 151 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0033
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0047
============================================================


============================================================
🔄 Round 152 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 152 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=-0.0021
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0097
============================================================


============================================================
🔄 Round 153 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 153 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0049
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0020
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2604, R²: -0.0058

============================================================
🔄 Round 156 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 156 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0025
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0093
============================================================


============================================================
🔄 Round 157 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 157 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0001
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0212
============================================================


============================================================
🔄 Round 159 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 159 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0016
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0115
============================================================


============================================================
🔄 Round 160 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 160 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0017
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0103
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2604, R²: -0.0059

============================================================
🔄 Round 163 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 163 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0035
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0039
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2604, R²: -0.0059

============================================================
🔄 Round 166 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 166 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0045
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0004
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2604, R²: -0.0061

============================================================
🔄 Round 169 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 169 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0053
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0048
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0062

============================================================
🔄 Round 170 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 170 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0069
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0001
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0062

📊 Round 170 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0063

📊 Round 170 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0063

============================================================
🔄 Round 174 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 174 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0013
   Val:   Loss=0.0881, RMSE=0.2967, R²=-0.0416
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0062

============================================================
🔄 Round 175 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 175 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0039
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0009
============================================================


============================================================
🔄 Round 176 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 176 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0030
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0077
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0062

============================================================
🔄 Round 177 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 177 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0003
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0232
============================================================


============================================================
🔄 Round 178 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 178 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0089
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0098
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0061

============================================================
🔄 Round 180 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 180 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0003
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0280
============================================================


============================================================
🔄 Round 181 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 181 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0023
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0098
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0063

============================================================
🔄 Round 183 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 183 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0027
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0053
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0062

📊 Round 183 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0062

============================================================
🔄 Round 186 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 186 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0067
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0040
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0061

============================================================
🔄 Round 190 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 190 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0010
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0149
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0062

============================================================
🔄 Round 193 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 193 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0009
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0356
============================================================


============================================================
🔄 Round 194 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 194 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0025
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0059
============================================================


============================================================
🔄 Round 195 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 195 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0015
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0423
============================================================


============================================================
🔄 Round 199 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 199 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0029
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0121
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0062

============================================================
🔄 Round 201 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 201 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0006
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0288
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0063

============================================================
🔄 Round 204 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 204 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0002
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0222
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0062

📊 Round 204 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0062

============================================================
🔄 Round 206 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 206 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0008
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0483
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0063

📊 Round 206 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0063

============================================================
🔄 Round 208 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 208 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0005
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0401
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0062

============================================================
🔄 Round 209 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 209 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0011
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0163
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2605, R²: -0.0062

============================================================
🔄 Round 211 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 211 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0008
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0352
============================================================


❌ Client client_38 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
