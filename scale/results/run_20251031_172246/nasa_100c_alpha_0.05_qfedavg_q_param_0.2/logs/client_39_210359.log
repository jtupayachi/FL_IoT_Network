[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc54461a-3179-4c14-aa52-c7a42602d49e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d21fb62a-d954-491d-98d2-179dac0ede7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f42bd84d-d24c-431f-b58f-b68974455b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3540412a-e189-4f94-a104-96aba80d40ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6d231e5-0b5c-49d1-9330-716bfdf12c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec4c5e91-28a4-40cd-8668-55985b8f8358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b3bbd58-965e-482e-9768-b41f590b37d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 361785a3-dcf2-4228-bb61-24eb78bda4bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 601c3a99-e498-4604-8baf-edf4e8e050f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38b64697-9dc9-4ab3-8b75-3a2f94782d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02236417-e01c-4ff0-9516-bb8998313bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66d08467-b76a-453c-ba81-ebf89a6f5092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bbf68b6-2775-4538-a964-b2313f7a8173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2875102b-5358-43a8-984b-4197d58a4bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c50b956-e63e-4235-8524-9932497d3793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad16e0ba-e25e-4ca5-81ad-8741cf2694c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c7c59d4-3b44-4e31-b89f-2d5fe3aad2f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89c094bc-d405-4ea5-93b8-e72d6e4c0a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebb0d520-c5cf-4646-ba2e-e90fca83099f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e26735fd-8dbe-4440-a241-bbb11cfd766d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c929707-57da-4f94-a396-c2895873a90c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 405620e2-0693-4832-8ad8-e7e567436512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a87af685-24e1-4256-a46f-1c17a07ca708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d6ee036-5bde-4f94-bbf3-0627276a8b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9773f59f-668d-4bf6-8dce-16978860a3a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a42fc282-cddd-4b01-bfea-4a936d1d4cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25a6c989-863d-4e7e-a596-2001712cad05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8860a868-8f36-4abc-b871-b2e0edf5161c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 527545d8-dcc6-4930-a8fd-c6ac50060a9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a98c2ef0-ccc9-472a-983f-28a37d9a2ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 893374ab-5816-485d-ac83-9114a870552b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75fbbcc8-1658-43f8-be48-74bf9d8fcddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d9eb9df-370c-4468-bdfa-ee6a80727a0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5403dfd-c445-48f2-b4bb-bc23c6e61ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c717d44-cd92-49b0-a099-df81bb2e12e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 791545a8-1424-43b6-bdfa-3c5c29fd9f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30928425-aaba-4c39-98b1-22469ba5f693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6d45c38-e8e1-4ef2-861b-b6d6a6b9cb52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 874c3a8c-3a1b-40a2-8fd5-1db09ab7ea3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 332b2de9-76f4-440d-a19b-8fcde74f3758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c24088e1-dc71-49c1-8b6a-b1c1c533ac9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d2418e9-67d0-4332-8df4-0871fafdc759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 668c14dd-5a56-4369-b906-5aec5f7abf9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 620ed07f-2a8e-41ca-a5ba-e8b55559d69a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3255ce9a-627c-4582-a67e-8db24f321c45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03d039ad-6ff2-4e1c-bc68-3fb1aebb91b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9978fc07-fef5-4367-ad1f-f800fae55bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23c52969-d22e-4a09-a012-4497c84434ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 218622e8-9ce8-49f3-ae06-fb38c8257e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1210ecee-7fd9-4e24-a751-dba53575ba8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ef311fe-9bfb-4616-9b8f-4b22731f1f4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4fea5a1-831d-4d17-98ae-8abc27852501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a1c6ba2-bf2b-48fc-b04a-bad56d07cdab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35afe9a0-e2c9-4cfa-9461-30796cfe5476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0654dd7c-ba5f-4f89-acd0-b44299c670d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11706956-6d5d-4f07-8024-168c747c9deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c17b57-7475-4e04-9121-767d679454c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1889a0d-15c0-41f6-8e23-9b5d95eb75ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0152e635-92db-4161-9593-2c47a86d5044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 167e123f-e269-48fe-be12-ecb3611f456c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 060cad7e-eea8-47a5-913f-ba7d11d9af28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7ce3e84-3ead-4fb3-9af3-a8ee8de99c96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06dacdee-48cb-40a9-a3bd-59e4b5093824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79ed5452-bab0-4107-abcb-f7789c0e4a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 920856da-e32b-4b00-8153-fb4320b1b98a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e8d8d54-ff83-4d23-b0cb-fefb04551873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3113088e-30aa-4370-b5f7-d2b979236a3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83312b5d-1ac7-4b52-85f5-11315b5c04a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc19955f-e222-48e0-a433-43aa473983d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3210568a-4192-4a51-bbb0-8bca2090dd84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d5949d4-97ff-4415-bfb0-e9915c4dca22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91571676-5869-4ece-b9bf-98f0204fa14d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c82fac1-f120-42e1-8cc5-3f8544b2601d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5b58d1c-233c-4da3-af97-8cb31c714c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa51ff4f-7e7e-47e7-8e4e-3c7d98687e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff0dfbb3-1199-484c-b0ec-611ecff94fd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00def0af-201c-49dd-8be8-b732d2445e9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fe2fcb3-80ed-47cb-871f-3c4885d0302c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17321bcb-8a9c-4eab-970b-c23ec61c0200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 524c9285-2254-477a-ba8b-924697809211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83b16f96-0d1f-4f21-a354-50443cd04dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66e1e3b8-7915-4dc2-b2cf-c9911bbe0106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f342137-5052-437d-b321-24982ff87e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9769941-b789-463d-8835-14b6e5335759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb7255ab-c895-45fe-bc54-57d88cce00a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afc64b42-c2aa-4af8-a423-813fd767d0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fcda7fc-4466-4753-9190-86cc89e7f5fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15aa2ae2-7af3-456a-bfef-8bdbfdf3c2a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02a0829c-80bb-4c6a-be89-6c05f06a0615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a5e7d1e-01dd-41c8-bd7a-a1abc0170fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c65a5a3-e389-4ac3-9a99-82245829fa53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94d06666-d015-4133-9dd2-f4e2be195e76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51e2ce55-b0d9-4403-a94a-6b992cb4fad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0462ffbf-4562-4d49-8de3-7f71d3015d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d600d2f8-1bb6-4060-a96a-be5d43de970f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b66337f8-2a92-4dab-a403-0ebd1ed7b2bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f4dfd56-37d4-4b44-af08-4af5c31e6a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7220576-94de-449e-8ba0-4c56485a118e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f0ebf51-481b-43ee-90dd-1917fdcca9f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9edb772e-bcfd-4b8e-b51e-fef5aaf87359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f345b5d-2513-4181-bdd1-b088438f28ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3e997ba-8486-4b94-bfe5-edb57a592b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6181d11-1bad-4ed2-af3b-2e28db28eac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64257f22-9184-4dc0-b585-2e464916b14f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3d04918-366f-4186-b658-c19015e266af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22896fce-81d4-4fa8-99c0-3ce49f0ad29d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d3497f-7584-4300-b30b-edd6689f3816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 392ff1dd-dc03-41a1-9795-35f89b8d3ff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ebde123-afb4-493b-b4b4-8a2a260f0855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed2df9c4-5fa3-4e0a-9249-4a9e8b47c81b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aebbdd20-2e5e-43c1-b838-5c9904a63581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b7ed85a-62b9-422a-948e-4e1ad7bac361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d34ad4f-72f1-419e-9320-a1c58f8f77ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f6513be-72cf-488e-84e3-395386ebf663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36059f3e-bed8-44ed-be6e-0c459b50ec23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77f02da0-1616-4ff5-a4c1-26927c8daf5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82c5b658-2c46-40d0-9b8c-ddaba067a3e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73e6537b-0518-4acb-baf1-931b24cc696b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 839fabfa-d158-45c2-a584-aa241e5aa939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39573a7b-5bcb-4573-95bc-104ca0c02e93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f83946b-f82f-4bdb-beb1-d9647a32bc3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34643488-90fa-4fa2-952b-84887e8e9732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b07509c1-366a-4481-ba81-42f6227680b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6441c4bb-a40d-4a67-b02a-9ccfa6bbbe87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f08e93dc-8ab1-4214-95f8-663be547865e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18a23dc5-b7aa-49b5-a939-452a64330a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81a482e2-0c35-4ebc-933f-5962f8df0f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d037c1ab-8ff3-4236-abf1-48800a7ea233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 947568f5-e37b-4b8d-af9e-b42cfe01340a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c946afcd-234b-4323-bb1d-46e2a65488b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2994533-2aaa-4bbb-a8db-f23a3ebd566d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5949d356-f1ef-46b9-99b6-2540e6e36aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46cff3c4-7ec1-49b1-a73a-f594486ae561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4553295c-2833-414b-9448-aab3c7a0d877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 223fc942-9c2b-48aa-aadb-2a883811238a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae48db87-0996-40cd-b597-a40d25c622a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43e3f360-4026-4c49-9335-49800d990a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0810a5e2-8e8d-4a73-b6d8-0c6a440781b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6873c94f-ab21-462c-b20e-57d00f494007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a454ae-b8c6-4585-b858-ca2217bce004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bfe2a1d-916f-48d0-931e-49c1e81a478b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6a1ec3f-1fe5-4d76-a48b-ecd4b4fbf2c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fd5fc1a-d376-42a9-8240-bc31648ebc15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a4824c9-c94f-4017-b637-885bcda0289c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72fd7562-96cf-4c3a-a7f2-fae8ec2c2f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0837c679-cc76-43fb-ada3-48f382cc1f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b8e4045-03c3-48d9-ac28-243f984cdbe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dc412f5-3825-450d-81ee-499d468cfca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84e6c60d-ad74-4fe2-82be-2c00e970b879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b96a4a8-9627-4eda-86e0-b720c1e1c8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24f75d35-d8ad-4380-805e-fc1b13f4d142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40d9ba6e-dc3a-4b05-af66-eaeb9a7543e6
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_39
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/test_labels.txt

📊 Raw data loaded:
   Train: X=(1819, 24), y=(1819,)
   Test:  X=(455, 24), y=(455,)

⚠️  Limiting training data: 1819 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  446 samples, 5 features
✅ Client client_39 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1954, RMSE: 0.4421, MAE: 0.3646, R²: -1.4689

============================================================
🔄 Round 5 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1216, val=0.1007 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0887, val=0.0933 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0866, val=0.0920 (↓), lr=0.001000
   • Epoch   4/100: train=0.0866, val=0.0925, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0866, val=0.0925, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0858, val=0.0917, patience=8/15, lr=0.000500
   • Epoch  21/100: train=0.0852, val=0.0911, patience=5/15, lr=0.000500
   • Epoch  31/100: train=0.0834, val=0.0905, patience=7/15, lr=0.000500
   • Epoch  41/100: train=0.0798, val=0.0907, patience=8/15, lr=0.000500
   📉 Epoch 43: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 5 Summary - Client client_39
   Epochs: 48/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0547
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0190
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1921, RMSE: 0.4382, MAE: 0.3611, R²: -1.4264

📊 Round 5 Test Metrics:
   Loss: 0.1827, RMSE: 0.4275, MAE: 0.3515, R²: -1.3088

============================================================
🔄 Round 10 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1395, val=0.1134 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0922, val=0.0925 (↓), lr=0.000250
   📉 Epoch 3: LR reduced 0.000250 → 0.000125
   ✓ Epoch   3/100: train=0.0878, val=0.0916 (↓), lr=0.000125
   • Epoch   4/100: train=0.0873, val=0.0912, patience=1/15, lr=0.000125
   ✓ Epoch   5/100: train=0.0872, val=0.0909 (↓), lr=0.000125
   📉 Epoch 11: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0870, val=0.0905, patience=6/15, lr=0.000063
   📉 Epoch 19: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 10 Summary - Client client_39
   Epochs: 20/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0042
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0032
============================================================


============================================================
🔄 Round 14 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1437, val=0.1440 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.1325, val=0.1309 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.1216, val=0.1195 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.1125, val=0.1099 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.1050, val=0.1018 (↓), lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   ✓ Epoch  11/100: train=0.0900, val=0.0861 (↓), lr=0.000016
   • Epoch  21/100: train=0.0887, val=0.0841, patience=3/15, lr=0.000016
   📉 Epoch 29: LR reduced 0.000016 → 0.000008
   • Epoch  31/100: train=0.0885, val=0.0841, patience=13/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 14 Summary - Client client_39
   Epochs: 33/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0061
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0128
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1374, RMSE: 0.3706, MAE: 0.3053, R²: -0.7354

============================================================
🔄 Round 17 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1303, val=0.1252 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1278, val=0.1226 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1249, val=0.1202 (↓), lr=0.000008
   📉 Epoch 4: LR reduced 0.000008 → 0.000004
   ✓ Epoch   4/100: train=0.1222, val=0.1179 (↓), lr=0.000004
   ✓ Epoch   5/100: train=0.1202, val=0.1168 (↓), lr=0.000004
   ✓ Epoch  11/100: train=0.1135, val=0.1111 (↓), lr=0.000004
   📉 Epoch 12: LR reduced 0.000004 → 0.000002
   📉 Epoch 20: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.1083, val=0.1071, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.1063, val=0.1055, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1044, val=0.1040, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.1027, val=0.1026, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1011, val=0.1013, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.0996, val=0.1002, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0982, val=0.0991, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0969, val=0.0981, patience=3/15, lr=0.000001

============================================================
📊 Round 17 Summary - Client client_39
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0956, RMSE=0.3093, R²=-0.1009
   Val:   Loss=0.0972, RMSE=0.3118, R²=-0.0495
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1131, RMSE: 0.3363, MAE: 0.2803, R²: -0.4285

📊 Round 17 Test Metrics:
   Loss: 0.1002, RMSE: 0.3166, MAE: 0.2668, R²: -0.2660

============================================================
🔄 Round 22 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 22 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0108
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0176
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2435, R²: -0.0135

============================================================
🔄 Round 30 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 30 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0004
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0444
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2432, R²: -0.0116

============================================================
🔄 Round 31 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 31 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0077
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0281
============================================================


============================================================
🔄 Round 34 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 34 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0008
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0125
============================================================


============================================================
🔄 Round 35 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 35 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0002
   Val:   Loss=0.0952, RMSE=0.3085, R²=-0.0121
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2429, R²: -0.0095

📊 Round 35 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2428, R²: -0.0091

📊 Round 35 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2428, R²: -0.0089

📊 Round 35 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2427, R²: -0.0083

📊 Round 35 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2427, R²: -0.0083

============================================================
🔄 Round 45 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 45 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=-0.0029
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0004
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2427, R²: -0.0082

============================================================
🔄 Round 47 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 47 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0010
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0014
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2426, R²: -0.0081

============================================================
🔄 Round 49 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 49 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0009
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0032
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2426, R²: -0.0078

📊 Round 49 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2426, R²: -0.0077

============================================================
🔄 Round 52 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 52 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0034
   Val:   Loss=0.0917, RMSE=0.3029, R²=0.0039
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2426, R²: -0.0077

📊 Round 52 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2426, R²: -0.0077

📊 Round 52 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2426, R²: -0.0078

📊 Round 52 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2426, R²: -0.0075

📊 Round 52 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2426, R²: -0.0075

📊 Round 52 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2425, R²: -0.0073

============================================================
🔄 Round 63 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 63 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3014, R²=-0.0003
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0024
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2425, R²: -0.0072

============================================================
🔄 Round 64 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 64 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=0.0007
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0077
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2425, R²: -0.0072

📊 Round 64 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2425, R²: -0.0072

============================================================
🔄 Round 66 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 66 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0020
   Val:   Loss=0.0949, RMSE=0.3081, R²=0.0023
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2425, R²: -0.0071

============================================================
🔄 Round 68 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 68 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0017
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0210
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2425, R²: -0.0070

============================================================
🔄 Round 70 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 70 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0012
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0099
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2425, R²: -0.0068

📊 Round 70 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2424, R²: -0.0067

📊 Round 70 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2424, R²: -0.0066

============================================================
🔄 Round 75 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 75 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0017
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0011
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2424, R²: -0.0065

============================================================
🔄 Round 78 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 78 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0000
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0033
============================================================


============================================================
🔄 Round 80 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 80 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0003
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0026
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: -0.0062

============================================================
🔄 Round 83 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 83 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0012
   Val:   Loss=0.0950, RMSE=0.3082, R²=0.0017
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: -0.0061

============================================================
🔄 Round 89 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 89 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0009
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0007
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2423, R²: -0.0060

============================================================
🔄 Round 91 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 91 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0017
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0024
============================================================


============================================================
🔄 Round 95 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 95 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0000
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0020
============================================================


============================================================
🔄 Round 96 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 96 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0018
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0000
============================================================


============================================================
🔄 Round 97 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 97 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0002
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0020
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2423, R²: -0.0057

============================================================
🔄 Round 100 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 100 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0009
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0021
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2423, R²: -0.0055

============================================================
🔄 Round 103 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 103 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0018
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0017
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2423, R²: -0.0054

📊 Round 103 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: -0.0054

📊 Round 103 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2423, R²: -0.0054

============================================================
🔄 Round 106 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 106 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0001
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0003
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: -0.0054

📊 Round 106 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: -0.0053

============================================================
🔄 Round 110 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 110 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0007
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0075
============================================================


============================================================
🔄 Round 111 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 111 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0008
   Val:   Loss=0.0974, RMSE=0.3120, R²=0.0016
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: -0.0051

============================================================
🔄 Round 112 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 112 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0000
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0029
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: -0.0051

============================================================
🔄 Round 114 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 114 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0002
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0221
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: -0.0052

============================================================
🔄 Round 116 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 116 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0008
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0016
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: -0.0052

============================================================
🔄 Round 117 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 117 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0004
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0018
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: -0.0052

📊 Round 117 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: -0.0051

📊 Round 117 Test Metrics:
   Loss: 0.0796, RMSE: 0.2820, MAE: 0.2422, R²: -0.0051

============================================================
🔄 Round 122 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 122 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0001
   Val:   Loss=0.0969, RMSE=0.3113, R²=-0.0017
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2422, R²: -0.0050

============================================================
🔄 Round 123 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 123 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0017
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0094
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: -0.0051

============================================================
🔄 Round 124 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 124 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0001
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0001
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2422, R²: -0.0050

============================================================
🔄 Round 126 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 126 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0000
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0043
============================================================


============================================================
🔄 Round 129 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 129 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=0.0007
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0021
============================================================


============================================================
🔄 Round 131 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 131 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0006
   Val:   Loss=0.0920, RMSE=0.3032, R²=-0.0005
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0047

============================================================
🔄 Round 137 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 137 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0008
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0037
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0047

📊 Round 137 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0046

📊 Round 137 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0045

============================================================
🔄 Round 141 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 141 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0005
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0017
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0047

📊 Round 141 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0047

📊 Round 141 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2422, R²: -0.0048

============================================================
🔄 Round 144 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 144 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0000
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0108
============================================================


============================================================
🔄 Round 145 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 145 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0001
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0002
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2422, R²: -0.0048

📊 Round 145 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2422, R²: -0.0050

📊 Round 145 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2422, R²: -0.0049

📊 Round 145 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2422, R²: -0.0049

============================================================
🔄 Round 151 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 151 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0013
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0043
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2422, R²: -0.0050

📊 Round 151 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2422, R²: -0.0049

============================================================
🔄 Round 153 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 153 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0023
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0174
============================================================


============================================================
🔄 Round 154 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 154 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0024
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0126
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2422, R²: -0.0048

📊 Round 154 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2422, R²: -0.0048

============================================================
🔄 Round 159 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 159 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0011
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0068
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2422, R²: -0.0048

📊 Round 159 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0047

============================================================
🔄 Round 161 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 161 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0005
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0005
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2422, R²: -0.0048

📊 Round 161 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2422, R²: -0.0048

============================================================
🔄 Round 163 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 163 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=-0.0003
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0018
============================================================


============================================================
🔄 Round 166 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 166 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=0.0000
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0020
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0046

============================================================
🔄 Round 167 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 167 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=-0.0005
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0041
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0045

============================================================
🔄 Round 170 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 170 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0005
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0213
============================================================


============================================================
🔄 Round 171 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 171 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0010
   Val:   Loss=0.0912, RMSE=0.3021, R²=-0.0080
============================================================


============================================================
🔄 Round 172 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 172 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0009
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0129
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0044

============================================================
🔄 Round 175 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 175 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0005
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0127
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0044

============================================================
🔄 Round 178 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 178 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0014
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0030
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0044

============================================================
🔄 Round 182 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 182 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=-0.0003
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0042
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0045

📊 Round 182 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0045

📊 Round 182 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0044

📊 Round 182 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0044

📊 Round 182 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0044

📊 Round 182 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0045

📊 Round 182 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0044

============================================================
🔄 Round 200 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 200 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0024
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0056
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0044

============================================================
🔄 Round 201 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 201 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0004
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0001
============================================================


============================================================
🔄 Round 202 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 202 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2982, R²=0.0002
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0009
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0044

📊 Round 202 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2421, R²: -0.0043

============================================================
🔄 Round 206 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 206 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0007
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0007
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2421, R²: -0.0043

📊 Round 206 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2421, R²: -0.0043

❌ Client client_39 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
