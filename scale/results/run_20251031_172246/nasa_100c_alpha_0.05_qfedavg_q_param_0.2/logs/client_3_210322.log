[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79ba64b4-98e2-49e6-a9f4-1676d597421e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 717acf47-4b00-49f9-b580-0754b6bda180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66abdac8-f333-44d3-8058-8aa7abccbe16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f347d8e-5a12-40ff-a70c-3ac98d42f833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6212341-e8ee-4d91-97f2-d0a327d054a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12671600-5cc1-4c35-94d2-5b35e87225e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c967485d-e2bd-43b9-8bdb-cad7f969048e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47146e05-f41a-4f31-ac31-47ce4a5a68f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c87c9d3-d827-4a07-b503-9764b6b4a45f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f33c00f-cb70-4c5d-8d53-8cef962cf484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 097c1414-544a-4e73-98e9-e3d2b6dac37e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e92d6c-23cc-4888-a8e3-0915c7ed0435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 693a4848-8aa7-45c7-8296-1e051164981b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fa1079d-3346-45db-a471-9240a4bcd9af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8270dab9-bff7-41df-973c-9d502c6baa2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc4e8e5-0053-4443-8431-b73b736299d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5ac1418-382a-4fde-93ca-64a813c055ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28953536-0e5e-4d1a-9ed2-a2c03741eaff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1e7388d-d83c-41b7-8608-dc0eca0887cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9387e94b-d6f2-4b01-afd4-f55a3d8804e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22b13481-ad0f-49a0-b1ee-7320c9e80882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b9a0c55-5efa-4b5b-8f48-f93cab12be6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ea14fa6-78af-4216-a1d3-c40b85409df0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a1cc5e9-4b7a-42e2-8b22-0d5ea4fcf836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cefd8cce-1db9-4d8b-95fb-75cb55d8533a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f276edf-6fa8-42a6-aaeb-9487e794503c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f19440d7-e6fe-4288-8d96-77c06d5f752a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1883c4f-ed36-476a-9ee2-46da727f3d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7326d672-a0f6-4a69-a73e-1433d29e034e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f224278-1891-4ca9-b37e-1a1b59cbf21e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df2fb6cf-3239-4fa6-b336-1a32a9386daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f8bc30e-fb92-414c-aa89-c16b9720c8be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 263cfbdd-1c8a-4d4f-9a80-396a753709ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39fdc2ec-8460-4e06-9a16-e55028535258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc8bd42-f9bd-4bac-b429-99011891cbd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc0df08f-8d0d-409b-8bb5-42b90f91736b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a50915-0a00-45df-9088-db87624322a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfec0382-b28a-486f-96e3-25fed8572df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f5f55b0-b9ab-46fb-ab75-3bef8594f4ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c17786e4-97b2-4c1a-8664-fa91db099968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fd14c9c-63cd-4b4a-8eb8-71cff7e09575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3adb8852-5139-4c9f-8381-fae4fb5d4650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53cf7617-40d3-4e4b-b31b-0724e436c99d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b51034c3-dd92-4283-b779-20b8d71f8ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df6d8b1c-ddcc-468e-8a79-0a551c29a650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d27d269b-65c2-4ea8-ad81-641f15c06179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 686d1ba6-f00c-4f0b-b188-d1288c17373f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bfa8207-9ae8-4790-910d-4c7b4602e166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c193a444-70dd-42b5-a69b-8e29cb80ac77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89eb6e2f-71d2-4948-9e32-22eeea649501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df9d1b69-07da-4161-acc1-38c184176e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bb7d773-7b05-48f8-b42b-a566166c1754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 645ea1b5-8562-428e-9e0a-04676a899614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b255f4-03b3-478e-b11e-ede539ea6709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 871253c3-287f-4550-8d7d-9b0bdf0834c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31646a45-a9fb-4502-aaa0-5ec534bbb781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96333c5f-0070-4906-9df9-de67ad76e979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8e7452d-a741-4c4b-b751-02f73a50f9ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c555de53-6ce9-400f-89fb-b152cb3e09f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b3b7302-da8a-4601-be4f-c78ed3e9cd41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5e33e4a-ca2d-4f13-96de-9e0a9bac53ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d65f0480-52ec-49f7-b7df-1e722e5047b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61bc842b-1790-4fc7-96a8-232926d811e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb779c36-117d-4bcc-aada-a546b8427e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82c214a4-2d87-4720-ac17-7b5dad0b1765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f726cfef-0f88-4f50-95ac-39b717bd4a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 913fb55f-21eb-4fea-b493-920adcb8cf9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b6a2f2f-fa5f-4534-b661-e47cf86a85b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 287cf34a-cbf1-43f2-972a-5eaa2957ffb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49152e61-db4e-4241-972c-8b2ed958e6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ee5552b-cf6d-415e-af3f-bf95e89d944f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc432215-3095-4dba-bd8d-2cd5d2ce8407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b539a4c9-4dc2-41c8-8bc0-ef54f109e289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 625e45a7-7c58-4d4c-9537-ae16e1bbb2c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27d2812b-8ac7-44c2-ae27-ce21192905db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8462b0a5-40a9-4a30-a49f-014c4d99d9a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4ad60b2-7c7a-4d50-8f84-a6c82ed0180c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3e30563-3943-49f7-87ae-4730e8cb4cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6aa1a1c-bc07-49db-a722-6e31145c7295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c1fc161-fcb3-4f28-8d64-e6eb1b6d6567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad4a1ecf-79ec-4bcd-bb7c-4b0b31187e56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d05da611-d220-42d1-bf69-4600bee18134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adf5fd73-f953-4a9f-95f2-629112e29da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bf073be-d17c-46b2-9a28-652827f27c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc7470ac-7e8d-421e-bdfb-92cfbd30a6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e064fde0-2b62-4290-86da-8e933347a063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddd9f563-6a43-4dd6-9ebb-e61393199bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 501f2a57-573d-4e55-8fe8-242c020ff966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbe1dad0-7f49-40dd-ab31-34672d2790ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75187386-b2bd-4b3a-986b-225f876f140b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e063d750-260d-4595-b5c8-2b18b16b2821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ac7b8b4-e8e1-414d-86e6-3764bf64451f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e907bda-b4cb-4848-8bb8-a62a74b11927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc6a6fa-4403-4d6e-9708-ef31c10da2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 271f8ec4-283d-4eac-a2b5-10be49287227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc472648-d0b9-4fa6-befd-60e9f117bd9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2692a893-4519-4e47-b926-d5c6b8d89e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bb5c7d0-86e5-4281-b1b0-6901f712415f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a8ed428-e527-4ffc-a2cf-c91fc42edb28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 683ef47f-71de-4d2f-a7e1-b14ac8ec7d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72e39470-aaca-406a-bdfa-adb1a3d6ecb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a609cc02-599c-4062-a734-15f6aa2f9120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9851317-eb7d-481e-8683-a2104131a890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31542c9c-f8fc-4223-8fee-54389c4c0382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0655682e-a47e-405e-8992-809af6a5b589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c043aae5-55fd-416b-b838-19115c001b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcc082be-9e5d-4c72-9900-4a53a2b531f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8232b3f-4733-49d8-9240-e936ec4badcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd9b42f4-b2f2-4f32-b5b2-dd9c73865064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ba0bbd7-1961-425c-8e3e-71b0f6be2b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bebb4b7-ab7d-4b10-98eb-56a6357b0c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c805083e-e9f2-4234-ac9b-ccf05612ff72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 350b6340-bbee-4e0e-90c3-b4bfd7d6fd0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd48b2d0-9bf1-47b4-b434-7cfe1cef0acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 878e4648-fd5f-4ce1-bf44-50a659424f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb4e44c-0e5c-441a-9e29-b00fe6139a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59ebdf5b-4591-4d15-9235-de199d33c409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78ba4d4f-94fa-4a64-b75d-b4560b059643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10dfd8c5-4baf-4619-9764-54786bd71a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fc496c9-9160-41d8-9d51-ff7751984139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39c34914-7f61-4648-9b49-27b018beab3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cff02130-7266-400c-9c63-64cf84d7cf26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05640629-c501-4d64-9f9e-27beab277bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a44818eb-9d1f-429d-a913-b6b0374c9324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c734b5fa-97cd-4052-8493-503d19247fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c277111-e24d-4fb4-9e31-c5006cb9a2fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 793c0279-ad3f-4fab-a25c-4c82bc48d77c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4fdec0e-3d5a-4bce-ab27-50af5fa691cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecdbf925-0013-4259-971a-4514d38c30a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cb88e37-5957-4455-b6d6-2c240942460f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ce685af-d946-4a82-8a20-d771d67de1a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f15c1a2-7090-4022-a62e-df0dcf775818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c61d786f-a139-44fb-9d70-120b538a7a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58b5f91a-3a84-42e9-b683-9789c3139505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0776761f-a9a4-4f72-b4c5-82250612e468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d95901b8-5c61-426b-9d04-ffa71b237038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c6c0fa0-d7c2-45c7-b4bf-823af9c18776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50c6d43c-0d9d-4a22-84e2-7add8927c678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da63f90b-12c6-4081-ab25-964265f96fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba706efc-0710-4e31-a2fc-86f568433366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 019293af-40a1-48ae-9f4b-6a0c231894c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1b11e07-1396-4fac-9d09-b7db43d375e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c972fd1-4d64-4381-b4d5-99d030281b94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45e1c1ac-5c97-43f0-adfe-d15b966a3dfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fefc6dc6-9ac2-4fd1-a6d9-59c7553d0103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49379660-e464-4b76-ba2f-ccd5ec30a047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c3cabaa-9e2d-43b8-bc7a-480a98cb0064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e85cf0b-07d9-4e89-8eb2-842093dfa532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea778ae-8111-45bb-a835-8e0c86005802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a859c2db-f607-4984-86d7-5c4576f04363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c0ea93a-1771-45cf-a080-aa7a2fc0cb38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85714215-6285-4a8c-a085-ff0c34941115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 836c8668-7ae7-4f84-b0b9-4f585599beb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91c096e6-2875-4451-817f-9384ee730f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cb070a2-5c15-4813-902e-ae9f6d15c8ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d058f6-b1f3-4ded-a869-8ffac5cab4a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a610cf06-c734-4bc9-9b8f-33c7f9538c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4cfafec-2208-4c8e-b967-eae489b35cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6850143-a18a-4ee8-b6d2-d1f411184e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 987cdaa2-4fd6-4822-9f3f-04f975adf369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 950948e7-b155-40f3-b286-c0bc56d41561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e91491fd-e897-4bc8-b560-cd24618dbab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e0079b5-cbb4-435c-bc39-2a4fab427fd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7384dbe-1974-45ab-b371-bae9de8db576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1f50b22-bcda-454c-82de-9780da4223c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63e774a2-d24c-40ab-819b-9f1b2e142d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a652593a-9882-47ca-bb3a-e3d452ccc44c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90107836-d2d5-48f8-8c03-b07ba42498d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58fb5e01-e772-4e1f-800d-77aaba9d59e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14aa1044-e2e1-45e5-980f-ebb258cd2789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10fee8ab-8090-4b12-9363-3cd14a90d477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd7c45ee-4c32-4bb6-941d-0ba4c3c4985f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de8b28e5-2fdf-4b15-948c-c902c9180e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ab532e0-80b5-4456-8ae1-023b41a04b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9552381-fd64-40ee-847c-0d6086808768
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_3
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_3
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_3/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_3/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_3/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_3/test_labels.txt

📊 Raw data loaded:
   Train: X=(1521, 24), y=(1521,)
   Test:  X=(381, 24), y=(381,)

⚠️  Limiting training data: 1521 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  372 samples, 5 features
✅ Client client_3 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1357, val=0.1122 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0834, val=0.0931 (↓), lr=0.001000
   • Epoch   3/100: train=0.0822, val=0.0929, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0822, val=0.0939, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0818, val=0.0936, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0802, val=0.0939, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 1 Summary - Client client_3
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0006
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0119
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.1851, RMSE: 0.4302, MAE: 0.3531, R²: -1.3164

============================================================
🔄 Round 5 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1642, val=0.1335 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1071, val=0.0888 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0863, val=0.0872 (↓), lr=0.000250
   • Epoch   4/100: train=0.0840, val=0.0872, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0843, val=0.0870, patience=2/15, lr=0.000250
   • Epoch  11/100: train=0.0838, val=0.0868, patience=8/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 5 Summary - Client client_3
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000250 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0008
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0026
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1818, RMSE: 0.4264, MAE: 0.3500, R²: -1.2759

📊 Round 5 Test Metrics:
   Loss: 0.1729, RMSE: 0.4158, MAE: 0.3413, R²: -1.1640

============================================================
🔄 Round 7 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1622, val=0.0945 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1031, val=0.0788 (↓), lr=0.000250
   • Epoch   3/100: train=0.0868, val=0.0823, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0862, val=0.0787, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0860, val=0.0802, patience=3/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0854, val=0.0800, patience=9/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 7 Summary - Client client_3
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0034
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0454
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.1665, RMSE: 0.4081, MAE: 0.3350, R²: -1.0842

============================================================
🔄 Round 8 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.1603, val=0.1285 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1312, val=0.1107 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1139, val=0.0956 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1000, val=0.0849 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0909, val=0.0795 (↓), lr=0.000063
   • Epoch  11/100: train=0.0861, val=0.0784, patience=5/15, lr=0.000063
   📉 Epoch 12: LR reduced 0.000063 → 0.000031
   📉 Epoch 20: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0858, val=0.0785, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 8 Summary - Client client_3
   Epochs: 21/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0026
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0004
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1544, RMSE: 0.3929, MAE: 0.3226, R²: -0.9323

============================================================
🔄 Round 11 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1596, val=0.1518 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1539, val=0.1453 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1480, val=0.1396 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1427, val=0.1344 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1380, val=0.1296 (↓), lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.1204, val=0.1128 (↓), lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.1084, val=0.1008 (↓), lr=0.000004
   📉 Epoch 23: LR reduced 0.000004 → 0.000002
   📉 Epoch 31: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.1041, val=0.0965 (↓), lr=0.000001
   • Epoch  41/100: train=0.1025, val=0.0949, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.1010, val=0.0933, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0996, val=0.0918, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.0983, val=0.0905, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0971, val=0.0892, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0960, val=0.0879, patience=4/15, lr=0.000001

============================================================
📊 Round 11 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0947, RMSE=0.3077, R²=-0.0927
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.1353
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1502, RMSE: 0.3876, MAE: 0.3183, R²: -0.8805

============================================================
🔄 Round 12 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1529, val=0.1661 (↓), lr=0.000001
   • Epoch   2/100: train=0.1526, val=0.1658, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1522, val=0.1654 (↓), lr=0.000001
   • Epoch   4/100: train=0.1519, val=0.1651, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1516, val=0.1648 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1498, val=0.1630 (↓), lr=0.000001
   • Epoch  21/100: train=0.1472, val=0.1605, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.1449, val=0.1582, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1427, val=0.1560 (↓), lr=0.000001
   • Epoch  51/100: train=0.1407, val=0.1539, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1386, val=0.1519, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1367, val=0.1499 (↓), lr=0.000001
   • Epoch  81/100: train=0.1347, val=0.1480, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1328, val=0.1460, patience=2/15, lr=0.000001

============================================================
📊 Round 12 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1311, RMSE=0.3620, R²=-0.5887
   Val:   Loss=0.1443, RMSE=0.3799, R²=-0.5475
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1396, RMSE: 0.3736, MAE: 0.3072, R²: -0.7470

============================================================
🔄 Round 14 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1438, val=0.1492 (↓), lr=0.000001
   • Epoch   2/100: train=0.1436, val=0.1490, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1434, val=0.1488, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1432, val=0.1485 (↓), lr=0.000001
   • Epoch   5/100: train=0.1430, val=0.1483, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1417, val=0.1470, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1396, val=0.1449, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1376, val=0.1429 (↓), lr=0.000001
   • Epoch  41/100: train=0.1356, val=0.1409, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1336, val=0.1388, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1316, val=0.1368 (↓), lr=0.000001
   • Epoch  71/100: train=0.1297, val=0.1348, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1277, val=0.1328, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1257, val=0.1307 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1240, RMSE=0.3521, R²=-0.4705
   Val:   Loss=0.1289, RMSE=0.3590, R²=-0.4995
============================================================


============================================================
🔄 Round 15 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1346, val=0.1401 (↓), lr=0.000001
   • Epoch   2/100: train=0.1344, val=0.1399, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1342, val=0.1397, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1340, val=0.1395 (↓), lr=0.000001
   • Epoch   5/100: train=0.1338, val=0.1392, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1326, val=0.1380, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1307, val=0.1360, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1287, val=0.1339 (↓), lr=0.000001
   • Epoch  41/100: train=0.1267, val=0.1319, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1248, val=0.1299, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1228, val=0.1279 (↓), lr=0.000001
   • Epoch  71/100: train=0.1209, val=0.1259, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1189, val=0.1239, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1170, val=0.1219 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1148, RMSE=0.3388, R²=-0.3672
   Val:   Loss=0.1201, RMSE=0.3465, R²=-0.3737
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1251, RMSE: 0.3537, MAE: 0.2920, R²: -0.5659

============================================================
🔄 Round 16 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1264, val=0.1465 (↓), lr=0.000001
   • Epoch   2/100: train=0.1262, val=0.1463, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1260, val=0.1460, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1258, val=0.1458 (↓), lr=0.000001
   • Epoch   5/100: train=0.1257, val=0.1456, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1246, val=0.1442, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1228, val=0.1420, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1210, val=0.1397 (↓), lr=0.000001
   • Epoch  41/100: train=0.1192, val=0.1375, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1175, val=0.1352, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1157, val=0.1329 (↓), lr=0.000001
   • Epoch  71/100: train=0.1140, val=0.1307, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1122, val=0.1284, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1105, val=0.1261 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1091, RMSE=0.3304, R²=-0.2862
   Val:   Loss=0.1241, RMSE=0.3523, R²=-0.5182
============================================================


============================================================
🔄 Round 17 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1277, val=0.1232 (↓), lr=0.000001
   • Epoch   2/100: train=0.1275, val=0.1230, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1273, val=0.1228, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1271, val=0.1226 (↓), lr=0.000001
   • Epoch   5/100: train=0.1269, val=0.1224, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1257, val=0.1211, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1237, val=0.1191, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1218, val=0.1170 (↓), lr=0.000001
   • Epoch  41/100: train=0.1199, val=0.1150, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1180, val=0.1130, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1161, val=0.1111 (↓), lr=0.000001
   • Epoch  71/100: train=0.1143, val=0.1092, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1125, val=0.1073, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1107, val=0.1054 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1090, RMSE=0.3301, R²=-0.2656
   Val:   Loss=0.1038, RMSE=0.3222, R²=-0.3189
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1073, RMSE: 0.3276, MAE: 0.2725, R²: -0.3433

📊 Round 17 Test Metrics:
   Loss: 0.0958, RMSE: 0.3095, MAE: 0.2593, R²: -0.1992

============================================================
🔄 Round 19 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1005, val=0.1054 (↓), lr=0.000001
   • Epoch   2/100: train=0.1003, val=0.1052, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1002, val=0.1051, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1000, val=0.1049, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0999, val=0.1048 (↓), lr=0.000001
   • Epoch  11/100: train=0.0990, val=0.1040, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0976, val=0.1027 (↓), lr=0.000001
   • Epoch  31/100: train=0.0962, val=0.1014, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0950, val=0.1002, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0938, val=0.0991, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0926, val=0.0981, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0916, val=0.0971, patience=5/15, lr=0.000001
   • Epoch  81/100: train=0.0906, val=0.0962, patience=3/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0897, val=0.0954 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0623
   Val:   Loss=0.0948, RMSE=0.3078, R²=-0.0636
============================================================


============================================================
🔄 Round 20 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0912, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0930, patience=4/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0897, val=0.0923 (↓), lr=0.000001
   • Epoch  31/100: train=0.0889, val=0.0916, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0881, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  51/100: train=0.0875, val=0.0904, patience=5/15, lr=0.000001
   • Epoch  61/100: train=0.0869, val=0.0899, patience=5/15, lr=0.000001
   • Epoch  71/100: train=0.0863, val=0.0895, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0859, val=0.0891, patience=13/15, lr=0.000001
   • Epoch  91/100: train=0.0855, val=0.0888, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 20 Summary - Client client_3
   Epochs: 97/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0259
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0090
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0111

============================================================
🔄 Round 22 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 22 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0199
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0063
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0802, RMSE: 0.2833, MAE: 0.2424, R²: -0.0043

============================================================
🔄 Round 24 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 24 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0110
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0016
============================================================


============================================================
🔄 Round 27 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 27 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0132
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0151
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2421, R²: -0.0017

============================================================
🔄 Round 31 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 31 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0030
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0336
============================================================


============================================================
🔄 Round 32 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 32 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0037
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0157
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2420, R²: -0.0008

============================================================
🔄 Round 33 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 33 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0064
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0007
============================================================


============================================================
🔄 Round 34 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 34 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0063
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0016
============================================================


============================================================
🔄 Round 35 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 35 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0049
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0071
============================================================


============================================================
🔄 Round 36 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 36 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0036
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0143
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: -0.0004

📊 Round 36 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: -0.0004

============================================================
🔄 Round 38 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 38 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0118
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0098
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: -0.0004

============================================================
🔄 Round 39 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 39 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0030
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0205
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: -0.0002

============================================================
🔄 Round 43 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 43 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0082
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0209
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: -0.0001

📊 Round 43 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: -0.0001

============================================================
🔄 Round 45 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 45 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0049
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0014
============================================================


============================================================
🔄 Round 46 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 46 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0041
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0048
============================================================


============================================================
🔄 Round 47 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 47 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0069
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0011
============================================================


============================================================
🔄 Round 48 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 48 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0039
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0055
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2418, R²: 0.0001

📊 Round 48 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2418, R²: 0.0001

📊 Round 48 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2418, R²: 0.0000

📊 Round 48 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2418, R²: 0.0000

📊 Round 48 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2418, R²: 0.0001

============================================================
🔄 Round 59 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 59 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0034
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0111
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0001

============================================================
🔄 Round 64 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 64 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0031
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0123
============================================================


============================================================
🔄 Round 65 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 65 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0047
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0031
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 67 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 67 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0024
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0093
============================================================


============================================================
🔄 Round 69 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 69 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0046
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0017
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0002

============================================================
🔄 Round 72 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 72 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0063
   Val:   Loss=0.0879, RMSE=0.2966, R²=0.0060
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0003

📊 Round 72 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 75 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 75 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0016
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0131
============================================================


============================================================
🔄 Round 78 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 78 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0004
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0207
============================================================


============================================================
🔄 Round 79 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 79 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0025
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0086
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0003

============================================================
🔄 Round 80 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 80 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0032
   Val:   Loss=0.0965, RMSE=0.3106, R²=-0.0069
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0003

📊 Round 80 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0003

============================================================
🔄 Round 82 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 82 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0045
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0016
============================================================


============================================================
🔄 Round 85 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 85 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2950, R²=-0.0039
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0089
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0003

📊 Round 85 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0003

📊 Round 85 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0003

============================================================
🔄 Round 90 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 90 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0026
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0071
============================================================


============================================================
🔄 Round 91 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 91 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0040
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0053
============================================================


============================================================
🔄 Round 92 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 92 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0057
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0100
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0004

📊 Round 92 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0004

============================================================
🔄 Round 96 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 96 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0031
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0038
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0004

============================================================
🔄 Round 102 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 102 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0042
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0009
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0004

📊 Round 102 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0004

============================================================
🔄 Round 106 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 106 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0051
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0036
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0004

📊 Round 106 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0004

============================================================
🔄 Round 108 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 108 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0032
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0051
============================================================


============================================================
🔄 Round 110 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 110 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0050
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0064
============================================================


============================================================
🔄 Round 111 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 111 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0027
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0090
============================================================


============================================================
🔄 Round 112 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 112 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0016
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0204
============================================================


============================================================
🔄 Round 113 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 113 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0046
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0102
============================================================


============================================================
🔄 Round 115 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 115 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0036
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0009
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0004

============================================================
🔄 Round 119 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 119 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0047
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0002
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0004

============================================================
🔄 Round 122 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 122 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0061
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0094
============================================================


============================================================
🔄 Round 123 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 123 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0044
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0136
============================================================


============================================================
🔄 Round 124 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 124 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0036
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0011
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

📊 Round 124 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 126 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 126 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0048
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0036
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 128 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 128 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0036
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0032
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

📊 Round 128 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

📊 Round 128 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 133 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 133 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0027
   Val:   Loss=0.0961, RMSE=0.3101, R²=-0.0035
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 134 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 134 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0058
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0085
============================================================


============================================================
🔄 Round 135 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 135 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0028
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0034
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

📊 Round 135 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

📊 Round 135 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 145 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 145 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0034
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0192
============================================================


============================================================
🔄 Round 148 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 148 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0040
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0020
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 149 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 149 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0020
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0064
============================================================


============================================================
🔄 Round 150 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 150 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0000
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0143
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

📊 Round 150 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 152 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 152 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0054
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0026
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

📊 Round 152 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 154 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 154 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0090
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0395
============================================================


============================================================
🔄 Round 155 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 155 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0039
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0007
============================================================


============================================================
🔄 Round 156 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 156 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0009
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0125
============================================================


============================================================
🔄 Round 158 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 158 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0052
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0013
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 160 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 160 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0033
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0037
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 162 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 162 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0030
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0036
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

📊 Round 162 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 165 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 165 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0029
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0450
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

📊 Round 165 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 168 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 168 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0064
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0121
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 170 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 170 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0037
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0082
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 172 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 172 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0042
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0025
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 173 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 173 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0031
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0123
============================================================


============================================================
🔄 Round 177 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 177 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0023
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0084
============================================================


============================================================
🔄 Round 179 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 179 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0019
   Val:   Loss=0.0979, RMSE=0.3129, R²=-0.0053
============================================================


============================================================
🔄 Round 180 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 180 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0022
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0067
============================================================


============================================================
🔄 Round 181 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 181 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0024
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0053
============================================================


============================================================
🔄 Round 182 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 182 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0006
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0122
============================================================


============================================================
🔄 Round 183 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 183 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0030
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0110
============================================================


============================================================
🔄 Round 184 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 184 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0018
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0089
============================================================


============================================================
🔄 Round 186 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 186 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0023
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0041
============================================================


============================================================
🔄 Round 188 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 188 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0011
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0148
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 190 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 190 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0013
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0099
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

📊 Round 190 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

📊 Round 190 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 194 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 194 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0013
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0078
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 196 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 196 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0017
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0103
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

📊 Round 196 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

📊 Round 196 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 199 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 199 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0030
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0022
============================================================


============================================================
🔄 Round 200 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 200 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0041
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0025
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

📊 Round 200 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

📊 Round 200 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 208 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 208 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0045
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0026
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

============================================================
🔄 Round 209 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 209 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0028
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0021
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: 0.0005

❌ Client client_3 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
