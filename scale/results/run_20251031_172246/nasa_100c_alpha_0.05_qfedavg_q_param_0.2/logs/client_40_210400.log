[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65d482c2-93c7-4245-9dca-30e94f4d5137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76701cd2-64ea-4c69-a7b2-652808e3edcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34cdc275-8939-48e2-a14c-025606768afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b4c7b95-fd60-4cc5-9ac9-d107b7d1a15f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3302b93-43c9-424e-b50f-5bf41b069f36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22b1d8d1-1b67-4bfd-b9c6-910b127588fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea169edf-2799-44e6-8df8-8049704a5d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5001fe4a-e76c-48c3-be55-be33f64ef38a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b4daa87-ea92-478c-ad03-4c01f311d3ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a369c781-cf8e-4bf6-ba4a-573b6f9ff67c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3e17ae8-9e70-4c58-ad58-e5edc354b646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a0cf186-b660-47b7-a962-d410e584e21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11b00f58-cb6a-4158-8e04-d334c98bf548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84f0d502-29d1-4e1f-8458-41a783a10433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afd1415f-b452-4e44-b01f-3e4f40e014ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1bfba1e-7d7a-46a7-a872-39935a9b34ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf29224-30c9-460d-b277-9571ca939bd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 872bea6c-7e2c-4eab-b6b5-579b54410275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25752862-13e2-40a0-b820-00d39e9b4202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5296b1a0-e737-4d71-988d-d95a965dfd96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dd01ca8-2433-4d39-8fd8-8bde8f665c9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ee9f7f7-873c-4803-a657-e53214456073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c2923fa-e421-4ace-ae16-b2f93b91e61f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a594fb6-e60d-486b-ab38-9ab548b23a72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b70bd2db-eadf-46ea-8f4c-64d6fada3a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84d53fd7-e7e5-46dd-b6d6-f1fa66c59c15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8ae3f87-b87c-4220-989f-815fab1e3b6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8959f78e-5088-43d4-9dc9-1cdbdab6ea0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8b4dc29-7349-41d1-85b6-e55659f2cbbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 557a170a-94d8-4816-938c-e1d8d6e67639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c42e1235-0bc6-461d-b2a8-1edece4ac66e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ad5773a-fd0f-45f3-88ce-a38c42df58c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38a26765-cc06-4cbc-85f0-2ab01a8bec26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0308751d-f93c-4382-97f1-174dc5ac8447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 932f269f-361d-4ce7-a913-dcfd4e1cbb3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ac4e1a7-90c7-401d-84fd-b5abe148ea46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 939cf47c-a8ed-4bd1-bfff-ecace61d766f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24c10c0f-4d30-418a-9ff1-20959b564ed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0980c0c-0690-420d-9477-c3557ab96db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceaf869b-a0fd-4978-9f48-6422a992fc14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ef0cf34-8c17-4b4c-a4d8-791014d5be1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77ed505c-0c12-4769-aec3-82c4b888f2b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fec57ff3-bbcb-4e98-b029-b7182202c60e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59f72525-866b-43b0-a422-8773f1331b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 666ad4ec-50ab-42e0-912e-5e29b101f3a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bf645b3-0d4c-4cf8-a80a-a56ff4a8ab9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8d4c46a-32af-41fc-89a2-31e2269ac4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d741c5d1-88c6-4d7e-b4f2-bb1a9769287b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3d38d22-693f-4cc1-afc9-b91966ad044e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5036007-c887-459d-a625-c192ad8ef038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7edf20e2-34b7-472c-b6b6-9462f964f196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d78f35ff-6b87-4822-8430-af9eac625160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6162230-70c4-4251-9911-f7b70de49f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f14f0a53-d200-455a-952f-8af385a5ad95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f208dab9-9c59-4b66-95db-ef714ba44eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ad0cfb9-08d5-4a4b-8584-4a3decf494bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7655add0-2fcd-4d23-ba59-f72015373e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3c4ea87-5e95-49db-b33b-9884298704dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be3bb76-148e-4ce1-9d06-672c8718810a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77b0ee5c-0153-4245-8036-422571674180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5fcfad1-91e1-4546-ac5a-6b986e253446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c0896c7-a03e-40b2-9d76-3614623d0dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d04cdd3f-2134-498c-a159-6db4f2779378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e571c2d-cdb2-435d-9020-802de9040ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb869758-8b8a-4725-872f-034f992c65bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 939a1a00-76ba-449d-9908-a2ac0c42ae31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42571924-3718-41ca-adac-ef9d367295f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aec77003-d208-40cb-bb76-5831c8d980d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ac57b7d-d71a-4120-8a0e-925e1ae3fbd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e67d6366-a9cc-4c35-9a14-dc042388bfa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e977307-1630-4852-92fc-236182d7e087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cb6301f-5d71-4fa5-b9fc-4eea4f0d469b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95a93fe2-ceb6-4dc7-aadf-00fd66d0b8e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f64c29c-5dd4-4ed2-ad04-276c6f896c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c25936b-5133-4884-ac6d-993d32933ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55b92981-985d-47d8-99a8-264777d2ebce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 496a75ba-a6da-44c0-8cba-4f75cab7cc55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54e3b62b-2e9a-4ea8-88f4-289723dcb9b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 890546f8-5e66-4b60-abf3-e449129fedb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afceefab-165d-4764-84fb-588464eea576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47bf0e1d-a701-4102-b7e7-9ca12034a7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 719827df-dc46-455c-b60f-e6308d8aac1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f626c21-9157-465a-bfb9-7da8a025d722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b940b454-279b-4397-9c8f-9c9820dcba6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43229866-13db-4912-a001-7d0d4d5db405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10ddb24b-e372-4eec-bd85-c06e1243ad5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd4b132f-3d12-4aff-9422-33dda6c484dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfafe9ea-b4e0-4a25-87f8-67fce819bf04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08beb2d0-7b8d-4a20-9288-174eeef756d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acecd89e-c9a7-420f-99f4-85e3f880b80b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09356e38-541c-4b78-936c-6d77e31b05b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f72d77b3-a6dc-4c44-a109-c521db6195ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b2fffdb-b235-4210-820e-c8936128912e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 282385bc-577b-45bd-83ff-dcfbafa3a203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1cf58a6-38c1-4e41-a5e4-bbf640210f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b19d3a9-d1d3-4aaa-82c8-59e8ef93142d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68fd44ad-106d-48fb-b258-7eb0da45b6a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f8c90c5-7330-4c9f-a61f-fec40e8502f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67539d04-8fee-4253-a1a4-9e7ac2b2239a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a44aa40-4c93-4123-a46b-40591c22f5ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5fe50bf-95d4-4786-8899-ee504bc5b5ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cf494fb-e7fe-4f52-9e77-ab8a9ef4292d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0dee228-a54a-4931-8876-b9251dbb0c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b20fe909-9443-43f6-b8f0-b44fd8e3aec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ed6cb73-ec94-4506-be19-8200b22265ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d5e6ffd-c9b4-42ca-955a-791638fdc7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c73d20c-72d1-49ed-bcb8-585b868206ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07f9e89b-777c-442e-92b1-20720c96e7be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 113a926e-bfcc-4efc-abf4-c07118af7e20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e39537c7-1494-4ca8-83ce-8f6ea840d333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a31a2e2d-e353-436f-b884-99d11de4682c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f0004ab-2820-4d29-a82a-879bde82297b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd7bfce4-52a7-49b4-968e-5a34e8e4f4d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5db41b24-f3bb-470f-aa7e-2a1efbb66761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6be80799-77a2-4679-9dd3-045ccf203161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79e7644f-8010-4f93-9d07-8458157ab18f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89bb6bfb-e3c7-4d6d-a79b-ffe9ec565b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08cf36df-1af9-4768-b2b9-69f2c4d7a9e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd6e3577-3105-4dba-b681-4e7ea3076619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 006b3804-2e94-4380-af18-4cacd24f5347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5901cad9-c554-4c4b-9302-3ff35bc4649e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message befe3f5b-6329-45ec-afeb-3cd4dab7c167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b38186df-f161-42d6-8619-05e16686707d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51c76bf0-659d-4859-9fb7-a7b48e30a134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d9a1ff5-2907-4230-a393-70e9f3d08ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c11386b-7bae-41ac-9979-0488a741f2c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faba742a-0efc-4d98-ad46-da7b0180d925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b63a84c3-d911-4d70-bf50-bb2d53503e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5bf643d-0aa9-4c03-ba4f-0dee69cb8f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d93080-a1ff-44eb-9306-a9668dc6d24a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eacc9ae-467b-481d-a322-77b2fdc7bb07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58e440f2-aec0-4dde-b646-62bea4a48217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db79ec1b-ab96-48d0-bb67-d156878675ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95e888ee-979f-4d75-8084-0b92c79ab012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 828ba745-57f8-4dd5-adf6-b7dcf52110ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c0c79a6-e558-4402-a6a6-1be81468b47e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f187a9e-09dd-42e3-861d-76b56ca23330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54985d9e-5c0f-4f8e-b5ed-bcd6aff1ff62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce3d3ca4-38fa-49bd-9f54-8b2ca59d8eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cc450ce-62b6-454a-8133-5802f8054487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3368b36f-f22b-4892-9099-85ea2c7b872d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 708f35bd-7b78-4679-bf03-78f252787fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4631ffb5-f7f0-4308-9ffa-60478ee1d732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8991de2e-cbcf-47cb-a92f-f94a4ac60a43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b5ef1cd-a798-4cb0-bd0b-cfe9e8eca2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52b84c4b-5050-4e80-a12d-d77da84f8e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 573e3293-d1ae-4a59-8ab3-668320803572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eb81e91-fb43-4245-ad0f-949be0ea8581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e75d953c-92f8-4afd-8590-dbaa6a897385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe2ea025-168e-49c1-a145-9b7854ae56c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 697a06e5-56d0-4971-bbbc-6be0e99f12fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a66f90d-5d50-4f32-881c-e9a47b75b076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 653de104-4e0e-4426-b321-02ffcd04dc76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68fd297a-6613-4838-95c4-2f71f6b2c96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2966b77-9d22-47bb-9ccc-838bc75b46fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 235299dd-34b7-498a-b780-02877f19d1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1781beec-9b2d-4ffd-9cce-9a46d27759e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be9353de-06d3-4b54-909d-9b77009cdecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 030b902e-3a9d-4f72-a08e-179342856ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e19da6ae-a32a-446a-af33-3dcab609836f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 145ded81-2bc4-4e62-b0d3-75482eddbae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 109ee00f-661e-4361-94a0-d6de72bdbaa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7ac35f4-2a18-4acb-9e2f-8b1b880a0480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0853d296-a519-4d66-91bf-819dd1b48ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f96ef54e-b6f7-4f42-a769-ea4607ff42a7
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_40
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_40
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_40/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_40/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_40/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_40/test_labels.txt

📊 Raw data loaded:
   Train: X=(1839, 24), y=(1839,)
   Test:  X=(460, 24), y=(460,)

⚠️  Limiting training data: 1839 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  451 samples, 5 features
✅ Client client_40 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1177, val=0.0812 (↓), lr=0.001000
   • Epoch   2/100: train=0.0825, val=0.0837, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0807, val=0.0866, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0808, val=0.0853, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0806, val=0.0848, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0792, val=0.0845, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 5 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0276
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0074
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1729, RMSE: 0.4158, MAE: 0.3389, R²: -0.9167

============================================================
🔄 Round 8 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1506, val=0.1128 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0937, val=0.0819 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0824, val=0.0810 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0829, val=0.0802 (↓), lr=0.000250
   • Epoch   5/100: train=0.0825, val=0.0800, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0820, val=0.0798, patience=7/15, lr=0.000250
   📉 Epoch 19: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 8 Summary - Client client_40
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0036
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0061
============================================================


============================================================
🔄 Round 13 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1501, val=0.1081 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.1092, val=0.0817 (↓), lr=0.000125
   • Epoch   3/100: train=0.0843, val=0.0820, patience=1/15, lr=0.000125
   • Epoch   4/100: train=0.0824, val=0.0818, patience=2/15, lr=0.000125
   ✓ Epoch   5/100: train=0.0820, val=0.0807 (↓), lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0815, val=0.0809, patience=6/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 13 Summary - Client client_40
   Epochs: 20/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0025
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0209
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1465, RMSE: 0.3828, MAE: 0.3154, R²: -0.6250

============================================================
🔄 Round 14 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1516, val=0.1292 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.1390, val=0.1168 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.1266, val=0.1059 (↓), lr=0.000031
   📉 Epoch 4: LR reduced 0.000031 → 0.000016
   ✓ Epoch   4/100: train=0.1158, val=0.0966 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1086, val=0.0925 (↓), lr=0.000016
   ✓ Epoch  11/100: train=0.0896, val=0.0768 (↓), lr=0.000016
   • Epoch  21/100: train=0.0839, val=0.0735, patience=5/15, lr=0.000016
   • Epoch  31/100: train=0.0837, val=0.0734, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 14 Summary - Client client_40
   Epochs: 31/100 (early stopped)
   LR: 0.000031 → 0.000016 (1 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0069
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0089
============================================================


============================================================
🔄 Round 15 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1442, val=0.1215 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1386, val=0.1166 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1325, val=0.1120 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1268, val=0.1078 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1216, val=0.1040 (↓), lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.1048, val=0.0933 (↓), lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0937, val=0.0869, patience=1/15, lr=0.000004
   📉 Epoch 22: LR reduced 0.000004 → 0.000002
   📉 Epoch 30: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0903, val=0.0853, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0890, val=0.0847, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.0879, val=0.0843, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0868, val=0.0839, patience=11/15, lr=0.000001
   • Epoch  71/100: train=0.0859, val=0.0837, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 15 Summary - Client client_40
   Epochs: 80/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0588
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0205
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1325, RMSE: 0.3640, MAE: 0.3025, R²: -0.4693

📊 Round 15 Test Metrics:
   Loss: 0.1288, RMSE: 0.3588, MAE: 0.2990, R²: -0.4277

============================================================
🔄 Round 17 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1332, val=0.1244 (↓), lr=0.000001
   • Epoch   2/100: train=0.1329, val=0.1241, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1326, val=0.1237 (↓), lr=0.000001
   • Epoch   4/100: train=0.1323, val=0.1234, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1319, val=0.1231 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1302, val=0.1214 (↓), lr=0.000001
   • Epoch  21/100: train=0.1275, val=0.1188, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1250, val=0.1165 (↓), lr=0.000001
   • Epoch  41/100: train=0.1226, val=0.1142, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1203, val=0.1120, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1181, val=0.1099 (↓), lr=0.000001
   • Epoch  71/100: train=0.1160, val=0.1079, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1140, val=0.1060, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1120, val=0.1041 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_40
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1105, RMSE=0.3324, R²=-0.3301
   Val:   Loss=0.1024, RMSE=0.3200, R²=-0.3310
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1154, RMSE: 0.3397, MAE: 0.2863, R²: -0.2792

📊 Round 17 Test Metrics:
   Loss: 0.1044, RMSE: 0.3231, MAE: 0.2758, R²: -0.1578

============================================================
🔄 Round 19 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1020, val=0.1086 (↓), lr=0.000001
   • Epoch   2/100: train=0.1018, val=0.1084, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1017, val=0.1082, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1015, val=0.1080 (↓), lr=0.000001
   • Epoch   5/100: train=0.1013, val=0.1078, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1002, val=0.1068, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0985, val=0.1050, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0969, val=0.1033 (↓), lr=0.000001
   • Epoch  41/100: train=0.0953, val=0.1016, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0937, val=0.1000, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0923, val=0.0985, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.0909, val=0.0971, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0896, val=0.0957, patience=3/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0884, val=0.0945 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_40
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0802
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0809
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0917, RMSE: 0.3028, MAE: 0.2623, R²: -0.0165

============================================================
🔄 Round 22 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0811, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0846, val=0.0808 (↓), lr=0.000001
   • Epoch  21/100: train=0.0842, val=0.0804, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0839, val=0.0800, patience=8/15, lr=0.000001
   • Epoch  41/100: train=0.0837, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  51/100: train=0.0835, val=0.0794, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 22 Summary - Client client_40
   Epochs: 52/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0105
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0305
============================================================


============================================================
🔄 Round 23 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0849, patience=1/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0828, val=0.0844 (↓), lr=0.000001
   • Epoch  31/100: train=0.0826, val=0.0840, patience=10/15, lr=0.000001
   • Epoch  41/100: train=0.0825, val=0.0836, patience=8/15, lr=0.000001
   • Epoch  51/100: train=0.0824, val=0.0833, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0823, val=0.0830, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 23 Summary - Client client_40
   Epochs: 63/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0026
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0481
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0906, RMSE: 0.3010, MAE: 0.2610, R²: -0.0046

============================================================
🔄 Round 25 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 25 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0135
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0261
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0036

============================================================
🔄 Round 27 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 27 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0123
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0157
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0036

📊 Round 27 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0035

📊 Round 27 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0034

📊 Round 27 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0034

============================================================
🔄 Round 33 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 33 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0088
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0173
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0034

📊 Round 33 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0034

============================================================
🔄 Round 38 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 38 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0054
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0353
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0034

============================================================
🔄 Round 39 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 39 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0077
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0145
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0034

============================================================
🔄 Round 41 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 41 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0090
   Val:   Loss=0.0705, RMSE=0.2655, R²=-0.0075
============================================================


============================================================
🔄 Round 42 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 42 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0085
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0089
============================================================


============================================================
🔄 Round 43 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 43 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0159
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0063
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0034

============================================================
🔄 Round 44 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 44 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0103
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0003
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0034

📊 Round 44 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0034

============================================================
🔄 Round 47 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 47 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0054
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0253
============================================================


============================================================
🔄 Round 48 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 48 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0062
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0163
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0035

============================================================
🔄 Round 50 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 50 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0094
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0009
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0035

============================================================
🔄 Round 52 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 52 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0100
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0018
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0035

📊 Round 52 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0035

📊 Round 52 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0035

============================================================
🔄 Round 60 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 60 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0019
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0439
============================================================


============================================================
🔄 Round 61 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 61 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0084
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0072
============================================================


============================================================
🔄 Round 62 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 62 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0082
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0062
============================================================


============================================================
🔄 Round 64 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 64 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0041
   Val:   Loss=0.0884, RMSE=0.2972, R²=-0.0223
============================================================


============================================================
🔄 Round 65 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 65 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0034
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0441
============================================================


============================================================
🔄 Round 66 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 66 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0029
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0299
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0036

📊 Round 66 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0036

📊 Round 66 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2610, R²: -0.0036

============================================================
🔄 Round 71 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 71 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0144
   Val:   Loss=0.0729, RMSE=0.2701, R²=-0.0094
============================================================


============================================================
🔄 Round 72 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 72 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0106
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0067
============================================================


============================================================
🔄 Round 73 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 73 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0067
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0087
============================================================


============================================================
🔄 Round 74 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 74 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0061
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0084
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0037

============================================================
🔄 Round 76 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 76 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0073
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0022
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0037

============================================================
🔄 Round 80 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 80 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0082
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0002
============================================================


============================================================
🔄 Round 84 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 84 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0126
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0066
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0037

============================================================
🔄 Round 85 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 85 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0115
   Val:   Loss=0.0719, RMSE=0.2682, R²=-0.0018
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0038

============================================================
🔄 Round 88 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 88 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0065
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0048
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0038

📊 Round 88 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0038

📊 Round 88 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0039

============================================================
🔄 Round 97 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 97 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0026
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0229
============================================================


============================================================
🔄 Round 99 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 99 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0024
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0318
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0039

============================================================
🔄 Round 102 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 102 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0034
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0279
============================================================


============================================================
🔄 Round 103 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 103 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0054
   Val:   Loss=0.0965, RMSE=0.3106, R²=-0.0054
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0039

📊 Round 103 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0040

============================================================
🔄 Round 105 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 105 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0058
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0035
============================================================


============================================================
🔄 Round 106 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 106 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0043
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0113
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0040

📊 Round 106 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0040

📊 Round 106 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0041

============================================================
🔄 Round 112 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 112 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0031
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0145
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0040

📊 Round 112 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0040

============================================================
🔄 Round 114 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 114 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0078
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0010
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0040

📊 Round 114 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0040

============================================================
🔄 Round 116 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 116 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0067
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0007
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0040

📊 Round 116 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0040

============================================================
🔄 Round 121 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 121 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0058
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0032
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0041

============================================================
🔄 Round 122 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 122 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0074
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0036
============================================================


============================================================
🔄 Round 123 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 123 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0048
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0054
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0040

============================================================
🔄 Round 124 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 124 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0070
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0014
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2611, R²: -0.0041

============================================================
🔄 Round 125 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 125 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0047
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0058
============================================================


============================================================
🔄 Round 126 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 126 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0038
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0094
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0041

============================================================
🔄 Round 127 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 127 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0039
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0085
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0041

============================================================
🔄 Round 129 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 129 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0008
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0560
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0041

============================================================
🔄 Round 132 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 132 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0046
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0068
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0041

📊 Round 132 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0041

📊 Round 132 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0042

============================================================
🔄 Round 138 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 138 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0014
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0286
============================================================


============================================================
🔄 Round 141 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 141 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0062
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0004
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0041

📊 Round 141 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0041

============================================================
🔄 Round 146 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 146 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0082
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0040
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0041

============================================================
🔄 Round 148 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 148 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0066
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0004
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0041

============================================================
🔄 Round 149 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 149 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0065
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0021
============================================================


============================================================
🔄 Round 150 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 150 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0043
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0068
============================================================


============================================================
🔄 Round 155 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 155 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0039
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0084
============================================================


============================================================
🔄 Round 157 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 157 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0045
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0053
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0041

📊 Round 157 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0041

============================================================
🔄 Round 163 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 163 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0059
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0007
============================================================


============================================================
🔄 Round 165 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 165 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0020
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0200
============================================================


============================================================
🔄 Round 169 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 169 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0023
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0128
============================================================


============================================================
🔄 Round 172 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 172 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0120
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0116
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0906, RMSE: 0.3010, MAE: 0.2611, R²: -0.0043

============================================================
🔄 Round 174 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 174 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0065
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0018
============================================================


============================================================
🔄 Round 175 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 175 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0068
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0011
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0043

📊 Round 175 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0042

============================================================
🔄 Round 177 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 177 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0075
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0033
============================================================


============================================================
🔄 Round 179 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 179 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0035
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0072
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0042

============================================================
🔄 Round 180 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 180 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0038
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0060
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0043

============================================================
🔄 Round 181 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 181 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0022
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0181
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0043

============================================================
🔄 Round 184 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 184 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0047
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0020
============================================================


============================================================
🔄 Round 185 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 185 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0084
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0007
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0043

============================================================
🔄 Round 187 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 187 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0061
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0024
============================================================


============================================================
🔄 Round 189 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 189 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0004
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0476
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0043

📊 Round 189 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0043

============================================================
🔄 Round 192 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 192 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0033
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0085
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0043

============================================================
🔄 Round 193 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 193 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0076
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0030
============================================================


============================================================
🔄 Round 194 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 194 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0066
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0023
============================================================


============================================================
🔄 Round 195 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 195 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0070
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0014
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0906, RMSE: 0.3010, MAE: 0.2611, R²: -0.0043

============================================================
🔄 Round 200 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 200 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0032
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0079
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0043

============================================================
🔄 Round 202 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 202 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0067
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0005
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0043

📊 Round 202 Test Metrics:
   Loss: 0.0906, RMSE: 0.3010, MAE: 0.2611, R²: -0.0043

📊 Round 202 Test Metrics:
   Loss: 0.0906, RMSE: 0.3010, MAE: 0.2611, R²: -0.0043

============================================================
🔄 Round 208 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 208 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0038
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0065
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0043

============================================================
🔄 Round 209 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 209 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0029
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0108
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2611, R²: -0.0043

============================================================
🔄 Round 211 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 211 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0107
   Val:   Loss=0.0785, RMSE=0.2803, R²=-0.0109
============================================================


❌ Client client_40 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
