[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c93354e4-a60d-494d-a509-9c4c81035e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d30cba3-30e0-470d-b666-362d1c57fc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c156ac59-4a6a-48c3-8fd0-be10556de4cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5f5289f-3ce9-4991-bef9-bc358196a400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aea38db-7c0b-42ab-8290-bedcc5e5646a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3634dd8-c7b6-4e93-a9ad-60cdb35da982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 106d8d60-ed84-47a9-9c95-745b4c1bcfc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a07e7473-b378-4149-8468-5423eb416925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b36ddc1f-8166-4b45-b47f-d19bd42ee25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad4ad692-ee7d-4399-9e5c-064df1b9d013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 590e13ed-8bd9-44df-9cd9-336908935f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d94df65-f1c9-4ab9-a80f-b807b2b417ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82258279-ebcb-4966-b0e1-21f2ed725a5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c4a2f2b-ead9-45ef-a54c-37ae787a843c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a7db550-66f6-4ecc-8a98-d90c942cdaed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf8c78f8-ab13-4ad1-b7dd-6acc3e0f8311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71fb5eec-77c9-473b-811c-a7ad3f81fff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 469aa91a-ebad-46c0-8cd5-435762684599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 282948e5-8bee-4d55-bea5-25ebc2f0e691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a299827d-409d-42bb-842f-670e37fc5629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 794b2312-ae81-4f0e-a4df-1e8ab292d802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a92d8819-e198-4798-b4c4-7e14c4325d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e575c0d-ed37-49bb-a0b7-7b420df6c352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c529c0aa-49b5-479b-94b2-a3333d586735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63c1bb0e-ae10-4a00-bb8c-13ad2c20e73e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54f44128-090c-4901-85cd-e08c20b13ef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47c0b9e3-aa9e-4062-a7c9-29e63e014d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0e0e631-8bf4-4861-8afb-9c92ccc770ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d445a73b-6908-4101-83f4-c80abf116292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da1f0019-983c-4e8e-8c48-7d1f5090b5f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdcdb1ab-aac2-4981-8281-83603a1915bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9755547a-bef4-4038-9551-e2c2fe32f5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57358e92-66fd-4495-bdd4-f49f80eea538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06e774e1-ca85-4532-b8a2-a77186d0eb0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd1a3614-462c-4851-9044-e8aec40b6c4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f303006-1619-46bf-bf61-6cef7f8649c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a71f2e6-bc7e-409a-851b-b0c61bff3e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 217a815f-b73a-40b0-be6a-17ff4f092d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97fe7cb5-4972-4ea4-b0dd-f7d4f3b17433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da25789b-17b5-4939-b444-ce9af1d7f860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a051dc0-2f25-4fe6-bdad-6dfef6c7a81c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4282438-4eb8-4b5b-ab13-ff3f669da690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00ab4ddf-1244-4634-918a-6f56195f364d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad4b0513-617e-47ca-ac13-87f1dcf4ad80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99f4039a-e52f-4374-8f6e-e143a3d9f991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ac6aaa9-ce57-4fba-9176-2685d9803f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73e829ee-bd29-4609-a59e-ff9698db5964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b5c1e52-f9f3-4937-b471-5deb48118c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4be36d7-497b-4861-b346-1967f66c6dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f54800e-9c86-4088-ba6d-dffa28077be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba46c115-94d5-4ef8-b3f7-24659e387f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f15e65b2-bf5b-4d2b-a776-cace3462760d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44d48321-59e7-4356-8676-5c78eb0cd8b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de4dbae-49a3-40aa-ac12-52c22de86d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eedba547-b16d-4296-8245-5f321b381685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f94e37a3-f3b6-4d4f-ad93-2b60b18f94b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4359ef07-6fdf-492e-b78a-ca71a415e619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f097388-6ff4-429d-bd52-59482de07f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a2ff5ce-9151-4252-87c6-6604972fd41f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e499731-7586-4992-9c69-21b42189ab9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6bc1976-4d61-48f5-841e-3ee10c895281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aa50218-9c23-41ee-99f0-e0e753feb0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19f3893f-ceb3-4957-bd62-fd1615c8c60c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a050d349-528c-45ae-bca5-bee36663de20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4433328-0b05-4cbe-923a-f2ce28b2235f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9797ec09-448b-4afa-aa32-61920e5aeddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcae81dd-3c80-4e8e-8816-d26b0714402e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03b5d2e9-ce9c-4721-ab98-e546ea338d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbf0aacc-f289-41fb-b2a6-1ca6bee6826c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0df04776-1fc6-42fe-9b67-7f69138bda76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cb64bf3-8354-4e4d-bfd3-7c40f2acad96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d57a3258-c111-4847-8911-889600b7e9dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc874c03-6c3c-4d2e-a2b4-a26991a60e16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e78945a6-2b08-4f1e-8d98-3dcb07706d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63c328db-ba35-4217-a9a3-b842f269946a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62899872-81e5-470a-8b94-7f4fc425afda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f124ac46-e4d3-48c2-b373-2131da0e7299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66102bea-e185-41f5-a517-051435f6a4c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af805bc2-cb9a-4bf7-9345-a5f9d16e6d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e477448-56af-49de-8572-bff48ed65445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e368bd2-d97b-4ec3-8902-0ae97d20067c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d257e08-8994-4ce5-9287-ae2f40bae15e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f6c2e0e-54a8-4127-973f-dbc944de14fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a844d050-36ea-4250-b5d2-832a819c3a43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 345fc956-d50b-4f36-a299-05df9fc7e42e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb5fd0b4-5973-4be1-bf92-0cf80981eab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6653b8e8-a692-4b36-968c-6ccf36eaa0d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c179f6f-7d41-4a38-b97e-c18713dd66da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce0a487b-cbaa-4017-867a-6bd4415ee634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a460139-b9eb-4be7-8832-7ee5038db2a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b54df0c9-0e9f-477a-9a7f-5ceea967b48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5f819a1-f1fb-49f4-952c-99073637abfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdd0d64e-939c-4de8-b0ed-08d5f4c99efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7890b462-24a8-4d99-bdf1-a7ca8014fab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 383ef63a-70c8-4707-b7f2-46c1c8bdacf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6effdde-0759-4620-a3eb-3f23264e5e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8c581e3-4e94-4890-aa8d-e51a0d917864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4cf9397-3884-4792-a874-96fc8dd4c67d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9bc75c5-a934-4102-967b-d3e2080a5c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f708cb8-b803-4667-85d5-84dd21810250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e22dac4a-e729-4baf-a82b-b00e1131ed23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04de69f7-9b50-4afb-9480-fa79959287a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ca82548-a334-4ac2-a23a-85c90454b6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93ee99d8-bfb4-4b0b-b644-cbb0bb767f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c020eb15-5e88-41c1-b5bd-a953c7001dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be06ceb7-6afb-44b2-81c3-442aec0a696b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d58dfe91-0608-4c85-bb77-438afbe29c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb13acda-c9ca-4b70-ab4e-f979e63000ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c6905dc-0491-4eac-b123-340be6a0d415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2be068c-5a47-4d09-99bf-acda8c82eff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37f66c72-4089-4bbd-b099-021d29ed6dad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 785e6432-c569-4826-90eb-6c09919e8b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2809d427-99de-4e92-bbee-2240125dcafb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c89c081f-e09d-40cb-ba4f-b335206bc1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bea2210b-0377-4b08-af91-fa3765ae1b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ddcf844-c651-4801-878b-73d8186054ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ff0986a-e366-4bb9-83a8-13a4435c1601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ff20116-d4d7-4d8f-94ad-16a8158568e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5681f55-409a-41fc-b7fa-0276cb19af6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39a6fddf-5f71-460f-84f5-98988d1e5932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b77effdc-eeba-4310-b08a-e434ce0acc55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1e810ec-75d8-478f-9eff-ea6f5386bec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 921aec7a-d304-4da6-ac4b-3e45d4cb00cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd6bd48a-3e74-4d90-a2db-23a8e3f6141a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf17e271-0716-4a3e-9982-eee3f03f7bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b643e824-3d17-4669-8db4-7324c5be690b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 541a1981-9181-40e7-b64b-851387a4d7b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7b89365-a746-4445-87d8-5122222dbf49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b85d6749-89b4-4021-8775-5b8ebfaecb36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a740824-24e6-4afd-aa33-6a28737da04f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f6fb98c-6e48-480d-b983-ebe8fb44022a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c53d09e-66b5-420e-91f2-53d398e0062c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfd7ce94-b826-4950-9ba1-918193f1e5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e4550f-ced2-4053-84c2-2cd1600f9f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7076129-6dd1-4931-8d1c-7603c4697a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75014fe1-1355-4c5f-8b1d-0306e83f0118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b1eb5da-67c3-4eba-b070-a6376173fad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ea0c725-8711-46ff-81b5-73f49c267943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b591ae1-cc4f-4e85-bbdc-f8a03f32ee4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a155410-7c3f-45b0-908f-ff58963c9a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81d82059-4029-47ea-89d4-a0a7a9d88fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12ac41f5-28e3-4d27-8a37-bc6a7a832a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3cd3a71-87a9-4ca0-b4fa-fdce8fd88c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6284b40-005f-4a21-b3dc-2d6c3e97d7cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef4756af-2752-493f-a1cc-75f03077b90b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55f493db-8c61-4aa7-a2a6-2f7db82c2a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f64fb00-51af-49d8-9031-63cbd6a49814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 830af612-6730-4c98-b4ed-cb137499a189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2935696f-320f-4393-aaa7-e49ac6307fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 683f1220-4c75-4e06-b0de-5426c5d803e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4caffdb-3526-499d-ba17-6ea4161e618e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdc2f3b1-efe8-42cb-a822-011fdec84239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 523ab188-7b02-4ec2-85b7-c7416702a862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30c714cb-a329-4ea9-b155-63cfd8eecf60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e01fff63-65bc-4001-8368-afb2d5b80367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90470857-0ae9-451c-9c55-6b61cfe3b939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdb1d6e6-332d-47eb-9261-d1effd8a0298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cc2af7d-293f-4797-a9b9-b2e775ba9209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3d43af5-e77a-4e6f-a65e-d4c6875d42e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1968b64b-d303-4cec-a298-f2a869015a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81bc2ce9-9beb-4322-b7a1-849e40852730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7601fdb-5798-4527-907f-23e3d5631512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecba7e98-bbfb-42cf-8533-790bc5fd6fbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e64f43f4-b91c-4964-9cee-2c858b60bff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44299ff4-bbdf-4c13-a146-2542ca09bdcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad4ab878-4640-4f39-b098-833549abe206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af394617-eac9-484b-81ac-8c52499d9db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4384001c-7eb7-4132-8d22-e6de30404ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 558b1a1e-e674-49ae-ae13-af4b14ab0e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf399972-0107-4240-8a7e-e844d6887162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c690dbb4-7b31-4db2-9fe2-bd34cfed0870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1791167-00f2-4775-99f3-6b04db3aabbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1788e9a6-41c4-4d89-a69c-f054c096f140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aa08381-d6e1-4725-8fc3-f6662204002a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_41
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/test_labels.txt

📊 Raw data loaded:
   Train: X=(527, 24), y=(527,)
   Test:  X=(132, 24), y=(132,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 518 samples, 5 features
   Test:  123 samples, 5 features
✅ Client client_41 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1336, val=0.0857 (↓), lr=0.001000
   • Epoch   2/100: train=0.0870, val=0.0867, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0857, val=0.0866, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0840, val=0.0869, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0832, val=0.0865, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0821, val=0.0871, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 6 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0043
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0175
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.1783, RMSE: 0.4223, MAE: 0.3476, R²: -1.2917

============================================================
🔄 Round 8 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1661, val=0.1297 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1281, val=0.0983 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0967, val=0.0831 (↓), lr=0.000250
   • Epoch   4/100: train=0.0853, val=0.0878, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0835, val=0.0848, patience=2/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0829, val=0.0850, patience=8/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 8 Summary - Client client_41
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0038
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0093
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1753, RMSE: 0.4187, MAE: 0.3441, R²: -1.2529

📊 Round 8 Test Metrics:
   Loss: 0.1713, RMSE: 0.4138, MAE: 0.3394, R²: -1.2011

============================================================
🔄 Round 10 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1583, val=0.1850 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1469, val=0.1693 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1351, val=0.1545 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1243, val=0.1409 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.1148, val=0.1286 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.0880, val=0.0921 (↓), lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0843, val=0.0832, patience=2/15, lr=0.000016
   • Epoch  31/100: train=0.0842, val=0.0823, patience=4/15, lr=0.000016
   • Epoch  41/100: train=0.0841, val=0.0820, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 10 Summary - Client client_41
   Epochs: 42/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0046
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0399
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.1552, RMSE: 0.3940, MAE: 0.3210, R²: -0.9951

============================================================
🔄 Round 13 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1571, val=0.1308 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1537, val=0.1273 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1497, val=0.1239 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1458, val=0.1207 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1421, val=0.1177 (↓), lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.1295, val=0.1083 (↓), lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.1200, val=0.1011 (↓), lr=0.000004
   📉 Epoch 22: LR reduced 0.000004 → 0.000002
   📉 Epoch 30: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.1165, val=0.0986, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.1150, val=0.0975, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.1136, val=0.0964, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.1123, val=0.0954, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.1110, val=0.0944, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1097, val=0.0935, patience=5/15, lr=0.000001
   • Epoch  91/100: train=0.1085, val=0.0926, patience=3/15, lr=0.000001

============================================================
📊 Round 13 Summary - Client client_41
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.1073, RMSE=0.3276, R²=-0.2690
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.1387
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1385, RMSE: 0.3722, MAE: 0.3009, R²: -0.7807

============================================================
🔄 Round 15 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1434, val=0.1114 (↓), lr=0.000001
   • Epoch   2/100: train=0.1433, val=0.1113, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1431, val=0.1111, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1429, val=0.1110, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1427, val=0.1109 (↓), lr=0.000001
   • Epoch  11/100: train=0.1417, val=0.1101, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.1401, val=0.1088, patience=4/15, lr=0.000001
   • Epoch  31/100: train=0.1385, val=0.1076, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.1370, val=0.1065, patience=4/15, lr=0.000001
   • Epoch  51/100: train=0.1355, val=0.1053, patience=4/15, lr=0.000001
   • Epoch  61/100: train=0.1340, val=0.1042, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.1325, val=0.1031, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.1311, val=0.1020, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.1296, val=0.1009, patience=4/15, lr=0.000001

============================================================
📊 Round 15 Summary - Client client_41
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1282, RMSE=0.3581, R²=-0.5106
   Val:   Loss=0.1000, RMSE=0.3162, R²=-0.2790
============================================================


============================================================
🔄 Round 16 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1246, val=0.1629 (↓), lr=0.000001
   • Epoch   2/100: train=0.1245, val=0.1628, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1244, val=0.1626, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1242, val=0.1624, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1241, val=0.1623 (↓), lr=0.000001
   • Epoch  11/100: train=0.1234, val=0.1613, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1222, val=0.1597 (↓), lr=0.000001
   • Epoch  31/100: train=0.1210, val=0.1581, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1199, val=0.1565 (↓), lr=0.000001
   • Epoch  51/100: train=0.1187, val=0.1548, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1175, val=0.1532 (↓), lr=0.000001
   • Epoch  71/100: train=0.1163, val=0.1516, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1152, val=0.1499 (↓), lr=0.000001
   • Epoch  91/100: train=0.1140, val=0.1483, patience=2/15, lr=0.000001

============================================================
📊 Round 16 Summary - Client client_41
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1128, RMSE=0.3359, R²=-0.3527
   Val:   Loss=0.1468, RMSE=0.3831, R²=-0.7969
============================================================


============================================================
🔄 Round 19 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0986, val=0.1133 (↓), lr=0.000001
   • Epoch   2/100: train=0.0985, val=0.1132, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0984, val=0.1130, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0983, val=0.1129, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0982, val=0.1128 (↓), lr=0.000001
   • Epoch  11/100: train=0.0977, val=0.1119, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0968, val=0.1106 (↓), lr=0.000001
   • Epoch  31/100: train=0.0959, val=0.1093, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0951, val=0.1081 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.0943, val=0.1068 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.0935, val=0.1056 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.0928, val=0.1044 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.0921, val=0.1033 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.0914, val=0.1022 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_41
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=-0.0766
   Val:   Loss=0.1012, RMSE=0.3181, R²=-0.2608
============================================================


============================================================
🔄 Round 20 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0944, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0944, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0943, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0942, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0941, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0936, val=0.0804, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0929, val=0.0799, patience=1/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0922, val=0.0794 (↓), lr=0.000001
   • Epoch  41/100: train=0.0915, val=0.0790, patience=10/15, lr=0.000001
   • Epoch  51/100: train=0.0908, val=0.0786, patience=8/15, lr=0.000001
   • Epoch  61/100: train=0.0903, val=0.0782, patience=5/15, lr=0.000001
   • Epoch  71/100: train=0.0897, val=0.0779, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 20 Summary - Client client_41
   Epochs: 71/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3009, R²=-0.0547
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0235
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2400, R²: -0.0327

📊 Round 20 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2392, R²: -0.0227

============================================================
🔄 Round 23 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 23 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0205
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0105
============================================================


============================================================
🔄 Round 26 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 26 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0012
   Val:   Loss=0.0969, RMSE=0.3114, R²=-0.0158
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2384, R²: -0.0136

============================================================
🔄 Round 27 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 27 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0055
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0028
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2384, R²: -0.0134

============================================================
🔄 Round 30 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 30 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0030
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0056
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2382, R²: -0.0114

============================================================
🔄 Round 31 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 31 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0005
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0111
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0787, RMSE: 0.2804, MAE: 0.2382, R²: -0.0109

============================================================
🔄 Round 34 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 34 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0006
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0057
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2380, R²: -0.0091

============================================================
🔄 Round 38 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 38 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0003
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0042
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2379, R²: -0.0086

📊 Round 38 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2379, R²: -0.0082

============================================================
🔄 Round 43 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 43 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0029
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0143
============================================================


============================================================
🔄 Round 46 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 46 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0009
   Val:   Loss=0.0742, RMSE=0.2723, R²=-0.0013
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2379, R²: -0.0077

📊 Round 46 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2379, R²: -0.0075

============================================================
🔄 Round 48 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 48 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0002
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0001
============================================================


============================================================
🔄 Round 49 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 49 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0002
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0019
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2378, R²: -0.0073

📊 Round 49 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2378, R²: -0.0071

============================================================
🔄 Round 56 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 56 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0019
   Val:   Loss=0.0805, RMSE=0.2836, R²=0.0039
============================================================


============================================================
🔄 Round 57 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 57 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0018
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0051
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2378, R²: -0.0070

📊 Round 57 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2378, R²: -0.0068

📊 Round 57 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2378, R²: -0.0066

============================================================
🔄 Round 66 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 66 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0033
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0408
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2378, R²: -0.0064

📊 Round 66 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2378, R²: -0.0065

📊 Round 66 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2378, R²: -0.0065

============================================================
🔄 Round 69 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 69 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0001
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0046
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2378, R²: -0.0064

📊 Round 69 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2378, R²: -0.0062

============================================================
🔄 Round 73 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.1002 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.1002, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.1002, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.1002, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.1002, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.1002, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1002)

============================================================
📊 Round 73 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0024
   Val:   Loss=0.1002, RMSE=0.3166, R²=-0.0227
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2377, R²: -0.0059

============================================================
🔄 Round 75 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 75 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0009
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0024
============================================================


============================================================
🔄 Round 78 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 78 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0016
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0050
============================================================


============================================================
🔄 Round 79 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 79 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0016
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0207
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2377, R²: -0.0055

📊 Round 79 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2377, R²: -0.0055

============================================================
🔄 Round 82 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 82 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0020
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0069
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2377, R²: -0.0055

📊 Round 82 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2377, R²: -0.0054

============================================================
🔄 Round 85 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 85 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0046
   Val:   Loss=0.0973, RMSE=0.3120, R²=-0.0139
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2377, R²: -0.0057

============================================================
🔄 Round 88 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 88 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0038
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0164
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2377, R²: -0.0055

============================================================
🔄 Round 89 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 89 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0028
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0002
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2377, R²: -0.0054

============================================================
🔄 Round 91 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 91 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0015
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0270
============================================================


============================================================
🔄 Round 93 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 93 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0007
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0089
============================================================


============================================================
🔄 Round 94 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 94 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0003
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0054
============================================================


============================================================
🔄 Round 95 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 95 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0011
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0024
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2377, R²: -0.0050

📊 Round 95 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2377, R²: -0.0052

============================================================
🔄 Round 98 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 98 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0052
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0249
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2377, R²: -0.0051

============================================================
🔄 Round 99 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 99 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0011
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0396
============================================================


============================================================
🔄 Round 102 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 102 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0002
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0062
============================================================


============================================================
🔄 Round 103 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 103 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0006
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0022
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0048

📊 Round 103 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0048

📊 Round 103 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0047

============================================================
🔄 Round 108 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 108 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0011
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0006
============================================================


============================================================
🔄 Round 109 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 109 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0023
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0395
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0045

📊 Round 109 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0045

📊 Round 109 Test Metrics:
   Loss: 0.0781, RMSE: 0.2796, MAE: 0.2376, R²: -0.0044

📊 Round 109 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0046

============================================================
🔄 Round 113 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 113 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0009
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0060
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0045

📊 Round 113 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0046

============================================================
🔄 Round 115 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 115 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0009
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0005
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0046

============================================================
🔄 Round 116 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 116 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0015
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0007
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0046

============================================================
🔄 Round 117 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0642 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0642, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0642, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0642, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0642, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0642, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0642)

============================================================
📊 Round 117 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0002
   Val:   Loss=0.0642, RMSE=0.2534, R²=0.0028
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0047

============================================================
🔄 Round 118 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 118 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0001
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0173
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0045

📊 Round 118 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0044

============================================================
🔄 Round 124 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 124 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0011
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0000
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0045

============================================================
🔄 Round 125 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 125 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0010
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0772
============================================================


============================================================
🔄 Round 126 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 126 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0002
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0047
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0044

📊 Round 126 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0044

============================================================
🔄 Round 130 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 130 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0021
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0186
============================================================


============================================================
🔄 Round 132 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 132 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0004
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0053
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0043

============================================================
🔄 Round 133 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 133 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0013
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0002
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0043

============================================================
🔄 Round 134 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 134 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0003
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0022
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0043

============================================================
🔄 Round 137 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 137 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0014
   Val:   Loss=0.0936, RMSE=0.3060, R²=0.0106
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0041

============================================================
🔄 Round 138 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 138 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0027
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0038
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0041

============================================================
🔄 Round 141 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 141 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0018
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0016
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0042

============================================================
🔄 Round 142 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 142 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0012
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0071
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0044

============================================================
🔄 Round 145 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 145 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0028
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0231
============================================================


============================================================
🔄 Round 148 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 148 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0005
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0029
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0045

📊 Round 148 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2377, R²: -0.0046

📊 Round 148 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0045

============================================================
🔄 Round 157 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 157 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0009
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0054
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0044

============================================================
🔄 Round 160 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 160 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0011
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0018
============================================================


============================================================
🔄 Round 162 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 162 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0019
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0083
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2376, R²: -0.0045

============================================================
🔄 Round 163 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 163 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0020
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0065
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0781, RMSE: 0.2796, MAE: 0.2376, R²: -0.0044

📊 Round 163 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0043

📊 Round 163 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0042

============================================================
🔄 Round 169 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 169 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0023
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0046
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0041

📊 Round 169 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0041

📊 Round 169 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0040

📊 Round 169 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0040

============================================================
🔄 Round 174 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 174 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0001
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0289
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0041

📊 Round 174 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0041

============================================================
🔄 Round 179 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 179 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0009
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0017
============================================================


============================================================
🔄 Round 182 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 182 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0014
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0006
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0041

============================================================
🔄 Round 183 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 183 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0034
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0526
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0042

============================================================
🔄 Round 185 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.1008 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.1008, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.1008, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.1008, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.1008, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.1008, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1008)

============================================================
📊 Round 185 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0014
   Val:   Loss=0.1008, RMSE=0.3175, R²=-0.0016
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0041

============================================================
🔄 Round 186 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 186 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0006
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0103
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0043

============================================================
🔄 Round 189 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 189 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0009
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0306
============================================================


============================================================
🔄 Round 190 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 190 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0009
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0014
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0042

============================================================
🔄 Round 191 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 191 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0009
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0014
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0042

============================================================
🔄 Round 192 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 192 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0008
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0019
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0042

📊 Round 192 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0041

============================================================
🔄 Round 194 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 194 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0001
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0278
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0041

============================================================
🔄 Round 197 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 197 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0005
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0013
============================================================


============================================================
🔄 Round 198 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 198 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0005
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0033
============================================================


============================================================
🔄 Round 200 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 200 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0011
   Val:   Loss=0.0951, RMSE=0.3083, R²=-0.0056
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0042

============================================================
🔄 Round 202 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 202 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0017
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0344
============================================================


============================================================
🔄 Round 203 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 203 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0048
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0160
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0042

📊 Round 203 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0042

📊 Round 203 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0041

============================================================
🔄 Round 208 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 208 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0004
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0022
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0043

============================================================
🔄 Round 209 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 209 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0010
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0027
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2376, R²: -0.0043

============================================================
🔄 Round 210 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 210 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0009
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0016
============================================================


============================================================
🔄 Round 211 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 211 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0013
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0355
============================================================


❌ Client client_41 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
