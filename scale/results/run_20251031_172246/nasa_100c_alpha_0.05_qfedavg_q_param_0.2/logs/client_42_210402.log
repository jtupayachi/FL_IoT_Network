[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7052f727-e7c9-405d-be64-4b98e5ca1445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54b15c99-7712-4c96-9af4-75d4651dac1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e82f4e02-0ba6-42e9-988c-a6c68d7b1400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e34c2ecc-05f4-45b2-b7d9-df5c07b209a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af54aeea-e740-4efb-94da-2b5760034c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 562addaa-fc82-4ddd-84b1-224b046410da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fd98f5b-4bbf-4f30-9d12-957036ef24fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a6f10f3-473e-4fe6-9a55-3b8482e17cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7d39709-a008-4e6a-91e5-5830bbf9289a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c50d7e19-405e-4679-b722-902e32d6f870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79d40289-8d40-4f5d-b003-50737e9824d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 386a1588-4931-4593-b055-5dc6e2659904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d2f4037-00e0-4e71-8600-32c4165dda6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c6f9c52-54c3-4bf2-b019-238c4847b140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 240ff9e2-b646-4875-9114-4d72bd8ea302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01c69dc8-3ae6-4366-a47f-a3f2b71f0348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14910d83-8dab-4444-8ec5-ae177e2b1d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a37b902-dd51-4f97-87b9-a77ffe7e63f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c56155df-b461-46f2-9572-8bdc585be88b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e87e7467-c97f-41cc-b54d-a3d3a4d70deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a51ef67b-4015-4fd0-a920-e9ae023dbc78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b613855-b34b-402b-80d9-8330581e6506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eba750d-c398-472e-8cfa-abb723cd1995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eef24f4d-e824-40e8-bad0-c44f4256e670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04a769d0-b11d-44a4-9d94-faa6ebcc8d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddc45cda-66fb-4a3e-a874-5dd69ab61e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a870a6d-31f3-4779-b4b0-fb57ac525a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15adcae0-82a4-4a39-9c38-a3607d909514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eda312ea-0fb2-45a9-bc10-2755349e461b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccbfcdf4-8a27-4360-8414-192a2b33fc36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b18f8bd8-3aec-4001-8db9-eb0af8b5a730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 273ddb04-ab12-49cb-b1a1-4beb4b11fe59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb87a25d-1a2a-453f-ac22-9e8f7dfc6f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1ce51f3-2c6c-4ea7-bfb0-a28a8a2dd500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98c76342-d430-43a1-9b06-85f13f57478d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dfbffee-0cc2-4329-a9f7-3600c134e5d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91b5ffbd-4ac1-4791-88c1-cbe3bf66a21a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43669f54-2b1d-4be1-b97f-eb3cab9c187b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6c58729-47dd-40ef-a859-c97f00f27b8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6817e39-5a9e-4e11-a5ce-4572ceaf9646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5245be60-1770-4b2f-a479-fd969bad40c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94634bf7-5a2f-4e91-a7fb-63e5acfdfa1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dc45d65-01ed-43d5-bdea-b08112fbc49b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e569c5fe-697c-47b4-b794-36cb91d26e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 398c2f23-d264-46ec-af45-3030ea09d3ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1064a087-213b-4414-93d5-6391ad9bdef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a25381e7-0cc9-4ef1-9f45-f0d139e76582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d9f23dd-41a0-4a2f-91f8-6ca9885d4beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 917c3171-9b4b-463a-9f8c-c5c88b37344f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbe6cc1e-074b-48d3-a5d3-71765f6a5966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adac5ce6-af5a-4cc2-b96f-2ab5dcb14711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eebe490-afc8-433e-b718-bc981ceb375e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 047c7232-41cc-4b84-bec2-1ca5beb40975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f34e63c6-27b7-47a2-8ac7-4f6aa9213ff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85ae2b58-7cd5-462c-9405-3ebdd60c3ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff2baf8c-a1f5-496d-8e48-9aa76cfe9289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e1bab3a-8c4e-4bc2-a2de-7b0bdd938098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2c0e98f-25e9-4fc6-9c3e-8b482b237c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6ddf2cd-c58d-433f-bf30-b8607c68b046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d666c8e-dfcd-4620-a3d8-7ec28337ed5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed33df16-a441-46dd-b239-d760a1567a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1958f1e0-f63d-4bc0-989b-6dc2c0640758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ec9cfb6-bbe8-4bd8-8acc-1e5d14f580e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a02d15b-2003-41f5-97e3-46083399cc6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f1d6706-ca70-4a51-9fea-4090f8cef2c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 296794d8-b554-4e5a-8291-34a8a99c8168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 255f1c54-d388-4f0a-8a17-059edad408bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3540044-e5c8-470d-a224-bb9d52770a1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 620c978e-0e92-49d5-a67d-e91e2e7004fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33aa1448-bc6a-4e25-b183-7c54c136d2fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ef57695-4572-45c8-8031-6ba6955b8c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12a642e4-5695-4f8e-a6c2-92c2dd9d9d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e820a3b8-8cef-401d-ad69-9478069d4f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b28d4c03-796f-4d89-8c8b-a02adf154772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ff93d3a-9408-4ee8-a43b-d60e65556d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa98d7d-c11d-46d4-88f5-49a39d86e0c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 096e8273-4bb7-4325-bc45-5db773cdf29d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 543d888c-25ce-4907-886f-6e0c1c0eb503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36619fa3-9699-4b9c-a347-a507e281559b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc9c95c5-30a8-41ce-b7ed-23bff5325993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcc8aa0b-7fd0-4e43-a50f-f533eeaa562e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d2cd317-b0e3-4188-94f2-0fa6dfc0338f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9336ffb5-be33-43c9-820e-c5f4834526d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1677092b-f7eb-4543-a639-0ad107082202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17241e6b-8a74-4c0c-aa64-d2b622d99cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 877c7998-a5ac-4060-8a44-87a0c54cd01c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52f3fe3a-5014-447a-a479-181d46a89042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3ac505b-ae19-4c79-ae21-e22e233a3ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd29a233-ec2f-46d6-86d6-bac5091061f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdfbbe4c-802e-41b2-8317-1358d1c7587b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3700cca5-823b-4c6d-ac54-49b830b5e0e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3354c0d6-b0c8-40c1-b10b-94cf8827a31b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e2dd53b-37f3-4f2e-aa66-bfc4da5998ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7eff927-645f-4a66-bffa-c93629983e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a1bdee1-176a-4c99-81f1-77860007d2a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 850b15f5-e9e2-43ad-92ff-2095a2ca6bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3d23176-e565-4076-a54f-45716eb74316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43c74891-da7a-42c0-a66b-6916e6800659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cab5489-b270-430c-8e47-9e7b283f65c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abbc35b2-4bef-494c-9edc-cf8da4d49065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d64f4e4-9b82-4b32-90fc-18aa1b6c8b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea3cd2fa-b33f-4f0e-88a5-c444df99ca7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2499940-f65d-4524-a0d1-1355a6145ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b326337-d416-4608-95ce-e65210e0c5d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb5ce6ba-0550-4e75-ab18-db157519d95f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0119fe53-ccee-40da-934c-dee2d74cb4cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85ffed39-0c79-487e-9fd5-f605efc72818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6e5c14d-4882-42d8-b12e-a5d6df443c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41ece30a-6e17-44e9-991f-d61012921ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9650dde-9b17-4336-a6e4-e2a44ef32800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 816cb2f7-7f27-4763-a2c5-d149de8fb7bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54f2bf6f-4ec0-4837-9bc9-6c64cb6e8169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfd7bf9b-79d9-47f4-ae44-9f4bddcce3e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 734591d4-af82-4fcd-b1f0-a08c47a220eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9255047-4857-4b8a-9d99-aac4eabff4b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4ebeefb-2942-40ba-befb-9e8ed5cc94e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c1f2ada-b5f7-4f2e-ad4f-ed61eb98f2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd8324ea-9d54-435c-9f86-ef0f4563d703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a267121f-6b29-4c28-a78a-d8650301b17d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c27c929-0f83-449c-a20d-a94e80c32803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00908247-3d77-4aec-81ed-70e2d1c5ce74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb74dbee-d710-4538-a03d-2fd109ad0b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e822ec7-e1cb-40e5-882e-c79c6e5f2081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c45ef92-6c7d-4094-b777-901b647872cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c20c6f-0ec9-4802-8d18-b6e6c90949d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 995d026f-d7a4-4b44-ace7-8c397ffe0d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb4079a1-bf72-4b39-8c67-a0ac19434bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98d9bca3-ece5-445b-a7d5-b73944f88cce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b65253fa-743b-4018-85a5-93d9e5a58aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 696f6ebb-e72a-40d5-aa61-fcef3d80b763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aa34f22-9ec8-42ef-8d85-6e95fb9f4b8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e73522f2-ffa9-446f-ac4f-8f659843c1af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62d69a99-8907-4718-990b-9925d15c219d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6ec8588-2dad-4e28-a686-033b03aac35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37c98004-4a4a-430b-b2ea-0b862a6e7bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bad9f63-18f2-46c6-9142-20ce4aadf809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e9cc032-a5dc-4b2f-9e29-fe3434818071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d19ff3e-552f-4306-b346-a6b120ba1811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1c47b29-73af-4eba-9e63-87df406517e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2605dea-bae9-44b8-80dc-58a92c1bb1db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b59202a3-c94e-4109-a7dd-890e061cae0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eef29170-30d7-4cab-bbf6-a9d04ce06d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13ea9434-1b2a-412d-b281-072be47d5b41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20caae2c-1f41-4e00-a260-c238b8810ae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fb8550d-0f6a-4831-9355-5dbd936eb088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2156554d-93e1-4761-bd92-489960c90f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03b6de25-6e5c-4e89-81f0-5dfb6d606e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8314051-24b9-4ad9-aa34-80eb84420806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53825c35-e12d-4264-bdab-003880193e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffc6e026-f138-44dc-bae0-82d156aba224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d75273f-c6da-4510-9762-282e091005a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f74afa5-51e9-4f66-a3c2-9a79cca2dd63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf46c08e-80bb-4946-a74e-99e2cef80a03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98e5fca3-ebde-45ef-8b44-e62be7da7cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbdd0095-b9a5-4bb0-8b8d-1d4997087393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf469bf6-081a-4fe9-b6a1-d2fd7c149206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 518b3fef-1c4f-4b44-80e2-d00c5a6598d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32653636-7705-4d83-94f2-5640536e7a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28750564-75fc-46a8-8ee4-660beb643de9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ab36b4b-8118-4f71-9b01-30cc4d0bbcf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48a53814-efa1-45b2-ac5a-8c520f1abad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f79111d0-11e5-477f-a144-4ea579f8601c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d914b35-a776-40fa-87ac-564236b11a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0e7f96c-3b03-44e6-b8ab-e1d6e0f80cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dd154c6-3bd6-43bd-b63f-26547f5a980f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1adabda5-7601-41bd-b85c-827b0ed997bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e188f5d6-2da0-4494-a69d-f13d3b146dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8e91843-296c-4e2d-9af6-28e359c135c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c7cf5da-7c7c-4442-8879-2f182fe0ba51
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_42
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_42
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_42/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_42/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_42/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_42/test_labels.txt

📊 Raw data loaded:
   Train: X=(1319, 24), y=(1319,)
   Test:  X=(330, 24), y=(330,)

⚠️  Limiting training data: 1319 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  321 samples, 5 features
✅ Client client_42 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1191, val=0.0894 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0827, val=0.0834 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0818, val=0.0826 (↓), lr=0.001000
   • Epoch   4/100: train=0.0814, val=0.0829, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0811, val=0.0832, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0789, val=0.0847, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 5 Summary - Client client_42
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0086
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0057
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1802, RMSE: 0.4245, MAE: 0.3435, R²: -1.1234

============================================================
🔄 Round 7 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1468, val=0.1371 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0939, val=0.0817 (↓), lr=0.000250
   • Epoch   3/100: train=0.0836, val=0.0827, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0823, val=0.0838, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0823, val=0.0826, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0819, val=0.0826, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 7 Summary - Client client_42
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0042
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0426
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.1737, RMSE: 0.4168, MAE: 0.3369, R²: -1.0465

📊 Round 7 Test Metrics:
   Loss: 0.1708, RMSE: 0.4133, MAE: 0.3340, R²: -1.0125

============================================================
🔄 Round 9 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1615, val=0.1561 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1389, val=0.1334 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1190, val=0.1144 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1028, val=0.0989 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0909, val=0.0885 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0821, val=0.0825, patience=4/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0819, val=0.0825, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 9 Summary - Client client_42
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0012
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0071
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1669, RMSE: 0.4086, MAE: 0.3301, R²: -0.9671

============================================================
🔄 Round 10 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.1670, val=0.1581 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1623, val=0.1546 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1591, val=0.1514 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1560, val=0.1485 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1533, val=0.1458 (↓), lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1411, val=0.1342 (↓), lr=0.000004
   📉 Epoch 17: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.1329, val=0.1262 (↓), lr=0.000002
   📉 Epoch 25: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.1296, val=0.1229 (↓), lr=0.000001
   • Epoch  41/100: train=0.1274, val=0.1207, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1253, val=0.1186, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1233, val=0.1165 (↓), lr=0.000001
   • Epoch  71/100: train=0.1213, val=0.1144, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1193, val=0.1124, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1174, val=0.1105 (↓), lr=0.000001

============================================================
📊 Round 10 Summary - Client client_42
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.1155, RMSE=0.3399, R²=-0.3743
   Val:   Loss=0.1087, RMSE=0.3297, R²=-0.4547
============================================================


============================================================
🔄 Round 11 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1599, val=0.1664 (↓), lr=0.000001
   • Epoch   2/100: train=0.1596, val=0.1661, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1593, val=0.1658 (↓), lr=0.000001
   • Epoch   4/100: train=0.1590, val=0.1655, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1587, val=0.1652 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1571, val=0.1635 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1547, val=0.1609 (↓), lr=0.000001
   • Epoch  31/100: train=0.1525, val=0.1584, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1503, val=0.1561, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1483, val=0.1538 (↓), lr=0.000001
   • Epoch  61/100: train=0.1463, val=0.1516, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1443, val=0.1495, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1423, val=0.1473 (↓), lr=0.000001
   • Epoch  91/100: train=0.1403, val=0.1451, patience=1/15, lr=0.000001

============================================================
📊 Round 11 Summary - Client client_42
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1390, RMSE=0.3729, R²=-0.6631
   Val:   Loss=0.1431, RMSE=0.3783, R²=-0.8800
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1460, RMSE: 0.3821, MAE: 0.3096, R²: -0.7202

============================================================
🔄 Round 15 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1334, val=0.1510 (↓), lr=0.000001
   • Epoch   2/100: train=0.1332, val=0.1508, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1330, val=0.1505, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1328, val=0.1503 (↓), lr=0.000001
   • Epoch   5/100: train=0.1326, val=0.1501, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1313, val=0.1488, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1292, val=0.1467, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1271, val=0.1445 (↓), lr=0.000001
   • Epoch  41/100: train=0.1250, val=0.1424, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1229, val=0.1403, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1208, val=0.1381 (↓), lr=0.000001
   • Epoch  71/100: train=0.1188, val=0.1360, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1167, val=0.1339, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1147, val=0.1318 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_42
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1122, RMSE=0.3350, R²=-0.4165
   Val:   Loss=0.1299, RMSE=0.3604, R²=-0.3817
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1312, RMSE: 0.3622, MAE: 0.2961, R²: -0.5462

📊 Round 15 Test Metrics:
   Loss: 0.1273, RMSE: 0.3567, MAE: 0.2927, R²: -0.4995

============================================================
🔄 Round 17 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1274, val=0.1260 (↓), lr=0.000001
   • Epoch   2/100: train=0.1272, val=0.1258, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1269, val=0.1256, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1267, val=0.1254 (↓), lr=0.000001
   • Epoch   5/100: train=0.1265, val=0.1252, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1253, val=0.1240, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1233, val=0.1221, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1213, val=0.1202 (↓), lr=0.000001
   • Epoch  41/100: train=0.1193, val=0.1183, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1172, val=0.1164, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1153, val=0.1145 (↓), lr=0.000001
   • Epoch  71/100: train=0.1133, val=0.1127, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1113, val=0.1108, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1094, val=0.1090 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_42
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1081, RMSE=0.3288, R²=-0.3238
   Val:   Loss=0.1074, RMSE=0.3278, R²=-0.2760
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1012, RMSE: 0.3181, MAE: 0.2704, R²: -0.1924

============================================================
🔄 Round 19 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0957, val=0.1228 (↓), lr=0.000001
   • Epoch   2/100: train=0.0956, val=0.1226, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0955, val=0.1223, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.0953, val=0.1221 (↓), lr=0.000001
   • Epoch   5/100: train=0.0952, val=0.1219, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.0945, val=0.1207, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0933, val=0.1186, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0921, val=0.1166 (↓), lr=0.000001
   • Epoch  41/100: train=0.0909, val=0.1145, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0899, val=0.1126, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0888, val=0.1106 (↓), lr=0.000001
   • Epoch  71/100: train=0.0878, val=0.1087, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0869, val=0.1069, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0861, val=0.1052 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_42
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0522
   Val:   Loss=0.1037, RMSE=0.3220, R²=-0.2617
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0919, RMSE: 0.3031, MAE: 0.2620, R²: -0.0827

📊 Round 19 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2566, R²: -0.0219

============================================================
🔄 Round 21 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0870, patience=1/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0835, val=0.0866 (↓), lr=0.000001
   • Epoch  31/100: train=0.0832, val=0.0861, patience=10/15, lr=0.000001
   • Epoch  41/100: train=0.0829, val=0.0858, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 21 Summary - Client client_42
   Epochs: 49/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0179
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0258
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2554, R²: -0.0104

============================================================
🔄 Round 22 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0849, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0832, val=0.0845, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0830, val=0.0842, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0828, val=0.0839, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 22 Summary - Client client_42
   Epochs: 43/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0109
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0254
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2549, R²: -0.0051

📊 Round 22 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2546, R²: -0.0015

============================================================
🔄 Round 26 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 26 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0056
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0281
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2545, R²: -0.0011

============================================================
🔄 Round 27 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 27 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0104
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0017
============================================================


============================================================
🔄 Round 28 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 28 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0101
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0025
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2545, R²: -0.0007

📊 Round 28 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2545, R²: -0.0004

============================================================
🔄 Round 30 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 30 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0045
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0284
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2545, R²: -0.0003

============================================================
🔄 Round 33 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 33 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0027
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0377
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2545, R²: 0.0001

📊 Round 33 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2545, R²: 0.0002

📊 Round 33 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2544, R²: 0.0003

============================================================
🔄 Round 37 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 37 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0051
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0100
============================================================


============================================================
🔄 Round 40 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 40 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0109
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0015
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0007

📊 Round 40 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0008

📊 Round 40 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0008

============================================================
🔄 Round 47 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 47 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0041
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0101
============================================================


============================================================
🔄 Round 48 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 48 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0035
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0115
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0009

============================================================
🔄 Round 50 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 50 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0052
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0040
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0009

📊 Round 50 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 53 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 53 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0063
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0013
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0010

📊 Round 53 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0010

📊 Round 53 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0009

📊 Round 53 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 60 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 60 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0076
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0048
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0010

📊 Round 60 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 63 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 63 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0034
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0088
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0011

📊 Round 63 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0011

============================================================
🔄 Round 66 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 66 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0029
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0251
============================================================


============================================================
🔄 Round 67 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 67 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0098
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0002
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0011

============================================================
🔄 Round 68 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 68 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0063
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0010
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2544, R²: 0.0012

============================================================
🔄 Round 72 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 72 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0006
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0617
============================================================


============================================================
🔄 Round 73 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 73 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0037
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0152
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0012

📊 Round 73 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0012

============================================================
🔄 Round 76 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 76 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0030
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0191
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

============================================================
🔄 Round 78 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 78 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0033
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0056
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

📊 Round 78 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

============================================================
🔄 Round 81 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 81 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0056
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0091
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

📊 Round 81 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

============================================================
🔄 Round 86 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 86 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0042
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0050
============================================================


============================================================
🔄 Round 87 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 87 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0049
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0022
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

📊 Round 87 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

============================================================
🔄 Round 92 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 92 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0046
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0021
============================================================


============================================================
🔄 Round 93 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 93 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0035
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0067
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

============================================================
🔄 Round 94 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 94 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0061
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0018
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 95 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 95 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0076
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0043
============================================================


============================================================
🔄 Round 96 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 96 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0061
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0043
============================================================


============================================================
🔄 Round 97 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 97 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0045
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0056
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

============================================================
🔄 Round 103 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 103 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0008
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0209
============================================================


============================================================
🔄 Round 106 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 106 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0026
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0122
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 109 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 109 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0056
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0034
============================================================


============================================================
🔄 Round 114 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 114 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0042
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0023
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 116 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 116 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0061
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0010
============================================================


============================================================
🔄 Round 119 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 119 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0020
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0075
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 121 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 121 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0025
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0055
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 121 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 121 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 121 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 126 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 126 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0012
   Val:   Loss=0.0742, RMSE=0.2723, R²=-0.0225
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 128 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 128 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0047
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0029
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 130 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 130 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0027
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0038
============================================================


============================================================
🔄 Round 132 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 132 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0046
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0021
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 136 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 136 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0018
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0061
============================================================


============================================================
🔄 Round 138 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 138 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0008
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0220
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 138 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 138 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 138 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 138 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 138 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 147 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 147 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0028
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0023
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

============================================================
🔄 Round 149 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 149 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0044
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0053
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 150 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 150 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0021
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0049
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 151 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 151 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0058
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0122
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

============================================================
🔄 Round 152 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 152 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0019
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0060
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

📊 Round 152 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

============================================================
🔄 Round 157 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 157 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0029
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0014
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 157 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 157 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 162 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 162 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0018
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0053
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 162 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 165 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 165 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0009
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0326
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 165 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 170 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 170 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0024
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0095
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 170 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 170 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 176 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 176 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0025
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0040
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 177 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 177 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0010
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0082
============================================================


============================================================
🔄 Round 179 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 179 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0006
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0441
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 182 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 182 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0023
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0020
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 182 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 185 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 185 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0034
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0007
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

============================================================
🔄 Round 189 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 189 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0025
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0017
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

📊 Round 189 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 189 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

============================================================
🔄 Round 198 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 198 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0043
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0010
============================================================


============================================================
🔄 Round 200 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 200 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0028
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0002
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 201 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 201 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0015
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0152
============================================================


============================================================
🔄 Round 202 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 202 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0013
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0089
============================================================


============================================================
🔄 Round 203 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 203 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0004
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0159
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 204 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 204 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0003
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0197
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

============================================================
🔄 Round 205 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 205 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0032
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0018
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 205 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0014

📊 Round 205 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2544, R²: 0.0013

============================================================
🔄 Round 210 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 210 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0019
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0032
============================================================


❌ Client client_42 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
