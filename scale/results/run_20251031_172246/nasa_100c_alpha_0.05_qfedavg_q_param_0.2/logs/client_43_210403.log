[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31c07fe4-53fc-4848-8ef9-f6b7af0cff73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b6ca38f-05eb-4ec4-8e19-18b5b6fdc88d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e7e2637-d76f-4e14-b100-70f7eb891812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b70a970-4d22-4bf6-884d-49c76c6ca16d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 119c1863-f3e9-4242-9144-bb9cbb799ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f180b280-7254-4b3b-a537-c5392a69d6c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fd57938-6043-4976-b33a-9d053756a592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf5b3225-c534-44be-a484-f96995962e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d1f00bd-67b8-4aca-b821-81891336592f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d008f8a-3f15-4a1c-87f4-bc2c4e6e8aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66d1d2df-a100-493c-aa87-5dad94af321b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f470e4ea-49e8-4b64-b0d0-903487854a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68135534-78d9-41e2-bac4-eaca4de35ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de94fbdd-c18c-478a-a862-69a7cb454046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bda377aa-a852-4f85-8584-b04b57b9105f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e209a60-2e55-4824-8481-3c2ddde9fad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c9d9493-808b-41e5-8bed-e659cd66dece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cb1f0dd-ef08-46d5-a182-bdf84fdd2b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e589c21-0cb1-417b-a1b2-df93568350e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db23d317-f788-45a4-aa6d-f5ba772393f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d7a9df8-9d64-432c-9a56-ceca8d622535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b1dabad-0c4e-4cf2-b305-efdc13da1385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f933bb85-b0ac-4fef-b546-01356f88489b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05e00095-9778-430c-b7b4-ae8930251dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccdae336-0902-482a-babb-248d9790ed1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e73811b-cfd1-4e40-8e64-66765bb18368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96a772bb-e4bb-4454-91d9-3b70cf2e1bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b685d4e0-d94d-4123-aa63-c28e28a241d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d7ff60a-0f61-4342-b6fd-0c3c14cc2488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7d52bc8-493b-4efd-bfb2-4136daeff09f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e02d4f7-aef7-4c6f-bfb9-7698300d08d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e60c24-b41d-45f1-a4aa-114e7a89e628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52e87afa-367b-4db4-8b1e-2279d3bb27c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9749260-a237-4a17-a8e6-4032c3f9173c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16008fa5-0bb3-439e-af7f-3412ace52a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9517fee9-ef18-4146-b95e-becbc4b0ffcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3936fc5-d4a0-460b-9b02-962332ecbb21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f2d8cbb-3166-4fbf-979d-6b0f1aedfcda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf4db700-3387-4520-ad50-81f3c03d9df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deda2d50-3072-4cb6-bfcd-3d155fde5581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa96fd87-2165-491a-97f8-b4f1b147bbf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1403ed2e-ac49-400f-8ec6-ee2d8a84b65a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1da80e8-6bb6-404e-9e5e-50399db3519d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 068ab4fe-8eb3-4e88-807c-0847a8b00846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7507a8e5-3664-484d-b1a2-352a6a27d9ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6289bb5-bb6e-4ef9-ab3a-6849a57e5c6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c3d1065-d131-4f65-ac73-00bcccb3a2f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 082a75f1-ccd5-49cd-b379-373720e2413c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47a5c637-a3dd-4a50-85f9-ac17571ac38d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c2c2f2c-c66d-4f53-9503-6055a34b017b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c2f4d96-b2ac-4dc3-8032-9a3c7b2b095f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcfdf952-e563-4c7a-ba43-f39666772180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f984a7c1-bfbe-423d-b787-fa4cc9407a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b02d1321-7f8c-4c59-aae5-c642a03177a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87ad8f6b-aecc-450a-922c-7b2489ebe526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 664ba2ba-3ded-4bf8-8f5a-c0661e2f5ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83591568-6f85-4c17-9fd4-cd76aedd1be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff7559b2-a2bd-46a2-a28f-60d825af634f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9edb4bab-c857-47d4-b025-adb297473a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6e1bee2-59ff-4cd4-a7d5-8135d81954a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1e89181-9142-4f89-a1fb-4d9d121deb1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 718c8a69-6d44-4d28-9b77-b3e92b0c951a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 822af9f9-c31c-4344-ab32-8c96618df9c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ffb9d4d-a257-4bba-9686-c9f166905e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04d00521-0c2d-4884-ba92-6bfee1c8ecd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dd07f3b-0578-43e0-ac61-907693632c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f60e16e-0a1b-4328-bfe4-20b0474a443e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceaa7f62-c500-4c7e-8df7-e1c7dc081ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edd55f10-df38-48e4-b6e1-ce3bf4e9f7e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 686bfc79-0111-4db5-9e53-1c6071cf29ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3088fb9-8b61-4b28-bf1a-3c646254f8c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53fa0437-1e97-4542-b4dc-8c72b6c669a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bd3dfc8-5ed0-4aba-8e61-9b14aec233b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1781672-1a9e-4086-afa2-2f9ef34df786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d672e2be-4209-491d-9307-6f10f4a72307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0a3280b-7549-430b-a258-92a96d7b7f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 609282a1-1291-4d24-baab-dc7a01e71f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de475297-42aa-4b60-836b-493dd01b7dfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 430432ab-b500-49f7-bdee-052665cf8d6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32142198-97c6-4933-9957-b2bc72d0610d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0362a51-f678-4866-b448-5297a6c408ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdba5f8e-5593-4a57-9327-7e43357301d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f4a920e-86c6-455f-bf18-aa72aaedf2b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97ee706f-0a04-446c-9429-02908df618cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0f7d7e8-f582-4fdd-8ba8-b751fef8bf6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a14036e7-fe0c-41d8-bf26-4e91f54c267b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3294658e-63a4-4207-a3e9-05e022826779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a3111b1-bfb2-410f-8f5e-3540f9085b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee93dd0-2494-4f70-addb-7d8c2338fd4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb714ad8-e558-4a5f-bba5-4a2920d355f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ccef823-3424-4672-8940-87d8d5de5d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b8aec9a-271f-47d3-bdc4-0d918734d873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3b93e68-2da5-4df4-9439-087ba1553522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74652f1c-0318-45ca-9ddd-c25bd9e8fe88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce424bb3-c11c-46ce-92f8-a27236e9bf90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a40d9aeb-00b2-46be-8f7a-cfb4130555fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9b1b44e-db15-4e9b-87d1-952e87bde032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d0e1ff7-0500-44bf-bf25-0824d4be6727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac6479b1-24cb-4130-8359-54d74e1d3a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83d35a6f-ae88-49c7-bcfc-b783881ad815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acfa79e6-255f-423c-9c38-5f1982455492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 002fa046-8a81-4ab1-8e57-6cc30b07f748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26964c4e-8224-4d98-8b4e-231a11066664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbd795d0-ad3e-4cca-9582-fd01c469d8d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aad2828b-563e-4405-8c2c-5a09cf813547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04b154c9-67b3-40a2-912e-1384059f6415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c66bacd8-422e-482b-b24e-2c387462874c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8538ec39-910b-4aec-8e42-f2782ecfffb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3d5f89b-cbe7-4f91-be74-923cbbaaa724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d37dd1e0-fed4-445e-aec4-6390bb1b945f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de405070-d819-4c73-80b4-a3542b7ec3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 970b41df-a738-4b9a-ac40-2eea9f1efe01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a3967b1-7edb-4099-99b3-101cb4635a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1382e471-b411-408f-b4e4-32e5390af70a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4907f510-0e70-4d01-be18-287f50be8328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53331287-3e31-4d43-b104-935e38e06e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6859b461-68f4-4246-bc8c-c6a865a2f9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3ff7f24-9779-431f-9478-f32c856f62b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c44d72c-fe95-4d60-b3f7-8d5cd4467b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8be42c73-f89e-45b5-be9b-8f6d06c6abf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e38ecf1d-f42c-41c4-af15-3e8a34bf03a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44e66872-cd51-473a-9e35-cb127c18998b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 206d67e4-d03c-4e8c-a386-10a6d670a8d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e165db7-6c10-4962-8d99-3576e69eee23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d9196d-5be7-4124-97bb-0991f6b49b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a272e426-3ba9-4dea-ba10-3d3633122092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dc0783b-3007-4e2c-b7a2-a0050312c714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6532429b-8d7a-4ff2-bd4e-7e1ddb7f47bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ae5f9f1-df1c-4c9a-9976-4cd4c24e2774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d2b95cd-6a25-40ad-85d4-cfd6440e5a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3d53a65-7bf4-4b60-9c57-9d022d48433a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecbce04d-4a84-4c69-bb9c-b8a472ee0fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e174fae-0e02-475b-ad1d-c1d880718d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3b65dc9-f826-4099-b867-a025df999ac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21aaa6dd-a210-47a8-bda5-80c35d3d1353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14a58686-2239-4227-b6d6-41f335563607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c10abff-f5e2-4845-9863-7e124031fba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b125e286-74f8-40c0-92c5-3a8481daf70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab2d45ef-941a-4f4d-a3b0-3ecf30bdc42a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 161667df-1f7a-4518-b3db-418e90d2ea4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8332c5c2-c9d0-4616-96eb-28e0730adcb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c77f052-8af4-40ff-a1e2-912ef249ca29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50cc2c31-297f-4d91-9d9b-7aacf3ccf524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c797608d-d042-4818-99d1-7f56c3226297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8b75280-3b48-4499-8448-0f5a1dc1d4d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ad628ad-6f74-4f30-bc10-b480f0d5ed90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ae32dc2-4d90-40fc-8e13-e2974fa16fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f15fce57-2ccf-4d62-88e8-be80ec6144cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb91f76d-6aab-4acf-89ca-6c8bb4dfa04a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a58f4d9-0046-4dae-8499-74b63dac182f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f81bc59d-52e9-4b57-9d69-2777b60448bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c38054f6-a8a1-47d7-9928-746100755036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a6944f8-dc4c-48d5-b05a-0184d750324c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 554c508c-d67a-4b71-9b38-08280cc9c91e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 816fd16d-93e9-4263-b419-32f2035ac213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38a9a8f0-ac97-407b-87ae-cb3f91be4dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2f11bd6-3719-4b1c-91c3-0c493ecdb54a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3293eddb-2de1-49f8-b7ed-47aa8de70aa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f433bf5-1099-40e6-b437-7d6f7c732281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ab7b052-cc11-427f-b189-801a78ab99c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1464e34c-56c7-41e1-93e0-c0c882c35f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2b5c5d0-b440-4cbd-9cf9-401ae7ceb6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e197dafe-b5b5-4175-a9f5-f46581c5d3eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 380588ef-c694-47d9-bbc2-287733213a1a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_43
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_43
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_43/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_43/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_43/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_43/test_labels.txt

📊 Raw data loaded:
   Train: X=(877, 24), y=(877,)
   Test:  X=(220, 24), y=(220,)

⚠️  Limiting training data: 877 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  211 samples, 5 features
✅ Client client_43 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1194, val=0.0758 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0855, val=0.0715 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0846, val=0.0709 (↓), lr=0.001000
   • Epoch   4/100: train=0.0844, val=0.0712, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0844, val=0.0714, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0837, val=0.0716, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 6 Summary - Client client_43
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0136
   Val:   Loss=0.0709, RMSE=0.2664, R²=-0.0051
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.1897, RMSE: 0.4356, MAE: 0.3557, R²: -1.2199

============================================================
🔄 Round 11 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1389, val=0.0877 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0905, val=0.0765 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0836, val=0.0737 (↓), lr=0.000250
   • Epoch   4/100: train=0.0840, val=0.0737, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0837, val=0.0737, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0833, val=0.0738, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 11 Summary - Client client_43
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0054
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0051
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1657, RMSE: 0.4070, MAE: 0.3319, R²: -0.9384

📊 Round 11 Test Metrics:
   Loss: 0.1602, RMSE: 0.4002, MAE: 0.3268, R²: -0.8743

📊 Round 11 Test Metrics:
   Loss: 0.1543, RMSE: 0.3928, MAE: 0.3211, R²: -0.8051

📊 Round 11 Test Metrics:
   Loss: 0.1438, RMSE: 0.3792, MAE: 0.3109, R²: -0.6824

============================================================
🔄 Round 16 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1301, val=0.1055 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1120, val=0.0919 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0962, val=0.0838 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0864, val=0.0817 (↓), lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   • Epoch   5/100: train=0.0826, val=0.0827, patience=1/15, lr=0.000031
   • Epoch  11/100: train=0.0814, val=0.0832, patience=7/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 16 Summary - Client client_43
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0136
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0020
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1345, RMSE: 0.3667, MAE: 0.3017, R²: -0.5738

============================================================
🔄 Round 17 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1252, val=0.1329 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.1207, val=0.1278 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1170, val=0.1253 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1147, val=0.1230 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1125, val=0.1208 (↓), lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1019, val=0.1105 (↓), lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0955, val=0.1041, patience=1/15, lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0931, val=0.1016, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0917, val=0.1001, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0903, val=0.0987, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0891, val=0.0974, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.0880, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0869, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0859, val=0.0940, patience=4/15, lr=0.000001

============================================================
📊 Round 17 Summary - Client client_43
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0535
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0615
============================================================


============================================================
🔄 Round 18 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1136, val=0.1112 (↓), lr=0.000001
   • Epoch   2/100: train=0.1133, val=0.1109, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1131, val=0.1106 (↓), lr=0.000001
   • Epoch   4/100: train=0.1128, val=0.1104, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1125, val=0.1101 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1111, val=0.1087 (↓), lr=0.000001
   • Epoch  21/100: train=0.1088, val=0.1065, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.1068, val=0.1045, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1048, val=0.1026 (↓), lr=0.000001
   • Epoch  51/100: train=0.1030, val=0.1009, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1013, val=0.0992, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.0996, val=0.0976 (↓), lr=0.000001
   • Epoch  81/100: train=0.0980, val=0.0960, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0965, val=0.0946 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_43
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0952, RMSE=0.3086, R²=-0.1563
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.1437
============================================================


============================================================
🔄 Round 19 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1015, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.1013, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1011, val=0.0976, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1009, val=0.0975, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1007, val=0.0973 (↓), lr=0.000001
   • Epoch  11/100: train=0.0996, val=0.0965, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0978, val=0.0951 (↓), lr=0.000001
   • Epoch  31/100: train=0.0961, val=0.0938, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0945, val=0.0926, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.0930, val=0.0915, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0916, val=0.0904, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.0903, val=0.0895 (↓), lr=0.000001
   • Epoch  81/100: train=0.0890, val=0.0886, patience=4/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0878, val=0.0879 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_43
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0709
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0238
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0957, RMSE: 0.3094, MAE: 0.2618, R²: -0.1201

============================================================
🔄 Round 21 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0871, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0831, val=0.0868, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 21 Summary - Client client_43
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0259
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0147
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2548, R²: -0.0294

============================================================
🔄 Round 22 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0828, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0831, val=0.0824, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0829, val=0.0820, patience=7/15, lr=0.000001
   • Epoch  41/100: train=0.0827, val=0.0817, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0826, val=0.0814, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 22 Summary - Client client_43
   Epochs: 53/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0024
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0266
============================================================


============================================================
🔄 Round 26 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 26 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0071
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0022
============================================================


============================================================
🔄 Round 28 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 28 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0116
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0127
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2539, R²: -0.0134

============================================================
🔄 Round 31 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 31 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0010
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0144
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2538, R²: -0.0121

============================================================
🔄 Round 32 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 32 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0035
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0004
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0865, RMSE: 0.2940, MAE: 0.2537, R²: -0.0117

📊 Round 32 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2537, R²: -0.0114

============================================================
🔄 Round 35 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 35 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0043
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0008
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2537, R²: -0.0112

============================================================
🔄 Round 38 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 38 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0004
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0092
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2536, R²: -0.0106

============================================================
🔄 Round 41 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 41 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0004
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0208
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2536, R²: -0.0101

============================================================
🔄 Round 42 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 42 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0025
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0287
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2536, R²: -0.0100

============================================================
🔄 Round 43 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 43 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0032
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0012
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2536, R²: -0.0098

============================================================
🔄 Round 44 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 44 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0014
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0015
============================================================


============================================================
🔄 Round 45 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 45 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0017
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.1167
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2536, R²: -0.0098

============================================================
🔄 Round 48 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 48 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0014
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0014
============================================================


============================================================
🔄 Round 49 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 49 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0021
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0034
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2535, R²: -0.0095

============================================================
🔄 Round 50 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 50 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0026
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0214
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2535, R²: -0.0093

📊 Round 50 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2535, R²: -0.0093

============================================================
🔄 Round 54 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 54 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0059
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0060
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2535, R²: -0.0094

============================================================
🔄 Round 56 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 56 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0001
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0042
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2535, R²: -0.0094

============================================================
🔄 Round 60 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 60 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0012
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0095
============================================================


============================================================
🔄 Round 62 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 62 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0000
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0024
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2535, R²: -0.0090

============================================================
🔄 Round 63 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 63 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0000
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0121
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2535, R²: -0.0089

============================================================
🔄 Round 64 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 64 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0015
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0027
============================================================


============================================================
🔄 Round 65 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 65 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0003
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0023
============================================================


============================================================
🔄 Round 69 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 69 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0022
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0188
============================================================


============================================================
🔄 Round 70 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 70 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0010
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0127
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2535, R²: -0.0085

============================================================
🔄 Round 73 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 73 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0026
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0149
============================================================


============================================================
🔄 Round 74 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 74 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0000
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0004
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2535, R²: -0.0084

============================================================
🔄 Round 77 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 77 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0027
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0171
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2535, R²: -0.0082

============================================================
🔄 Round 81 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 81 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0009
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0027
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2535, R²: -0.0081

============================================================
🔄 Round 82 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 82 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0013
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0013
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2535, R²: -0.0081

============================================================
🔄 Round 83 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 83 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0017
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0052
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2535, R²: -0.0081

============================================================
🔄 Round 85 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 85 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0025
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0215
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2535, R²: -0.0081

📊 Round 85 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2535, R²: -0.0080

============================================================
🔄 Round 89 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 89 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0017
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0061
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2535, R²: -0.0080

📊 Round 89 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2535, R²: -0.0079

📊 Round 89 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2535, R²: -0.0078

============================================================
🔄 Round 93 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 93 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0025
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0110
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2535, R²: -0.0077

============================================================
🔄 Round 96 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 96 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0001
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0026
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2535, R²: -0.0077

============================================================
🔄 Round 97 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 97 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0019
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0050
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2535, R²: -0.0078

============================================================
🔄 Round 99 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 99 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0036
   Val:   Loss=0.0747, RMSE=0.2732, R²=-0.0065
============================================================


============================================================
🔄 Round 100 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 100 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0000
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0022
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2535, R²: -0.0077

============================================================
🔄 Round 101 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 101 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0026
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0073
============================================================


============================================================
🔄 Round 102 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 102 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0012
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0059
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0076

📊 Round 102 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0075

============================================================
🔄 Round 105 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 105 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0028
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0331
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0075

============================================================
🔄 Round 107 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 107 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0005
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0003
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0074

============================================================
🔄 Round 110 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 110 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0030
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0146
============================================================


============================================================
🔄 Round 111 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 111 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0017
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0081
============================================================


============================================================
🔄 Round 112 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 112 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0010
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0002
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0073

============================================================
🔄 Round 118 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 118 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0003
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0022
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0074

📊 Round 118 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0074

============================================================
🔄 Round 120 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 120 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0018
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0034
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0073

============================================================
🔄 Round 122 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 122 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0009
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0026
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0072

============================================================
🔄 Round 127 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 127 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0009
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0003
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0072

============================================================
🔄 Round 130 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 130 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0028
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0081
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0072

============================================================
🔄 Round 135 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 135 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0004
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0001
============================================================


============================================================
🔄 Round 136 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 136 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0015
   Val:   Loss=0.0682, RMSE=0.2611, R²=-0.0102
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0861, RMSE: 0.2933, MAE: 0.2535, R²: -0.0069

📊 Round 136 Test Metrics:
   Loss: 0.0861, RMSE: 0.2933, MAE: 0.2535, R²: -0.0069

📊 Round 136 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2535, R²: -0.0069

📊 Round 136 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0070

📊 Round 136 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0070

============================================================
🔄 Round 143 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 143 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0008
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0068
============================================================


============================================================
🔄 Round 146 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 146 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0004
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0031
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0072

📊 Round 146 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0071

============================================================
🔄 Round 150 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 150 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0020
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0063
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0073

============================================================
🔄 Round 152 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 152 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0012
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0015
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0072

📊 Round 152 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0073

============================================================
🔄 Round 155 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 155 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0001
   Val:   Loss=0.0965, RMSE=0.3106, R²=0.0033
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0072

📊 Round 155 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0072

============================================================
🔄 Round 158 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 158 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0015
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0008
============================================================


============================================================
🔄 Round 160 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 160 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0033
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0181
============================================================


============================================================
🔄 Round 162 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 162 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0010
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0001
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0071

============================================================
🔄 Round 165 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 165 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0005
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0051
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0070

============================================================
🔄 Round 166 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 166 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0010
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0001
============================================================


============================================================
🔄 Round 168 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 168 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0025
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0257
============================================================


============================================================
🔄 Round 169 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 169 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0026
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0096
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2535, R²: -0.0069

============================================================
🔄 Round 174 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 174 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0025
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0108
============================================================


============================================================
🔄 Round 175 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 175 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0000
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0049
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2535, R²: -0.0068

============================================================
🔄 Round 178 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 178 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0005
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0062
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2535, R²: -0.0069

============================================================
🔄 Round 179 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 179 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0002
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0040
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2535, R²: -0.0069

============================================================
🔄 Round 182 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 182 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0027
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0067
============================================================


============================================================
🔄 Round 186 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 186 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0008
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0041
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0070

============================================================
🔄 Round 187 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 187 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0016
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0132
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0070

📊 Round 187 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0070

============================================================
🔄 Round 189 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 189 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0016
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0078
============================================================


============================================================
🔄 Round 193 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 193 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0007
   Val:   Loss=0.0716, RMSE=0.2675, R²=-0.0023
============================================================


============================================================
🔄 Round 195 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 195 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0004
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0011
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2535, R²: -0.0068

============================================================
🔄 Round 196 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 196 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0017
   Val:   Loss=0.0922, RMSE=0.3037, R²=0.0027
============================================================


============================================================
🔄 Round 197 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 197 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0010
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0010
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2535, R²: -0.0070

============================================================
🔄 Round 200 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 200 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0003
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0056
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2535, R²: -0.0069

📊 Round 200 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2535, R²: -0.0068

============================================================
🔄 Round 204 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 204 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0027
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0069
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2535, R²: -0.0069

============================================================
🔄 Round 207 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 207 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0010
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0019
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2535, R²: -0.0068

============================================================
🔄 Round 208 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 208 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0011
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0014
============================================================


❌ Client client_43 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
