[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 608a941a-2165-4032-a41a-1d9f30a6d64e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26ca40b4-c0b5-475f-8654-be25a64af7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14ceb91d-74b8-4b38-ab6a-ed5e581c0c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e379ad39-6bde-496c-abb9-80c036028ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cb5a0c9-8f38-4b96-a18e-f17e9f26e483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b4f4366-74d6-4854-b243-1527367b5780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e2ffeb6-a8f0-4af5-8d75-43041a558b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a32c4049-65ff-4a84-ab44-cc93a66775c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4b65b27-fa76-4951-878c-a5339382dcd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb498541-8eba-4487-818d-d661fbd54a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9c285a5-caf5-4bdb-b6c0-d2e734f5457f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96a69912-a695-4600-a5b3-fba2ffd5086c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 036e274d-1667-45d6-a72b-ef673b071f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8fa8fa7-dc62-49e0-8ef5-1a1816b4e3eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6acafdf-ba30-4ee6-b6e7-4b9ce414a325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 448b2103-bd3b-4b58-bdf2-5dbddeb2462b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea07f2cd-ed78-4eeb-92a4-fbea3d4af520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdf643e3-58f1-4a17-ab58-301a55714d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c84ee06b-4cdd-4174-8692-96de66ae3cda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f1925c0-2e21-4bfe-9c9e-5d08bd866203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48bb8ed4-17d2-4ffe-9436-a4ad30893afa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d87fbd6d-5895-452f-ad5f-f335397ec76d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 822d88e8-abee-4739-9fd6-f19285a3ebd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a64aa2a-0b04-46ee-bc07-511a92db45cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e53b0a6-bba7-43a2-b4c1-91222c75c515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14c509d7-7c08-4405-b15d-42b81ee87d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e727e04-4bf6-4550-b91a-b403433d5f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 120c3c74-31b1-4a4a-8d88-9d1a84202034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b80d1543-3e3d-4b35-b6cb-b637eaacadb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fab65cad-912b-4a68-b397-c5d69185da3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d267f3e7-255c-4a52-a8a1-ed5aa0f155c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d27a0f54-cfbe-47d2-8f18-85c93c3e6fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 555f66c1-8bab-4866-bc3a-ee552f18051f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7d6d54b-bce6-43bb-adb3-1e22ef7a9c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b1015c3-bb8c-4682-8138-e87c4a3bd679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 239df8e0-0b63-4044-b3d4-5408492d51c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30f6a994-d971-4b58-80c4-962a6dad7d8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15cfb17f-44a1-42ae-97bd-990b353dd38d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b80f42e-bee3-4c99-ba8f-2427ea475626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc288eaa-9f34-4d66-a7f1-ba361e002bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a8607af-75db-4f47-86cb-d4935417682e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3a9549f-4e1f-45c3-91b5-0461db7b125a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acb44acc-9d6c-4fa9-a5ee-ba82047a4de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6698fd9-7e36-4cb3-985b-0a52033a6f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c871db8-95ed-4d7f-95c4-5c9613ebcefc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ff3595a-7ba7-475b-88fe-ce569aa9267e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e9ac1a3-eb73-4078-b52b-22ebbb5fa087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1b39969-76ec-4ed3-80ac-fd1b9204d06a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f6f6842-4fc6-4851-9d4a-0982d591ed51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f5cb87d-9190-4d1a-81ae-01873c8fbc28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8526120-cd4c-4e22-8b22-cbbc0d43ad71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fdcb05f-ccfc-4e96-8b62-f7afba953f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76b5a687-101e-4222-a333-964973626931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aa1de13-b207-419d-8da3-04c743a905df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f693a85-e2c1-4a1b-8ac5-b108f3aa1fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae31a295-31af-4fa3-8fcd-0a93a8fb37d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f76a3ed-aa24-4921-8a04-50580254860e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f49fe761-04f4-4fcc-9a1c-53e55b4dd89c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df6f5349-0a30-4a4d-8b33-cece8f9dcdca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69a6482d-c50c-4044-aaa0-816795ef4025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55de87f1-80cf-4c27-bff3-7fffae85a5d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33788b49-8cda-4acd-a18c-2a855e6e692c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b61a4d8c-4b5a-4642-b0dd-733002e16933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d98b7a9d-9c94-4128-bbe2-22c5e8221ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eca64f87-3fb3-43d8-a979-a55eda1a9ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc8636ae-7add-4463-90a9-68f4f250d7cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8afb16a2-0b86-49bc-a003-251eeec18e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e957964-085c-419f-a404-474d0bd38626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41d377ee-aebf-4023-b338-8346e1809b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c5b3a84-14da-47b0-891e-0ebd4fe896e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88c26008-31c7-4b36-b353-9ee7aa96eacf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d616945f-d19c-4bda-89e3-5b012cb4b242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 130cd842-68e6-4938-8177-d02a80e8fe81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5557c464-a49b-4080-896f-317936b0cda7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 544d9f5c-852b-4f76-9741-28711e62a940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1641b55-0ac0-4458-92f8-d5d5132071ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b4cbbbc-9cad-43d4-b773-a2d5330ae1c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e02491a3-c153-44b2-8961-e67fdd639352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fb3c4a2-817f-4726-be25-a9cfd97ab721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 674cb8a4-083f-4e80-a1b7-a8541c95c1b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad34cd2a-5acc-46b7-8a36-95753f6f04ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 225248c1-ed9e-43b5-b193-4a059bced751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35f19701-49f8-4aa8-9dde-6a02d2aef3b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7872eca5-44e1-4712-9922-14c1afa4c3b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d47fc9d-1ac1-41f7-a30c-5f80128e5e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abcdf41b-be04-4a95-b99b-ed9bdf2f6a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a104d7c-9610-4b9e-bb5b-23cc7b61ae56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 517d435c-3ca3-4b37-beb8-e8084ba6cf30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db2e5f53-2488-4dae-afbe-3fd7ac48090c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23af1cf6-9d4a-4830-b4f0-082e4fe11d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d424c8b1-c60a-4b78-99a6-c01c7fd03dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eba1df2-1f82-4057-bb66-f35e739d2dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8700d162-0265-40e2-b08f-f8556a501e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bff86c3-eae3-4bcc-98ab-8590dd540d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3782e7a-3722-4606-9a0f-19e337127d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8df614b3-6505-435b-8a9d-e4ba45d632be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ac0d9cc-d665-445f-9af4-be1297720138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d7e35ff-3d65-41a0-b771-2f75afeb00e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37f9c9f0-bc32-4d20-8de2-674c52463109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0b538eb-191e-4057-8722-36477e7cd7a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e094855-5322-410b-b4dc-57b2c11ec0a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 341a8bba-ad14-48ba-9f92-de15a719724b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f74ce507-f2ff-4871-9505-83966b3a6156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4ca89af-7013-4667-9983-69d8ec922364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f75d0559-bf7c-450e-8af6-419c17872f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2577d431-900b-4936-964a-f3ebf05cc0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 930db6ba-b75a-4c71-9d55-e954cb36d56f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e0e8db0-d923-4659-b955-82e29c0881c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de95ef48-f319-4a53-8f87-9f69847a418c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28dfc760-4dc9-4d77-a55f-5a3bde5723a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08cb0280-8fc0-4e25-a34a-eb06e1b0d2c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e816798-67fd-45fd-9929-8d0120c234e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 467e7f95-e8f3-4045-9b0c-87b1ef5b39e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31dce61f-972b-4b40-a747-55faa12c28fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aebf5438-c5f2-43cd-ab43-e54e2ca37fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 976cded8-c948-409e-a62a-b67c03b7fbc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bf4ff92-4656-4dde-a11f-f4c84018570b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1431b6d6-62f6-4eee-aff4-0fd021fda7c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dfcfbcf-9404-47d4-80b6-c8139074dc37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c4aa3ee-2c89-4042-9dcf-b96be7586968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5effe7a0-fa32-4fc5-a467-f647bd155129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0491b9b7-ee78-4f8b-ac9e-9297872bb3ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d09c08bc-026f-4bf7-9521-ed16b99aa9a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cee26a5-85aa-4b93-9300-4e25018d0420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43184c4d-d955-483b-8749-d9e15386a343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58cda01d-cacf-4726-a3b5-2d7c3e357785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aec34a8-2dc9-4935-88da-d375ab69191f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 958800fe-4fb0-4688-a536-7c8f936bb45f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d27e615-adaa-4f16-afd1-006e0c3487ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fab3baa6-1aaf-411e-a031-1e9e030de14b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 902a3cee-ee91-4bb7-ae28-76a993330e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07e212fd-e616-450a-86c1-fe747c312343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f1f6887-da04-40a2-aa13-26f8b7360947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1c62cbe-6d5f-4e19-a985-35b2e827679a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd2bfdc-f61e-4b8f-9657-62db6b641e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 568d15d3-4903-46f7-9afb-9f263040bebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 867b5b8d-3fd3-4dbb-8a5e-6c6ea407b92e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f18b34e9-cadf-44e9-a003-bd249740482f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a72a6925-a723-42b9-9d02-41ce959cf698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4615cdae-71b6-42bb-881b-d0e085e9f964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70c88fc7-362e-4bcb-92c6-35b3abc27d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cca54c31-0936-463e-a338-482e5ac3e9bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7308b676-fcf8-4491-91d6-e7e6dcb86851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12cdd99e-64b7-442b-bc42-64e184a09e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f13f8402-4303-4009-8314-a11d5cd6d815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a59a40e2-97a2-4f42-860b-87ff60129b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba51e936-c329-4b4a-b1d6-5e81b4044879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45b85ee3-241f-47fc-9e4f-a76b31bcc4a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a27549f3-d31c-4a9c-b433-9dba31277826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a2cf5dc-04d7-4211-a456-fd762bba25a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b67277fc-f982-45b2-95d1-9c6cbe2fd931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 643270ba-ab88-48e7-a7b8-336b85237803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b455a15b-84b7-400b-b2bf-9051c5273344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87b1bf14-d9bf-480b-baba-f2117a8b922a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a61ba43-c8fc-43ba-8085-2a8523d552ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2a30135-02d9-4d4c-8e1d-06bf32a4d1ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18cd2188-5150-47f0-b437-f2c8619af0d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 889e3b89-56cf-4434-b3be-e71db698ac17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdac6246-52c1-45ec-8789-b5a1cdbbf4b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2c0e661-3e11-41a0-a87d-150c278049c1
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_44
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_44
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_44/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_44/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_44/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_44/test_labels.txt

📊 Raw data loaded:
   Train: X=(1072, 24), y=(1072,)
   Test:  X=(268, 24), y=(268,)

⚠️  Limiting training data: 1072 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  259 samples, 5 features
✅ Client client_44 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 7 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1117, val=0.0760 (↓), lr=0.001000
   • Epoch   2/100: train=0.0848, val=0.0769, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0832, val=0.0784, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0832, val=0.0781, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0830, val=0.0779, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0810, val=0.0781, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 7 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0028
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0026
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.1819, RMSE: 0.4264, MAE: 0.3505, R²: -1.1494

📊 Round 7 Test Metrics:
   Loss: 0.1789, RMSE: 0.4230, MAE: 0.3476, R²: -1.1148

============================================================
🔄 Round 9 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1385, val=0.1270 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0873, val=0.0900 (↓), lr=0.000250
   • Epoch   3/100: train=0.0818, val=0.0907, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0806, val=0.0906, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0804, val=0.0902, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0802, val=0.0902, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 9 Summary - Client client_44
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0151
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0082
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1751, RMSE: 0.4184, MAE: 0.3437, R²: -1.0690

============================================================
🔄 Round 10 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1570, val=0.1391 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1338, val=0.1173 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1137, val=0.0998 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0978, val=0.0871 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0876, val=0.0809 (↓), lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0830, val=0.0800, patience=5/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0828, val=0.0800, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 10 Summary - Client client_44
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0007
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0114
============================================================


============================================================
🔄 Round 11 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.1607, val=0.1370 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1561, val=0.1337 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1529, val=0.1307 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1499, val=0.1279 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1472, val=0.1254 (↓), lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1349, val=0.1141 (↓), lr=0.000004
   📉 Epoch 17: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.1268, val=0.1064 (↓), lr=0.000002
   📉 Epoch 25: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.1235, val=0.1033 (↓), lr=0.000001
   • Epoch  41/100: train=0.1214, val=0.1012, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1194, val=0.0992, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1174, val=0.0973 (↓), lr=0.000001
   • Epoch  71/100: train=0.1155, val=0.0954, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1137, val=0.0936, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1119, val=0.0918 (↓), lr=0.000001

============================================================
📊 Round 11 Summary - Client client_44
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.1103, RMSE=0.3320, R²=-0.2830
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.3438
============================================================


============================================================
🔄 Round 12 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1560, val=0.1459 (↓), lr=0.000001
   • Epoch   2/100: train=0.1557, val=0.1456, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1553, val=0.1454 (↓), lr=0.000001
   • Epoch   4/100: train=0.1550, val=0.1451, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1547, val=0.1448 (↓), lr=0.000001
   • Epoch  11/100: train=0.1531, val=0.1433, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1506, val=0.1410, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1483, val=0.1389 (↓), lr=0.000001
   • Epoch  41/100: train=0.1461, val=0.1369, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1440, val=0.1350, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1419, val=0.1331 (↓), lr=0.000001
   • Epoch  71/100: train=0.1399, val=0.1313, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1378, val=0.1294, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1358, val=0.1276 (↓), lr=0.000001

============================================================
📊 Round 12 Summary - Client client_44
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1342, RMSE=0.3664, R²=-0.6438
   Val:   Loss=0.1260, RMSE=0.3549, R²=-0.5026
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1596, RMSE: 0.3995, MAE: 0.3281, R²: -0.8861

📊 Round 12 Test Metrics:
   Loss: 0.1538, RMSE: 0.3921, MAE: 0.3224, R²: -0.8175

📊 Round 12 Test Metrics:
   Loss: 0.1435, RMSE: 0.3788, MAE: 0.3122, R²: -0.6955

📊 Round 12 Test Metrics:
   Loss: 0.1343, RMSE: 0.3665, MAE: 0.3029, R²: -0.5874

============================================================
🔄 Round 17 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1278, val=0.1144 (↓), lr=0.000001
   • Epoch   2/100: train=0.1276, val=0.1142, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1274, val=0.1140, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1272, val=0.1139 (↓), lr=0.000001
   • Epoch   5/100: train=0.1270, val=0.1137, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1258, val=0.1126, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1237, val=0.1109, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1217, val=0.1091 (↓), lr=0.000001
   • Epoch  41/100: train=0.1196, val=0.1074, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1176, val=0.1057, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1156, val=0.1040 (↓), lr=0.000001
   • Epoch  71/100: train=0.1137, val=0.1024, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1117, val=0.1007 (↓), lr=0.000001
   • Epoch  91/100: train=0.1098, val=0.0992, patience=2/15, lr=0.000001

============================================================
📊 Round 17 Summary - Client client_44
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1080, RMSE=0.3286, R²=-0.3056
   Val:   Loss=0.0978, RMSE=0.3127, R²=-0.2289
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1192, RMSE: 0.3453, MAE: 0.2881, R²: -0.4090

📊 Round 17 Test Metrics:
   Loss: 0.1064, RMSE: 0.3261, MAE: 0.2748, R²: -0.2571

============================================================
🔄 Round 19 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0980, val=0.1055 (↓), lr=0.000001
   • Epoch   2/100: train=0.0979, val=0.1053, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0977, val=0.1052, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.0976, val=0.1050 (↓), lr=0.000001
   • Epoch   5/100: train=0.0975, val=0.1048, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.0967, val=0.1038, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0955, val=0.1021, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0943, val=0.1004, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0932, val=0.0988, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0921, val=0.0972, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0911, val=0.0957, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0901, val=0.0942, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0892, val=0.0928, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0884, val=0.0915, patience=3/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_44
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0562
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.1644
============================================================


============================================================
🔄 Round 20 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0912, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  21/100: train=0.0894, val=0.0827, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0884, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0876, val=0.0813, patience=6/15, lr=0.000001
   • Epoch  51/100: train=0.0869, val=0.0808, patience=7/15, lr=0.000001
   • Epoch  61/100: train=0.0862, val=0.0803, patience=7/15, lr=0.000001
   • Epoch  71/100: train=0.0857, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0852, val=0.0797, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 20 Summary - Client client_44
   Epochs: 82/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0302
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0298
============================================================


============================================================
🔄 Round 21 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 21 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0472
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0025
============================================================


============================================================
🔄 Round 23 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 23 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0138
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0105
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2522, R²: -0.0206

📊 Round 23 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2520, R²: -0.0179

============================================================
🔄 Round 25 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 25 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0118
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0065
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2518, R²: -0.0161

📊 Round 25 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2515, R²: -0.0132

📊 Round 25 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2514, R²: -0.0129

============================================================
🔄 Round 32 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 32 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0052
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0199
============================================================


============================================================
🔄 Round 33 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 33 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0077
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0074
============================================================


============================================================
🔄 Round 34 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 34 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0081
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0013
============================================================


============================================================
🔄 Round 37 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 37 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0067
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0143
============================================================


============================================================
🔄 Round 38 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 38 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0062
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0090
============================================================


============================================================
🔄 Round 40 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 40 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0091
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0077
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2512, R²: -0.0099

📊 Round 40 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2511, R²: -0.0097

📊 Round 40 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2511, R²: -0.0094

📊 Round 40 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2511, R²: -0.0092

📊 Round 40 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2511, R²: -0.0091

============================================================
🔄 Round 49 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 49 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0059
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0060
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2511, R²: -0.0090

📊 Round 49 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2511, R²: -0.0088

============================================================
🔄 Round 53 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 53 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0057
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0041
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2510, R²: -0.0088

============================================================
🔄 Round 57 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 57 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0048
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0077
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2510, R²: -0.0085

============================================================
🔄 Round 62 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 62 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0042
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0089
============================================================


============================================================
🔄 Round 63 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 63 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0104
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0083
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2510, R²: -0.0083

📊 Round 63 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2510, R²: -0.0081

📊 Round 63 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2510, R²: -0.0078

============================================================
🔄 Round 71 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 71 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0057
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0051
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0852, RMSE: 0.2920, MAE: 0.2509, R²: -0.0076

============================================================
🔄 Round 75 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 75 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0062
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0090
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0852, RMSE: 0.2919, MAE: 0.2509, R²: -0.0073

============================================================
🔄 Round 79 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 79 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0048
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0051
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0852, RMSE: 0.2919, MAE: 0.2509, R²: -0.0071

============================================================
🔄 Round 82 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 82 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0026
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0192
============================================================


============================================================
🔄 Round 83 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 83 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0035
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0093
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0852, RMSE: 0.2919, MAE: 0.2509, R²: -0.0071

============================================================
🔄 Round 85 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 85 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0027
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0263
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0852, RMSE: 0.2919, MAE: 0.2509, R²: -0.0070

============================================================
🔄 Round 89 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 89 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0040
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0072
============================================================


============================================================
🔄 Round 92 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 92 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0071
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0058
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0852, RMSE: 0.2918, MAE: 0.2508, R²: -0.0066

============================================================
🔄 Round 93 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 93 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0031
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0102
============================================================


============================================================
🔄 Round 94 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 94 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0037
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0246
============================================================


============================================================
🔄 Round 95 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 95 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0062
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0017
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0852, RMSE: 0.2918, MAE: 0.2508, R²: -0.0065

============================================================
🔄 Round 96 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 96 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0052
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0027
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0852, RMSE: 0.2918, MAE: 0.2508, R²: -0.0065

============================================================
🔄 Round 97 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 97 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0034
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0109
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0852, RMSE: 0.2918, MAE: 0.2508, R²: -0.0066

📊 Round 97 Test Metrics:
   Loss: 0.0852, RMSE: 0.2918, MAE: 0.2508, R²: -0.0065

📊 Round 97 Test Metrics:
   Loss: 0.0852, RMSE: 0.2918, MAE: 0.2508, R²: -0.0065

📊 Round 97 Test Metrics:
   Loss: 0.0851, RMSE: 0.2918, MAE: 0.2508, R²: -0.0063

============================================================
🔄 Round 103 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 103 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0044
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0242
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0851, RMSE: 0.2918, MAE: 0.2508, R²: -0.0061

📊 Round 103 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2508, R²: -0.0060

============================================================
🔄 Round 108 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 108 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0043
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0047
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2508, R²: -0.0059

============================================================
🔄 Round 109 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 109 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0030
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0118
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2507, R²: -0.0058

============================================================
🔄 Round 112 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 112 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0046
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0083
============================================================


============================================================
🔄 Round 114 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 114 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0052
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0009
============================================================


============================================================
🔄 Round 116 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 116 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0052
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0155
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2507, R²: -0.0058

📊 Round 116 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2507, R²: -0.0058

============================================================
🔄 Round 119 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 119 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0042
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0054
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2507, R²: -0.0058

============================================================
🔄 Round 121 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 121 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0026
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0106
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2507, R²: -0.0056

============================================================
🔄 Round 123 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 123 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0061
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0084
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2507, R²: -0.0056

📊 Round 123 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2507, R²: -0.0055

============================================================
🔄 Round 128 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 128 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0067
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0051
============================================================


============================================================
🔄 Round 131 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 131 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0047
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0021
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2507, R²: -0.0055

============================================================
🔄 Round 132 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 132 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0053
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0047
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2507, R²: -0.0054

============================================================
🔄 Round 133 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 133 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0028
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0186
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2507, R²: -0.0054

📊 Round 133 Test Metrics:
   Loss: 0.0851, RMSE: 0.2916, MAE: 0.2507, R²: -0.0053

============================================================
🔄 Round 136 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 136 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0073
   Val:   Loss=0.0941, RMSE=0.3068, R²=0.0039
============================================================


============================================================
🔄 Round 137 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 137 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0055
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0027
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2507, R²: -0.0052

📊 Round 137 Test Metrics:
   Loss: 0.0851, RMSE: 0.2916, MAE: 0.2507, R²: -0.0052

============================================================
🔄 Round 142 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 142 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0015
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0157
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2507, R²: -0.0052

============================================================
🔄 Round 143 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 143 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0051
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0004
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2507, R²: -0.0054

============================================================
🔄 Round 146 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 146 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0037
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0124
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0851, RMSE: 0.2916, MAE: 0.2507, R²: -0.0053

============================================================
🔄 Round 151 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 151 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0014
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0187
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2507, R²: -0.0054

📊 Round 151 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2507, R²: -0.0054

📊 Round 151 Test Metrics:
   Loss: 0.0851, RMSE: 0.2916, MAE: 0.2507, R²: -0.0053

============================================================
🔄 Round 157 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 157 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0013
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0143
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0851, RMSE: 0.2916, MAE: 0.2507, R²: -0.0053

============================================================
🔄 Round 158 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 158 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0051
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0022
============================================================


============================================================
🔄 Round 160 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 160 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0018
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0131
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2507, R²: -0.0052

============================================================
🔄 Round 161 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 161 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0036
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0061
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2507, R²: -0.0052

============================================================
🔄 Round 162 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 162 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0026
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0085
============================================================


============================================================
🔄 Round 163 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 163 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0032
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0080
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2507, R²: -0.0052

============================================================
🔄 Round 165 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 165 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0048
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0026
============================================================


============================================================
🔄 Round 166 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 166 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0033
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0067
============================================================


============================================================
🔄 Round 167 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 167 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0074
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0037
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2506, R²: -0.0050

============================================================
🔄 Round 168 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 168 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0074
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0032
============================================================


============================================================
🔄 Round 169 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 169 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0032
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0174
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2506, R²: -0.0048

📊 Round 169 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2506, R²: -0.0047

============================================================
🔄 Round 173 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 173 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0031
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0095
============================================================


============================================================
🔄 Round 174 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 174 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0075
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0017
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2506, R²: -0.0048

============================================================
🔄 Round 179 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 179 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0047
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0180
============================================================


============================================================
🔄 Round 181 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 181 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0039
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.0028
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2506, R²: -0.0047

📊 Round 181 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2506, R²: -0.0048

📊 Round 181 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2506, R²: -0.0047

============================================================
🔄 Round 185 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 185 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0084
   Val:   Loss=0.0815, RMSE=0.2856, R²=0.0083
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2506, R²: -0.0047

============================================================
🔄 Round 187 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 187 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0030
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0070
============================================================


============================================================
🔄 Round 188 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 188 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0033
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0191
============================================================


============================================================
🔄 Round 190 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 190 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0012
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0279
============================================================


============================================================
🔄 Round 191 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 191 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0030
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0063
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2506, R²: -0.0047

============================================================
🔄 Round 193 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 193 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0031
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0082
============================================================


============================================================
🔄 Round 195 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 195 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0045
   Val:   Loss=0.0676, RMSE=0.2601, R²=0.0006
============================================================


============================================================
🔄 Round 196 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 196 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0025
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0106
============================================================


============================================================
🔄 Round 197 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 197 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0041
   Val:   Loss=0.0881, RMSE=0.2967, R²=-0.0075
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2506, R²: -0.0048

📊 Round 197 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2506, R²: -0.0047

📊 Round 197 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2506, R²: -0.0047

📊 Round 197 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2506, R²: -0.0047

📊 Round 197 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2506, R²: -0.0045

📊 Round 197 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2506, R²: -0.0046

📊 Round 197 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2506, R²: -0.0046

============================================================
🔄 Round 210 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 210 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0053
   Val:   Loss=0.0778, RMSE=0.2788, R²=-0.0060
============================================================


============================================================
🔄 Round 211 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 211 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0031
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0063
============================================================


❌ Client client_44 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
