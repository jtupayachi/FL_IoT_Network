[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dc24e2f-07b1-4cdc-9e5a-93a20cc6cb92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15895f63-3d58-41b1-a1e3-820055d0c4b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86957664-eecf-4cc2-bc5d-a94e232c16bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c8a94fd-6498-4e2a-a77e-5528a3abe0d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47ab14a7-75e0-4119-8bc3-e62eda1e08d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 904b5d93-d7e9-44d8-9c7a-699bce3baa62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f398460d-285d-44be-9ddf-a8150e716419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a663c564-155b-4468-b9ed-40305a43b81b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d5813aa-15da-430e-b505-a6d670482057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dbdf372-537f-449c-b1f2-1e2c9d16eb05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message accdf4ab-7477-43ce-bbcd-6355c97d4798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22d07790-39a6-453b-9d8b-d678908fe93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47fd33bc-51ba-4478-ae71-bd1012569396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5eb79a2-be41-486b-bec1-a392bf083be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 088b9d42-c440-4158-af24-f05e70203980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5366fb9-050e-4361-bbff-60ca1041f39b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01b0cd84-6471-473e-ad77-b62cd5dcf36d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47c9785b-7be2-4bef-b682-1cb6ea638608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 693b8a26-00a0-41ea-97cc-68929b227550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8136261-4ce1-4b17-886e-0fc5de4ee7fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e29d0da9-0c4e-4250-9618-56b96f508f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8a3e69b-88b8-4f38-ae5d-9d9325f3c445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a74d005-75a1-44c3-8ae0-c8dd33f5f943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7f2b28e-781f-4d37-b868-30684980e7e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e9e891a-a184-47ac-bd78-3a3644d699c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4f08e8a-b86f-485e-adc7-2385c8909835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00fe9c20-58ca-4367-888b-f73f85e85b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22afbabc-d6ff-451f-8aa5-f7705a44d1e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fc737f8-aff4-4084-9b84-0910c2da7910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e38ec92-712a-4e6e-8083-9c3b31bcb1ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22f7c1c6-f10e-4013-b1d7-381c02072d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 869bf79c-d4e9-4dda-8ae6-cf63e5d91ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56904791-8113-444f-ada2-0cbe25ad1c2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 637f7228-9c08-4777-9828-fa93ab4458ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb1e947b-00ea-444a-917d-208af09b56d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 628222a3-33b1-4996-b904-1902fe961f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a16d1c33-4c6f-4318-af21-0b95dfad6b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8622204b-e3b8-4e0a-8159-0f5ea33e16a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67a9728a-b0c4-414a-a359-ca1e69cb5e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7fcecc4-18ef-408c-a1d0-766cd26869a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12579f2c-bc21-4495-ac62-0f559fb6bd73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e37ccac-2eb0-4e3a-a57b-fd010d208d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c58816e-e05a-489c-bb23-6ee6f644eedc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5879e983-fde3-4e64-baba-79d52cee68ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d18e6391-355b-4f1e-885f-d96cc5ae4417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5898cd4f-0c45-42a7-b9ea-4c2c40124581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a42c3dac-7649-4f3f-b061-e337660168f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d6527f6-b078-4473-ac92-c1fda89df347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebdd9555-43aa-4407-8362-1a2a009d91bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54cad24f-50f0-49b2-ab48-6c75cce8fa48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5e1a4b2-7956-49dc-9a0c-d2fee8c5daeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbae1a5a-3e4a-4f50-8a8a-c5e225bfb318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd56e4e5-c01b-489e-a3c0-cfb6182e256d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6af62129-4128-417d-af34-fc6cdda2d307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fd624be-b775-4a0b-a5f2-d7d2f7b0c2f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 945feaeb-d4e9-45c9-bc87-28320f6a8b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53a5e3f1-fe9b-42bb-8263-53993b8c61c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 385ebd50-9f91-44f5-a914-c58afd164de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 925182b6-51d8-4f0f-8e13-3a75993b8e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2791da7c-744a-4a78-aaf8-20a8535147a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d58afd67-cab7-4ec6-b4a0-c4f716d05623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47aceb43-1ded-4257-9b06-1fe9ec2f0cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2123bef5-6d9a-446b-946a-2d4e59cb0ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4eecb3d-6616-429f-ae12-313c6de69a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6eaf605-00cf-4e1f-a052-789f012b20e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 631d2d8a-1932-4edf-80b5-85696cbdbdea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddc4970f-3772-441c-8ba8-ed0a60199629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62a33265-30a8-43db-8226-aa72bbb5dd69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a37481ed-d2c1-4cff-a4c5-e2387cad4914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd7679b9-7dce-4ce8-bb4d-bb2e80401662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c536937-22f9-4e58-9a92-417a36b24219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90b1688b-3331-4bb2-81de-d06dc77cd2b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcc437d4-b921-4ee4-ba19-5283c1b03bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2a1ef7c-a2c7-4140-a075-afed8b7580a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d8b3aa0-3a84-4be2-95f7-4d81ef75d17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23eb0302-613f-40d3-a954-e94374e77d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c116900c-2371-4920-b3c1-4317aea8f49c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cb8529d-b8c9-4ac3-a5af-06d866454998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39aad553-96d1-4956-8641-43fb9ba2429c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50011863-c562-4345-b480-7f901c39aee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77f42f1a-957e-4824-a4f4-0858e30f8ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2bb7ac0-1b72-4263-b707-b592b35640fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b798a20e-90d2-4b4b-adfd-9341f30a07a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fc882fc-f44e-49fe-bdbe-667d2d922f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f62a2532-3925-4337-9956-4ebf3873c65b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 710ef6f6-b98b-42f2-8a05-a915c673c1e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb454464-f683-44fa-9c50-f950facc2ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f536bb7d-0c20-49cb-a88d-26243592f569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7c81bcb-7488-42b0-bbb8-f2f615cf2012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c0a4769-f965-4403-b5b2-52ad6734b6d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb25b050-81f0-480e-ab91-e34d9294c9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bfbe2ba-9a04-449f-a05e-0768eee46d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4cc0569-215d-4fbc-9d03-10831c5d2e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1004e0f4-436c-4a1b-b2d7-2bec70f73872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6213c789-9588-4626-8f50-b011544df673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f336b7a-ce5e-4d2b-a388-81c74013ca34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3620bd2d-5db2-4ebd-a2af-550070e60b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 932d6bb3-832c-4e2a-a60c-ce34355a0c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05098631-2ba5-4754-8fb7-988875d6f96f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0da1b073-2861-438d-8658-b6f5a2ef9ca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ba6a0d0-098e-4afd-b31e-b53b6a1cf065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message defc573c-6e3a-41c6-b763-ab77ad80f68c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5370d56c-c479-4a61-9b90-43d6001a56b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ad888f3-dff3-4d8f-b069-d1940e3c3697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed4f577e-cd60-4745-9671-46a11cea11d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee950e0b-71a3-4373-a324-80cebdeb3aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1fbcbff-e741-47f0-8f56-53c36ab10964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8956802c-d246-411a-9b44-300d636c937f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc0b5fe1-6a07-4bbe-80b8-e25b5ab0311c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c0034c5-5472-416a-9702-9564f8f19a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af7198b9-83f6-4f11-a923-5cd2d9ed19ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d26b03ea-966f-4fcb-a90f-678e4224cb8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90797dd9-9a04-4699-9b21-d1bc4374a7ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70720cc7-345f-4ba4-9d4c-fca8007153d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c062335-0cce-4d9c-a670-e066d113fa79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f9b5c77-0f48-4fe7-aa4f-5477bdc44149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee9c255b-c104-4a96-90bd-904c3239e1e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7245120f-8251-47af-9beb-03c3ca748415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e452993-2731-46d4-b94c-1271b4a57360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e71f5cb-eeb1-4865-98a7-2faa1c15866c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec2f67e5-0e91-4c89-a105-b3c813a80672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e9e91b1-7fba-4e67-ad01-a8b8d9e69c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 288b46ae-0eca-4c3f-b8f5-ed335f36a57c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3e79bde-b75b-4583-8b8f-f64a038b8571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ce27f3a-8141-4632-80ff-a37a17b946a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eaa13e5-59cd-46a4-8803-1013a99c7fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0abbcd4-f799-4e8b-b7c2-ec9e3b52f9fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38a11da2-11e5-4941-b15b-e2fe2abb6d30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d47d0135-1e39-44ff-a179-e7409fd917a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40f3d5b8-50e6-4d12-a517-9df4d0ad421c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d86ee54f-dc5c-45c4-bca1-816c2c8face7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f090dc7-615d-4e71-954f-267838ac6a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3af7618e-6ed7-4aa4-aacd-8fcc9ca0eaed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f3596cc-0876-4820-a5db-be0052145958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 348e1680-16cb-472d-8586-c30b11cda1d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8216066c-f46e-4408-86c3-82e4ea94972a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2870570-76ee-469f-8fc3-cf4c433352fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 609e331c-3cbe-44bb-910d-5fe190c6e0fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e19eba5c-d9ec-419f-a5b9-b18bf174af74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76b93e40-90b5-4eb5-ab83-913f9bd89202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b048c9d9-648a-4159-8747-08a360c73233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 944f2517-1368-4c31-8cde-7fdd0f89c0a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ccb1713-8634-4b93-8075-c4e8df59eb14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19d24bde-db64-466c-96e9-84c8c50f29ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 151c26ab-0ec8-4ea7-9085-89e8fbca5fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bed91b33-651c-4080-90a4-0c5d66731e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a38e3471-d9e9-4cd7-81fe-08eab47f6acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 555d1c2b-77c9-4e27-8440-fe6bf06ae813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78d60dad-7bc7-4505-a695-54039c7726db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae478ba5-ddfb-471c-afc9-d09282ba7507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff68c55f-c5ef-4b3e-aaa1-99192bad7d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1d4f531-7787-4504-8aaf-ea0a01ca718e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b58ea01d-f28e-40ae-93b9-9a70be5c7b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca7c3bd2-3ce0-44fa-983a-1e02d699573d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b784838-3961-494f-be6a-6563d3ddac97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd32f1cc-10c8-47ec-8cd4-cda5c91f5c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7b96a68-e4ad-4929-a85e-9afc9047b561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea88f05c-9535-4186-a415-bdb8a4c5b4fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 651d1394-7c6a-4c6d-908d-ba708bc9b4ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 524bdf8c-4c2a-4ee2-8433-43cc68acbdfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d275f364-05ac-41cc-b110-64fedcce7fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec00640e-68b6-46da-b743-e58c6d1c5e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85d60c8e-6d16-4819-8467-59ba38b28ac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c448d85-e58c-4c4c-a5a2-bcb6ad2baf19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a26135d-b559-4148-86ee-1929d3e72c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fda86a7a-e312-4248-b504-e5913e71c4c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c723ec7-1ce4-469b-b2ba-322df91b4b3e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_46
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_46
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_46/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_46/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_46/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_46/test_labels.txt

📊 Raw data loaded:
   Train: X=(1336, 24), y=(1336,)
   Test:  X=(335, 24), y=(335,)

⚠️  Limiting training data: 1336 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  326 samples, 5 features
✅ Client client_46 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.2088, RMSE: 0.4569, MAE: 0.3762, R²: -1.4355

============================================================
🔄 Round 7 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1099, val=0.0771 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0821, val=0.0764 (↓), lr=0.001000
   • Epoch   3/100: train=0.0810, val=0.0762, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0811, val=0.0762, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0810, val=0.0762, patience=3/15, lr=0.001000
   • Epoch  11/100: train=0.0796, val=0.0755, patience=1/15, lr=0.001000
   📉 Epoch 18: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0754, val=0.0778, patience=11/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 7 Summary - Client client_46
   Epochs: 25/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0238
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0045
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.1920, RMSE: 0.4382, MAE: 0.3597, R²: -1.2403

============================================================
🔄 Round 8 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.1258, val=0.0796 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0812, val=0.0784 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0814, val=0.0776 (↓), lr=0.000250
   • Epoch   4/100: train=0.0808, val=0.0775, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0808, val=0.0775, patience=2/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0805, val=0.0776, patience=8/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 8 Summary - Client client_46
   Epochs: 18/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0010
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0009
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1889, RMSE: 0.4347, MAE: 0.3565, R²: -1.2042

============================================================
🔄 Round 9 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1558, val=0.1479 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1336, val=0.1262 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1148, val=0.1084 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0998, val=0.0939 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0890, val=0.0841 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0813, val=0.0777, patience=4/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0812, val=0.0776, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 9 Summary - Client client_46
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0034
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0127
============================================================


============================================================
🔄 Round 13 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.1369, val=0.1709 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1331, val=0.1677 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1305, val=0.1646 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1281, val=0.1618 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1258, val=0.1591 (↓), lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1151, val=0.1470 (↓), lr=0.000004
   📉 Epoch 17: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.1081, val=0.1387 (↓), lr=0.000002
   📉 Epoch 25: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.1053, val=0.1353 (↓), lr=0.000001
   • Epoch  41/100: train=0.1035, val=0.1330, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1017, val=0.1308, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1001, val=0.1287 (↓), lr=0.000001
   • Epoch  71/100: train=0.0985, val=0.1266, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0969, val=0.1246, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0954, val=0.1226 (↓), lr=0.000001

============================================================
📊 Round 13 Summary - Client client_46
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0939, RMSE=0.3065, R²=-0.2189
   Val:   Loss=0.1209, RMSE=0.3477, R²=-0.3284
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1622, RMSE: 0.4028, MAE: 0.3298, R²: -0.8925

============================================================
🔄 Round 14 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1390, val=0.1434 (↓), lr=0.000001
   • Epoch   2/100: train=0.1387, val=0.1431, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1385, val=0.1428 (↓), lr=0.000001
   • Epoch   4/100: train=0.1382, val=0.1426, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1379, val=0.1423 (↓), lr=0.000001
   • Epoch  11/100: train=0.1364, val=0.1408, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1341, val=0.1386, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1320, val=0.1364 (↓), lr=0.000001
   • Epoch  41/100: train=0.1299, val=0.1344, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1279, val=0.1324, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1259, val=0.1304 (↓), lr=0.000001
   • Epoch  71/100: train=0.1239, val=0.1285, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1220, val=0.1265, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1200, val=0.1246 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_46
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1184, RMSE=0.3442, R²=-0.4936
   Val:   Loss=0.1229, RMSE=0.3505, R²=-0.4725
============================================================


============================================================
🔄 Round 15 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1317, val=0.1256 (↓), lr=0.000001
   • Epoch   2/100: train=0.1315, val=0.1254, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1313, val=0.1252, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1311, val=0.1250 (↓), lr=0.000001
   • Epoch   5/100: train=0.1309, val=0.1248, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1296, val=0.1236, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1276, val=0.1217, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1256, val=0.1197 (↓), lr=0.000001
   • Epoch  41/100: train=0.1236, val=0.1178, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1216, val=0.1159, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1197, val=0.1140 (↓), lr=0.000001
   • Epoch  71/100: train=0.1177, val=0.1121, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1157, val=0.1102, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1138, val=0.1083 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_46
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1119, RMSE=0.3345, R²=-0.3863
   Val:   Loss=0.1066, RMSE=0.3265, R²=-0.3709
============================================================


============================================================
🔄 Round 17 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1219, val=0.1247 (↓), lr=0.000001
   • Epoch   2/100: train=0.1218, val=0.1245, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1216, val=0.1243, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1214, val=0.1241 (↓), lr=0.000001
   • Epoch   5/100: train=0.1212, val=0.1239, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1200, val=0.1227, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1180, val=0.1207, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1161, val=0.1188 (↓), lr=0.000001
   • Epoch  41/100: train=0.1142, val=0.1168, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1123, val=0.1149, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1104, val=0.1130 (↓), lr=0.000001
   • Epoch  71/100: train=0.1085, val=0.1111, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1067, val=0.1093, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1049, val=0.1074 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_46
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1026, RMSE=0.3204, R²=-0.2874
   Val:   Loss=0.1058, RMSE=0.3253, R²=-0.2951
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1113, RMSE: 0.3336, MAE: 0.2810, R²: -0.2980

============================================================
🔄 Round 20 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  21/100: train=0.0837, val=0.0936, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0829, val=0.0928, patience=6/15, lr=0.000001
   • Epoch  41/100: train=0.0823, val=0.0920, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.0817, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  61/100: train=0.0811, val=0.0907, patience=6/15, lr=0.000001
   • Epoch  71/100: train=0.0806, val=0.0902, patience=7/15, lr=0.000001
   • Epoch  81/100: train=0.0802, val=0.0897, patience=7/15, lr=0.000001
   • Epoch  91/100: train=0.0799, val=0.0893, patience=5/15, lr=0.000001

============================================================
📊 Round 20 Summary - Client client_46
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0149
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0231
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2618, R²: -0.0726

============================================================
🔄 Round 21 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0899, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0796, val=0.0895, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0794, val=0.0891, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 21 Summary - Client client_46
   Epochs: 40/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0148
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0237
============================================================


============================================================
🔄 Round 22 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0837, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0802, val=0.0834, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 22 Summary - Client client_46
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0105
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0288
============================================================


============================================================
🔄 Round 23 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 23 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0113
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0043
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0889, RMSE: 0.2981, MAE: 0.2583, R²: -0.0370

📊 Round 23 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2576, R²: -0.0314

============================================================
🔄 Round 27 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 27 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0065
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0004
============================================================


============================================================
🔄 Round 28 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 28 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0069
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0046
============================================================


============================================================
🔄 Round 29 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0647 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0647, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0647, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0647, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0648, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0648, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0647)

============================================================
📊 Round 29 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0078
   Val:   Loss=0.0647, RMSE=0.2544, R²=-0.0085
============================================================


============================================================
🔄 Round 30 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 30 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0034
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0145
============================================================


============================================================
🔄 Round 31 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 31 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0002
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0537
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2571, R²: -0.0267

============================================================
🔄 Round 32 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 32 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0081
   Val:   Loss=0.0702, RMSE=0.2650, R²=-0.0078
============================================================


============================================================
🔄 Round 33 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 33 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0048
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0030
============================================================


============================================================
🔄 Round 35 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 35 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0016
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0188
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2569, R²: -0.0252

📊 Round 35 Test Metrics:
   Loss: 0.0878, RMSE: 0.2964, MAE: 0.2569, R²: -0.0247

📊 Round 35 Test Metrics:
   Loss: 0.0878, RMSE: 0.2964, MAE: 0.2568, R²: -0.0246

============================================================
🔄 Round 39 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 39 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0071
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0100
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2567, R²: -0.0236

============================================================
🔄 Round 41 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 41 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0015
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0493
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2566, R²: -0.0229

============================================================
🔄 Round 44 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 44 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0028
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0083
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2566, R²: -0.0229

============================================================
🔄 Round 48 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 48 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0026
   Val:   Loss=0.0686, RMSE=0.2620, R²=-0.0105
============================================================


============================================================
🔄 Round 49 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 49 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0048
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0046
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0876, RMSE: 0.2960, MAE: 0.2566, R²: -0.0222

============================================================
🔄 Round 51 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 51 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0023
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0065
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0876, RMSE: 0.2960, MAE: 0.2566, R²: -0.0221

📊 Round 51 Test Metrics:
   Loss: 0.0876, RMSE: 0.2960, MAE: 0.2565, R²: -0.0220

============================================================
🔄 Round 53 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 53 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0033
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0112
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0876, RMSE: 0.2960, MAE: 0.2566, R²: -0.0221

============================================================
🔄 Round 54 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 54 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0031
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0072
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0876, RMSE: 0.2960, MAE: 0.2566, R²: -0.0222

============================================================
🔄 Round 56 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 56 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0001
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0218
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0876, RMSE: 0.2960, MAE: 0.2565, R²: -0.0221

📊 Round 56 Test Metrics:
   Loss: 0.0876, RMSE: 0.2959, MAE: 0.2565, R²: -0.0217

============================================================
🔄 Round 62 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 62 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0052
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0033
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0876, RMSE: 0.2959, MAE: 0.2565, R²: -0.0215

============================================================
🔄 Round 64 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 64 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0008
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0122
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: -0.0210

============================================================
🔄 Round 68 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 68 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0043
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0028
============================================================


============================================================
🔄 Round 69 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 69 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0010
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0136
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: -0.0210

📊 Round 69 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: -0.0206

============================================================
🔄 Round 73 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 73 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0055
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0054
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2563, R²: -0.0202

============================================================
🔄 Round 77 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 77 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0021
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0076
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0874, RMSE: 0.2957, MAE: 0.2563, R²: -0.0198

📊 Round 77 Test Metrics:
   Loss: 0.0874, RMSE: 0.2957, MAE: 0.2563, R²: -0.0200

📊 Round 77 Test Metrics:
   Loss: 0.0874, RMSE: 0.2957, MAE: 0.2563, R²: -0.0199

📊 Round 77 Test Metrics:
   Loss: 0.0874, RMSE: 0.2957, MAE: 0.2563, R²: -0.0197

📊 Round 77 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2562, R²: -0.0196

============================================================
🔄 Round 85 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 85 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0019
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0089
============================================================


============================================================
🔄 Round 87 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 87 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0036
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0016
============================================================


============================================================
🔄 Round 89 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 89 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0045
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0117
============================================================


============================================================
🔄 Round 92 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 92 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0043
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0035
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2562, R²: -0.0191

📊 Round 92 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2562, R²: -0.0191

============================================================
🔄 Round 95 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 95 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0014
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0068
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2562, R²: -0.0189

📊 Round 95 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2562, R²: -0.0191

============================================================
🔄 Round 98 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 98 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0036
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0238
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2562, R²: -0.0189

============================================================
🔄 Round 100 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 100 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0014
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0059
============================================================


============================================================
🔄 Round 101 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 101 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0051
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0076
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2561, R²: -0.0187

============================================================
🔄 Round 102 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 102 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0030
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0010
============================================================


============================================================
🔄 Round 103 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 103 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0027
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0057
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2561, R²: -0.0185

============================================================
🔄 Round 104 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 104 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0011
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0164
============================================================


============================================================
🔄 Round 105 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 105 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0019
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0037
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2561, R²: -0.0185

============================================================
🔄 Round 108 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 108 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0044
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0006
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2561, R²: -0.0182

📊 Round 108 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2561, R²: -0.0181

📊 Round 108 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2560, R²: -0.0179

============================================================
🔄 Round 114 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 114 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0021
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0037
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2561, R²: -0.0181

============================================================
🔄 Round 115 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 115 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0017
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0134
============================================================


============================================================
🔄 Round 116 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 116 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0009
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0179
============================================================


============================================================
🔄 Round 117 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 117 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0038
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0384
============================================================


============================================================
🔄 Round 119 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 119 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0023
   Val:   Loss=0.0713, RMSE=0.2670, R²=-0.0178
============================================================


============================================================
🔄 Round 120 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 120 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0010
   Val:   Loss=0.0709, RMSE=0.2663, R²=-0.0079
============================================================


============================================================
🔄 Round 122 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 122 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0039
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0008
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2560, R²: -0.0178

============================================================
🔄 Round 123 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 123 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0008
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0095
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2560, R²: -0.0179

============================================================
🔄 Round 124 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 124 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0052
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0096
============================================================


============================================================
🔄 Round 125 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 125 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0027
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0005
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2560, R²: -0.0177

============================================================
🔄 Round 126 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 126 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0029
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0003
============================================================


============================================================
🔄 Round 127 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 127 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0032
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0023
============================================================


============================================================
🔄 Round 128 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 128 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0032
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0028
============================================================


============================================================
🔄 Round 129 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 129 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0034
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0032
============================================================


============================================================
🔄 Round 131 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 131 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0032
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0069
============================================================


============================================================
🔄 Round 133 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 133 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0039
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0015
============================================================


============================================================
🔄 Round 134 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 134 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0037
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0174
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2560, R²: -0.0174

============================================================
🔄 Round 135 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 135 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0018
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0157
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2560, R²: -0.0173

============================================================
🔄 Round 136 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 136 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0019
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0248
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2560, R²: -0.0172

============================================================
🔄 Round 138 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 138 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0020
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0026
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2559, R²: -0.0171

============================================================
🔄 Round 140 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 140 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0025
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0116
============================================================


============================================================
🔄 Round 141 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 141 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0009
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0199
============================================================


============================================================
🔄 Round 143 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 143 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0026
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0004
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2560, R²: -0.0174

📊 Round 143 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2560, R²: -0.0174

============================================================
🔄 Round 148 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 148 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0028
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0135
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2560, R²: -0.0176

============================================================
🔄 Round 149 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 149 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=-0.0017
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0113
============================================================


============================================================
🔄 Round 151 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 151 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0037
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0183
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2560, R²: -0.0176

📊 Round 151 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2560, R²: -0.0176

============================================================
🔄 Round 161 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 161 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0044
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0085
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2559, R²: -0.0172

📊 Round 161 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2559, R²: -0.0173

📊 Round 161 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2559, R²: -0.0171

📊 Round 161 Test Metrics:
   Loss: 0.0872, RMSE: 0.2952, MAE: 0.2559, R²: -0.0168

============================================================
🔄 Round 171 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 171 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=-0.0059
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0193
============================================================


============================================================
🔄 Round 172 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 172 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0037
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0014
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2559, R²: -0.0165

📊 Round 172 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2559, R²: -0.0166

============================================================
🔄 Round 178 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 178 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0022
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0060
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2559, R²: -0.0165

============================================================
🔄 Round 179 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 179 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0026
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0011
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2559, R²: -0.0166

============================================================
🔄 Round 182 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 182 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0028
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0275
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2559, R²: -0.0166

============================================================
🔄 Round 184 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 184 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0043
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0042
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2559, R²: -0.0165

============================================================
🔄 Round 185 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 185 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0025
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0006
============================================================


============================================================
🔄 Round 186 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 186 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0020
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0051
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2559, R²: -0.0167

============================================================
🔄 Round 189 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 189 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=-0.0026
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0068
============================================================


============================================================
🔄 Round 190 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 190 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0021
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0196
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2559, R²: -0.0165

============================================================
🔄 Round 191 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 191 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0026
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0110
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2558, R²: -0.0165

============================================================
🔄 Round 192 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 192 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0024
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0002
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2558, R²: -0.0164

============================================================
🔄 Round 199 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 199 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0054
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0058
============================================================


============================================================
🔄 Round 200 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 200 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0030
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0014
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2558, R²: -0.0163

📊 Round 200 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2558, R²: -0.0163

📊 Round 200 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2558, R²: -0.0162

============================================================
🔄 Round 204 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 204 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0031
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0019
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2558, R²: -0.0164

📊 Round 204 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2558, R²: -0.0163

============================================================
🔄 Round 206 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 206 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0007
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0203
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2558, R²: -0.0162

📊 Round 206 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2558, R²: -0.0163

❌ Client client_46 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
