[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2c8f14f-fbd4-4ce8-9fa6-27434ba01244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 841a82c1-8e52-469d-9323-3fcbac650c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a37ec8a6-57aa-4cbe-a489-512ddea3fa9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 196bdf1b-56bb-47a8-8272-53a4123b3aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeb03ac5-47a3-43ef-9c1b-98e98d69e18a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b251149e-bf25-4a9e-89c0-66e2edf3fd37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcd3c21f-8979-4c7a-9902-1be61a733536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38bb007e-0a87-4742-b6f5-a45609483a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c3c2602-1b22-4d45-8c95-c89d456737fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c134fed6-b298-430c-aa95-e85b647f5b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fd03d08-5a40-4624-aba7-c5e9f8b72a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 919506b4-14be-4f3c-a35a-15739fd41fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd6ab676-b0a6-4c29-b489-2573f317061d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc19488a-09bc-4c71-bd74-b5856f9ea220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f05063cf-b607-498b-a1d7-7058b850636c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d855110-7ccc-4591-9077-cdd9d6bb293b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd783b20-1873-4b57-b319-3f9d17004efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa1f1c03-e6d2-43f0-bfa7-f023a74d00b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b72d455-c72a-4737-8fb2-0d2657a42b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d05e6cdc-ad1f-47a0-a6c5-1290957a3d53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1da55c05-26fd-477e-a8b8-c4a37ff41305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e24c3638-fa30-487e-8c64-4da5f556ccf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4942a01-8079-40eb-8325-ef2a10842fe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87dff7a0-231d-444f-8388-bab9f9bf5a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9ca0ff3-67ad-462d-82f7-588c17afc15d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de6b5c64-1ef8-4221-a049-8f024bc81aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f02c084d-6968-44f7-b86d-cef3de4d5004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5e5c7c7-66bf-497c-9847-522a1a4477b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c733a633-c9c1-4152-bad4-de156beb67df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb75cf39-44ad-495e-8551-c7582f036aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a21e59f-04e8-4899-9e42-15f1367f0e4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c9b0616-a342-4830-8a64-ad56f777a624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a10ab4c-837c-484a-887f-c17fbb9b715f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23daf452-7af3-447c-928b-ae71e968f77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cce42ed5-bb2b-4872-8ad5-3cdaf8eab246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0707c0b5-392d-4bd9-9e2e-ebcb638626cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19dae3e4-0d7b-4a8d-b9bc-776be0c04de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4f9caf6-7970-4971-a5b4-4491b9374984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f16ad6e6-10d5-4887-9d87-1dbedd74b22e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91bc5c95-49e7-47ca-96c6-a5bccf8ce803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd08f247-5327-4601-ac73-6c4a9354bbb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96705839-f600-425f-912a-6ad580608b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ac59e28-d9f2-44cc-89d6-03d1018b7ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7faaba0-7517-448d-922c-a36a2166bdd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a079a0d6-d8a4-4890-8da1-7579c2ffb583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 318cfb7a-841d-4328-b82c-7abd0b8efc22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7034188c-1c6a-439c-8077-86350802225f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d79d1f2-b8f0-4aa7-8411-9a1b98a72d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba71d6a0-2b81-4f41-8186-adcf0abdf71f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 245a45c2-1610-4ecb-8eec-ba68e19bbce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ce21ad0-ad71-4968-898d-c742c3af6b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d299bbca-23f7-47a4-8b80-5bc8ad3fd3fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5659c0f-87f1-47b8-ba48-dd1b2af6e798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 815e6768-562b-4bb7-9299-05e4f0dc0f5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a06060e3-d54d-4551-ad4b-a11cb2e3e810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81e0dcfd-166a-42e6-9b74-34e5caa26c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d225a808-810a-42a7-a800-1e7a133d2121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14465d24-a014-4746-8f0f-b2f94256c7b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1922249b-66ac-4351-b197-0bc761836c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154c3fb6-1e27-485a-86ca-bcf5d05c22ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8fba889-f2f2-4eae-bea2-c58e6c021b47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bddec911-c8d7-453b-b753-b56ec8087ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80d647f0-dedb-421c-bc7b-8e00833d5c7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5a11b4e-f517-437c-ad16-6591ab1b5158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 632cb5df-8ae0-499d-b750-ac65b9c0a580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f8223c2-dab5-4120-a999-0edf3b259769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c11e1b29-cec8-4d65-b7e3-fb04b037e9ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8998dea7-0c21-40fb-ace6-f7b36c184fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c42e409b-16ab-4ce6-903f-549f62630db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 874132eb-baf2-482b-a5c4-9bed320dd058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1f0e4fc-a428-454d-a30e-a7d0a4044781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09da843c-2ae6-4a4d-9a4c-1cde5ef9f0b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd059bd2-6eef-48bd-9483-1d502d703f70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c263e6e4-6fe3-411f-a809-8721ee58b21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d30ed57-8e51-442d-834b-97e98a3c3785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85ff1850-c1c4-46c5-a4dc-3ca525fa5083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2c3f7b1-1bd6-441f-8f42-745402abe857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4cdfde5-0124-4cc8-b062-4e09b1ff00e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8824d607-600b-44e8-8390-e029637e78fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 516da917-3e22-4607-9de2-62529beae6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0db7ed7d-3a6c-4883-bba3-f572e23e7f09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 505c9ff3-c5ad-459f-ad00-802cbf162394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1f98e2d-a918-4e1e-9bdc-4d737fe0c8e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39ab61d9-f81b-441f-a5fa-18436e4af95f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbd1cd67-ce5a-4512-a6b8-f1cd3761d74e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45ee2384-bb34-4cef-9533-fea301b1aede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21e356b1-4cd8-4c28-9890-4f5a9b2c0d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23024254-bd6c-4533-a73d-8bc4096fd7b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7beb108-5c57-4e87-8a5a-af461b0000de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f96e80c-faa9-48f0-86c2-31e9227687e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1337dcc-e40b-47e9-84db-9401992a5524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60dbe060-aa2a-4c56-9dd7-da60ab43ee66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c943f7b-796a-4113-b016-fd10656ccf98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 552721bd-7c20-4784-9e78-7463e3d2fb7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 815dc06a-a6d3-4a79-81b0-ecec2d41c6de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d59647-c857-4dae-8260-0cc3b4d7e46b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 801f923b-1969-47f1-8713-86595db370f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3cd83e0-616f-4c1f-9599-dc570eb21f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f15f93cb-4939-4f30-96bd-6069aea2ccdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8492c55-c7df-4c3f-9c26-7f502272c23b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 568cea41-c8cb-4c45-87fe-0b4f7a050c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f0b23dc-0e92-4b43-a592-723a71c75a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6a36a8d-d722-433c-a974-33b803ba951c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f043a51d-68b0-43bf-a4c6-b4eecac6e16d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c860ca1c-b128-4af4-a5cc-a68ae9d2c104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49001c6f-1043-4e8d-99ec-0302d98a57af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c78d7f8-e92d-4059-915e-a6d442fbd04a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 701448f3-609a-4649-b162-6547113de692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87931d83-da06-4353-b73b-fc3e744f64e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ef4dd77-6422-497a-aaef-9194b79d44cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88243157-e77b-46db-ae97-90e5e45b5a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f461614-53ff-4f10-a30e-544a06ec1b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c37ffb6-e77a-4b78-bf5e-a4266ce0bb89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50f26ade-f366-47a5-85eb-2ce41c4dbed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4d6f456-46b3-4bf5-8bc7-cde6fb25d0c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 869e82c6-b773-4802-ac4e-0418ca7b50a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9869603c-2e22-47d7-b82f-c4ece4683888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4902b2a-e0be-438d-bcb8-9cd9e9f5e9f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 040be36d-d106-43e8-b6a5-bdcf0938052a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a957b0c-7a59-4a95-918d-280690a763f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8877c103-fa46-47d6-b3d5-0fc17041dcbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f01172b-4c92-488e-afcd-5606ef9bd685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da310b61-c627-4d1e-b7ff-e0f8c117caf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b299704f-e4bf-4bb6-b99e-8bea9191083d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9430120-0867-41b3-ab12-3dbda2655231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cda0ae9-3f9d-48fe-9249-7cc9ca9c4b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7c34f6d-41ff-4abb-b72e-b0fad8ebf93a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de5538e8-6181-4231-a306-178da48f6d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5222a5b8-df68-4e55-8784-cb0f4e8bfad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b29a13e0-7684-4639-bd04-caedd942dea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d62fdbe6-1603-49fe-acbb-401bec89e371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40d6b664-4ebf-44ca-81d7-51cf7b9f429e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03574ab4-900b-43bd-af7c-0253bf100bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cb8b807-4ca2-4934-a112-f3d680a3db57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3712b45-4918-4495-9d49-aede0130889a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1b9a3f2-9679-403e-a6c7-cc356562930e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6a6f936-8781-479c-b17f-1581b55511d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d469d5cc-75ea-434c-b4d7-ba5d39057c20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 981fd60a-71f3-4da5-9343-32690a8deee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88c53d38-fdd7-4d20-89a5-cc2de1a97e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5965488e-5107-489a-8aef-6e004285da31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33b0e149-1369-4fa2-abb0-927b26aa95eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11435139-0421-41a7-af22-484c05045f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c253f4cf-ff44-4f95-a1d7-04ffc81ac0eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3edefa7-6da4-4baa-8974-b455c8c47d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c4c801f-0eef-4794-be92-ecd2c36d4459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05336af0-0bab-4548-a1ed-b8a4450e27c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 693e0be5-2470-4d1b-b547-cc05ff53e265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f401764f-2ea2-4c86-a0fa-3ef200795857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c62a0c2-c321-4df2-8c4d-c803c975546a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 006ae125-8a39-4360-8ebc-4137ab3c71b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57ddcea1-aac3-4972-9829-b9498b6b9eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9219efc-0a0b-47bc-9316-2b84a66bd524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41a4b05a-02d5-41df-b5b7-c5eefdcd9da6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dcb43b2-9dfb-4db7-8029-bb522e118e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 331137c3-38d3-4f09-b208-890de8ac3cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 252e1966-87db-478d-b6fb-47d042a7628b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38d0c390-698a-4e98-8386-81b1c5802bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 224a39d2-f6b9-4951-81ea-9399aaaa788a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e6c16ab-2063-4ef6-b0db-bfbe2b2fb3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d6db5c5-4c8d-4ff3-9f38-f907948e85c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a59beec-fb8b-406d-b557-b6beeacc6565
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_47
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/test_labels.txt

📊 Raw data loaded:
   Train: X=(1674, 24), y=(1674,)
   Test:  X=(419, 24), y=(419,)

⚠️  Limiting training data: 1674 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  410 samples, 5 features
✅ Client client_47 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 7 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1154, val=0.0695 (↓), lr=0.001000
   • Epoch   2/100: train=0.0861, val=0.0691, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0834, val=0.0697, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0834, val=0.0692, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0833, val=0.0692, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0823, val=0.0689, patience=3/15, lr=0.001000
   📉 Epoch 18: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0781, val=0.0701, patience=13/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 7 Summary - Client client_47
   Epochs: 23/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0113
   Val:   Loss=0.0690, RMSE=0.2627, R²=0.0068
============================================================


============================================================
🔄 Round 8 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1313, val=0.1070 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0807, val=0.0872 (↓), lr=0.000500
   📉 Epoch 3: LR reduced 0.000500 → 0.000250
   • Epoch   3/100: train=0.0790, val=0.0898, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0785, val=0.0884, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0785, val=0.0888, patience=3/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0783, val=0.0887, patience=9/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 8 Summary - Client client_47
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0013
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0393
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1529, RMSE: 0.3910, MAE: 0.3189, R²: -0.8503

📊 Round 8 Test Metrics:
   Loss: 0.1489, RMSE: 0.3859, MAE: 0.3149, R²: -0.8021

📊 Round 8 Test Metrics:
   Loss: 0.1293, RMSE: 0.3596, MAE: 0.2955, R²: -0.5647

📊 Round 8 Test Metrics:
   Loss: 0.1248, RMSE: 0.3532, MAE: 0.2912, R²: -0.5102

📊 Round 8 Test Metrics:
   Loss: 0.1211, RMSE: 0.3479, MAE: 0.2875, R²: -0.4653

============================================================
🔄 Round 17 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1164, val=0.1096 (↓), lr=0.000125
   📉 Epoch 2: LR reduced 0.000125 → 0.000063
   ✓ Epoch   2/100: train=0.0878, val=0.0838 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0801, val=0.0826 (↓), lr=0.000063
   • Epoch   4/100: train=0.0799, val=0.0829, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0798, val=0.0831, patience=2/15, lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0795, val=0.0833, patience=8/15, lr=0.000031
   📉 Epoch 18: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 17 Summary - Client client_47
   Epochs: 18/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0040
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0056
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1078, RMSE: 0.3283, MAE: 0.2740, R²: -0.3047

============================================================
🔄 Round 19 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0999, val=0.1081 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0961, val=0.1033 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.0922, val=0.0990 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.0889, val=0.0954 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.0863, val=0.0924 (↓), lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.0806, val=0.0857 (↓), lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0799, val=0.0843, patience=5/15, lr=0.000004
   📉 Epoch 24: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0798, val=0.0841, patience=1/15, lr=0.000002
   📉 Epoch 32: LR reduced 0.000002 → 0.000001
   • Epoch  41/100: train=0.0798, val=0.0840, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 19 Summary - Client client_47
   Epochs: 45/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0017
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0116
============================================================


============================================================
🔄 Round 21 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0829, patience=5/15, lr=0.000001
   • Epoch  21/100: train=0.0835, val=0.0821, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0829, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0824, val=0.0809, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0820, val=0.0805, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0817, val=0.0802, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 21 Summary - Client client_47
   Epochs: 63/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0180
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0148
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2479, R²: -0.0083

============================================================
🔄 Round 22 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0823, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.0825, val=0.0816, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0821, val=0.0811, patience=6/15, lr=0.000001
   • Epoch  41/100: train=0.0819, val=0.0807, patience=5/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0816, val=0.0804 (↓), lr=0.000001
   • Epoch  61/100: train=0.0815, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 22 Summary - Client client_47
   Epochs: 66/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0102
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0186
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2476, R²: -0.0045

📊 Round 22 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2474, R²: -0.0027

============================================================
🔄 Round 25 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0768, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0824, val=0.0764, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 25 Summary - Client client_47
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0139
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0143
============================================================


============================================================
🔄 Round 29 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0967, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0775, val=0.0964, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 29 Summary - Client client_47
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=-0.0103
   Val:   Loss=0.0965, RMSE=0.3107, R²=-0.0143
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0017

============================================================
🔄 Round 33 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 33 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0165
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0091
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0016

📊 Round 33 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0016

============================================================
🔄 Round 35 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0803, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0813, val=0.0800, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 35 Summary - Client client_47
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0063
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0278
============================================================


============================================================
🔄 Round 36 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0768, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0822, val=0.0765, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0821, val=0.0763, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 36 Summary - Client client_47
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0073
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0279
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

============================================================
🔄 Round 39 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 39 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0161
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0020
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

📊 Round 39 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

📊 Round 39 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

============================================================
🔄 Round 46 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 46 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0137
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0067
============================================================


============================================================
🔄 Round 47 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 47 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0090
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0222
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

📊 Round 47 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

📊 Round 47 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

📊 Round 47 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

📊 Round 47 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

📊 Round 47 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

============================================================
🔄 Round 53 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 53 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0137
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0010
============================================================


============================================================
🔄 Round 55 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 55 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0147
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0030
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

📊 Round 55 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

============================================================
🔄 Round 59 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 59 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0120
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0084
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

📊 Round 59 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

📊 Round 59 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

📊 Round 59 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

📊 Round 59 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2473, R²: -0.0015

============================================================
🔄 Round 66 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 66 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0047
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0405
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0016

============================================================
🔄 Round 69 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 69 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0139
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0021
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0016

============================================================
🔄 Round 71 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 71 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0105
   Val:   Loss=0.0730, RMSE=0.2703, R²=-0.0069
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0016

============================================================
🔄 Round 74 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 74 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0107
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0054
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0016

📊 Round 74 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0016

============================================================
🔄 Round 78 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 78 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0067
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0216
============================================================


============================================================
🔄 Round 79 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 79 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0098
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0071
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0016

📊 Round 79 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0016

============================================================
🔄 Round 81 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 81 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0121
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0058
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0016

============================================================
🔄 Round 82 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 82 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0067
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0241
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0016

============================================================
🔄 Round 86 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 86 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0082
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0137
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0016

============================================================
🔄 Round 88 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 88 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0101
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0049
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0016

============================================================
🔄 Round 90 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 90 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0093
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0081
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0017

============================================================
🔄 Round 92 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 92 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0049
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0359
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0017

============================================================
🔄 Round 94 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 94 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0083
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0107
============================================================


============================================================
🔄 Round 98 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 98 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0074
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0142
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0017

📊 Round 98 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0017

============================================================
🔄 Round 100 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 100 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0150
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0024
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0017

============================================================
🔄 Round 101 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 101 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0100
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0025
============================================================


============================================================
🔄 Round 102 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 102 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0102
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0050
============================================================


============================================================
🔄 Round 104 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 104 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0102
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0025
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0017

📊 Round 104 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0018

📊 Round 104 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0018

📊 Round 104 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0018

📊 Round 104 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2473, R²: -0.0018

============================================================
🔄 Round 112 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 112 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0092
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0075
============================================================


============================================================
🔄 Round 113 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 113 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0115
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.0050
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 114 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 114 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0101
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0049
============================================================


============================================================
🔄 Round 115 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 115 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0067
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0179
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0017

📊 Round 115 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 117 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 117 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0056
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0200
============================================================


============================================================
🔄 Round 120 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 120 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0097
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0028
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

📊 Round 120 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 124 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0971, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 124 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=-0.0059
   Val:   Loss=0.0972, RMSE=0.3118, R²=-0.0166
============================================================


============================================================
🔄 Round 129 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 129 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0047
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0200
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 132 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 132 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0081
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0060
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

📊 Round 132 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 135 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 135 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0090
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0031
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 137 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 137 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0093
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0011
============================================================


============================================================
🔄 Round 138 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 138 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0069
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0106
============================================================


============================================================
🔄 Round 140 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 140 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0031
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0467
============================================================


============================================================
🔄 Round 141 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 141 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0086
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0027
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

📊 Round 141 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 146 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 146 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0131
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0044
============================================================


============================================================
🔄 Round 147 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 147 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0079
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0062
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0017

📊 Round 147 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0017

📊 Round 147 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0017

============================================================
🔄 Round 154 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 154 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0060
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0140
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0017

============================================================
🔄 Round 156 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 156 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0090
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0074
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0017

📊 Round 156 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0017

📊 Round 156 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0017

============================================================
🔄 Round 160 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 160 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0122
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0013
============================================================


============================================================
🔄 Round 163 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 163 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0090
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0008
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0017

============================================================
🔄 Round 165 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 165 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0141
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0074
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

📊 Round 165 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

📊 Round 165 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 168 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 168 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0065
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0102
============================================================


============================================================
🔄 Round 171 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 171 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0132
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0008
============================================================


============================================================
🔄 Round 172 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 172 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0090
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0036
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0019

📊 Round 172 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0019

============================================================
🔄 Round 177 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 177 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0079
   Val:   Loss=0.0742, RMSE=0.2723, R²=-0.0035
============================================================


============================================================
🔄 Round 178 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 178 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0055
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0187
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 180 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 180 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0057
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0171
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 184 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 184 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0090
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0034
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

📊 Round 184 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0017

============================================================
🔄 Round 188 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 188 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0082
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0033
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 189 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 189 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0020
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0552
============================================================


============================================================
🔄 Round 190 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 190 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0089
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0021
============================================================


============================================================
🔄 Round 192 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 192 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0066
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0101
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 195 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 195 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=-0.0052
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0126
============================================================


============================================================
🔄 Round 198 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 198 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0078
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0068
============================================================


============================================================
🔄 Round 201 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 201 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0103
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0001
============================================================


============================================================
🔄 Round 202 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 202 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0027
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0341
============================================================


============================================================
🔄 Round 203 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 203 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0140
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0087
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 204 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 204 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0020
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0570
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 205 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 205 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0058
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0111
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 207 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 207 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0040
   Val:   Loss=0.0682, RMSE=0.2611, R²=-0.0266
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0018

============================================================
🔄 Round 208 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 208 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0072
   Val:   Loss=0.0687, RMSE=0.2621, R²=-0.0048
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2472, R²: -0.0017

============================================================
🔄 Round 209 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 209 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0095
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0018
============================================================


❌ Client client_47 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
