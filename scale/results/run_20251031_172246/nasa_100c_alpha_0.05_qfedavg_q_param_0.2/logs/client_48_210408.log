[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a3ef50-e76e-4cc5-93b4-54b8dc0d60c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08c309df-c9ec-4184-8577-ad74587bf65b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc3e5d02-83e4-42a5-8fb7-ba04b575fb61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4be1c0b5-6f33-414b-9b6e-895730c51556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd106c25-9439-48d5-95cd-704e2f92aab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d40c0a07-9a33-4888-bc03-0359343a8058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 897b831b-c817-4a4b-b872-120b52ed7ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 710e77c9-8f36-44c6-8b98-2cedccf35c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 204db32e-f6cb-42fa-a90d-615a4b0e6da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfebbb5b-6dfd-4a2d-85dd-2eb87f84e02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b1d2934-23dd-40dc-89e5-f2c0464e3b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef60126c-8c1e-4993-a53a-3997cf638ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36bb8e46-9b81-4739-ac37-09ec21afd084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b5951ac-fd8c-4564-936a-1163d03f633c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dcd2d87-258d-4f14-b746-b5f5807823eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03631b8e-4648-47f8-b53b-bb041e813925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fc4c688-5d78-423b-af6a-d8cde919c230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3892105-40a0-4cfc-a3ff-db99da7a34e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1832b87f-56af-4218-9dbf-c45da3f1584b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb0b4791-5d39-471a-a17a-7302f16db972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 931c66c2-3f2a-4ac6-8154-f610d959fd09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25496cba-8024-487a-a06a-52846741ea4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84b00a6c-2fe4-47b3-ae68-5cc088928165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cc5aa03-db11-4bcb-b880-8cf12f54ab4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f43032-3134-4f2b-8523-02678e10beb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f89ea75c-59ec-4cfd-aa88-26c142c8e9e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5e73ce1-9db1-4882-b7e3-730cb1ba0f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 867b1ad5-62b0-4f9e-b03a-0a6e71afc0c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 993092cd-dea1-4f72-b9ea-214ea4226edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e43e6a80-32b5-48a5-9900-49d205663a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9320f324-4988-4902-87f2-5d7667d6047e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de1af7b1-e91a-4d8f-ab0d-340813841fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa65fe98-3602-4499-9571-7cc1e6a9c808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a6766b8-6462-4710-ba83-4b1491b7612a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f9e269a-97b7-4859-9cf9-003f0114b1ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cdf20b7-cebe-428e-8f4b-d91eba7e841f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49fbbf86-197f-4c9b-9ac1-b647cd6dbfe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 841174ba-d6d8-4b32-8180-e69d52745e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bec8c44e-93b2-4990-afb6-3aa3ed02a009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90a17457-50fc-4d67-a1ec-a473163a9413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e616e6a-4f50-4309-8791-ca0dac2a6a95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28b60f0e-106c-4254-8eea-aacc2d31dd6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92f1c422-986e-4cfe-8168-cc3534a360f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f849896-68d7-41ca-86b2-5ba8698c0f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcdccac7-7185-4f19-bb60-46db9f3b7a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9dd4fa8-b5b6-4dde-ac5f-f3959de6638a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57cd484b-aab0-43ad-97cc-1434d2aded24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2083a262-29c1-45d6-b7be-34ddee564106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6fd8e3e-d35d-4bb3-8e17-01ac69f69ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc2ea101-7a12-4d47-a970-da5dd958623f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21bb7b88-545c-4c1f-9d62-44c407a9f973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 672e1a74-9df5-4315-96e7-f236fbed2bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fe6d423-f088-46c1-b4b9-567a448e2aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 986d3c9e-7d61-4ebe-8f15-fec21d304d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5980baa-1bfd-4f3b-9586-a1686761d002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8934405-a3ca-4311-986a-5d22c688fc41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 056c4076-99ec-4c8c-810d-6805679fec04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 956108cb-cc9f-444f-a321-618c7fb34a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0171a46a-658a-449f-925a-ee5538f1bc32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e0b5156-33bc-4e2a-9354-5da57e7ce61c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adabbf32-3567-43db-98e5-80017f2cd816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97a174a4-5392-4008-8974-694cc06ec229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ac40717-c3cd-4d40-83ab-e41aacce99d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b1bd210-5da6-486f-b8a6-09af28694598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa0ac6cb-5a4c-4e6a-ab81-fbea27437b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 651eb82f-2ca7-418c-aca7-e5650592eac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ea0c2e3-423a-423d-b0af-f735a9742ff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d12a969d-9b0f-462b-bd08-8261f790e396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e101cf5-ee9a-4a73-b6f9-bc32f785464c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b62dcc8-0a1a-4517-99c1-fe40e756cfed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cae67124-9e74-41fe-bc50-bc984e4b96d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c863cbec-3aef-4050-999d-bb2910a3c47d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0407202-493b-4e7f-afec-e9fad010cb07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83c16739-1b73-41c2-88a9-41673e551c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0215c67-cb08-404c-863c-7a760273a82b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff46b95e-eafa-4c3e-90c8-438133b97194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c10165b-fdfb-41fc-9da1-74e6b8daf2f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5247c79d-272d-40e8-b031-c137e9a2179d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a339e34b-dde2-4064-93ef-7c55c4210d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87a5b7ba-e99d-4bf6-a516-8b420da63209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43248597-da17-49eb-ae23-0a78ff691589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd23792e-ac68-4a3a-bd61-10e4b0bb3a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fb31e31-3c9a-4f8c-b6d3-263f7438aa44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64f98b80-dff2-4b58-b501-0e090118c76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ef4d8b5-fa71-47f7-a001-d6087a19eff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48e56696-d3d4-47dd-85fb-54640c32be31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18f23bf4-78bb-4890-acfa-b540c02b0f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb929b4b-0967-4094-ae40-390bea27bc64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f38b176-2983-412d-8da0-df18a90ba034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf884f9a-a7bf-4d3d-b0ea-51385cdd934c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccbdcd36-91a3-4aa3-a99e-e0c71e231aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7837685-effe-4497-a066-5511d1ed6317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e70bd8af-b371-410c-9107-1f9c492df58f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2045304-894c-42e9-8b04-471190ccab91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6728bc2c-1042-4e40-ab4f-36498e9b49c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 856a07f3-ca7b-4b6e-8a75-cdc7172df4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 540c2c14-f06e-40d9-936f-df6e547b99a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 616faa68-5c95-472f-961d-c44e232b66df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96c3a03a-31c6-49e6-b838-c0d1b5df6c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0911a4f0-b320-4fb4-a02d-ddea50e4d0d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e44c9cb5-aca7-4638-8499-13468a33f5cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7db18825-87f8-4cee-8f53-f38e5d1a057c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cd8817d-6a73-4f60-831e-7c53bc5bc618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c66d7f19-6e38-4177-8a51-aa0ed1ce2a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e72a63d-bca2-4761-b28e-09dd5a86e784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7231ab06-6441-4b70-a50c-2d7e04ce04a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97a76e51-cbf9-4bd2-b4ba-aeecdfd75b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ee2209c-237f-4333-b9f0-0fd68c5a87dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fb0115b-1829-492a-ac2b-bc900c4d04e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 095c265e-e924-4e43-98e2-de47ee1f1b4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7933a01-042c-4651-9f90-d4b2b07986bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce51a6d7-f3b1-4ce5-b6e1-d401490770b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e48ed1a7-b019-4983-8cbb-afe12e66cbaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2416d0a4-97a7-4c3b-8ac0-94f184ac39ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3ba479e-4f4f-4092-9116-54aad12d4a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f3ddd05-4ec7-455f-8d8f-21285c761060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24e047a3-04b0-45ab-a242-6876f7c52314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f55b054b-6e54-4eea-af67-f750819226ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f245bff-230c-4380-a4d9-ba9eaea11f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11b4b1d8-99db-4a9e-9f55-2ae415978fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99e56a04-8101-4daa-a973-a242121095c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d8eb4fb-a978-483b-924e-9e524536266f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fa35ab1-4586-45d5-ac53-42b7cd984cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 522462a4-58e7-45c4-94a6-4a94cf4eadcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77016e7d-8e67-44a1-8f35-695e06c8d2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 521f1260-815a-4b56-80e0-4d11109d6df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d72a6fc-d334-446d-8009-3981125f7db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91e49916-edf2-468a-8afc-e04201fca7bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30809a2e-fa65-4437-b3e5-ee882ce618c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e826ac4-95a5-493b-8096-9903c3b12849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2f3a312-d022-4f0a-8909-4164143996e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cb2363e-b743-44f5-8852-982fd5bb6dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb01640b-29ee-4a44-a9f1-a135d648cddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5f18f45-6a11-4554-a5e6-dcb35f102805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f47e117-13e2-4902-a217-b5e32acd2fea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7231c70c-f3be-4236-b389-ef083bdb209d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baa242c3-9f2b-497a-905a-055017f5290d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74cb2b58-30ca-40e5-af29-908c8bfec0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23321e94-5076-4878-a0f0-13e83210e8eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 994f624e-3cbf-4ad7-ad75-888e61c1f815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c800494-1242-47da-b034-fda6c70fddf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 127596de-e484-4f2a-b0d2-cef31f5472ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59b8d53e-458b-4321-ad4a-c59faa1f45e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d69c3b7e-0984-4f26-bf64-d97e3be4caf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f9ec6b1-e4e3-4f10-8558-4e2fad720f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8887c0b-6b54-4bd3-81b5-39a57a1e6ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53dd9f31-e539-4120-a7c9-437c6c6c204c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbdc23b5-864f-4236-8d44-a1c60793c33f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 085b4ac6-043d-4f4c-af00-d1ee05a27f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84fa005f-8027-4d15-bb43-7a3fb0c29908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c944d09-ea07-4b1e-a830-e1c0aaef72c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d1d2d49-8918-4b5a-9432-5db4401f5250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9861c4a6-2ed9-4810-a765-af30e313d58f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2aa1208-17a2-4d33-9a7e-4c122d312856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 865b55a8-a6bc-414f-9491-059e1e740d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcf28c81-f867-43eb-94b2-2c6a940e2150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87745d29-2820-414e-965e-045109a9f64c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bd7c817-3ace-4fee-9339-b60b490e2f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca74e8af-c451-491a-abb8-518af70f2e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b05e9e7-90de-4e31-81f5-b397f5f5343e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6008b439-14b7-46c3-bec5-88c736ea5945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40966d88-dba0-4699-aab0-834fda9537dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60f918b7-9d68-4cd0-9783-4618b03c157e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2761e42b-45df-475d-ae7e-2d2a208ed97b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29f5223c-a97e-4726-ac92-7f8b53b564cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e32d8d42-d76a-4a53-8b8f-a4d107c0f522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3241a940-f081-4410-8fc8-3f470d34537f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_48
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_48
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_48/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_48/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_48/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_48/test_labels.txt

📊 Raw data loaded:
   Train: X=(1068, 24), y=(1068,)
   Test:  X=(267, 24), y=(267,)

⚠️  Limiting training data: 1068 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  258 samples, 5 features
✅ Client client_48 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1126, val=0.0909 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0895, val=0.0828 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0889, val=0.0819 (↓), lr=0.001000
   • Epoch   4/100: train=0.0867, val=0.0823, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0867, val=0.0823, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0855, val=0.0823, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 6 Summary - Client client_48
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0053
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0025
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.1802, RMSE: 0.4245, MAE: 0.3435, R²: -1.1674

📊 Round 6 Test Metrics:
   Loss: 0.1630, RMSE: 0.4037, MAE: 0.3266, R²: -0.9601

📊 Round 6 Test Metrics:
   Loss: 0.1575, RMSE: 0.3969, MAE: 0.3214, R²: -0.8945

============================================================
🔄 Round 13 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1257, val=0.0964 (↓), lr=0.000250
   • Epoch   2/100: train=0.0867, val=0.0961, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0850, val=0.0917 (↓), lr=0.000250
   • Epoch   4/100: train=0.0845, val=0.0923, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0845, val=0.0919, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0842, val=0.0917, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 13 Summary - Client client_48
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0020
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0101
============================================================


============================================================
🔄 Round 15 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1327, val=0.1110 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1148, val=0.0970 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0998, val=0.0883 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0903, val=0.0853 (↓), lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   • Epoch   5/100: train=0.0865, val=0.0858, patience=1/15, lr=0.000031
   • Epoch  11/100: train=0.0856, val=0.0862, patience=7/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 15 Summary - Client client_48
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0210
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0065
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1362, RMSE: 0.3690, MAE: 0.3026, R²: -0.6378

============================================================
🔄 Round 16 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1227, val=0.1571 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.1184, val=0.1506 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1149, val=0.1475 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1127, val=0.1445 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1107, val=0.1417 (↓), lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1011, val=0.1284 (↓), lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0957, val=0.1201, patience=1/15, lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0937, val=0.1169, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0926, val=0.1149 (↓), lr=0.000001
   • Epoch  51/100: train=0.0915, val=0.1130, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0905, val=0.1112, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.0896, val=0.1095, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0888, val=0.1079, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0881, val=0.1064, patience=3/15, lr=0.000001

============================================================
📊 Round 16 Summary - Client client_48
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0411
   Val:   Loss=0.1051, RMSE=0.3242, R²=-0.1805
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1320, RMSE: 0.3633, MAE: 0.2988, R²: -0.5876

============================================================
🔄 Round 17 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1309, val=0.1137 (↓), lr=0.000001
   • Epoch   2/100: train=0.1306, val=0.1133, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1302, val=0.1131 (↓), lr=0.000001
   • Epoch   4/100: train=0.1299, val=0.1128, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1296, val=0.1125 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1279, val=0.1109 (↓), lr=0.000001
   • Epoch  21/100: train=0.1254, val=0.1086, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.1231, val=0.1064, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1210, val=0.1044 (↓), lr=0.000001
   • Epoch  51/100: train=0.1189, val=0.1026, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1170, val=0.1007, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1151, val=0.0990 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1133, val=0.0973 (↓), lr=0.000001
   • Epoch  91/100: train=0.1115, val=0.0957, patience=2/15, lr=0.000001

============================================================
📊 Round 17 Summary - Client client_48
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1094, RMSE=0.3308, R²=-0.2441
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.2365
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1168, RMSE: 0.3418, MAE: 0.2843, R²: -0.4052

============================================================
🔄 Round 19 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1037, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.1035, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1034, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1032, val=0.0938, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1030, val=0.0936 (↓), lr=0.000001
   • Epoch  11/100: train=0.1021, val=0.0929, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.1006, val=0.0917, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0992, val=0.0906, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0978, val=0.0895, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.0965, val=0.0886, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0953, val=0.0877, patience=5/15, lr=0.000001
   • Epoch  71/100: train=0.0942, val=0.0868, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0932, val=0.0861, patience=5/15, lr=0.000001
   • Epoch  91/100: train=0.0922, val=0.0855, patience=7/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_48
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3024, R²=-0.0595
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0284
============================================================


============================================================
🔄 Round 20 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0923, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0922, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0921, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0912, val=0.0943, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0902, val=0.0937, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0893, val=0.0932, patience=3/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0885, val=0.0929 (↓), lr=0.000001
   • Epoch  51/100: train=0.0877, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 20 Summary - Client client_48
   Epochs: 56/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0511
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.0165
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2547, R²: -0.0294

📊 Round 20 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2539, R²: -0.0210

============================================================
🔄 Round 23 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 23 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0109
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.0040
============================================================


============================================================
🔄 Round 24 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 24 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0084
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0058
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2533, R²: -0.0158

📊 Round 24 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2531, R²: -0.0143

📊 Round 24 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2529, R²: -0.0132

============================================================
🔄 Round 28 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 28 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0054
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0040
============================================================


============================================================
🔄 Round 29 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 29 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0040
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0177
============================================================


============================================================
🔄 Round 33 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 33 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0030
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0368
============================================================


============================================================
🔄 Round 34 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 34 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0039
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0079
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2525, R²: -0.0103

📊 Round 34 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2524, R²: -0.0097

============================================================
🔄 Round 40 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 40 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0052
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0012
============================================================


============================================================
🔄 Round 43 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 43 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0059
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0053
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2523, R²: -0.0088

============================================================
🔄 Round 46 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 46 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0048
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0014
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2523, R²: -0.0087

📊 Round 46 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2523, R²: -0.0086

📊 Round 46 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2523, R²: -0.0085

============================================================
🔄 Round 50 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 50 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0040
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0016
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2523, R²: -0.0084

📊 Round 50 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0083

📊 Round 50 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2523, R²: -0.0083

📊 Round 50 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2523, R²: -0.0084

============================================================
🔄 Round 55 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.1004 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.1004, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.1004, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.1005, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.1005, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.1005, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1004)

============================================================
📊 Round 55 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0055
   Val:   Loss=0.1004, RMSE=0.3169, R²=0.0014
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0083

📊 Round 55 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2523, R²: -0.0083

============================================================
🔄 Round 57 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 57 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0056
   Val:   Loss=0.0921, RMSE=0.3034, R²=0.0046
============================================================


============================================================
🔄 Round 58 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 58 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0043
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0001
============================================================


============================================================
🔄 Round 59 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 59 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0048
   Val:   Loss=0.0980, RMSE=0.3131, R²=-0.0018
============================================================


============================================================
🔄 Round 60 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 60 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0051
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.0171
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2522, R²: -0.0080

============================================================
🔄 Round 65 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 65 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0027
   Val:   Loss=0.0748, RMSE=0.2734, R²=-0.0085
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2522, R²: -0.0079

📊 Round 65 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2522, R²: -0.0078

📊 Round 65 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2522, R²: -0.0078

📊 Round 65 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2522, R²: -0.0078

📊 Round 65 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2522, R²: -0.0076

📊 Round 65 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2522, R²: -0.0075

============================================================
🔄 Round 72 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 72 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0021
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0397
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2521, R²: -0.0075

============================================================
🔄 Round 74 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 74 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0053
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0163
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2521, R²: -0.0071

============================================================
🔄 Round 78 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 78 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0035
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0035
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2521, R²: -0.0072

📊 Round 78 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2521, R²: -0.0071

============================================================
🔄 Round 80 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 80 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0037
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0058
============================================================


============================================================
🔄 Round 81 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 81 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0029
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0105
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2521, R²: -0.0071

============================================================
🔄 Round 84 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 84 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0030
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0065
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2521, R²: -0.0071

📊 Round 84 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2521, R²: -0.0070

📊 Round 84 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2521, R²: -0.0069

============================================================
🔄 Round 90 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 90 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0035
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0072
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2521, R²: -0.0069

📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0067

============================================================
🔄 Round 93 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 93 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0027
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0228
============================================================


============================================================
🔄 Round 95 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 95 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0045
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0018
============================================================


============================================================
🔄 Round 96 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 96 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0033
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0045
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2521, R²: -0.0068

============================================================
🔄 Round 98 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 98 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0032
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0150
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0067

============================================================
🔄 Round 101 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 101 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0013
   Val:   Loss=0.0917, RMSE=0.3027, R²=-0.0098
============================================================


============================================================
🔄 Round 103 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 103 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0020
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0063
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0064

============================================================
🔄 Round 105 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 105 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0037
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0004
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0064

📊 Round 105 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0063

============================================================
🔄 Round 108 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 108 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0030
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0021
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0062

============================================================
🔄 Round 112 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 112 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0033
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0124
============================================================


============================================================
🔄 Round 113 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 113 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0040
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0025
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2520, R²: -0.0062

============================================================
🔄 Round 114 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 114 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0029
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0033
============================================================


============================================================
🔄 Round 115 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 115 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0035
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0001
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0063

============================================================
🔄 Round 116 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 116 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0036
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0020
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0062

============================================================
🔄 Round 117 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 117 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0018
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0095
============================================================


============================================================
🔄 Round 119 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 119 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0017
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0066
============================================================


============================================================
🔄 Round 122 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 122 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0037
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0075
============================================================


============================================================
🔄 Round 123 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 123 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0030
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0148
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2520, R²: -0.0062

📊 Round 123 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2520, R²: -0.0062

============================================================
🔄 Round 126 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 126 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0032
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0029
============================================================


============================================================
🔄 Round 127 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 127 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0036
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0033
============================================================


============================================================
🔄 Round 128 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 128 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0035
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0014
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2519, R²: -0.0061

============================================================
🔄 Round 129 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 129 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0033
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0047
============================================================


============================================================
🔄 Round 130 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 130 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0039
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0055
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2519, R²: -0.0061

============================================================
🔄 Round 134 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 134 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0048
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0345
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0059

============================================================
🔄 Round 137 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 137 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0030
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0009
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0059

============================================================
🔄 Round 138 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 138 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0029
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0021
============================================================


============================================================
🔄 Round 140 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 140 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0028
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0020
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0058

📊 Round 140 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0059

============================================================
🔄 Round 144 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 144 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0019
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0054
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2519, R²: -0.0060

============================================================
🔄 Round 148 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 148 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0032
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0061
============================================================


============================================================
🔄 Round 149 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 149 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0032
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0115
============================================================


============================================================
🔄 Round 150 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 150 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0026
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0118
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2520, R²: -0.0061

============================================================
🔄 Round 151 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 151 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0024
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0039
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2520, R²: -0.0062

============================================================
🔄 Round 152 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 152 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0054
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0199
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2520, R²: -0.0061

============================================================
🔄 Round 156 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 156 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0014
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0084
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2520, R²: -0.0061

============================================================
🔄 Round 159 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 159 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0023
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0155
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0060

============================================================
🔄 Round 160 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 160 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0024
   Val:   Loss=0.0805, RMSE=0.2836, R²=-0.0045
============================================================


============================================================
🔄 Round 161 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 161 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0041
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0060
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0060

📊 Round 161 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2520, R²: -0.0061

============================================================
🔄 Round 166 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 166 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0019
   Val:   Loss=0.0890, RMSE=0.2982, R²=-0.0091
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0058

============================================================
🔄 Round 171 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 171 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0043
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0425
============================================================


============================================================
🔄 Round 172 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 172 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0026
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0033
============================================================


============================================================
🔄 Round 173 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 173 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0039
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0085
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0057

============================================================
🔄 Round 176 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 176 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0039
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0248
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0058

📊 Round 176 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0058

📊 Round 176 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0057

📊 Round 176 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0058

============================================================
🔄 Round 180 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 180 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0022
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0033
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0057

📊 Round 180 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0058

============================================================
🔄 Round 185 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 185 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0017
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0051
============================================================


============================================================
🔄 Round 188 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 188 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0037
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0028
============================================================


============================================================
🔄 Round 190 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 190 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0036
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0031
============================================================


============================================================
🔄 Round 191 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 191 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0037
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0037
============================================================


============================================================
🔄 Round 192 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 192 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0041
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0050
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0057

📊 Round 192 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0057

📊 Round 192 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0057

📊 Round 192 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0056

============================================================
🔄 Round 197 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 197 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0032
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0014
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0059

============================================================
🔄 Round 198 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 198 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0036
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0100
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0058

============================================================
🔄 Round 202 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 202 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0025
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0040
============================================================


============================================================
🔄 Round 203 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 203 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0013
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0065
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0057

============================================================
🔄 Round 204 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 204 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0022
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0064
============================================================


============================================================
🔄 Round 205 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 205 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0020
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0042
============================================================


============================================================
🔄 Round 207 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 207 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0046
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0167
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0058

============================================================
🔄 Round 210 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 210 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0036
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0194
============================================================


============================================================
🔄 Round 211 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 211 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0030
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0006
============================================================


❌ Client client_48 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
