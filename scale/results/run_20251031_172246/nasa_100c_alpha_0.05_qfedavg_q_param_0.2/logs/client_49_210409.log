[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf769daf-242a-4aef-b927-fa8d5d1b9cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 944b77c4-b216-458d-98a3-6f1a44899b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f54fb461-2d87-4ec8-a44f-3f054858685e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eae16ac1-be22-4758-99cc-947369824bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f5ee40a-75d7-4f08-b2de-68452120ec7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc345137-abb1-4706-afb2-2609817cf4b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0d1e068-2106-41eb-bea9-7d8ccc2dd19a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60d5ab2f-538e-4aea-a521-8b43e776dffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db79f5b3-180d-410d-9bc7-f7b7125cdfb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19b88767-b209-4710-beee-293eb280d007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71cf132b-5fa0-42b3-b25d-898204e2361b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ed5d82e-57aa-4310-8042-82c828b0a4d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35e5b4ed-ae4e-42d4-83e8-1809240c787f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 045c9ddb-b6f9-4651-a0e6-b78d56872200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b47d0d6-701b-4e00-9587-b058f6786169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa485d8c-2544-476f-96a2-e3b81b3390b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a17529c-12fc-4453-b5d0-dcbdd0bf699e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5667b1c-44f8-4b7f-b1c0-0dcb46e94ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2a03f98-798a-4739-bfa3-5b6cee859b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ff1656a-55e1-4a19-96cb-8def069e47f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08db5461-d30c-4c0f-b4de-ac8317ae19d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56581903-e96e-43a6-b394-307977dc018b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c1b8956-954f-48b7-bcdb-2b02be94927e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ec7dc34-f93a-437d-8097-89b74ec39e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b6a8b2d-0b8a-45c6-a1e9-2ab146aa66dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1ce8ade-cb27-4667-8444-e3d1d43c89d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 400cbd65-8e19-4e1b-b969-748bedddaf6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06672db0-68b0-4c53-918f-a0f2a04edda8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe80a8b0-5492-4503-b945-fc24923dd745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bd9889e-dec5-4bcb-908d-eeedb245a5bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76442015-47c9-4f13-99fa-ffc943b560b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b746d4f-2e75-451f-9e86-50e35e014f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 825be9ed-15e3-4d9c-87f4-bff510e385cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 615b55a9-4b00-427f-ae59-81597517924f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a22ee9a2-05e0-4ba5-a9a2-870409588e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf8f8763-c146-4ed7-b9c6-4cb560738d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 837e36c1-467e-48ae-899c-67c5316f62e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cd78ccc-b4fd-43d5-8f0c-a19bda3b654f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaae99d5-8a4e-4626-8431-055515641f46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0700a9b7-4de4-4d0b-b665-43895c907922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a78eeb8d-2f8e-470e-a558-e3ba1a45d8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80a89825-d8fd-4102-a276-4c5327b1c015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c620725-45cf-4135-96f5-d8bb6658db9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 447db9fa-bb5a-4139-8e3e-1ebae1771bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 642debac-3093-48c5-8da2-0f7f09eb4786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0848aeb-9725-4dbc-adf9-2bd4ab33e8fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9948b4b-3e7a-4477-9ae9-19c0b240ba1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a756d1b-c157-4db4-b032-30ff9be00fda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7210e5c-feeb-4350-933a-8bd30877bba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 016fb9fb-1e5b-4387-8d88-9fd50213461e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2090a49-9a89-4e00-abe0-4680c7bf6ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d83b99-2868-437e-b794-f007c1b14ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3e60fe5-4393-412b-bacc-306d099f6dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60271dc4-7717-4ae1-a1e4-e0dd69776a8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04acfabf-f3f0-433d-880d-ddfeccfce27e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ee85450-53d9-4ff3-a504-5f002b0ae4e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d11c41bc-334a-453e-a32f-e7a13445d938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 051df589-15af-405c-b6db-51c103b6364c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd15342f-85b0-4cc6-b02b-8d442525ac3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b30a076-d02f-4e92-91aa-e9fa8ed1db1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 826af83c-4139-45b0-a6cc-18c097d17df3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b7e3e5d-989a-4eb2-94a3-a3a85b232465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af3ef0a9-8943-4583-ba0b-3be865e0c24f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f4303dc-ef4c-451c-9327-5299c1250e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28aa984e-567a-42ea-9919-7ed4d0ade083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb8ac80-126f-47d5-813e-89627a85e9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c2012d1-35eb-4e82-9d25-63535aa846f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0455b622-3936-4758-9443-79a22a966631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f58d449-0a61-4cea-8bcd-bbb8abccfa31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cef7f96-6db2-4e3f-a5aa-deef64d4036d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7eec3ed-4031-431e-93ed-09637256880f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b92e235-6090-41ab-a0a1-f1fef8dc2925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9444e3b-e745-4e9f-a610-d7adfafdea6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e96a387-4eed-45ea-8924-a6b1c3d8a6fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eea25de-5a6e-4a9f-8848-bed5af713f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c5ab84a-d86e-4de5-8710-be040acb5b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 229b0f7e-ce91-40fd-8f09-1aac8507b3a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 926cb527-cce3-4e63-b0dc-c3e0f2d2b1bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38025850-19be-42c2-a949-257110e16a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbae9cbf-db94-4cd5-87a3-aa9ce7a7501c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1811c957-5ebe-48c8-b9cc-c5f69b20b304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41b56706-ae5d-49c4-b282-313aa7504117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4787a8a0-8fba-4630-b37a-71770cd0cfc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fca277b3-1b62-44b1-a69c-a806fc8c81e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bc904ca-ebb7-46ef-b65f-34868161a17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96a7e421-ba0d-4611-aa97-135f1e1b2e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f690f5d5-ed1b-426e-b68d-329719580865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd643820-52f5-4ede-a6eb-4aaf2ba8ce59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 390dd7f1-d7ce-459e-878a-80f3b677fe1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea82f579-cb90-4cbe-bb56-fcb1565cebf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b21721e-ab71-442b-a546-cd055dccb4d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0adc4216-ef55-4fc3-ab76-8c07908ac08f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca6b7389-df18-47f6-85e8-45fee93aba83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3e17c4c-0cae-43f0-9c31-7e3936b00b7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95e90edd-c692-43d3-a271-1a2ae45173aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90871eb5-9ca9-423d-af24-18ac10e87197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d20f554-5851-4c74-a274-b353f1a5688a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9949ceb-2a55-4f80-9f8a-2bec685082df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb0cfd38-47ef-4a57-bf97-19ee9599f0e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5a69e40-deb1-474f-bba9-4bfc0902e0b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94d3c59b-7956-4c16-9239-b1849eb17d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3345332a-fc94-472c-993a-ff4fe9b3ab37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4862baa-4dc5-49cd-bfe1-65d5209bd080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63ed5ba4-7d67-4cdd-84df-f5f4d81e8392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3daf0dc6-a3aa-4305-846c-acfe448f9aef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85b692e8-302a-431b-9773-cafc51da5eea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb9a42c-ab85-42db-891f-6cad96fb24a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bbb9c45-b177-44ec-a89f-2fe836d424dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06446ff5-72e5-4009-83b2-622b642a982c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2dcfcb1-5606-4832-8fbf-e77e7b5ceb66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb00eae2-307c-4cb7-8cdb-133df6aff9ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c3386a4-fcbe-4eb2-8810-da4a11bf3707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0c077b4-b557-42c5-b18d-0c393d14bb33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5374a2b4-fd2a-4f02-ada5-e9e50de9d987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1cd0462-83df-4405-83cc-3ae6442c958d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7653a8d-defd-4ca2-a7c7-b756403c82fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91110564-741c-4dfd-97ed-70ce96e50ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aea992f-8933-4f0f-8b7c-543fa8b8b2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34e3bc54-1796-4bdd-81d7-f04c7c387eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f7af8c1-cd43-4c09-a1e0-83c8316cf562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe874569-8875-433e-99fd-8498354480c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 690a1e21-9717-4d1d-8ec1-99aac717895f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d50e60a-0abf-46ef-83c4-cece9f72b6e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 049cba37-a2c0-4bd5-b21c-e587aa296002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68f29519-43a4-4e9a-8e56-495fe2ebda55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f16f11c-0c96-4bb0-aca9-cd3aa040be08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bb1dbf7-7425-43de-83e1-57f5584df86a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4245de5f-44a1-4ca8-9371-84f825be0cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb6e46e0-7f93-4cf7-a69d-47d692aa5139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7925982c-1dc6-4ff5-980a-7d7a15fa7d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ebacd0a-62b3-42b0-88fb-c086083d9e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db1e00ff-de11-41af-b594-043c33c32a54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eece4a80-f69f-4e4c-98d5-df60cb42287f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb35797-3609-4b95-a8a8-b23b5da92ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d13859f0-8d50-41a4-a62f-901c79eff865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7194b0c-6d3b-4a7c-9a42-646df7903f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90c24194-71bc-4825-9691-0187f4e71874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40726c46-bef8-4aea-80fc-802f86e0ecb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25fe7ba2-55ed-4319-9248-9598bcd52157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b13725a-9421-4adb-bff7-8f3cde7cd50c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f85f11-3c4e-4d7e-a129-754eb795579d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ffdb183-14bc-49eb-ae6b-47c3ad44af45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 419555b0-39e5-4db4-96ff-2b32b83f27be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7454940-cd7c-45de-9823-b1988d1f8660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a3bad30-afb0-46bd-abec-9fac5b7a9a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e4c477a-4d34-428a-aadb-404f2972782f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57c50c4e-9834-4161-9c19-74a2a3c30cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b24909bf-82b1-419a-90ee-85b5ed724bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2f5ded8-ddc4-4fe2-a2f5-5b09096a3564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62e1b344-e3c6-4def-8c19-a9c7c4275b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a231811e-4592-44d9-a313-f04c89edf440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 307d8c5e-01cd-4eb6-9a94-bd5e64f0d103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ff6b089-bfc8-43eb-98d0-f9473dbb3c9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f5d5e34-4d82-4e4d-b176-8ffc32b7ab47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d64e551f-2654-485a-b3b6-40d94ceb6051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d03e84b5-5cea-4ce7-ae19-cf27c089ab75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ed1903c-23d8-4ec3-b828-e58d57304395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 534b86eb-28cc-492e-9700-e7400f4d2be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 028cf916-ecf0-4116-abdd-8db6cf7ee299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73a0ee27-e481-41d1-a074-2902da4da200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bc3b24e-2950-4259-8a13-229c918ef629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e180c6b9-aa65-474f-b042-3523438d0ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c684927c-b119-4cb0-9d0f-474b17147658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb150348-b25c-46fc-a28a-643c7606c2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2daf8e2-d8d5-4f7f-aeb2-f1ff930959cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0033ea99-0984-481c-a8bf-1da1e155edd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95ef541f-5261-45b6-ac30-764acbe7656f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfa32d95-284a-41e5-9156-0e761dce615f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca01d14c-ee73-455e-8490-34933d68cae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cca09bee-3d4a-48d6-86f2-4534c433301f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4f24147-06f6-4474-b76c-51c42d2be964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc9a077-b737-40fd-9594-16ead89f5a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02c1e604-d1e5-4387-8620-fe3588129972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21acb156-511c-4f9f-9528-fb6b7fdf36ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f301a3b-f2c5-4631-9c9d-01722078155f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aac9a953-22a4-4dca-b18f-2ff328d5185e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 831238aa-dbbb-47fa-9a3d-d3f11a07610d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ca9f6f6-7f8c-49ab-95d3-7ba61a645cfa
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_49
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/test_labels.txt

📊 Raw data loaded:
   Train: X=(2404, 24), y=(2404,)
   Test:  X=(601, 24), y=(601,)

⚠️  Limiting training data: 2404 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  592 samples, 5 features
✅ Client client_49 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1198, val=0.0977 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0866, val=0.0916 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0836, val=0.0907 (↓), lr=0.001000
   • Epoch   4/100: train=0.0837, val=0.0916, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0835, val=0.0916, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0806, val=0.0929, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 6 Summary - Client client_49
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0105
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0099
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.1795, RMSE: 0.4237, MAE: 0.3491, R²: -1.2681

============================================================
🔄 Round 8 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1551, val=0.1193 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1011, val=0.0833 (↓), lr=0.000250
   • Epoch   3/100: train=0.0865, val=0.0833, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0855, val=0.0830, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0852, val=0.0831, patience=3/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0845, val=0.0835, patience=9/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 8 Summary - Client client_49
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0068
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0046
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1701, RMSE: 0.4124, MAE: 0.3392, R²: -1.1484

📊 Round 8 Test Metrics:
   Loss: 0.1662, RMSE: 0.4077, MAE: 0.3351, R²: -1.0995

📊 Round 8 Test Metrics:
   Loss: 0.1604, RMSE: 0.4005, MAE: 0.3290, R²: -1.0265

============================================================
🔄 Round 11 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.1543, val=0.1306 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1270, val=0.1147 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1103, val=0.1017 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0970, val=0.0928 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0883, val=0.0889 (↓), lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0836, val=0.0887, patience=6/15, lr=0.000031
   📉 Epoch 17: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 11 Summary - Client client_49
   Epochs: 20/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0249
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0082
============================================================


============================================================
🔄 Round 13 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1511, val=0.1649 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1457, val=0.1584 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1403, val=0.1523 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1354, val=0.1467 (↓), lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   ✓ Epoch   5/100: train=0.1308, val=0.1414 (↓), lr=0.000008
   ✓ Epoch  11/100: train=0.1178, val=0.1273 (↓), lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004
   📉 Epoch 21: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.1076, val=0.1152 (↓), lr=0.000002
   📉 Epoch 29: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.1043, val=0.1112, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1026, val=0.1091 (↓), lr=0.000001
   • Epoch  51/100: train=0.1011, val=0.1070, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0997, val=0.1051, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.0984, val=0.1033 (↓), lr=0.000001
   • Epoch  81/100: train=0.0971, val=0.1015, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0959, val=0.0998, patience=2/15, lr=0.000001

============================================================
📊 Round 13 Summary - Client client_49
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0949, RMSE=0.3080, R²=-0.1048
   Val:   Loss=0.0984, RMSE=0.3136, R²=-0.2444
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1348, RMSE: 0.3671, MAE: 0.3021, R²: -0.7028

============================================================
🔄 Round 15 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1388, val=0.1494 (↓), lr=0.000001
   • Epoch   2/100: train=0.1385, val=0.1491, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1382, val=0.1488 (↓), lr=0.000001
   • Epoch   4/100: train=0.1379, val=0.1485, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1377, val=0.1482 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1360, val=0.1467 (↓), lr=0.000001
   • Epoch  21/100: train=0.1335, val=0.1443, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.1312, val=0.1420, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1290, val=0.1398 (↓), lr=0.000001
   • Epoch  51/100: train=0.1268, val=0.1377, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1247, val=0.1357, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1226, val=0.1336 (↓), lr=0.000001
   • Epoch  81/100: train=0.1205, val=0.1316, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1184, val=0.1297, patience=2/15, lr=0.000001

============================================================
📊 Round 15 Summary - Client client_49
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1160, RMSE=0.3405, R²=-0.4118
   Val:   Loss=0.1279, RMSE=0.3577, R²=-0.3415
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1258, RMSE: 0.3546, MAE: 0.2929, R²: -0.5886

📊 Round 15 Test Metrics:
   Loss: 0.1110, RMSE: 0.3331, MAE: 0.2776, R²: -0.4019

============================================================
🔄 Round 18 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1149, val=0.1245 (↓), lr=0.000001
   • Epoch   2/100: train=0.1147, val=0.1243, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1145, val=0.1241, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1143, val=0.1239 (↓), lr=0.000001
   • Epoch   5/100: train=0.1141, val=0.1237, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1129, val=0.1225, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1110, val=0.1205, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1091, val=0.1186 (↓), lr=0.000001
   • Epoch  41/100: train=0.1073, val=0.1168, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1055, val=0.1149, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1038, val=0.1132 (↓), lr=0.000001
   • Epoch  71/100: train=0.1021, val=0.1114, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1005, val=0.1098, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0989, val=0.1081 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_49
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0974, RMSE=0.3120, R²=-0.1696
   Val:   Loss=0.1067, RMSE=0.3267, R²=-0.1737
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0883, RMSE: 0.2971, MAE: 0.2526, R²: -0.1154

📊 Round 18 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2459, R²: -0.0396

📊 Round 18 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2444, R²: -0.0231

============================================================
🔄 Round 22 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 22 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0308
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0144
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2437, R²: -0.0153

============================================================
🔄 Round 23 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 23 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0208
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0148
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2435, R²: -0.0126

📊 Round 23 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2431, R²: -0.0079

============================================================
🔄 Round 28 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 28 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0102
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0292
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2430, R²: -0.0073

============================================================
🔄 Round 32 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 32 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0092
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0188
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2428, R²: -0.0059

📊 Round 32 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2428, R²: -0.0057

============================================================
🔄 Round 35 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 35 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0092
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0218
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2427, R²: -0.0048

📊 Round 35 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2427, R²: -0.0047

📊 Round 35 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2427, R²: -0.0045

📊 Round 35 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: -0.0042

============================================================
🔄 Round 42 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 42 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0104
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0048
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2426, R²: -0.0039

📊 Round 42 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2426, R²: -0.0039

============================================================
🔄 Round 45 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 45 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0110
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0022
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2426, R²: -0.0039

============================================================
🔄 Round 49 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 49 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0109
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0037
============================================================


============================================================
🔄 Round 51 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0983, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0983, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0982, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0983)

============================================================
📊 Round 51 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0066
   Val:   Loss=0.0983, RMSE=0.3135, R²=-0.0164
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2426, R²: -0.0035

📊 Round 51 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2426, R²: -0.0034

============================================================
🔄 Round 53 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 53 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0068
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0228
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2426, R²: -0.0035

📊 Round 53 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2426, R²: -0.0035

📊 Round 53 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2426, R²: -0.0034

📊 Round 53 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2426, R²: -0.0035

============================================================
🔄 Round 57 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 57 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0070
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0164
============================================================


============================================================
🔄 Round 58 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 58 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0062
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0288
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2426, R²: -0.0034

============================================================
🔄 Round 59 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 59 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0086
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0093
============================================================


============================================================
🔄 Round 61 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 61 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0066
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0152
============================================================


============================================================
🔄 Round 62 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 62 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0060
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0285
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2425, R²: -0.0031

============================================================
🔄 Round 64 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 64 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0082
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0092
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2425, R²: -0.0031

============================================================
🔄 Round 65 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 65 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0077
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0120
============================================================


============================================================
🔄 Round 66 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 66 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0118
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0016
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2425, R²: -0.0029

============================================================
🔄 Round 67 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 67 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0085
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0071
============================================================


============================================================
🔄 Round 68 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 68 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0053
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0237
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2425, R²: -0.0030

============================================================
🔄 Round 70 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 70 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0177
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0192
============================================================


============================================================
🔄 Round 72 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 72 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0073
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0099
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0027

============================================================
🔄 Round 73 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 73 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0092
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0028
============================================================


============================================================
🔄 Round 75 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 75 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0086
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0042
============================================================


============================================================
🔄 Round 77 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 77 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0085
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0075
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2424, R²: -0.0023

📊 Round 77 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2425, R²: -0.0024

============================================================
🔄 Round 79 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 79 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0074
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0096
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2424, R²: -0.0023

============================================================
🔄 Round 81 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 81 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0057
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0183
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2424, R²: -0.0023

============================================================
🔄 Round 82 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 82 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0048
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0191
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2424, R²: -0.0023

============================================================
🔄 Round 84 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 84 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0117
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0132
============================================================


============================================================
🔄 Round 85 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 85 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0076
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0084
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2424, R²: -0.0023

============================================================
🔄 Round 88 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 88 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0078
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0079
============================================================


============================================================
🔄 Round 90 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 90 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0068
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0091
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2424, R²: -0.0021

============================================================
🔄 Round 91 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 91 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0084
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0018
============================================================


============================================================
🔄 Round 92 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 92 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0085
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0037
============================================================


============================================================
🔄 Round 95 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 95 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0089
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0010
============================================================


============================================================
🔄 Round 97 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 97 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0075
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0053
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2424, R²: -0.0020

============================================================
🔄 Round 98 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 98 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0066
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0095
============================================================


============================================================
🔄 Round 102 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 102 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0123
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0041
============================================================


============================================================
🔄 Round 104 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 104 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0025
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0415
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2424, R²: -0.0017

============================================================
🔄 Round 106 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 106 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0076
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0051
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2424, R²: -0.0017

============================================================
🔄 Round 107 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 107 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0081
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0061
============================================================


============================================================
🔄 Round 108 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 108 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0066
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0079
============================================================


============================================================
🔄 Round 109 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 109 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0093
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0057
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2424, R²: -0.0016

📊 Round 109 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2423, R²: -0.0015

📊 Round 109 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2424, R²: -0.0016

📊 Round 109 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2423, R²: -0.0015

============================================================
🔄 Round 115 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 115 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0072
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0118
============================================================


============================================================
🔄 Round 116 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 116 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0095
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0042
============================================================


============================================================
🔄 Round 117 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 117 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0068
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0055
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2424, R²: -0.0016

============================================================
🔄 Round 118 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 118 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0044
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0461
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2424, R²: -0.0015

============================================================
🔄 Round 119 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 119 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0058
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0105
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2424, R²: -0.0015

📊 Round 119 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2423, R²: -0.0015

📊 Round 119 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2423, R²: -0.0015

============================================================
🔄 Round 124 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 124 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0082
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0016
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2423, R²: -0.0014

============================================================
🔄 Round 125 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 125 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0068
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0064
============================================================


============================================================
🔄 Round 127 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 127 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0127
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0031
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0014

============================================================
🔄 Round 129 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 129 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0064
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0071
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0013

📊 Round 129 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0013

============================================================
🔄 Round 133 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 133 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0093
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0111
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0013

📊 Round 133 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0012

📊 Round 133 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0012

============================================================
🔄 Round 137 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 137 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0057
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0077
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0012

📊 Round 137 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0011

============================================================
🔄 Round 143 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 143 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0050
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0116
============================================================


============================================================
🔄 Round 145 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 145 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0078
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0064
============================================================


============================================================
🔄 Round 146 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 146 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0062
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0091
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0013

============================================================
🔄 Round 149 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 149 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0079
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0051
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0013

📊 Round 149 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0013

============================================================
🔄 Round 151 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 151 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0053
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0129
============================================================


============================================================
🔄 Round 152 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 152 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0081
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0011
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0013

============================================================
🔄 Round 160 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 160 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0065
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0042
============================================================


============================================================
🔄 Round 161 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 161 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0044
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0149
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0012

============================================================
🔄 Round 162 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 162 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0054
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0103
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0013

============================================================
🔄 Round 163 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 163 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0031
   Val:   Loss=0.0959, RMSE=0.3096, R²=-0.0215
============================================================


============================================================
🔄 Round 165 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 165 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0052
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0125
============================================================


============================================================
🔄 Round 166 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 166 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0072
   Val:   Loss=0.0680, RMSE=0.2607, R²=-0.0081
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0011

📊 Round 166 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0011

============================================================
🔄 Round 169 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 169 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0046
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0111
============================================================


============================================================
🔄 Round 173 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 173 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0070
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0080
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0010

📊 Round 173 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0009

📊 Round 173 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0010

============================================================
🔄 Round 177 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 177 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0053
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0078
============================================================


============================================================
🔄 Round 178 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 178 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0084
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0025
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0010

============================================================
🔄 Round 180 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 180 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0064
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0033
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0010

📊 Round 180 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0010

============================================================
🔄 Round 184 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 184 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0076
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0086
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0010

============================================================
🔄 Round 186 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 186 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0035
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0403
============================================================


============================================================
🔄 Round 188 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 188 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0050
   Val:   Loss=0.0940, RMSE=0.3065, R²=-0.0094
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0010

============================================================
🔄 Round 189 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 189 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0064
   Val:   Loss=0.0937, RMSE=0.3062, R²=-0.0051
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0010

============================================================
🔄 Round 190 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 190 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0076
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0121
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0009

============================================================
🔄 Round 192 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 192 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0047
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0136
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0009

============================================================
🔄 Round 194 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 194 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0054
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0072
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0008

📊 Round 194 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0009

============================================================
🔄 Round 197 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 197 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0037
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0197
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0010

📊 Round 197 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0009

📊 Round 197 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0009

📊 Round 197 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0009

============================================================
🔄 Round 206 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 206 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0055
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0063
============================================================


============================================================
🔄 Round 207 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 207 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0036
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0125
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0009

============================================================
🔄 Round 210 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 210 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0039
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0133
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0009

❌ Client client_49 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
