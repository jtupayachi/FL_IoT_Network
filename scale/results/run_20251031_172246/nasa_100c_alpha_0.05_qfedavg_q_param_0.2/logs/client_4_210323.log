[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a19488ef-e315-4511-bbf4-94c9ea6e1081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b495e5b-d1e4-4b12-8ebf-f76b83078e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6881622c-6aa7-4730-90a5-70b62aa967e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bfeea5e-01db-4f91-98f0-d5df2303c0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0daa69be-2c1f-43dd-9718-f3c9465c0685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51e7b38f-0ae4-4601-8727-cde304227eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f93995e4-0808-462c-8c8e-e5675940a35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef25bd92-bd29-461b-936c-79b9fb5b4654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40f78948-3620-48e7-9ee4-2f4fb82bd935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e09d67d-55e6-4e0b-81d9-71bac1dc2d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 122e3db1-3370-43bb-938b-3cf25d4c353c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d11b37f-5ee8-40fc-a1c8-0f856e01bbef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e46930a8-43f3-455f-aa75-69f3f0e3d6dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3443d424-b018-4013-9fdf-ca6418a11fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f21eb26d-eb90-41c1-be9a-eb42e9502991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d03baced-fe73-4e83-b406-9281391dc231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 667543b3-2cd9-484a-8a3c-b883140a66ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66cc54e2-3261-4227-b0e5-7296a05f8ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c83ce6bb-c356-4e77-8290-efeab9f1702a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d8aff73-f325-4016-a906-dcca3b4d23af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e729b4e-da20-4dad-9604-5106c09c98b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cb06456-8560-46d1-9ddf-ced176864eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e00e0d3-eecf-4ff4-bfbb-cc5d1a0555eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c7c29b0-ebb5-4ff9-91df-548c2a039e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83aebc48-1a4d-433e-8b27-fc0174752aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d25bf14a-baca-42d2-81af-ffe5c1baae6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0e2b74a-3245-446f-8876-f5c3bfe80fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00865f62-3fde-49f1-b895-c9936dcff8a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d55bb616-fddb-44ce-9123-7d07b65d4777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60796b3e-88bd-4ff4-a190-032e373d9c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40782d66-6aa9-4fcc-bd93-ce722ae5e621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac42f379-c0e0-4e2b-99b5-cc3c2bbfc941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c2467d1-d2ef-4d4c-ad38-d88fdb786c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1983e28-1719-4a6c-91cc-c3ab20401d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48df6ef5-3125-4e53-9232-821dd2f13c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1ea85bd-a0e2-4be3-81ba-a520275aa5a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40c817d8-58b4-48f8-aa79-0b551091126a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db071184-0577-4618-87c8-8068e30dd82a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3af85c99-8853-4169-841c-4812aa441d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49ee2ac6-bf44-4a83-864f-d9e23d46e825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c06a0dc7-ad3a-47b1-80d5-5c6c53530779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 702647e3-9564-400f-a5fc-710302f74172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdf05b52-0f4f-4acf-97b9-6c03e8d4e50d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b74b9ea1-2448-4a18-b4fe-9e538b62fa17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4a89d09-bd7f-40aa-8252-d080e7ec2040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fac90e9a-f4f5-4b31-b57f-3893232de12d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d75f3b60-eb83-4db5-b287-11d77618ff40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6debc843-1f01-470d-9446-87e88bc6a2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e53a147c-b95d-4f1e-8240-71145b384b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a702f9fd-35f9-4ba2-a142-dacf2d7c918c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46b0822a-f0b5-4300-9e97-7f69965d234f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b51802a6-3c61-4cbf-be4e-4e162139ef1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4545ad4-ac2e-43d1-89af-7d2a8719bfd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61037395-b1c2-4a2c-9750-f611623d07d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 728bacc2-e5e8-4bbc-bae7-c805324ea8fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 775e7d36-1ca6-4ba0-8b2c-672954bf37da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68b57637-0075-44f4-9bbf-ed9c5d805246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dabd9cab-e8cb-4298-a4e4-3c0d9f215ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6cfa2ef-cb6f-4cd0-8f1d-2f3808b63bdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c154deb-b99b-4f2c-9876-15f3d919f811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb28e366-79af-4b77-94b8-181ca2e44e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55fe8c40-180f-4a84-bc60-7b985856494c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ba6340-8e14-4335-8225-4b7190ad4bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 750befcc-ad1e-497f-a6c8-7087822b08ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0b99cf9-7000-45ef-8a9d-db1a2279c75f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82c1440f-da90-4724-897a-d813d22065d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77b50ead-7b07-4c64-a3aa-2a06902ed984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8d85665-fe64-434a-b99b-9012be6c3d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7d9945a-47cc-4c34-92c7-821e451ce668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41275674-5f3f-452f-97f5-4beb0bd726b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05b88077-b1ee-4692-9e8f-7a513a5b1872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7978f699-8603-48bc-ac51-5e2725259d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee04959c-a263-47f7-a425-d42f8559cd7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f6d05a3-dbb6-4f00-af50-978c4e72a66c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89e9d115-d4a9-48f6-a68e-b470e84c5a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9b4e0ad-6d52-492e-965d-fdeb5851d8c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52acc3e8-05e1-440e-9949-4c333ce7ad78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c543885f-c123-4c48-ac99-89ad5488a94e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4981148a-0061-49f0-9cfd-7ad4ae40da25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff0b8cac-7afb-473a-8f65-e5eb5762a6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 267d4a8e-b0b3-4d7d-bf48-640f0238950f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc60da12-3933-49dc-812d-e8f28d58befd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e5eedc7-7447-4278-b00a-945c104480ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a3f772d-1c16-4fb3-a162-948334549eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 384a593c-631b-4bb5-9b0f-18e0013a48e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35a0632c-fed5-49bd-a56c-c64cc2a67572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9283eb9d-03d1-4d35-9595-6ab10904ed9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4fe1785-1ca2-45f7-ad1e-00901ef80711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82681c7c-dea9-4ea9-996f-e3075e30b519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0cd3a6b-39d2-4b80-bd46-1cad3aa37837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b82d072e-6ccd-4467-8fae-d683b72fe067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d474c8ba-94df-47e7-920a-98eb673e8093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f4b04b1-66a7-48d8-8d36-95cf3df3e3cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c543aaf5-eadf-43da-8bcd-0c47d833ebc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e725696-9a1b-459f-a938-20629d2b92d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4edca47b-4c61-4e02-b634-116644939066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6d5e9af-f2f0-4cbd-8ba0-be35df817458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dfb7d1e-8367-4ff4-a08d-f45fd072cf98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d98ccee3-6d39-4920-b79f-1e30e05490ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42a08bd0-a51e-4d06-9c5e-a8cc3f615448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d834dfc5-3ab9-4882-8920-bcd42aa7425c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75735ff6-abb5-44d6-82f1-207d38eef1f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebdd71cd-608b-4cc7-ae9c-9a140ab2fd1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f78bb744-a5f8-4d99-ba2c-2cae004ccbe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6add7e4-2b99-4a57-93b3-cfd14c51a8ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd7fc0f0-a9c9-40fc-bb6a-925648bf03d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd43534-954b-48ea-a126-c78f2d901e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f15aaca5-af28-42b5-a6c6-dcdbc8c2decf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e570dac0-561a-4fb3-aa38-6cf146918f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e08021b7-dd37-42cf-9400-460f633de982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7b7ead9-749c-45f9-b0f7-58b501611646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d56d7af-a95e-4cb1-a7d7-e22260912ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6371aefa-830f-4fb9-b3b1-4672a2208a5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 578ba1b5-2530-428c-bb8d-d6ee0957b02a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f7b1540-cbb7-4596-9978-11b97f1bfc0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61edf5ce-a186-4460-bc34-43a0713744af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 698df764-d6bf-4aed-ab46-8ab8bb79b5fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b028d18a-fdf4-4a7b-8017-7f7ff7e0ad94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c03f696-32d3-46da-9fc8-45b4c66e3405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e545131-ad60-452a-a594-21c2a60c939f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 372b17fa-6072-46e4-9ff7-9f48de3e5d71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdad290d-a2e0-4544-8a4e-5b3c1f166aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d6cb913-b461-4fcc-b732-91c5c85ce81c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c706b8e-ca1e-431f-a97b-605458d6f070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff7589b2-1b2e-4948-9f2e-ab1892b77ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7df9a2d4-30e4-4fbd-a7e1-a97021be472c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5480a0b7-b999-47cc-a2af-aea42b812c07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 591b42df-eabb-4391-8c50-dc2e791650e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2e010ee-0535-481f-b1cc-a78100c4e50d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a1d1795-d44f-4bc9-9bbd-d14bda46cd2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 613cd98e-0ced-46d6-b15b-54a982db0dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32260846-248a-46ec-9874-3aeb1366c118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b0b22c4-744b-44b3-a320-391ce8da6672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52cbd267-3062-44fb-be39-f90e42df319f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 698c65be-18cd-40b2-b1e3-606d1d11a352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fec185de-5062-467b-a2f5-f127551aa6ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce6157be-19e6-4e13-8a7f-325ccf8134c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58025213-2075-4077-84d2-a403dcb1deba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34afa483-071d-45eb-b2cf-93e6554fe38e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b7f5c4d-397f-4421-8ae1-8f95bf3b6920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22baa18d-243b-4184-ad42-b178851a0260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc52e6b3-38d6-4dca-bcf2-05685da3c33b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3a074fb-27d3-4bbc-b146-1c17fc7f1ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc7909f8-e149-43a2-af5b-a488eb36fa1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5e83de8-5998-4f3a-958a-52b610bce678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46c5f671-1a7f-4c3e-bbbc-4a17e2d71839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aa79db8-5ba8-4bc1-96d1-808068121707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 446d978a-eeb6-4ba4-a4e0-7c13e7b748a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ede7e431-0a5c-4eef-851e-f3799f5bed5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dea41b5-4772-470d-952b-6790fd6695fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53f2bee8-21fe-4275-a17c-177726ca5da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97ee1718-a08e-424d-84e4-edeca3c888b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e90e34-8d79-4c8d-ba51-00730058f3ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5920b67b-9035-4103-ab40-ed92e50936f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 659bcbbd-857b-440d-9052-f52160f1412b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17e21d2d-2280-4f5d-b0f6-f639468304af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fd486b4-a7ea-4ae2-8f91-387c6fa9f370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35f92f81-5bfe-4959-a560-049cd8ad0d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 590c22fb-f9db-4b1e-859a-5070890e86b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 944818cf-4aa2-469a-b883-0b774e8e70df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b741812b-0a87-4195-95fd-df24866c76d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7198297-865b-4d7c-a11c-e4e6bfa2d194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0b6459f-0b0f-45c4-85a5-9c748df420a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b328d964-0384-462c-bb28-1d3e6d7927d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78464952-7740-4507-902c-b59599c8cf9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b204e176-a66f-4f7d-bd0b-cd28591a5fa1
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_4
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_4
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_4/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_4/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_4/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_4/test_labels.txt

📊 Raw data loaded:
   Train: X=(724, 24), y=(724,)
   Test:  X=(181, 24), y=(181,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 715 samples, 5 features
   Test:  172 samples, 5 features
✅ Client client_4 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1249, val=0.0816 (↓), lr=0.001000
   • Epoch   2/100: train=0.0893, val=0.0953, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0836, val=0.0841, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0832, val=0.0862, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0832, val=0.0863, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0820, val=0.0865, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 2 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0969, RMSE=0.3113, R²=-0.1610
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0230
============================================================


============================================================
🔄 Round 4 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1762, val=0.1341 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1132, val=0.0887 (↓), lr=0.000250
   • Epoch   3/100: train=0.0833, val=0.0903, patience=1/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0837, val=0.0862 (↓), lr=0.000250
   • Epoch   5/100: train=0.0825, val=0.0867, patience=1/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0822, val=0.0867, patience=7/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 4 Summary - Client client_4
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0042
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0025
============================================================


============================================================
🔄 Round 5 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1903, val=0.1649 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1686, val=0.1447 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1500, val=0.1283 (↓), lr=0.000063
   📉 Epoch 4: LR reduced 0.000063 → 0.000031
   ✓ Epoch   4/100: train=0.1340, val=0.1139 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.1229, val=0.1072 (↓), lr=0.000031
   ✓ Epoch  11/100: train=0.0910, val=0.0796 (↓), lr=0.000031
   📉 Epoch 21: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0849, val=0.0768, patience=6/15, lr=0.000016
   📉 Epoch 29: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 5 Summary - Client client_4
   Epochs: 30/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0040
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0036
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1890, RMSE: 0.4348, MAE: 0.3578, R²: -1.2709

📊 Round 5 Test Metrics:
   Loss: 0.1733, RMSE: 0.4163, MAE: 0.3424, R²: -1.0825

📊 Round 5 Test Metrics:
   Loss: 0.1705, RMSE: 0.4129, MAE: 0.3396, R²: -1.0480

============================================================
🔄 Round 11 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1649, val=0.1536 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1622, val=0.1509 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1593, val=0.1483 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1565, val=0.1459 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1540, val=0.1436 (↓), lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1445, val=0.1357 (↓), lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.1376, val=0.1298 (↓), lr=0.000002
   📉 Epoch 23: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.1348, val=0.1274, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1327, val=0.1255 (↓), lr=0.000001
   • Epoch  51/100: train=0.1307, val=0.1237, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1287, val=0.1220, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1268, val=0.1202 (↓), lr=0.000001
   • Epoch  81/100: train=0.1249, val=0.1186, patience=1/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1230, val=0.1169 (↓), lr=0.000001

============================================================
📊 Round 11 Summary - Client client_4
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.1209, RMSE=0.3477, R²=-0.4566
   Val:   Loss=0.1154, RMSE=0.3398, R²=-0.3523
============================================================


============================================================
🔄 Round 12 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1601, val=0.1529 (↓), lr=0.000001
   • Epoch   2/100: train=0.1598, val=0.1527, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1596, val=0.1524, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1593, val=0.1522 (↓), lr=0.000001
   • Epoch   5/100: train=0.1591, val=0.1520, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1576, val=0.1506, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1554, val=0.1485, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1533, val=0.1466 (↓), lr=0.000001
   • Epoch  41/100: train=0.1513, val=0.1447, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1494, val=0.1429, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1475, val=0.1411 (↓), lr=0.000001
   • Epoch  71/100: train=0.1456, val=0.1393, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1438, val=0.1375, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1419, val=0.1358 (↓), lr=0.000001

============================================================
📊 Round 12 Summary - Client client_4
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1404, RMSE=0.3746, R²=-0.6755
   Val:   Loss=0.1342, RMSE=0.3663, R²=-0.6242
============================================================


============================================================
🔄 Round 15 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1356, val=0.1458 (↓), lr=0.000001
   • Epoch   2/100: train=0.1354, val=0.1456, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1353, val=0.1454, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1351, val=0.1453 (↓), lr=0.000001
   • Epoch   5/100: train=0.1349, val=0.1451, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1338, val=0.1439, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1319, val=0.1420, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1301, val=0.1400 (↓), lr=0.000001
   • Epoch  41/100: train=0.1282, val=0.1381, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1264, val=0.1362, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1245, val=0.1342 (↓), lr=0.000001
   • Epoch  71/100: train=0.1227, val=0.1323, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1208, val=0.1303, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1190, val=0.1284 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_4
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1174, RMSE=0.3426, R²=-0.4122
   Val:   Loss=0.1266, RMSE=0.3558, R²=-0.4866
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1308, RMSE: 0.3616, MAE: 0.2990, R²: -0.5713

============================================================
🔄 Round 17 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1322, val=0.1161 (↓), lr=0.000001
   • Epoch   2/100: train=0.1321, val=0.1160, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1319, val=0.1158, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1317, val=0.1156 (↓), lr=0.000001
   • Epoch   5/100: train=0.1315, val=0.1155, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1303, val=0.1145, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1284, val=0.1128, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.1264, val=0.1111, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.1245, val=0.1095, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1227, val=0.1079, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.1208, val=0.1063, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1189, val=0.1047, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.1171, val=0.1032, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1153, val=0.1016, patience=3/15, lr=0.000001

============================================================
📊 Round 17 Summary - Client client_4
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1134, RMSE=0.3367, R²=-0.3484
   Val:   Loss=0.1003, RMSE=0.3167, R²=-0.2424
============================================================


============================================================
🔄 Round 19 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1012, val=0.1049 (↓), lr=0.000001
   • Epoch   2/100: train=0.1011, val=0.1048, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1009, val=0.1046, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1008, val=0.1045, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1006, val=0.1043 (↓), lr=0.000001
   • Epoch  11/100: train=0.0998, val=0.1035, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0984, val=0.1022 (↓), lr=0.000001
   • Epoch  31/100: train=0.0970, val=0.1010, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0957, val=0.0997, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.0945, val=0.0986, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0933, val=0.0975, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.0921, val=0.0964, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0910, val=0.0954, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0900, val=0.0945, patience=5/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_4
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=-0.0787
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0746
============================================================


============================================================
🔄 Round 20 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0935, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0933, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0932, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0931, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0930, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0923, val=0.0856, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.0912, val=0.0850, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0902, val=0.0843, patience=7/15, lr=0.000001
   • Epoch  41/100: train=0.0893, val=0.0838, patience=8/15, lr=0.000001
   • Epoch  51/100: train=0.0884, val=0.0833, patience=8/15, lr=0.000001
   • Epoch  61/100: train=0.0876, val=0.0830, patience=6/15, lr=0.000001
   • Epoch  71/100: train=0.0870, val=0.0826, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0863, val=0.0824, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 20 Summary - Client client_4
   Epochs: 85/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0398
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0056
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2489, R²: -0.0302

📊 Round 20 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2483, R²: -0.0177

============================================================
🔄 Round 22 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0820, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0855, val=0.0817, patience=7/15, lr=0.000001
   • Epoch  31/100: train=0.0853, val=0.0814, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0851, val=0.0811, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 22 Summary - Client client_4
   Epochs: 44/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0088
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0148
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2480, R²: -0.0101

📊 Round 22 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0087

📊 Round 22 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2480, R²: -0.0077

============================================================
🔄 Round 26 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 26 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0070
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0011
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2480, R²: -0.0071

============================================================
🔄 Round 28 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 28 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0037
   Val:   Loss=0.0934, RMSE=0.3055, R²=-0.0099
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2480, R²: -0.0067

============================================================
🔄 Round 29 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 29 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0042
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0088
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2480, R²: -0.0063

============================================================
🔄 Round 30 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 30 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0028
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0250
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2480, R²: -0.0062

============================================================
🔄 Round 32 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 32 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0009
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0133
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2480, R²: -0.0057

============================================================
🔄 Round 34 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 34 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0056
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0008
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2480, R²: -0.0056

📊 Round 34 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2480, R²: -0.0055

============================================================
🔄 Round 37 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 37 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0033
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0016
============================================================


============================================================
🔄 Round 39 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 39 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0017
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0063
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2481, R²: -0.0050

============================================================
🔄 Round 41 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 41 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0005
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0090
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2481, R²: -0.0049

📊 Round 41 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2481, R²: -0.0048

============================================================
🔄 Round 46 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 46 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0054
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0026
============================================================


============================================================
🔄 Round 47 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 47 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0030
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0003
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2481, R²: -0.0047

📊 Round 47 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2481, R²: -0.0046

📊 Round 47 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2481, R²: -0.0046

============================================================
🔄 Round 51 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 51 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0003
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0158
============================================================


============================================================
🔄 Round 52 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 52 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0059
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0167
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2481, R²: -0.0045

📊 Round 52 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2481, R²: -0.0045

📊 Round 52 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2481, R²: -0.0045

============================================================
🔄 Round 59 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 59 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0058
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0049
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2481, R²: -0.0044

============================================================
🔄 Round 60 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 60 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0023
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0030
============================================================


============================================================
🔄 Round 63 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 63 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0042
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0094
============================================================


============================================================
🔄 Round 64 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 64 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0043
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0081
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2481, R²: -0.0042

📊 Round 64 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2481, R²: -0.0041

============================================================
🔄 Round 71 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 71 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0010
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0178
============================================================


============================================================
🔄 Round 72 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 72 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0018
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0020
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2482, R²: -0.0041

📊 Round 72 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2482, R²: -0.0040

============================================================
🔄 Round 76 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 76 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0036
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0104
============================================================


============================================================
🔄 Round 77 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 77 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0016
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0027
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2482, R²: -0.0040

📊 Round 77 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2482, R²: -0.0040

📊 Round 77 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2482, R²: -0.0039

📊 Round 77 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2482, R²: -0.0039

📊 Round 77 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2482, R²: -0.0039

============================================================
🔄 Round 84 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 84 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0021
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0265
============================================================


============================================================
🔄 Round 85 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 85 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0012
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0018
============================================================


============================================================
🔄 Round 89 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 89 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0004
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0058
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2482, R²: -0.0038

📊 Round 89 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0038

📊 Round 89 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0038

📊 Round 89 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0037

============================================================
🔄 Round 94 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 94 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0008
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0008
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0037

============================================================
🔄 Round 96 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 96 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0015
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0046
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0037

============================================================
🔄 Round 99 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 99 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0026
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0043
============================================================


============================================================
🔄 Round 100 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 100 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0013
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0071
============================================================


============================================================
🔄 Round 101 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 101 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0004
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0052
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0036

📊 Round 101 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0036

📊 Round 101 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0036

============================================================
🔄 Round 106 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 106 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0017
   Val:   Loss=0.0940, RMSE=0.3065, R²=0.0041
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0036

============================================================
🔄 Round 107 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 107 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0005
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0025
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0035

============================================================
🔄 Round 110 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 110 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0004
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0072
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0035

============================================================
🔄 Round 113 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 113 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0005
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0062
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0035

============================================================
🔄 Round 114 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 114 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0033
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0033
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0035

📊 Round 114 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0035

📊 Round 114 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0034

============================================================
🔄 Round 124 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 124 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0023
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0072
============================================================


============================================================
🔄 Round 125 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 125 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0003
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0004
============================================================


============================================================
🔄 Round 126 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 126 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0008
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0034
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0034

============================================================
🔄 Round 128 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 128 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0010
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0002
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0034

📊 Round 128 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0033

============================================================
🔄 Round 130 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 130 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0045
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0080
============================================================


============================================================
🔄 Round 133 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 133 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0002
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0000
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0033

============================================================
🔄 Round 137 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 137 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0004
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0136
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0033

============================================================
🔄 Round 140 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 140 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0015
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0022
============================================================


============================================================
🔄 Round 141 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 141 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0032
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0114
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0033

============================================================
🔄 Round 143 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 143 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0025
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0062
============================================================


============================================================
🔄 Round 144 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 144 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0021
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0053
============================================================


============================================================
🔄 Round 145 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 145 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0016
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0069
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0033

📊 Round 145 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0033

📊 Round 145 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0032

============================================================
🔄 Round 148 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 148 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0032
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0116
============================================================


============================================================
🔄 Round 150 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 150 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0025
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0009
============================================================


============================================================
🔄 Round 152 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 152 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0001
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0012
============================================================


============================================================
🔄 Round 157 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 157 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0002
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0001
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0032

============================================================
🔄 Round 159 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 159 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0012
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0041
============================================================


============================================================
🔄 Round 160 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 160 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0016
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0145
============================================================


============================================================
🔄 Round 162 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 162 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0027
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0047
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0032

============================================================
🔄 Round 164 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 164 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0010
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0026
============================================================


============================================================
🔄 Round 165 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 165 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0014
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0056
============================================================


============================================================
🔄 Round 167 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 167 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0008
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0028
============================================================


============================================================
🔄 Round 168 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 168 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0049
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0020
============================================================


============================================================
🔄 Round 169 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 169 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0009
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0039
============================================================


============================================================
🔄 Round 170 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 170 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0001
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0013
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0031

============================================================
🔄 Round 171 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 171 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0016
   Val:   Loss=0.0729, RMSE=0.2701, R²=-0.0117
============================================================


============================================================
🔄 Round 172 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 172 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0009
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0238
============================================================


============================================================
🔄 Round 175 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 175 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0010
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0048
============================================================


============================================================
🔄 Round 179 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 179 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0014
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0009
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0030

📊 Round 179 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0030

============================================================
🔄 Round 181 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 181 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0034
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0001
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0030

============================================================
🔄 Round 182 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 182 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0015
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0035
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0030

============================================================
🔄 Round 188 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 188 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0016
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0042
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0030

📊 Round 188 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0030

============================================================
🔄 Round 191 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 191 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0005
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0014
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0030

📊 Round 191 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0029

📊 Round 191 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0029

============================================================
🔄 Round 197 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 197 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0031
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0221
============================================================


============================================================
🔄 Round 198 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 198 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0027
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0066
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0030

📊 Round 198 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0030

============================================================
🔄 Round 200 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 200 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0005
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0280
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0029

📊 Round 200 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0029

============================================================
🔄 Round 202 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 202 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0027
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0262
============================================================


============================================================
🔄 Round 203 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 203 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0005
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0031
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0029

============================================================
🔄 Round 206 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 206 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0014
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0036
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0029

============================================================
🔄 Round 208 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 208 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0001
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0015
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0029

============================================================
🔄 Round 209 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 209 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0006
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0000
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0029

============================================================
🔄 Round 211 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 211 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0011
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0015
============================================================


❌ Client client_4 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
