[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da1138ab-9aed-48fe-a62c-6f4a0fdbf0a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b56b085d-cac0-4da8-8641-01c45555803b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10de4802-4707-4ff8-8c96-24e47332d7be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b83a348-fb45-4a48-9c0c-3b6f39dc9e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62a447a4-d5a8-4b3d-b520-86fe7990d729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fa79900-926f-4c6e-b0cd-ad6b01971a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 027bda30-acdb-430e-bef1-390575c6d127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83e95216-3632-4274-b847-069b1d14820b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6f89fb9-bbc2-4e6d-81b8-3fc7235bc7c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a3a958b-4c11-48a2-9414-9ee8465e5171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ec53f6d-10b7-4700-a0ea-04819a0c0f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aa84b5a-48fd-4be7-9f5f-669721694ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c0f3afa-6b54-4ea8-a281-567236c3ce95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc6b9f3a-6869-4c97-bffa-c38aba219ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8298c80a-f033-4b3f-9756-088098763631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4420809-1667-460b-9fbc-76acaca0e746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba003fb1-cc51-4916-9c82-1ecf5ef499d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c09fd853-296c-4245-b957-8019f4e60f0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 993e2659-02b2-4bb8-a61b-2f8bfc5dd900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c43d599c-e0f3-4cd9-b461-7ce63d721723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f31152d3-745c-4169-8b6e-b75dfc50e553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c6de8b2-76a4-4cca-9fc8-b93006e3ea94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50e31ae0-a346-4d14-8652-750c3950fd3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9320940-78da-4d77-a25c-217adfef521e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34739075-36f5-47f7-a311-373d8f084ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c59b2ab-3788-4617-92b0-496275544ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f5a21c6-2ae8-4847-93d9-ac2e2daa83b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c568021-640d-4b4f-bd70-67f254c0caa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 613e7b08-688c-4b4d-8e86-e0c829579c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bec2f6f-cbb2-4240-bbf4-511627d8a77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34ff5494-0ef9-4ce9-989d-d5ea89712f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8561505f-6937-4fd5-a0ff-f96602347570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23516344-40d0-4e26-82fa-1db12b0d3d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49c3a56c-ff57-4809-aa27-6c174f4b2656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8a3ce01-117a-4c3c-9095-0cae6b5c84c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab83e2ea-90e1-4a59-9976-8e4cf419df2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce3417f2-c8e4-405f-81fe-9356b4f2fad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c8ecd53-22ec-494b-af0d-c8179264f4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 033a24e7-cabe-419c-afd3-5403b8194590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c251265f-f19a-4ecf-9c52-0ab6919decf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50705de2-6ec5-4290-adb8-fcb3eb537134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeeb7c0c-4248-4df9-bec9-1e8b04cd440f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c1c464d-4cf0-490c-8cf9-f376eb61f6b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d5394fe-6f91-4f1b-b7e5-7223d790bfaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8107e247-e8e4-46a9-9291-32adad9e3660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1d681c7-7e1c-4219-9be0-990b85c7163b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a3b522c-b728-4934-aac5-16b2844d5c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da39df67-c45a-4f60-aa1d-e578e92704e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a4c2b6a-3fe4-488a-bf5e-35dcf3e2a514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51425319-4d02-463f-937c-c3395e569f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49123318-3d58-42ed-b625-6765b1297218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6edd9f8-b433-4df9-b0ec-c36c5b9b08af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffcd1ff4-15fd-4035-9932-6466db4dcac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85be7e9e-b1dc-4562-abb0-3894fc248601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48d28006-e39d-41cc-a9e4-7a1efda2b698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc62c3df-df05-4f8b-971b-63ef51af0137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ca6dec1-ba71-4d7c-aa8b-78749dab5789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a741dc27-ee3a-4d82-a997-4a9e746a8238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c134ec9-d728-4bd6-a0e7-5d1cfd9ac596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ef6924a-f016-4e9f-9ca1-62a506eaa6f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beac5254-7e68-4352-99d5-5f74b2797586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb9119ae-be19-464b-bf54-6d778ba27748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47fe8cda-9e10-4c82-8d21-aac8c636b339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3215d1f-028c-4152-aea6-a8bf8c4b0baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b369ff2d-f92c-40a5-81b0-64b5d6accf53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1fd3339-195a-4332-8358-0a83481d25e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4d7e9f5-69ed-4b47-bc9c-0a7f4abe1427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b2b32ef-f262-4603-8c3d-56d64970f852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ae05d19-04d0-45e4-9b80-3816cc0a3b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a434d73-a017-4cc7-89f5-9af3e3fa448f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85c3df3f-0855-4f5c-97b0-b1076093d598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9d30cfd-7db6-4626-ba94-f3089c3ce62e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91183b54-e495-49e4-a406-5d72235461e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6aedff5-f660-4a95-8d29-9219c2042b51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0d01c0b-d48f-4c15-8e6c-72be126faab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20caec2b-d04b-41b5-bc07-8bc0887606bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc3616af-e256-4914-b24b-549d78f013a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cf182ba-b064-42b1-9448-87b6e61ed49b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd59e527-c9bd-49bd-8900-c8ff8d14ac5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7115cc41-89de-4719-99e6-8a06deefc5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38dfd8cf-057c-4445-baff-94251a470138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3afec3b8-e45a-4772-9e99-ec116f3ceea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deb12e76-eb6f-470c-92d8-116c94d90b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc1088e5-5a7a-44a2-b58e-b565f1c54ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9429cfd-dee6-4f5d-9c71-c5b14f1ae4c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6f7d544-a18f-420a-9a5c-7632fbbd7138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05117960-b87e-463e-9a45-4115b0df4578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c53b8242-ecb2-4da7-99fb-d051cd8b15e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab97a9f3-c232-4120-b584-f899c4ceebcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8849b449-d921-4ab6-acf7-c639bf959521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fc45b9c-2265-41e0-97c9-e4757042a3e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53c49ee3-86d3-492e-ab35-c25ec15c8109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4feb0db5-f3bc-4acf-a2a8-1690d9f95988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 667f7601-4301-4a46-b471-ae2dfe20ae0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa38962c-68a6-40cd-9881-829b58fb09e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3497be87-f57d-4b82-8d36-839dd08af32d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 178bbc34-82fa-45da-8177-a3655d4fb7bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e765c7f3-5e92-4210-9010-ac594ee9904d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 951753ab-e301-44c7-a354-78b826dc0719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcc6752c-496c-4009-890d-46e278093431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b343a43a-ec04-4785-80a7-907328cdf8c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61a7bf2c-785e-47ca-a855-8a1f8b9c4465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d22261b4-3bb1-4d74-81c9-65d873edc534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 201537d6-e9ee-482c-ade6-060d94956f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23e70535-97bc-4e55-864c-9240d40c1cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0caa5a6e-c6fa-444b-8f10-4e1ad7f80db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dca742c9-f390-4898-afa1-2166ee3dd936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02285c59-1048-42bc-aae8-8e7d0b13a351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a0ed95d-15c1-4f56-bc45-03d3f2e997fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da09f826-20b8-401c-b2c6-2e3f5bce30c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52581dcf-52f3-45f3-ac82-2150de381229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19061c27-bbb5-4ee8-8f12-4d74b018f743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94c7bec7-e04d-4326-9cf7-f5c45358ac74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 741d5781-8250-4b7d-98da-11481f4562f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d419736-8d72-49aa-991f-3192484fdfb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be987a72-0853-43ff-84e2-9fa51a5500c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 389baf13-76af-43f8-9929-9ecee5474ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f3772c1-0c45-450a-bb1b-e7c785ed2072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db320569-ebe4-4d82-abdb-4fcdd37ecd59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34967393-13f3-49a3-8077-44778d622643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be4d9bb2-e0cb-4e2e-a87d-5508d8ecdddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7654589-4983-48be-be56-645939deedaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6301089-b116-472d-91db-6d169c412602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d393e6a-b5e3-4df8-82bd-f6a3dc0d16d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be00a652-e8ba-4472-ab00-e5e3728d46b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab0298d9-69d1-46b5-9494-953315346ce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b453d557-7f66-4ba1-9cf8-f836a2ee822e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aa5aefe-44e2-4134-84e6-1f67c4a79123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 345bba3f-8798-475a-a69b-f0c3f36f224c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d53594e1-cde9-4f17-9310-9d11ae7667f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56debd21-df2f-4e4b-8f01-8bdd815cf6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 305af169-0f14-4df6-91dd-9b0c13e9a173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d71765-b3b1-4214-ab47-04bdb45c0a4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67b1f0cf-cbd8-4c1e-8332-c3bf305bc3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 623a1102-1e14-4ab9-8093-bfce3f18a6b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1679840-214f-4701-a392-3d7930411f4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 550c43a5-2eb0-4061-b84f-dc6e31bf96bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e8fe860-80aa-44bb-9b98-3ab07a5f26e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9ea67dc-1026-46b2-a346-4d4a67048417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60a83e94-dcff-41ce-8957-fb0e814a872f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b80884a9-1cf9-4503-84e4-908710d1774b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9519ae0b-c61a-46d4-989e-1c8251c453b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55bb2ca2-2f44-4f85-8383-d6ce43ca4338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fefef16-1edd-4747-a0bd-86aa9fd299cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 910a82b7-558d-4dec-a0f1-5c59f913bc67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efbdf65a-8215-4b7c-9f78-dcc292b2429c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b59273d-b6a6-4f38-8f32-067b380db99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfae2799-aef1-43e0-858a-917cd284c2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40e1a0e8-1ed8-491c-8567-ea3e0054ddb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acd4931d-df81-40fb-b7ca-9f2b988f367c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91e2db74-baae-4ca8-8077-d9f08e1e4222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83cdd8b9-7db1-4f2f-84ef-a4921e634a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02116dae-8812-464b-8b8e-f572c864a228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60e9d4d3-5175-4311-9174-12fdb91303d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8449fc8c-0190-40d6-b741-09ba5d00e669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70ffba21-9f89-48a2-8cac-17c030f83ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e59cb817-3c8b-48a7-9245-2ea4fe5f3c1a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_50
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_50
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_50/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_50/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_50/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_50/test_labels.txt

📊 Raw data loaded:
   Train: X=(2043, 24), y=(2043,)
   Test:  X=(511, 24), y=(511,)

⚠️  Limiting training data: 2043 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  502 samples, 5 features
✅ Client client_50 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1151, val=0.0923 (↓), lr=0.001000
   • Epoch   2/100: train=0.0881, val=0.0932, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0895, val=0.0943, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0871, val=0.0926, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0869, val=0.0930, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0853, val=0.0932, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 6 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0912, RMSE=0.3021, R²=-0.0541
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0275
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.1853, RMSE: 0.4305, MAE: 0.3536, R²: -1.2953

📊 Round 6 Test Metrics:
   Loss: 0.1786, RMSE: 0.4226, MAE: 0.3471, R²: -1.2122

============================================================
🔄 Round 9 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1512, val=0.0978 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0965, val=0.0863 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0900, val=0.0817 (↓), lr=0.000250
   • Epoch   4/100: train=0.0888, val=0.0823, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0886, val=0.0826, patience=2/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0882, val=0.0827, patience=8/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 9 Summary - Client client_50
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=0.0053
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0167
============================================================


============================================================
🔄 Round 11 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1559, val=0.1492 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1354, val=0.1299 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1174, val=0.1144 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1031, val=0.1028 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0930, val=0.0961 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0860, val=0.0932, patience=1/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0858, val=0.0929, patience=11/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 11 Summary - Client client_50
   Epochs: 25/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0010
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0034
============================================================


============================================================
🔄 Round 13 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1553, val=0.1469 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1523, val=0.1439 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1492, val=0.1411 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1463, val=0.1385 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1436, val=0.1361 (↓), lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1347, val=0.1285 (↓), lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.1279, val=0.1225, patience=1/15, lr=0.000002
   📉 Epoch 22: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.1252, val=0.1202 (↓), lr=0.000001
   • Epoch  41/100: train=0.1231, val=0.1182, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1210, val=0.1163, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1190, val=0.1145 (↓), lr=0.000001
   • Epoch  71/100: train=0.1170, val=0.1127, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1151, val=0.1109, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.1133, val=0.1093, patience=3/15, lr=0.000001

============================================================
📊 Round 13 Summary - Client client_50
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.1114, RMSE=0.3337, R²=-0.2748
   Val:   Loss=0.1078, RMSE=0.3283, R²=-0.2394
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1500, RMSE: 0.3873, MAE: 0.3187, R²: -0.8578

============================================================
🔄 Round 15 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1398, val=0.1344 (↓), lr=0.000001
   • Epoch   2/100: train=0.1396, val=0.1341, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1393, val=0.1339, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1391, val=0.1337 (↓), lr=0.000001
   • Epoch   5/100: train=0.1388, val=0.1335, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1374, val=0.1322, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1352, val=0.1302, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1330, val=0.1283 (↓), lr=0.000001
   • Epoch  41/100: train=0.1309, val=0.1264, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1288, val=0.1246, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1268, val=0.1228 (↓), lr=0.000001
   • Epoch  71/100: train=0.1247, val=0.1210, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1227, val=0.1192, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1207, val=0.1174 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_50
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1191, RMSE=0.3452, R²=-0.3742
   Val:   Loss=0.1159, RMSE=0.3404, R²=-0.2932
============================================================


============================================================
🔄 Round 17 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1297, val=0.1323 (↓), lr=0.000001
   • Epoch   2/100: train=0.1295, val=0.1321, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1293, val=0.1319, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1291, val=0.1317 (↓), lr=0.000001
   • Epoch   5/100: train=0.1289, val=0.1315, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1277, val=0.1303, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1257, val=0.1283, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1238, val=0.1263 (↓), lr=0.000001
   • Epoch  41/100: train=0.1219, val=0.1243, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1200, val=0.1224, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1181, val=0.1204 (↓), lr=0.000001
   • Epoch  71/100: train=0.1162, val=0.1185, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1144, val=0.1166, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1126, val=0.1148 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_50
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1110, RMSE=0.3332, R²=-0.2752
   Val:   Loss=0.1131, RMSE=0.3363, R²=-0.2796
============================================================


============================================================
🔄 Round 20 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0940, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0939, val=0.0977, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0938, val=0.0977, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0936, val=0.0976, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0935, val=0.0976, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0928, val=0.0973, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0917, val=0.0969, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0906, val=0.0967, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0897, val=0.0964, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 20 Summary - Client client_50
   Epochs: 43/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=-0.0781
   Val:   Loss=0.0967, RMSE=0.3110, R²=-0.0072
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2506, R²: -0.0486

📊 Round 20 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2491, R²: -0.0306

📊 Round 20 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2478, R²: -0.0161

============================================================
🔄 Round 25 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 25 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0054
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0141
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0144

============================================================
🔄 Round 28 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 28 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0017
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0209
============================================================


============================================================
🔄 Round 29 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 29 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0042
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0036
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2473, R²: -0.0111

============================================================
🔄 Round 35 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 35 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0037
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0012
============================================================


============================================================
🔄 Round 36 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 36 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0018
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0160
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2471, R²: -0.0091

============================================================
🔄 Round 40 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 40 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=-0.0014
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0072
============================================================


============================================================
🔄 Round 41 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 41 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0004
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0101
============================================================


============================================================
🔄 Round 42 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 42 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0012
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0316
============================================================


============================================================
🔄 Round 43 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 43 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0022
   Val:   Loss=0.0955, RMSE=0.3091, R²=-0.0063
============================================================


============================================================
🔄 Round 44 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 44 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0037
   Val:   Loss=0.0929, RMSE=0.3047, R²=0.0035
============================================================


============================================================
🔄 Round 49 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 49 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0025
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0028
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2470, R²: -0.0080

📊 Round 49 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2470, R²: -0.0079

============================================================
🔄 Round 51 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 51 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0022
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0089
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2469, R²: -0.0078

📊 Round 51 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2470, R²: -0.0079

📊 Round 51 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2470, R²: -0.0079

📊 Round 51 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2469, R²: -0.0078

📊 Round 51 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2470, R²: -0.0079

============================================================
🔄 Round 58 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 58 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0026
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0030
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2469, R²: -0.0077

============================================================
🔄 Round 60 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 60 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0024
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0018
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2469, R²: -0.0075

============================================================
🔄 Round 67 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 67 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0008
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0062
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2469, R²: -0.0073

============================================================
🔄 Round 68 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 68 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3001, R²=-0.0007
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0068
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2469, R²: -0.0073

📊 Round 68 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2469, R²: -0.0072

📊 Round 68 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2469, R²: -0.0070

============================================================
🔄 Round 72 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 72 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0002
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0146
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2468, R²: -0.0069

============================================================
🔄 Round 73 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 73 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0038
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0008
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2468, R²: -0.0067

📊 Round 73 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2468, R²: -0.0064

============================================================
🔄 Round 78 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 78 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0014
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0017
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2468, R²: -0.0065

============================================================
🔄 Round 82 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 82 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0008
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0034
============================================================


============================================================
🔄 Round 83 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 83 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0038
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0104
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2468, R²: -0.0063

📊 Round 83 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2468, R²: -0.0065

📊 Round 83 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2468, R²: -0.0066

============================================================
🔄 Round 88 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.1037 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.1037, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.1038, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.1038, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.1038, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.1038, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1037)

============================================================
📊 Round 88 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0022
   Val:   Loss=0.1037, RMSE=0.3221, R²=-0.0066
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0813, RMSE: 0.2850, MAE: 0.2468, R²: -0.0064

============================================================
🔄 Round 89 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 89 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0015
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0020
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2468, R²: -0.0063

📊 Round 89 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2467, R²: -0.0060

============================================================
🔄 Round 95 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 95 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0025
   Val:   Loss=0.0946, RMSE=0.3076, R²=0.0010
============================================================


============================================================
🔄 Round 96 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 96 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0001
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0113
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2468, R²: -0.0060

📊 Round 96 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2468, R²: -0.0062

📊 Round 96 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2468, R²: -0.0061

============================================================
🔄 Round 100 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 100 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0025
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0206
============================================================


============================================================
🔄 Round 103 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 103 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0008
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0047
============================================================


============================================================
🔄 Round 105 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 105 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2939, R²=-0.0006
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0316
============================================================


============================================================
🔄 Round 106 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 106 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0003
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0106
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2467, R²: -0.0057

============================================================
🔄 Round 108 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 108 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0004
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0347
============================================================


============================================================
🔄 Round 110 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 110 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0030
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0051
============================================================


============================================================
🔄 Round 112 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 112 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0005
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0026
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0056

============================================================
🔄 Round 113 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 113 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0007
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0150
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0056

============================================================
🔄 Round 119 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 119 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2939, R²=-0.0012
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0228
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0056

============================================================
🔄 Round 121 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 121 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0003
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0025
============================================================


============================================================
🔄 Round 123 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 123 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0006
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0027
============================================================


============================================================
🔄 Round 124 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 124 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0007
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0009
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0055

============================================================
🔄 Round 125 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 125 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0026
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0013
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0055

📊 Round 125 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0054

============================================================
🔄 Round 130 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 130 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0031
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0028
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0054

============================================================
🔄 Round 132 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 132 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0001
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0050
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0053

============================================================
🔄 Round 134 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 134 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0004
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0021
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0053

📊 Round 134 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0053

============================================================
🔄 Round 136 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 136 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0010
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0008
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0051

============================================================
🔄 Round 139 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 139 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0013
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0018
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2467, R²: -0.0051

============================================================
🔄 Round 140 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 140 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0007
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0101
============================================================


============================================================
🔄 Round 141 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 141 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0016
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0041
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0052

============================================================
🔄 Round 142 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 142 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0020
   Val:   Loss=0.0928, RMSE=0.3047, R²=0.0002
============================================================


============================================================
🔄 Round 143 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 143 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0003
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0045
============================================================


============================================================
🔄 Round 144 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 144 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0012
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0080
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0054

============================================================
🔄 Round 145 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 145 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=-0.0002
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0054
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0055

📊 Round 145 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0054

============================================================
🔄 Round 151 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 151 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0014
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0035
============================================================


============================================================
🔄 Round 152 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 152 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0012
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0018
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0055

============================================================
🔄 Round 153 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 153 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0015
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0028
============================================================


============================================================
🔄 Round 154 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 154 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0020
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0024
============================================================


============================================================
🔄 Round 155 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 155 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0015
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0026
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0055

============================================================
🔄 Round 158 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 158 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0010
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0002
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0054

============================================================
🔄 Round 159 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 159 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0005
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0085
============================================================


============================================================
🔄 Round 163 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 163 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0012
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0009
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0053

📊 Round 163 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0053

📊 Round 163 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0052

============================================================
🔄 Round 168 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 168 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0008
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0198
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0052

============================================================
🔄 Round 170 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 170 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0005
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0001
============================================================


============================================================
🔄 Round 173 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 173 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0004
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0040
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2467, R²: -0.0051

============================================================
🔄 Round 176 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 176 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0002
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0033
============================================================


============================================================
🔄 Round 178 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 178 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0002
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0085
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2467, R²: -0.0051

📊 Round 178 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0052

📊 Round 178 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2467, R²: -0.0051

📊 Round 178 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2467, R²: -0.0051

============================================================
🔄 Round 182 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 182 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0001
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0041
============================================================


============================================================
🔄 Round 185 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 185 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0008
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0018
============================================================


============================================================
🔄 Round 186 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 186 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0016
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0096
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0052

============================================================
🔄 Round 187 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 187 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0005
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0011
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0053

📊 Round 187 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0053

============================================================
🔄 Round 190 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 190 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0016
   Val:   Loss=0.0881, RMSE=0.2967, R²=0.0048
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0052

============================================================
🔄 Round 192 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 192 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0000
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0167
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2467, R²: -0.0051

📊 Round 192 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2467, R²: -0.0051

📊 Round 192 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2467, R²: -0.0050

📊 Round 192 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0051

============================================================
🔄 Round 200 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 200 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0009
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0055
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2467, R²: -0.0051

📊 Round 200 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2467, R²: -0.0050

📊 Round 200 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0052

============================================================
🔄 Round 205 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 205 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0002
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0028
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2467, R²: -0.0051

============================================================
🔄 Round 206 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 206 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0030
   Val:   Loss=0.0959, RMSE=0.3096, R²=-0.0150
============================================================


============================================================
🔄 Round 208 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 208 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0003
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0007
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2467, R²: -0.0052

============================================================
🔄 Round 211 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 211 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0005
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0033
============================================================


❌ Client client_50 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
