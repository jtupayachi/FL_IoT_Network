[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4327b940-4043-4bbe-91d8-b95bd1560cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd832091-98a4-4151-9504-c1b906af3101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dc359b8-64e6-4fe5-9c4f-2a3f14736f39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe462dee-0fb5-4248-aa1b-445f3d50ac0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 447a7e51-d522-4f8c-a342-711737db895d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b49da873-6ea6-4694-a05d-d8a8868c4aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ff44e1a-0a16-40f4-8e00-2199427aeb1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca51e62d-375a-43cd-a45f-2ad5227865d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20dd88f3-849f-4c58-80dc-06542de76d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcdcd384-8c41-4c22-888a-6a1d0fc2f3ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a70248-4070-4dca-9ff1-d64bb5cdb0c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a064530d-f89a-444b-9e06-966f10591f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc171230-1e76-410a-a372-46c5008a10ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe49b132-2f73-4f60-a981-b2a6018b002f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4341f89f-49bd-4b7b-946d-28a919a15cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cea7052-3b77-4ebe-a9fb-86f6310e355d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 504a6fe3-ccf7-42d1-8c9f-b99e878a6fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6775ee9d-0277-4ac0-9bdc-20ecb3849698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a095397-592a-444f-a6c5-382e2de0ca52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c2af483-bb1c-49e8-94a2-46f3f5913b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd41c4f9-ed80-475e-ba4f-628ff2079a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d76e57f8-f1fe-4504-8191-a037da95f3c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a765b851-8bdc-49f8-823c-f49a4949781e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e19a443c-8369-4ddc-b463-58b29f2def11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3fb0f59-8e0f-4367-99b3-1e922782a672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 409e4834-8b84-4aa2-8fab-9c30f4e6e72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86abd426-da15-4da8-a3fa-062e96542026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41462876-148c-4bb9-a6d3-b04ed6992de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message accd8628-8542-48d4-81a5-a7600b7610ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb7774f8-2210-424b-882c-9312ef29995d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 023eefe7-7003-4ef5-b304-c038e6f94c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b02b5cad-7e3e-405b-b2ac-ba4e8fb90e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09865040-d7e5-45ae-8aa6-eabc7d4af019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aaacffb-423a-49f3-b6c8-a9cc9ee8b3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 231f44c4-82ef-4312-badd-ecc10d3db71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f579c1ad-70d7-47da-8bc5-2f0d42a8150e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f83f3887-1ec3-496d-9411-ea710a8c47b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cbafa22-c9d7-4eb3-b0c9-5e56b23883d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e01b9f6-3a92-4910-a884-1cd586ec54cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0047703-ae41-4f52-a91c-3243fd711139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e392ae7-47b0-4a9f-9b04-ba083ebfd741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4dd6fba-909a-4ca2-8283-99ae2ace2eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f39018f-1e9d-4532-90d3-102fb03fa7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8fcd530-786e-4a7c-abed-53b3fac92d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 170c0e32-a82d-4b42-8ebd-cb70359eb29d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cab43370-e054-4545-893d-c0e63a9871e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c1347d9-b335-41a5-88ad-e503bfcf7162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19f2c9de-d3f2-4e8f-af64-22f231729dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 211e1344-af97-47d5-93be-526323c46d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e812cf4b-4085-420b-a280-1c0b84dcfeaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36bca215-1b58-4c51-9d01-33f8b749e6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0977d88-3378-4519-a4f9-08dcf73bcedd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc4cfabb-5f0e-4224-9731-2ccf8c0daec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe3e77cc-1aba-42be-8b62-3d3653b9eee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a024ee8-1a7c-44b4-869c-6dba04748377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63514fe6-1d87-48e5-9ba8-04ea2e0ad05b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49dc1065-9459-46c0-9401-e8684d6f3576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4083a546-4216-4620-b1c1-f90364d6380d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b26722df-fb88-4f78-b11c-e0436a6e494e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 547c9180-eea7-4015-846a-83c349c2486f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12878121-0a6b-4a39-8e84-719cb270a8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 785c6e1b-1b96-4331-b9a2-55b7a6d98ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 035c9163-40b6-4660-b739-a792e49b1e5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cc13d9a-da6d-4007-9869-b2efb29f0689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca36c8a3-6a0c-45b2-b402-9f1c8cd71fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1086153d-5ba5-46a7-a009-e64316d08ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb0757f7-827e-467f-be71-fcea0bab3f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 575fbd43-b6a9-43c5-9fe3-f9880100890b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17e87ee7-1e73-4c47-a98c-99e2582ab56c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ff993c0-b7b9-434f-ad88-f2d3f3e747d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f876d58-2dd9-4570-9554-1081625be2e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f00b641-2613-449d-ad48-f90d417dbb1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e3fd520-ef04-4888-9afe-6c152b1adb22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a90ecb34-c39c-49af-b14c-60935ea7bf0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec838a7d-07c2-41c0-8256-4b774e7ffa56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d9260a8-70a9-4c58-ac92-fd90325f48c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63b89ebb-89a2-4399-bc96-aee4d7d578c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e881b66-26b8-462c-b607-14b367887336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76d9eab5-e1cc-46bc-9b80-975e51dcb900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ea06944-1f99-493e-97f2-bc82c4c42d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cd068b9-1beb-4a29-9b28-f700eaa286f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d59d4e86-c6d0-47b4-a4c1-fd123b95a1b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bef6061d-c53e-411c-9b5e-499d9bf0d6a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bc6af5e-79a1-4315-a87e-1512efe5bb8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d1ccd93-cdae-4d76-968f-fd5078515cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78df0157-5901-4305-bd00-82d24221ce22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9afc0d79-f7a6-4965-a25b-ab1b526c9d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1454a8b9-8456-437c-96e0-5a8437286f09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5864e659-20d2-46c3-85c1-83f33139edc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95ce8702-82ac-45d9-8690-d62862f6defa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad61b931-d77d-4e95-a38c-6f392ca412da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 665f561c-d5eb-486b-b7cb-b589a5e23b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 652f5264-433d-4b19-bd13-215767c2f94d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5afaa991-ed77-4e7b-b1c2-6a4a096562e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccb14591-fef9-406d-9927-7fc124b479c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25a32c45-42c5-42db-9bbe-cff9046ea752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7fd3e4b-57e4-4b96-a0b7-51620c3a48cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed539323-63cf-4554-b7e8-44475b652c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a5d57ed-31e6-4986-bcd0-710239d3e063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 735b6c76-d3c9-4df1-bfed-3d31db6d045c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e17db7c-00df-48ff-be09-6a17ebcdad8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2302adc7-1405-4a58-a137-eaca0c4c50cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 745b847e-6600-4dd8-8d9b-01fd0575ee96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c642817c-679f-44c8-8952-e87605094bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fc4723d-5a86-4b05-ad46-ec5915965ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa9be430-d7df-44db-aa7f-f777c384569e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 534a1fc8-d8f1-48c9-bdb3-547878adf2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fcc902a-6f8d-457d-947e-e6b0df0d48fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dbc8a6a-7611-4253-a56f-bafc61eb24ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fde24601-44c9-4443-8535-3a95b9b2637c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 503b0b28-f87f-4c4a-80a2-0f413c5f4d4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c604fe4c-11a3-49e8-8d65-fbecf0e47003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac2591e7-4295-4729-b2d2-be51ee399f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d2b0f0d-8a4b-4a28-b257-8000a4256d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b6f3be9-ddee-49e8-ac27-22ab06cf4e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34c2c6c3-3868-4471-81a3-9016e8f30c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89dd3d89-2c6e-47f4-a0a2-10fbf6afd944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3510355-d5ab-4647-93ff-2514a25c831a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 472e8291-9a03-4cb2-b692-a97b3bb8a626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d2ce8b3-a1ea-41d9-a5ee-5c64fb51518f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70e71daa-0c5d-43bc-b871-d8405d8a0e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52490d46-be4f-436e-9eb6-56ec83bdc99c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd93cc1d-88fe-429e-bfbd-10361bdca1ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9553008-7726-4e57-b580-be56961be621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a18f3646-fb21-4288-8e51-4d0234ea6c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e75d47aa-b9da-45d9-891f-95540fcc9e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62eff847-5a0c-4c4b-9910-afcfa4ea1b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6aade90-641b-4e52-bcf5-4540940ad832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67d7dae9-8e3c-4168-8752-7e23652e3ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35a5972e-8723-49e1-bcfb-18948a639d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15359243-cb57-44be-b538-67901d741ca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04107343-a8f6-4b98-9d32-35cf53dd129c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22e97206-89b3-433d-bfc6-79e3a73f4bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edb446d9-3097-4437-bd0c-a6ff82f8e0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 837f05ca-49db-4039-9102-85e1131a002e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c50a10f-c606-45fd-a977-6ecd15aa0da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3c2a6f9-1952-4e4a-83e4-1a3182189dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9d0d95a-bf41-4eaf-b401-9cc1587d7359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aebf857b-e799-41aa-85f2-25ff02f04e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc1558a3-5e65-4f43-86f3-53bfb6942dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 423e5da7-b130-49f9-930e-6ab33720c7e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 793abad5-aaf6-4bb9-b75e-498490a5cff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 303444fe-d503-4456-9058-19bfd2b32adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 388db6dc-642a-469b-a0bb-cb4c00c9db2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1223531-aab4-4e76-9de9-983f61538a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 063fd39e-e3a8-4122-86ea-8f57c1fd43fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c27c84c-2a95-4f54-99af-30a56cdedc32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0c78abc-7c00-401d-8473-8d8028d3ee50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7d4d945-e75e-4091-9ffc-65de3efbc1c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1bf3357-fd87-410d-a8f8-0f6f84db127a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 561f9625-134b-4dbe-bf08-9c1a28092c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3679dce-34a0-4fa7-bd1d-554d89a1fe8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5eaea64-78d9-48b3-b4e6-e3ecaeb84688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d999374-e18c-4c44-837d-a3b180aad70c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3babd48-595f-41c2-89e2-c48e498a2edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f97f25f-d83e-4c6a-80de-a091afd3422f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cba08b59-e912-4ff4-a163-43129f3a377a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd670bd7-63bb-44d7-9ea2-48419766c0fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbcd9224-c874-4692-8be1-34a3d0fcf2b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ba66f33-df8c-466f-b813-5eb82279b263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e208758e-0906-409d-8cf1-7c0d7c99f779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dc0cb8c-a760-4d5a-9392-a2d72e0739a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fea2b2a1-b279-4461-91e1-ac1531bd6083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a60c5fb5-1c59-4699-817e-e8914e60a8d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bf191f0-f067-44a9-a0d9-df722c23d4b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c726aed-475e-4535-99f7-1bcb89bb0b9d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_51
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_51
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_51/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_51/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_51/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_51/test_labels.txt

📊 Raw data loaded:
   Train: X=(505, 24), y=(505,)
   Test:  X=(127, 24), y=(127,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 496 samples, 5 features
   Test:  118 samples, 5 features
✅ Client client_51 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1597, RMSE: 0.3997, MAE: 0.3278, R²: -1.0756

============================================================
🔄 Round 12 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1147, val=0.0942 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0846, val=0.0822 (↓), lr=0.001000
   • Epoch   3/100: train=0.0847, val=0.0841, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0827, val=0.0829, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0826, val=0.0838, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0796, val=0.0873, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 12 Summary - Client client_51
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0053
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0118
============================================================


============================================================
🔄 Round 13 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1508, val=0.0882 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1038, val=0.0768 (↓), lr=0.000250
   • Epoch   3/100: train=0.0888, val=0.0882, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0874, val=0.0781, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0864, val=0.0777, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0856, val=0.0790, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 13 Summary - Client client_51
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0154
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0399
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1352, RMSE: 0.3677, MAE: 0.3004, R²: -0.7570

============================================================
🔄 Round 14 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1449, val=0.1354 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1310, val=0.1222 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1164, val=0.1111 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1040, val=0.1023 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0943, val=0.0964 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0824, val=0.0935, patience=5/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0820, val=0.0932, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 14 Summary - Client client_51
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0397
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0160
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1205, RMSE: 0.3472, MAE: 0.2838, R²: -0.5661

============================================================
🔄 Round 16 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1304, val=0.1411 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.1273, val=0.1375 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1243, val=0.1356 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1224, val=0.1338 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1205, val=0.1321 (↓), lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1112, val=0.1238 (↓), lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.1055, val=0.1186, patience=1/15, lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.1033, val=0.1166, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1019, val=0.1154, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.1007, val=0.1142, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0995, val=0.1131, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.0983, val=0.1120, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0972, val=0.1110, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.0961, val=0.1100, patience=1/15, lr=0.000001

============================================================
📊 Round 16 Summary - Client client_51
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0959, RMSE=0.3097, R²=-0.1702
   Val:   Loss=0.1091, RMSE=0.3304, R²=-0.1092
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2525, R²: -0.1838

============================================================
🔄 Round 19 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0972, val=0.1239 (↓), lr=0.000001
   • Epoch   2/100: train=0.0971, val=0.1238, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0969, val=0.1236, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0968, val=0.1235, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0967, val=0.1234, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0959, val=0.1227 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.0947, val=0.1216 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.0936, val=0.1205 (↓), lr=0.000001
   • Epoch  41/100: train=0.0925, val=0.1195, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0914, val=0.1185, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0905, val=0.1176, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0895, val=0.1168, patience=5/15, lr=0.000001
   • Epoch  81/100: train=0.0886, val=0.1159, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.0878, val=0.1152, patience=5/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_51
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0989
   Val:   Loss=0.1145, RMSE=0.3384, R²=-0.0670
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2437, R²: -0.0693

============================================================
🔄 Round 22 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 22 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0144
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0337
============================================================


============================================================
🔄 Round 24 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 24 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0159
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0009
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2405, R²: 0.0056

📊 Round 24 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2405, R²: 0.0059

============================================================
🔄 Round 26 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0664 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0664, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0664, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0664, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0664, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0664)

============================================================
📊 Round 26 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=-0.0088
   Val:   Loss=0.0664, RMSE=0.2577, R²=-0.0092
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2406, R²: 0.0061

============================================================
🔄 Round 29 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 29 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0093
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0103
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2406, R²: 0.0063

📊 Round 29 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2406, R²: 0.0063

============================================================
🔄 Round 31 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 31 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0061
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0251
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0765, RMSE: 0.2765, MAE: 0.2407, R²: 0.0063

📊 Round 31 Test Metrics:
   Loss: 0.0765, RMSE: 0.2765, MAE: 0.2407, R²: 0.0063

============================================================
🔄 Round 33 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 33 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0071
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0037
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0765, RMSE: 0.2765, MAE: 0.2407, R²: 0.0063

📊 Round 33 Test Metrics:
   Loss: 0.0765, RMSE: 0.2765, MAE: 0.2407, R²: 0.0063

📊 Round 33 Test Metrics:
   Loss: 0.0765, RMSE: 0.2765, MAE: 0.2407, R²: 0.0063

📊 Round 33 Test Metrics:
   Loss: 0.0765, RMSE: 0.2765, MAE: 0.2407, R²: 0.0063

============================================================
🔄 Round 37 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 37 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0022
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0448
============================================================


============================================================
🔄 Round 39 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 39 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0048
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0118
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2408, R²: 0.0062

============================================================
🔄 Round 45 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 45 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0070
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0250
============================================================


============================================================
🔄 Round 46 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 46 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0066
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0093
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2408, R²: 0.0062

📊 Round 46 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2408, R²: 0.0062

📊 Round 46 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2408, R²: 0.0062

============================================================
🔄 Round 49 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.1000 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.1000, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.1000, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.1000, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.1000, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.1000, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1000)

============================================================
📊 Round 49 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0058
   Val:   Loss=0.1000, RMSE=0.3162, R²=-0.0086
============================================================


============================================================
🔄 Round 51 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 51 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0038
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0494
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2408, R²: 0.0062

📊 Round 51 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2408, R²: 0.0062

📊 Round 51 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2408, R²: 0.0062

============================================================
🔄 Round 56 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 56 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0047
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0079
============================================================


============================================================
🔄 Round 57 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 57 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0047
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0185
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2408, R²: 0.0062

============================================================
🔄 Round 58 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 58 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0062
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0067
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2408, R²: 0.0061

============================================================
🔄 Round 59 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 59 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0020
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0258
============================================================


============================================================
🔄 Round 60 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 60 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0052
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0071
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2408, R²: 0.0061

📊 Round 60 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2408, R²: 0.0061

📊 Round 60 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2408, R²: 0.0061

============================================================
🔄 Round 64 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 64 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0059
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0087
============================================================


============================================================
🔄 Round 65 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 65 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0095
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0120
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2408, R²: 0.0061

============================================================
🔄 Round 66 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 66 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0064
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0131
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2409, R²: 0.0060

============================================================
🔄 Round 70 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 70 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0084
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0162
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2409, R²: 0.0059

============================================================
🔄 Round 75 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 75 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0048
   Val:   Loss=0.0986, RMSE=0.3140, R²=-0.0060
============================================================


============================================================
🔄 Round 76 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 76 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0042
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0103
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2409, R²: 0.0059

============================================================
🔄 Round 78 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 78 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0076
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0541
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2409, R²: 0.0058

============================================================
🔄 Round 83 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 83 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0076
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0080
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2409, R²: 0.0058

📊 Round 83 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2409, R²: 0.0059

📊 Round 83 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2409, R²: 0.0058

============================================================
🔄 Round 88 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 88 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0065
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0077
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2409, R²: 0.0058

============================================================
🔄 Round 89 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 89 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0053
   Val:   Loss=0.0974, RMSE=0.3120, R²=-0.0033
============================================================


============================================================
🔄 Round 90 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0990 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0990, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0990, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0990, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0990, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0991, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0990)

============================================================
📊 Round 90 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0059
   Val:   Loss=0.0990, RMSE=0.3147, R²=-0.0054
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2409, R²: 0.0058

📊 Round 90 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2409, R²: 0.0057

============================================================
🔄 Round 92 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 92 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0060
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0003
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2409, R²: 0.0057

============================================================
🔄 Round 93 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 93 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0051
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0260
============================================================


============================================================
🔄 Round 95 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 95 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0078
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0041
============================================================


============================================================
🔄 Round 98 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 98 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0067
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0035
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2409, R²: 0.0057

============================================================
🔄 Round 101 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 101 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0035
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0102
============================================================


============================================================
🔄 Round 104 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 104 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0072
   Val:   Loss=0.0967, RMSE=0.3110, R²=-0.0108
============================================================


============================================================
🔄 Round 106 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 106 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0061
   Val:   Loss=0.0959, RMSE=0.3097, R²=-0.0095
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0055

============================================================
🔄 Round 111 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 111 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0049
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0066
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0055

============================================================
🔄 Round 114 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 114 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0037
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0097
============================================================


============================================================
🔄 Round 115 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 115 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0061
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0285
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2409, R²: 0.0055

============================================================
🔄 Round 119 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 119 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0035
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0173
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2409, R²: 0.0055

📊 Round 119 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0055

============================================================
🔄 Round 124 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 124 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0027
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0300
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0055

📊 Round 124 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0055

============================================================
🔄 Round 126 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 126 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0049
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0044
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0054

============================================================
🔄 Round 127 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 127 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0069
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0005
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0054

============================================================
🔄 Round 130 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 130 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0074
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0207
============================================================


============================================================
🔄 Round 131 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 131 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0076
   Val:   Loss=0.0964, RMSE=0.3105, R²=0.0013
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0054

============================================================
🔄 Round 132 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 132 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0043
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0149
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0054

============================================================
🔄 Round 133 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 133 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0053
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0014
============================================================


============================================================
🔄 Round 135 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 135 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0046
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0090
============================================================


============================================================
🔄 Round 136 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 136 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0028
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0143
============================================================


============================================================
🔄 Round 137 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 137 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0051
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0089
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0053

============================================================
🔄 Round 138 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 138 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0030
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0193
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0053

============================================================
🔄 Round 141 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 141 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0074
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0411
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0053

📊 Round 141 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0054

============================================================
🔄 Round 144 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 144 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0060
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0305
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0054

📊 Round 144 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0054

📊 Round 144 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0055

📊 Round 144 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0054

============================================================
🔄 Round 152 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 152 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0055
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0006
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2409, R²: 0.0055

📊 Round 152 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2409, R²: 0.0055

============================================================
🔄 Round 154 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 154 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0063
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0016
============================================================


============================================================
🔄 Round 155 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 155 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0052
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0062
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0054

============================================================
🔄 Round 158 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 158 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0040
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0064
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0054

============================================================
🔄 Round 159 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 159 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0039
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0186
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0054

📊 Round 159 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2410, R²: 0.0054

📊 Round 159 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0054

============================================================
🔄 Round 164 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 164 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0013
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0307
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0053

============================================================
🔄 Round 166 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 166 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0046
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0040
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0053

============================================================
🔄 Round 167 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 167 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0034
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0104
============================================================


============================================================
🔄 Round 168 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.1016 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.1016, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.1016, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.1016, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.1016, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.1016, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1016)

============================================================
📊 Round 168 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0032
   Val:   Loss=0.1016, RMSE=0.3187, R²=-0.0086
============================================================


============================================================
🔄 Round 170 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 170 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0079
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0073
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0052

📊 Round 170 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0052

============================================================
🔄 Round 173 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 173 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0022
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0199
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0052

============================================================
🔄 Round 175 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 175 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0021
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0184
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0052

============================================================
🔄 Round 179 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 179 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0029
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0099
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0052

📊 Round 179 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0053

============================================================
🔄 Round 184 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 184 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0034
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0083
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0052

============================================================
🔄 Round 185 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 185 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0094
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0554
============================================================


============================================================
🔄 Round 186 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 186 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0040
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0082
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0053

============================================================
🔄 Round 187 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 187 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0043
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0114
============================================================


============================================================
🔄 Round 189 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 189 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0052
   Val:   Loss=0.0890, RMSE=0.2982, R²=-0.0012
============================================================


============================================================
🔄 Round 193 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 193 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2966, R²=-0.0054
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0167
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0052

📊 Round 193 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0052

============================================================
🔄 Round 195 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 195 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0074
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0073
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0053

============================================================
🔄 Round 201 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 201 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0061
   Val:   Loss=0.0971, RMSE=0.3116, R²=-0.0174
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0052

============================================================
🔄 Round 204 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 204 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0081
   Val:   Loss=0.0978, RMSE=0.3127, R²=-0.0010
============================================================


============================================================
🔄 Round 205 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 205 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0035
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0078
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0052

============================================================
🔄 Round 206 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 206 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0074
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0736
============================================================


============================================================
🔄 Round 207 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 207 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0048
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0559
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2410, R²: 0.0052

============================================================
🔄 Round 211 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 211 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0042
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0084
============================================================


❌ Client client_51 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
