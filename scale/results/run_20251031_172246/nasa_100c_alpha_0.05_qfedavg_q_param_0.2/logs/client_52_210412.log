[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8672ddfa-d9b2-4cc0-a14d-0afe12f61894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61d3f7ed-5dfb-4d1d-9ae8-f9db30f1be18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d0ce652-a94b-4016-ab82-6ea1fd0c1666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34cdbc47-4a1e-469a-a636-a35b8753f14e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20467f1b-32ae-4663-b1c1-a17adb07190b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d678806b-545d-4f84-a443-52198ec7a03e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4121cb6-8281-4fab-954d-52e34fed158e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42575e14-e8d2-4e12-a02a-9e268e888295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 545d3457-bea4-4252-8817-2d027184acbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f78cecaa-ce95-4b7a-8b35-4a353c707983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa9cf9cc-18bf-414f-98b3-1c75ceb0538b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f4afca8-7850-462c-9014-f97ea9e0fd3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff812a60-9d92-4690-9bd2-c5e626f43883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cefc8062-25f3-43ae-ac9e-9a1498a02e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfd109eb-bcc3-42a7-b790-731e37c72a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message badde9ee-53d2-4210-b4bc-40af2e90db9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf23ebf6-a5f7-4e68-a6c4-c8ed2c4a6ed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8abe4fa8-abb1-4ef6-892d-7cd104a37082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4c1aea4-97ef-4196-96eb-35940a402322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46d82b53-b3af-4cbc-8085-12517eb5080f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dac48ebd-7516-418d-be5c-f7e2e3f445ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54968dfe-a1b2-4050-940a-5f5e77e4690d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49245b4d-b85c-4507-b0b2-22321330c2f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5a923ac-ecf6-413d-a761-a79ac53c4e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1252c83-8d0d-483c-a19f-f10257b1347e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce659d52-72a2-465f-a7b1-f755cc7bd16f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 995e8f0a-8736-4f36-9bdd-125ccf7d498c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b18139ea-6471-4293-a1a4-8dc356dcde1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2a3f1c4-5cbd-4e3b-ab15-a885afb92ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f72762f8-7619-41e0-a70d-15760a56b6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9790590e-28ff-40cf-9ac8-b919878d0b2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b1f18f3-865e-40cc-a0f9-393e3bfb62c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4a5f51d-f108-45c4-8aaf-cba750d331c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cabe7d3-8921-41b0-837d-b0f3df81b3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d47ba037-2d83-4037-9d4f-d4d6575f60b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adaca014-9481-405e-aec1-2dd48be39ba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d949aadf-d366-4df5-bd0f-b3e1e315c4f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 642aa219-3d61-4d1f-830a-1f77f53a7bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bf7b97a-d0bc-4ec5-a899-97f261012bc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e4231e3-b6ea-4fca-be02-0e21e232e40e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b60882e-77a3-4495-b136-6f2088a4e6a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f3efc48-545a-445a-afbd-41558527ebcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c9275ba-181b-41f3-8d50-e9117a69f8ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f474a9a-4ae3-4274-8594-9cdcd57931ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dca35a7e-34b4-4cae-9ecd-61bb43c28878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f739c537-ee03-4113-98bd-7477dfb8340a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8236dfd-4422-475d-a0d6-4546028832e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87b3559c-607d-4102-8e1c-f9adbcbcb889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f8c870d-1aca-4610-9486-fd7fd0988184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7888215-8ce3-44a3-bb9c-5c60497569cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3baf8136-c342-4be0-8295-019f2a4f8294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d674b5f5-5354-4202-b43f-cac913aa5243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51fd3a81-3bda-44eb-990a-709aced34d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 533d6a5a-c57c-4ec3-810f-96321cbdb5a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0b5fa4d-fad1-4fd8-be8d-257a5c6fd430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1aed04f-b292-4bce-bdaa-16cc101f6cca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e978bb37-0399-4051-a480-d7c3b3c1e5dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e1a89c6-3d0d-4c20-b8a2-92c3d069800f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e85bec7-0372-4f8d-a7ac-865d7a72d9f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8bff55c-8abc-43ca-95aa-587ed910d7a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 200dc51d-de23-41c2-87c4-43bd2581c9fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45b17273-7c1b-4b06-8206-1a096124b81d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3280c210-9808-4113-8b9a-9a6ee156b6b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04311875-f658-43a3-9d5d-e478df11fae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e254ffb4-42a0-46e8-ab7f-8383649f1e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7502a30e-07ef-4c2d-98ce-2a758ae6a061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1a3331b-d989-4246-9d39-50006bd881c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a10e9358-937a-4315-8fc2-57502ccd9916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63d4fdf0-5307-4d6f-b82d-78d0f1f98986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4910b169-d8d2-4d55-bd1d-4654060ac1c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3bd3e91-9a63-494d-9f6e-cd3e37304098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed356053-01d8-4c48-879e-e74258299fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4a6daf5-2504-478e-97a8-c4a10a7dcda2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2120867a-ccac-47c3-ac6d-08510f8a3eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b88e90c1-d15d-46fc-bab3-2d0a65f5fe9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10f6973e-101c-411c-a17a-3317aea665bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72137463-d9b5-4fc0-a871-73d18f342aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c92233fa-23bd-444c-896e-78ab82275b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e89d0baa-4bd2-43d1-9d51-8d3edd74978f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d746474e-367d-4910-8851-847e23ae6a43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7e28aec-75a9-42c8-98ff-3cd6ec04bb64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e63e5f45-670d-4865-be38-a859a69da596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 869fcc02-69c8-4b67-b095-e48c5cc17075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12591bbb-825e-4224-a89e-bbf11327cf92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c31a3fb0-5f57-4dff-b34a-f1d969b18b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfe54b14-5687-4413-bcdb-c67f878ed262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 089f0086-7443-45ad-880f-5b966def9604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d853a0e-845f-44ed-8bc7-87e76b2334b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d3a2e81-1ced-4b2a-a872-0d09746a6d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d91b156d-2989-41d5-9629-243dda6d4af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 608bd593-0f4f-4a29-94be-e1283dfef6ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e89f2af-24ed-4a52-aa8d-266da1e157b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd94e4cf-e933-4370-9d26-1e29116c21a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2e1b8e2-6b14-4db7-9abb-927909bfa5b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80182013-bd5d-4264-87a1-5a06e5e7adc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac11cefa-1a38-48c5-957f-72de6d39d4df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6435f1c7-a3ec-43ae-9fdd-ebccbc361752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df928aa6-d34b-4f1c-ab94-d3c94a207a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12b0632b-8bda-473e-8a4d-83e368ce1ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 210a8b07-f56e-4e1d-a8f5-71ff18360c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72fe20f7-1dfa-4356-89ef-7bf12e18a356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad429520-084e-4f58-9235-9827f0277f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87ea7d01-617c-4063-af28-a017dfa101d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d3005b1-06e1-4e44-af2f-6f195c1bbf6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dd0b2b6-3ced-4ba1-9355-20b131f362ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16f59de9-e181-4acd-83d2-9c7a59369c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2a46990-7b5b-4c82-9dfc-a87b774f2dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db9691b8-4f15-4be3-9b76-b0bfe8b12025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a72552a4-1983-4b49-8b9f-e28ff78be861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05bca8c2-0bb7-410f-93d1-6747a5d84f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35dc2568-0ddf-43cc-a4b8-e152fba13e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa186d22-e1c2-49a0-ad28-4e74d4e93f2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 726c1141-54ec-4f10-a582-dc6ee77ee209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19d97115-c0da-45ae-92a9-833a04eae395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfbc4fc0-aedf-4b28-91c9-a47b2e0d63d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51a9908b-893c-4487-ba70-1bcb9cd60f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63aa119f-675c-432c-9f93-d8b26eef1cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c08a2192-921a-4f1d-b505-79c8e405e43a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f07117f-a613-4fc6-9f08-a1d85b59133c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed492e83-28ea-4046-8ce3-c8980d8b69a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69a44bf4-8bcf-493f-a98a-11a4e61eef37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67d21599-bdf6-40a1-b4ee-5115c3b19f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc6a8435-57d0-4d17-937d-835192824735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42243e79-d5d9-459c-a1ea-f2ce2bbcb0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e431e0c-5b6a-4064-82b1-f61eb2694f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ccac37b-a0d4-4b3b-844d-41b6c35a47c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67f123e8-5548-46f1-bb8f-10a312f40b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81a6dde4-b733-406d-aa7c-e3320bf0bf23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0d70764-01ae-456f-9525-2c5fbcd69a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3cbd5ed-b888-4cad-a1a6-e61946ea7c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fc74327-7156-4eb5-84ff-090e53fd6fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c735ab7-5995-4823-978f-b5ae7177a3b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3d4a8c0-8782-4b30-93c8-63d5da762701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6551c9ac-a974-41f4-b88a-4d67fa212472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd8ed178-24f3-4280-8987-eadc8b1d7512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31319586-27ae-4f2c-bc05-4bcf15fec71d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a9943f4-23f0-4fd8-b4ca-09a76d8a2352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2bf6f3c-12ab-463a-a0d3-5b2cf949eb73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df38e89b-cd1b-40a6-8060-720f90a4c667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19983db7-d4ef-4fc5-ad81-ea53da7a6192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67190227-73e3-4da3-bca7-e25f0a234867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e203b983-f9af-4605-a0b6-db1160e19dad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7b170c9-05cb-4727-a14f-b7f1d6053808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06992f90-5d96-4a8a-a529-db187117ded9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f6f6b6-efe6-406d-887a-8db1dbdda513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 027b5914-b166-465c-9a8a-8bf8c4f68055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d80b1730-b8ec-404d-aecd-89c2ad51bf9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93d3e551-9bbc-43f7-ab3b-c4e75080c244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e452ec31-0d64-496b-a6f4-bae507d016fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a507b73-9d7f-4a22-8ecb-3e3a8f1a8445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37cc22d5-d596-49a8-9cf1-49633d129e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50c351b8-a924-427a-86d3-500b408ac338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1514abc-398b-42ca-ba01-c511698afb4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6316cd4-fb37-45ce-8fe6-ab4b5e1d738c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d795015-4693-4ecf-9762-b35be4877048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 247518d9-1a7b-455b-b7ef-df5ff5034fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44e9fdee-4ed8-47c0-a65c-cf7bee2128ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03be1232-5a8d-44e8-919a-a937c4779384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 522ce15c-ae57-4dda-8134-39dc8254fc8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe56f93d-e0ec-4964-9eb6-be938f9fc8b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3661baa-3de5-40a9-91cc-de578d6b43f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c913c84-d090-41d3-a0a6-ae2a15947f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34123167-60f6-4a45-84fe-5bd7de37040a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c750636f-b09d-490c-af51-44449bfc7717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message effa80ca-5d3d-4906-a206-116f3d2bb8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cebcb86-10da-45d5-9923-253c0f238add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 324b48de-1d91-4eb3-9fc5-00a5cf78c9a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84ac4bb1-d2aa-4bd9-997e-000ed99cb0b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 816a10b1-4657-440d-874e-8856b61994e5
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_52
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_52
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_52/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_52/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_52/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_52/test_labels.txt

📊 Raw data loaded:
   Train: X=(1116, 24), y=(1116,)
   Test:  X=(280, 24), y=(280,)

⚠️  Limiting training data: 1116 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  271 samples, 5 features
✅ Client client_52 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 7 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1135, val=0.0906 (↓), lr=0.001000
   • Epoch   2/100: train=0.0830, val=0.0901, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0821, val=0.0900 (↓), lr=0.001000
   • Epoch   4/100: train=0.0821, val=0.0898, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0819, val=0.0897, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0806, val=0.0884, patience=1/15, lr=0.001000
   • Epoch  21/100: train=0.0755, val=0.0884, patience=8/15, lr=0.001000
   📉 Epoch 22: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 7 Summary - Client client_52
   Epochs: 28/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0387
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0248
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.1669, RMSE: 0.4086, MAE: 0.3271, R²: -1.1400

============================================================
🔄 Round 8 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1278, val=0.0877 (↓), lr=0.000500
   • Epoch   2/100: train=0.0876, val=0.0880, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0845, val=0.0873, patience=2/15, lr=0.000500
   ✓ Epoch   4/100: train=0.0836, val=0.0868 (↓), lr=0.000500
   • Epoch   5/100: train=0.0834, val=0.0870, patience=1/15, lr=0.000500
   📉 Epoch 10: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0828, val=0.0871, patience=7/15, lr=0.000250
   📉 Epoch 18: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 8 Summary - Client client_52
   Epochs: 19/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0038
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0126
============================================================


============================================================
🔄 Round 9 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1548, val=0.1435 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.1150, val=0.0990 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.0898, val=0.0761 (↓), lr=0.000125
   ✓ Epoch   4/100: train=0.0860, val=0.0741 (↓), lr=0.000125
   • Epoch   5/100: train=0.0863, val=0.0753, patience=1/15, lr=0.000125
   📉 Epoch 10: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0860, val=0.0752, patience=7/15, lr=0.000063
   📉 Epoch 18: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 9 Summary - Client client_52
   Epochs: 19/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0010
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0084
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1504, RMSE: 0.3878, MAE: 0.3108, R²: -0.9274

📊 Round 9 Test Metrics:
   Loss: 0.1451, RMSE: 0.3809, MAE: 0.3057, R²: -0.8603

============================================================
🔄 Round 13 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1477, val=0.1577 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.1359, val=0.1439 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.1244, val=0.1317 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.1144, val=0.1209 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.1057, val=0.1114 (↓), lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   ✓ Epoch  11/100: train=0.0855, val=0.0893 (↓), lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0836, val=0.0860, patience=5/15, lr=0.000008
   📉 Epoch 23: LR reduced 0.000008 → 0.000004
   📉 Epoch 31: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0835, val=0.0857, patience=9/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 13 Summary - Client client_52
   Epochs: 37/100 (early stopped)
   LR: 0.000031 → 0.000002 (4 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0042
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0174
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1395, RMSE: 0.3735, MAE: 0.3004, R²: -0.7879

============================================================
🔄 Round 14 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1479, val=0.1538 (↓), lr=0.000002
   📉 Epoch 2: LR reduced 0.000002 → 0.000001
   ✓ Epoch   2/100: train=0.1470, val=0.1530 (↓), lr=0.000001
   • Epoch   3/100: train=0.1464, val=0.1526, patience=1/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1459, val=0.1522 (↓), lr=0.000001
   • Epoch   5/100: train=0.1455, val=0.1518, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1433, val=0.1497, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1403, val=0.1469, patience=1/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1376, val=0.1443 (↓), lr=0.000001
   • Epoch  41/100: train=0.1351, val=0.1420, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1328, val=0.1397, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1305, val=0.1375 (↓), lr=0.000001
   • Epoch  71/100: train=0.1283, val=0.1354, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1261, val=0.1334, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1239, val=0.1313 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_52
   Epochs: 100/100
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.1218, RMSE=0.3490, R²=-0.4863
   Val:   Loss=0.1295, RMSE=0.3599, R²=-0.4011
============================================================


============================================================
🔄 Round 16 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1351, val=0.1319 (↓), lr=0.000001
   • Epoch   2/100: train=0.1348, val=0.1317, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1346, val=0.1315, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1344, val=0.1314 (↓), lr=0.000001
   • Epoch   5/100: train=0.1342, val=0.1312, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1328, val=0.1300, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1306, val=0.1281, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1285, val=0.1262 (↓), lr=0.000001
   • Epoch  41/100: train=0.1263, val=0.1243, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1242, val=0.1224, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1220, val=0.1206 (↓), lr=0.000001
   • Epoch  71/100: train=0.1199, val=0.1188, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1178, val=0.1170, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1158, val=0.1152 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_52
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1135, RMSE=0.3369, R²=-0.3777
   Val:   Loss=0.1137, RMSE=0.3371, R²=-0.2571
============================================================


============================================================
🔄 Round 17 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1256, val=0.1482 (↓), lr=0.000001
   • Epoch   2/100: train=0.1254, val=0.1480, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1252, val=0.1478, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1250, val=0.1475 (↓), lr=0.000001
   • Epoch   5/100: train=0.1248, val=0.1473, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1237, val=0.1459, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1220, val=0.1435, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1202, val=0.1411 (↓), lr=0.000001
   • Epoch  41/100: train=0.1184, val=0.1387, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1166, val=0.1363, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1148, val=0.1338 (↓), lr=0.000001
   • Epoch  71/100: train=0.1130, val=0.1314, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1113, val=0.1290, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1096, val=0.1266 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_52
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1079, RMSE=0.3285, R²=-0.2722
   Val:   Loss=0.1244, RMSE=0.3527, R²=-0.5977
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1065, RMSE: 0.3264, MAE: 0.2684, R²: -0.3657

============================================================
🔄 Round 18 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1138, val=0.1207 (↓), lr=0.000001
   • Epoch   2/100: train=0.1136, val=0.1205, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1134, val=0.1203, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1132, val=0.1201 (↓), lr=0.000001
   • Epoch   5/100: train=0.1130, val=0.1199, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1118, val=0.1186, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1099, val=0.1166, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1081, val=0.1147 (↓), lr=0.000001
   • Epoch  41/100: train=0.1062, val=0.1128, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1045, val=0.1109, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1028, val=0.1091 (↓), lr=0.000001
   • Epoch  71/100: train=0.1011, val=0.1073, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0995, val=0.1056, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0980, val=0.1040 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_52
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0969, RMSE=0.3112, R²=-0.1629
   Val:   Loss=0.1026, RMSE=0.3203, R²=-0.1781
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0947, RMSE: 0.3077, MAE: 0.2562, R²: -0.2135

============================================================
🔄 Round 20 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0962, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0961, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0959, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0958, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0957, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0949, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  21/100: train=0.0938, val=0.0780, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0927, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0917, val=0.0766, patience=6/15, lr=0.000001
   • Epoch  51/100: train=0.0908, val=0.0760, patience=8/15, lr=0.000001
   • Epoch  61/100: train=0.0899, val=0.0755, patience=8/15, lr=0.000001
   • Epoch  71/100: train=0.0892, val=0.0751, patience=7/15, lr=0.000001
   • Epoch  81/100: train=0.0886, val=0.0748, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.0881, val=0.0746, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 20 Summary - Client client_52
   Epochs: 94/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0303
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0005
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2413, R²: -0.0059

📊 Round 20 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2412, R²: -0.0025

============================================================
🔄 Round 25 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 25 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0075
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0098
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2412, R²: -0.0016

============================================================
🔄 Round 27 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 27 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0100
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0044
============================================================


============================================================
🔄 Round 28 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 28 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0113
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0025
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2412, R²: -0.0006

📊 Round 28 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2412, R²: -0.0003

============================================================
🔄 Round 30 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 30 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0122
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0041
============================================================


============================================================
🔄 Round 31 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 31 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0037
   Val:   Loss=0.0953, RMSE=0.3086, R²=-0.0071
============================================================


============================================================
🔄 Round 37 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 37 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0036
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0137
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2412, R²: 0.0008

📊 Round 37 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2412, R²: 0.0009

============================================================
🔄 Round 39 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 39 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0063
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0051
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2412, R²: 0.0010

============================================================
🔄 Round 40 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 40 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0009
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0269
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0011

📊 Round 40 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0012

📊 Round 40 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0013

============================================================
🔄 Round 44 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 44 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0031
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0016
============================================================


============================================================
🔄 Round 46 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 46 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0018
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0062
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0013

📊 Round 46 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0014

📊 Round 46 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0015

📊 Round 46 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0014

📊 Round 46 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0015

============================================================
🔄 Round 59 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 59 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0029
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0536
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0015

📊 Round 59 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0015

📊 Round 59 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0016

📊 Round 59 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0016

============================================================
🔄 Round 65 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 65 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0013
   Val:   Loss=0.0942, RMSE=0.3068, R²=-0.0151
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0016

============================================================
🔄 Round 66 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 66 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0069
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0150
============================================================


============================================================
🔄 Round 67 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 67 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0019
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0012
============================================================


============================================================
🔄 Round 71 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 71 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0001
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0179
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0017

📊 Round 71 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0018

============================================================
🔄 Round 73 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 73 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0020
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0210
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2412, R²: 0.0018

============================================================
🔄 Round 74 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 74 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0018
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0290
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2412, R²: 0.0018

============================================================
🔄 Round 77 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 77 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0003
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0042
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2412, R²: 0.0019

============================================================
🔄 Round 79 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 79 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0037
   Val:   Loss=0.0939, RMSE=0.3065, R²=0.0091
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2412, R²: 0.0019

============================================================
🔄 Round 83 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 83 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0011
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0001
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2412, R²: 0.0019

📊 Round 83 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2412, R²: 0.0019

============================================================
🔄 Round 87 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 87 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0001
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0049
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2412, R²: 0.0019

============================================================
🔄 Round 90 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 90 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0011
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0014
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2412, R²: 0.0020

============================================================
🔄 Round 91 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 91 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0000
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0035
============================================================


============================================================
🔄 Round 92 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 92 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0007
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0020
============================================================


============================================================
🔄 Round 93 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 93 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0014
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0023
============================================================


============================================================
🔄 Round 94 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 94 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0021
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0112
============================================================


============================================================
🔄 Round 95 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 95 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0054
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0008
============================================================


============================================================
🔄 Round 98 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 98 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0006
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0028
============================================================


============================================================
🔄 Round 99 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 99 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0027
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0065
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2412, R²: 0.0020

============================================================
🔄 Round 100 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 100 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0006
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0005
============================================================


============================================================
🔄 Round 102 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 102 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0006
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0368
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2412, R²: 0.0021

📊 Round 102 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2412, R²: 0.0021

📊 Round 102 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 109 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 109 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0006
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0002
============================================================


============================================================
🔄 Round 110 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 110 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0019
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0088
============================================================


============================================================
🔄 Round 112 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 112 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0035
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0022
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

📊 Round 112 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

📊 Round 112 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 117 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 117 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0022
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0078
============================================================


============================================================
🔄 Round 118 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 118 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0009
   Val:   Loss=0.0912, RMSE=0.3019, R²=0.0026
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

📊 Round 118 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 122 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 122 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0004
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0050
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

📊 Round 122 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 125 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 125 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0008
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0038
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

📊 Round 125 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 129 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 129 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0010
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0047
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

📊 Round 129 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 132 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 132 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0014
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0051
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

📊 Round 132 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 134 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 134 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0022
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0204
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0022

============================================================
🔄 Round 136 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 136 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0025
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0097
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0022

============================================================
🔄 Round 138 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 138 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0034
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0010
============================================================


============================================================
🔄 Round 139 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 139 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0022
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0182
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0022

📊 Round 139 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0022

============================================================
🔄 Round 142 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 142 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0019
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0070
============================================================


============================================================
🔄 Round 143 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 143 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0013
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0048
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 145 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 145 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0007
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0048
============================================================


============================================================
🔄 Round 147 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 147 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0022
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0099
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

📊 Round 147 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

📊 Round 147 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 151 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 151 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0031
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0070
============================================================


============================================================
🔄 Round 153 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 153 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0004
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0019
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

📊 Round 153 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 156 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 156 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0027
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0101
============================================================


============================================================
🔄 Round 157 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 157 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0003
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0064
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 158 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 158 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0012
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0089
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 160 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 160 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0048
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0032
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 161 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 161 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0001
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0006
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 162 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 162 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0008
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0021
============================================================


============================================================
🔄 Round 164 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 164 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0008
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0134
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 167 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 167 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0000
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0012
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

📊 Round 167 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 171 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 171 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0022
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0094
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0022

============================================================
🔄 Round 176 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 176 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0035
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0134
============================================================


============================================================
🔄 Round 177 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 177 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0001
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0011
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 178 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 178 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0005
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0005
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 184 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 184 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0029
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0033
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 186 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 186 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0019
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0176
============================================================


============================================================
🔄 Round 187 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 187 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0001
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0034
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

📊 Round 187 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

📊 Round 187 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 191 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 191 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0004
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0068
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 192 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 192 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0042
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0080
============================================================


============================================================
🔄 Round 193 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 193 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0010
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0045
============================================================


============================================================
🔄 Round 194 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 194 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0036
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0195
============================================================


============================================================
🔄 Round 197 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 197 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0017
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0058
============================================================


============================================================
🔄 Round 198 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 198 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0006
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0023
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 199 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 199 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0032
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0122
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

📊 Round 199 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 205 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 205 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0012
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0057
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

📊 Round 205 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 207 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 207 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0014
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0031
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0021

============================================================
🔄 Round 208 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 208 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0017
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0046
============================================================


❌ Client client_52 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
