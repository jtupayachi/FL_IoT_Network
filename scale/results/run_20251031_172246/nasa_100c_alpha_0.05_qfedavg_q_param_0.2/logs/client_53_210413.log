[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0ed58b2-3d76-466d-87a8-9d20b75d86f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec940764-3724-42ad-b6dc-d2b9053941e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fec08b82-2620-4f82-8ebc-fd2c74a23d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73c07d9a-3ec1-453f-bccf-81142f1fc46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc812da8-faa8-4563-a326-0011a65f25f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b9f4aad-e45e-44a1-a8f0-55a81eb24ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaa81e9e-05de-4e35-a2c1-6ae6505d1d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49f4412b-26e3-4245-a161-1e8bdf03cae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 381fae94-ffb0-494d-84f0-14972088a224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cea9e64d-9acd-4447-aa80-9cee3f8367c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99a824ac-915d-4280-999c-811bc231db52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be6fd575-d84a-4109-83a5-14d4d0826539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 467041be-4adb-440e-a8d1-da254170038b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44cfcb98-0213-4742-a461-8544b31c9fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d71dfcd6-70ee-45da-bd64-418448f03fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f260cb78-db04-4609-b47f-ec2cb0bf47e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d54a8d7-2027-4b61-9304-f6fbdaa838f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb3f91f3-1374-4a81-ae44-9a3886585fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc4c932a-5ac0-48c5-9a12-3266fa2504be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77814679-38b9-4ffa-a017-f558c90203bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53c3ea20-f79e-4005-ae67-c475b6f48967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d462d06-9c1f-4164-b808-dccc2d3fb9fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46b9f149-4fd1-4683-9adb-778de50d880a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb6fd4e0-2c21-47ed-a40a-f6b384007a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 621759c4-aeed-4ca7-a7da-34a8a5c2224d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89156328-fc06-4797-b0a3-989d3b8234cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 379a4861-4ebc-43f6-940c-b3baca0a5b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be151a01-4e01-470e-bc27-5fa3877269ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0556b4d-bc11-41f8-8012-74cf2f86319b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa96ebee-e72a-427a-81b4-fc12145c4b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c8e21ac-d750-4379-a1d9-c72da6297682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ce7ffc3-8e05-426f-9678-9b572aa2331a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0022a64-8f08-4339-b9e8-6d425989be74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44a03700-86fe-4a4c-a4bd-5b1ea6a83bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6826ac3-d844-41d8-83b3-c99d94c63e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb7b5990-9d09-4585-9f91-b08c3af70dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a82ee921-2f25-4b10-82cf-411ad84d8d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a003f0b-56a6-4fd2-b817-38885c5c966e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dddc77b4-860f-4afb-a0ac-e5fb586cdc15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6145be76-d31d-43fe-988e-b9cfd4a4750d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e6f1d2c-5d37-4789-8afb-d7a018c50cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 361e4377-1d32-41bc-9c69-5b295ee63795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6774118a-9cc0-4df2-912e-8683c509e88b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8821710e-2d66-4980-a231-c3f6193b04b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a08d600d-bcfe-471f-9447-79e90314f9b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b2585e8-bda5-4dfe-921d-ff524d7a05a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb40101e-4d90-4a0c-a76d-fabf81fc0347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f12ed8c-d8ed-4053-ae6c-574ecbdf8e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b14edc9a-b562-4f00-85b1-8fa8508ab12e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d97eb8c5-ddb7-428c-aba8-7d6d01c28d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6597fe6-7689-4b71-aab7-c2f83b67cdb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fd885cf-e503-4fd4-b0e5-4c26a66ab103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 629e4ba9-0087-4dd7-9a29-8efc1d2ddaa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dea36615-ef53-45ee-8780-4da947ebc355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 337a1283-710e-44d5-8f24-d68c1cf519b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6aaa84f-3335-4223-9454-dc19fef81245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cddd842-f53b-4b14-8b67-a74636772502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bad377d-b300-4ba7-bc3f-fc8f3c30666d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4d6828d-9caf-4e18-8261-1dc56727f170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93787995-3d08-4edd-afc2-e3c31b25d3f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddd60cbe-59b5-4b4f-b4e4-7c5f55d56b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5d29886-e584-4efa-96ea-45335e8d6b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28981eaf-8fe2-4229-8ab5-22e2721fc911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8cdf71f-ac77-41b4-818f-05c475b382eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9dcb938-29a7-4eae-b2d5-a6389febd434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6dca0af-47e9-4474-bc32-01e1bd1602c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14668295-dbb5-4695-a73a-989547be7936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8cb0cac-1cb1-4ba8-a6d1-7e417dc1933e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0e26144-a15f-4622-8b59-7f8981f3cdad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 214972f9-b819-4aa7-ad45-9815d9f4681e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbca81fa-7aad-4744-b7df-d097cde7fecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc08b626-738f-4629-ad69-8c7f0206ca28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0740d6de-32dc-4df3-829f-7a667b8228fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86561eba-9678-4308-823f-1b773f03bb64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84898640-ed5e-4938-aa67-e2c81398a93e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 699f5916-1780-4ed6-9abc-9e7e6ea1b9f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30d9c48b-dc1d-437a-9b70-8bc9873d435f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76c35d1d-4736-4a8c-a2b8-5c94549fcdae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2342c9e7-01a2-423d-ba6e-60e3eed99e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cf654a9-b0ab-4097-b5e6-a754abdf4107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58c629db-c510-4645-8f1c-1249c5c1de59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4be80466-448b-4828-832d-cc2c29b9e9b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1307b849-8400-4440-b729-ca3f6dcd5c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c85643d7-4e1e-4d97-88e8-bc541b293a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d6658b9-90c0-46a9-966e-db01e3709d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd006492-203c-4cbe-a578-413203b9e2c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09b87541-77f8-4250-957d-0ce0109ae6d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8e46b97-0d31-4879-9589-9f4290821278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88942edb-af20-42f1-be05-9e59d06d4268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a3dc473-6469-4ab6-8aef-7853c8860207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0128d6a-74b3-469b-94f7-80f8ea788182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 098cf9b4-3e16-4c07-a616-0483aba364c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 495345ac-1087-4a10-93b0-32cb3c5f264c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcd2811e-e3e3-472f-b5ad-6c3c1d44a7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65b8eab3-3b66-4ca2-bfce-28ed6b8b6802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c03a1de1-f572-4447-8063-d66f16f50734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d43a22f-c191-4b86-9777-c4a5b06c03da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 470c7636-d55f-4e89-bc9e-a197d2d4ce75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c838c934-89be-49cc-a819-b69992195b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed637ec3-87c4-4d07-870f-664d388f4a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c92726b-dee3-4d65-af56-f9a0db0bca45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f769a3f-6c32-439a-8d60-e044aea3d888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bafdb4ad-0734-4fd6-aced-d4597b35d1c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddb1f1ff-6432-4c70-b73a-2ee120e038bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94689572-ec9f-412a-883f-5917bac74a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5a3b0c6-2329-4d25-be66-a73e5a43ca1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 439622cf-5a7b-44bd-8e8f-0981c3d938d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44a9ef5c-3bad-44cb-a820-958ab5197ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7a34fa8-8de2-4441-aec9-bca4c1e29d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 899466ee-c3b9-4a13-9b8f-2b053866c542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1cc9998-0f36-4efe-a4a9-02f5692c3136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 299424bb-6fd2-47dd-8475-5a2bb1bf61c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22f3d760-aa4b-45cd-b3ba-4069be958dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1bb907b-aa45-4df8-bd1a-d155e1e6e6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 718602f0-8f41-42ce-a324-ac611c01254d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b16ea389-778f-4c73-9825-935f667062e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 901da961-f972-45ea-9528-428fa0fdbc88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30601559-6691-4051-a9c5-c83615d53c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dc1c3a6-6fc0-417d-8013-f52546443a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb207975-8409-4504-ad9e-9c4b4e1cc950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c160106-3d52-40d3-babb-e565befb0989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 617cc2ef-03b1-4590-be11-e59b8802adc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b9f1e5b-a5ad-4c9f-83d6-bff70e50ba22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9c25f83-7229-4ac3-8d66-2f0970120a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01ea287d-5a3f-4994-a5b1-dabfbee4bbf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f37bd5de-44fa-43cc-9e75-14743d077c1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2f2117d-2fb5-41aa-a09a-50193852013e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 944b675f-85bd-43d5-a9bc-a1daaa5635e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e71064cd-b1e7-47eb-90b9-07839c35bae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d4e1226-fa4e-4872-a7e6-ac9b87704f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10403b80-2c36-42a5-b0c8-1ea542e2a6e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83cec34e-459b-4860-87bd-1f26dffcd3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e79f066-5c48-42fc-8166-6db79166b6e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c37bf9b0-8cbf-4d67-939f-67b17bad3e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c96d60fa-0fde-46a5-87b3-ab0a1c77a8b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 965dc90b-97e5-4df4-a5af-158b8f47b18b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40934bc1-d201-480e-b541-88311bdbad78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21ffe8cc-9db2-43cf-abe8-4fbf45787a4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbdbca20-43da-487e-b348-778eb4cf2172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76f5fdd2-a1b6-426e-bcf6-3e9e4481150f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85aab254-9b62-44d6-aa14-c5f51c1392ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38504230-8e75-46df-acc5-22e12005085f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da7201d8-4671-4d09-abba-645ca224d782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4b49d5d-1582-4ba1-907e-53bbbcf5773e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3a730f3-a812-431c-9fb5-8ef5bf58a82a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32334dc5-8a6e-4eeb-960d-c770459ca793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0a4ebfb-c02b-466a-9632-bdcc6bc2f5ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb81ed65-316f-4639-92a2-d80771f9365c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d89aabb2-874b-43f4-9b95-d5202b67de5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3bbe70c-1cfd-462e-bc1b-5011ae44e33a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e742cc2-3164-494a-89ae-61b1c713526f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38657abf-2513-48e5-ad69-60a824440358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 571a8101-eb81-46c9-9084-37064b4cefc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d54003f-a90e-4331-978e-369e350318d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eff74f4-f9b3-4833-9857-8fb184b2e899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b5ea574-425b-4664-b54f-d619134cfded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a99090d-3d61-4957-b8ea-e8ce275a04ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4090cca2-dfc8-4418-a1d5-a1527929967e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5733baa5-8aee-4da8-b6d3-796dca551e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47679ae2-e46f-4607-ad1d-0ea9939f7040
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_53
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/test_labels.txt

📊 Raw data loaded:
   Train: X=(1126, 24), y=(1126,)
   Test:  X=(282, 24), y=(282,)

⚠️  Limiting training data: 1126 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  273 samples, 5 features
✅ Client client_53 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 7 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1116, val=0.0841 (↓), lr=0.001000
   • Epoch   2/100: train=0.0831, val=0.0870, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0839, val=0.0904, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0842, val=0.0898, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0838, val=0.0886, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0821, val=0.0867, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 7 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0076
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0049
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.1653, RMSE: 0.4066, MAE: 0.3248, R²: -0.9795

📊 Round 7 Test Metrics:
   Loss: 0.1626, RMSE: 0.4033, MAE: 0.3222, R²: -0.9475

📊 Round 7 Test Metrics:
   Loss: 0.1591, RMSE: 0.3989, MAE: 0.3188, R²: -0.9053

📊 Round 7 Test Metrics:
   Loss: 0.1539, RMSE: 0.3922, MAE: 0.3138, R²: -0.8424

📊 Round 7 Test Metrics:
   Loss: 0.1499, RMSE: 0.3872, MAE: 0.3103, R²: -0.7955

📊 Round 7 Test Metrics:
   Loss: 0.1451, RMSE: 0.3809, MAE: 0.3060, R²: -0.7376

============================================================
🔄 Round 13 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1334, val=0.0821 (↓), lr=0.000250
   • Epoch   2/100: train=0.0870, val=0.0864, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0854, val=0.0789 (↓), lr=0.000250
   • Epoch   4/100: train=0.0844, val=0.0810, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0844, val=0.0802, patience=2/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0840, val=0.0802, patience=8/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 13 Summary - Client client_53
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0012
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0111
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1399, RMSE: 0.3740, MAE: 0.3014, R²: -0.6749

============================================================
🔄 Round 17 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1251, val=0.1076 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1054, val=0.0899 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0906, val=0.0808 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0849, val=0.0793 (↓), lr=0.000063
   • Epoch   5/100: train=0.0844, val=0.0794, patience=1/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0842, val=0.0791, patience=7/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 17 Summary - Client client_53
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0017
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0050
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0983, RMSE: 0.3135, MAE: 0.2655, R²: -0.1769

📊 Round 17 Test Metrics:
   Loss: 0.0897, RMSE: 0.2994, MAE: 0.2585, R²: -0.0737

============================================================
🔄 Round 20 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0920, val=0.0897 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0898, val=0.0867 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.0879, val=0.0844 (↓), lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   ✓ Epoch   4/100: train=0.0865, val=0.0827 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.0858, val=0.0821 (↓), lr=0.000008
   • Epoch  11/100: train=0.0846, val=0.0802, patience=2/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004
   📉 Epoch 20: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0844, val=0.0797, patience=9/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 20 Summary - Client client_53
   Epochs: 27/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0041
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0147
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2548, R²: -0.0182

📊 Round 20 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2538, R²: -0.0077

============================================================
🔄 Round 22 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0828, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  21/100: train=0.0822, val=0.0957, patience=7/15, lr=0.000001
   • Epoch  31/100: train=0.0820, val=0.0952, patience=9/15, lr=0.000001
   • Epoch  41/100: train=0.0819, val=0.0948, patience=9/15, lr=0.000001
   • Epoch  51/100: train=0.0818, val=0.0944, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 22 Summary - Client client_53
   Epochs: 60/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0044
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0458
============================================================


============================================================
🔄 Round 24 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0797, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0851, val=0.0794, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 24 Summary - Client client_53
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0091
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0258
============================================================


============================================================
🔄 Round 25 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 25 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0097
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0245
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2528, R²: -0.0003

============================================================
🔄 Round 26 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 26 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0078
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0280
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2528, R²: 0.0001

============================================================
🔄 Round 27 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 27 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0103
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0112
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2528, R²: 0.0002

============================================================
🔄 Round 29 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 29 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0086
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0256
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2527, R²: 0.0006

📊 Round 29 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2526, R²: 0.0009

📊 Round 29 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2526, R²: 0.0011

📊 Round 29 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2526, R²: 0.0011

============================================================
🔄 Round 39 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 39 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0057
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0170
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2525, R²: 0.0012

============================================================
🔄 Round 45 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 45 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0089
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0000
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2525, R²: 0.0012

============================================================
🔄 Round 46 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 46 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0052
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0120
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2525, R²: 0.0013

📊 Round 46 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2525, R²: 0.0013

============================================================
🔄 Round 52 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 52 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0035
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0416
============================================================


============================================================
🔄 Round 55 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 55 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0079
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0060
============================================================


============================================================
🔄 Round 56 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 56 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0071
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0025
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2525, R²: 0.0013

📊 Round 56 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2525, R²: 0.0013

============================================================
🔄 Round 62 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 62 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0104
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0103
============================================================


============================================================
🔄 Round 63 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 63 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0070
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0012
============================================================


============================================================
🔄 Round 64 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 64 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0078
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0010
============================================================


============================================================
🔄 Round 65 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 65 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0056
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0070
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2525, R²: 0.0014

============================================================
🔄 Round 66 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 66 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0038
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0164
============================================================


============================================================
🔄 Round 70 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 70 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0046
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0102
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2525, R²: 0.0014

📊 Round 70 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2525, R²: 0.0014

📊 Round 70 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

📊 Round 70 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 76 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 76 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0056
   Val:   Loss=0.0708, RMSE=0.2661, R²=-0.0039
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 77 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 77 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0069
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0068
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

📊 Round 77 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 82 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 82 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0078
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0104
============================================================


============================================================
🔄 Round 84 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 84 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0067
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0027
============================================================


============================================================
🔄 Round 86 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 86 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0078
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0038
============================================================


============================================================
🔄 Round 87 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 87 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0063
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0032
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

📊 Round 87 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

📊 Round 87 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 92 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 92 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0041
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0079
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 93 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 93 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0035
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0109
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

📊 Round 93 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 97 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 97 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0038
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0197
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 98 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 98 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0048
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0060
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 100 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 100 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0036
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0093
============================================================


============================================================
🔄 Round 103 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 103 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0059
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0008
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 104 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 104 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0027
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0175
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 105 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 105 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0037
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0093
============================================================


============================================================
🔄 Round 106 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 106 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0066
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0039
============================================================


============================================================
🔄 Round 107 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 107 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0035
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0080
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 111 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 111 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0017
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0335
============================================================


============================================================
🔄 Round 114 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 114 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0035
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0074
============================================================


============================================================
🔄 Round 115 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 115 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0030
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0089
============================================================


============================================================
🔄 Round 116 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 116 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0059
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0030
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 118 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 118 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0029
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0100
============================================================


============================================================
🔄 Round 119 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 119 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0044
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0039
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 121 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 121 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0081
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0042
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

📊 Round 121 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 123 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.1017 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.1016, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.1016, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.1016, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.1016, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.1016, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1017)

============================================================
📊 Round 123 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0017
   Val:   Loss=0.1017, RMSE=0.3188, R²=-0.0118
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

📊 Round 123 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 126 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 126 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0044
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0196
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 128 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 128 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0087
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0038
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 134 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 134 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0032
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0086
============================================================


============================================================
🔄 Round 136 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 136 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0090
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0089
============================================================


============================================================
🔄 Round 137 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 137 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0033
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0074
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 138 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 138 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0059
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0004
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0013

📊 Round 138 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

📊 Round 138 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 144 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 144 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0049
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0013
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 145 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 145 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0075
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0059
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 149 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 149 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0032
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0079
============================================================


============================================================
🔄 Round 151 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 151 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0027
   Val:   Loss=0.0948, RMSE=0.3080, R²=-0.0090
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 152 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 152 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0044
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0046
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

📊 Round 152 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

📊 Round 152 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 156 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 156 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0049
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0025
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

📊 Round 156 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 158 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 158 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0020
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0137
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

📊 Round 158 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 164 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 164 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0024
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0172
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 169 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 169 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0062
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0008
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 170 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 170 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0043
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0020
============================================================


============================================================
🔄 Round 171 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 171 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0036
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0053
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

📊 Round 171 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 181 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 181 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0023
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0120
============================================================


============================================================
🔄 Round 182 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 182 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0005
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0415
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0013

============================================================
🔄 Round 183 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 183 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0025
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0084
============================================================


============================================================
🔄 Round 184 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 184 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0058
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0014
============================================================


============================================================
🔄 Round 185 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 185 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0024
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0192
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

📊 Round 185 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 189 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 189 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0071
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0035
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 191 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 191 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0039
   Val:   Loss=0.0943, RMSE=0.3070, R²=-0.0024
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 193 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 193 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0010
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0276
============================================================


============================================================
🔄 Round 195 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 195 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0017
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0120
============================================================


============================================================
🔄 Round 197 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 197 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0034
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0104
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

📊 Round 197 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 201 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 201 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0024
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0129
============================================================


============================================================
🔄 Round 202 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 202 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0040
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0076
============================================================


============================================================
🔄 Round 203 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 203 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0042
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0031
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0013

============================================================
🔄 Round 205 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 205 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0037
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0027
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 206 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 206 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0030
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0055
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 209 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 209 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0020
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0570
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2524, R²: 0.0014

============================================================
🔄 Round 211 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 211 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0031
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0052
============================================================


❌ Client client_53 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
