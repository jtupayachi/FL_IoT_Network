[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21767529-c1fd-46ce-8ace-216a48aedddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54099e5a-4ff7-43d7-a086-e92dce48a200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 212a0fcd-9789-49d0-9175-a1f0076b4c1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e792a41b-69c9-4be8-8a67-a6aaaa484f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8851d943-d89a-4c9f-b20d-c90a9962154c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f372c9fc-f12a-49eb-9720-018ce6504f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a997ccf-b362-4bd1-8cbe-d0d8aea595cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62997ad0-7c0b-4525-9456-a6a2eae54c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 855b6f0c-b354-485b-8b81-7efb79e33174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80a34a19-1cf8-4bb1-8312-766276b14338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2669b5cb-084f-409e-9aca-63748be1f89a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a925990a-da94-4652-9bfd-67813bd18904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9ad3074-be12-4c6b-9036-cbf80346cb04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72e06d71-7799-4425-a87d-838fa3350326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de0a0d04-7e51-47fd-a9e3-1192619bf9fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cf5223f-e4b2-4f58-adc5-b9b6dcf0a9fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48fd1a15-f83f-4c7e-adb5-603dbd64e1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99d553e3-b2b5-442d-93c3-177b573bbc2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 714bb013-5dcb-4309-ad4b-63d937c15407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7be9a4b-2f5e-42cd-8f4e-42a202acdfc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6b39661-84fe-4894-aec4-109ba8e3499f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faf9dbd0-6189-40ce-9f75-a0fabf490aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9573ccf0-8240-407d-a064-80c543499fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 974368bd-7051-431d-8378-4b0b94e54515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca8f0abb-61af-43f2-9944-f40e45e38cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02c44db7-1dae-47c0-a641-539e3f29a133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efe7a45a-5df5-4c7f-b59d-7bed70b5d555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fc3d41a-c274-409f-983f-a201583fed2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14cc5dab-a778-47d3-ad2e-5259f36a5781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c902c5ea-2f8b-4f6f-b117-de3bd3c92691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5ddf8c6-cf2c-4c9a-bf1a-63a2f602f306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a3bdca3-86c1-4be7-a98e-b606334e66f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f4c1a11-e343-41ef-b8d0-ca76592032ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01835e41-5536-46e6-9030-2a8db41c86b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeeaa20a-142c-4b52-936c-89e24a9c2dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54841c08-30cb-4474-9900-11342cc28708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c5745c3-369a-411e-aae1-c681330b475c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88cd43e-5174-401d-9fff-8323472b8d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7361191c-d2a9-4f63-b8cf-9192807ed981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d20f3bc0-f3ec-4a84-8f91-44a3aa580073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c90e0e5-0d6c-4f41-b01f-c8f967581dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 375d3c83-d2cf-40dd-a1e8-89872af5ecc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1c6135a-02f7-404f-b610-f95f88a2ccee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 596a01f1-170c-440a-a8ed-8d1683127639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bbad668-6f44-4918-82fc-906f5c9eabae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eee2074-6522-4eee-94b6-69dfa0ccf5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62e23bed-bb9a-4ddf-9d73-9377f4d14b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cccf4f95-de3b-4d11-b374-4635ac99400a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 708d55b9-d4c4-4f33-9b4b-f2e2c004ee09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4df9aeac-58b3-47ce-a82b-1a566dbd1dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66102ac8-523d-44b1-8dc8-2e8bbe126dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a44f7416-9e41-42e2-8ff1-34e20e7ec653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24660450-fae8-4c5a-8186-63d0a81ba15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac24fe15-8afe-49cb-b024-a8b0bd79dd3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78fde628-dfc0-40db-beae-f573363757f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eea862ee-b253-4363-97fe-ae4ca7e68fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e4ab430-ba86-4a10-90f1-7baf880a6c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4ae02d5-1e2a-44f0-ab04-64c9207661c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbeb76be-6f2a-4b17-8459-f626c04dc90c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c513d4b-505b-442e-870e-e28f243ff0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c584db6-a257-4a34-af5e-ccf7dee2b3cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88e1105e-961a-4fee-9f28-0eb90d944516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f6d0053-538a-4944-bbb1-64c1add8e761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 585f9b95-77b6-4b95-b061-fb0b8b32ef16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a49e1491-b17f-4041-b551-178e9cfd8fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca8cc79d-d6c7-4a4d-92e7-f2290cfafcb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0acc0469-a06c-4ee2-a776-e7c6e2de5532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ace4944-b620-4c10-84e2-fc801270d880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c9d3997-04d2-4cc6-88d2-65bc34f1e5fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fefe23d-1402-4c06-b67a-4f9489c93b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b3a7ac-5fe7-4cac-a1ed-4148180a7b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58831691-b4df-4534-a5e3-f92aa5c1c7eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a89abfbc-b1f9-481b-8a5a-fc688bcb85f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5803658-0bf9-4b1b-96a7-44d1b9026ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daf45d54-9710-4467-9b74-f7184f75a0a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d4f284b-9c7a-4fe1-973d-627285c68842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d9a723e-4e06-46be-a9bc-74e808e18328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3709fda6-da81-4ad9-80b6-fae912c5a8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a92993ae-dfce-4cd4-83b6-7515e2a1c9cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 928d78bf-0675-42ff-9103-dd49c6d20237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23fa95c8-f178-449a-a38e-9f19e8dc2886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6a19d4e-34e4-4ad2-a64e-fda0a6baad46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4590e961-0691-49dd-8bcc-0c475be9e764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73c9b5d8-b8b3-43aa-b604-865b4cc901e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a888a05d-84a7-4977-957f-f02d11b15370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bb168cb-e031-480b-b0d2-ccd4478a1d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27b52f61-4e36-48f7-8f2f-922887f5e60f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39e5b1d6-0da5-496c-a7fe-63be87bb2482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e6f1701-13d5-4806-9bf0-e62cd1d8425b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f524ef34-422a-4a91-b6a3-6512fb90a7fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd881df6-362b-4951-828b-b21d3d96fee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c8ae134-fe67-4f69-98b2-3271bd913b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7effba48-7104-4434-8058-188f94ddde64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73941afc-f93f-4db0-88bd-cbfa4e34b111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beda8ef0-c266-4566-9e93-ffd21cd91e80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9608a190-5893-4368-a1f9-b69e3ea65c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 057a5547-daee-4490-a3fa-49cda2fb5e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e79c0f94-5de3-4f9e-a3fb-359c4667fa6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3a82733-af86-40da-a839-4ea27e5f4764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e44044b-e8ef-4137-b33a-c39c92e40475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7430f9ae-2eef-48de-b20e-f1b625ce9673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87876fb3-d758-4faf-8727-088c5176fae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ffba059-52f8-4cce-ad85-417d1422a7ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d28eea6-51b7-4921-951a-8594d4f2938a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80f1e489-9d06-4d2d-9c9b-8d3ce146ac56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f17b7941-d449-44fd-837e-7b6f4b6841e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64ef4223-57cd-4af8-a7ff-84426d0bdae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 724bd0e4-b6f5-40cc-b965-7dc2be604db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1531f5e-3248-4475-8a4e-f6853f5c1c6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07c0d8f0-8d66-4106-b4d1-5c7b1fdefd9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8ad370c-75cc-433f-ac62-04ca64899898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53eb0531-f816-4c9c-9bb9-bb621b76323d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f59c56c7-e26b-497b-a3a1-ca7941c7a964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f47b26a-a8c6-48a6-bfc8-f6a6ebbe784a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dad7ed5e-763e-46c9-a860-8f140e0bd674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 251bbfe6-ae6a-409b-932f-5a07562ae48f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdf2d56b-3958-4c3e-b4ff-b0a2136f2ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45dd5f17-a32e-4a08-baba-f02b38f49d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5b3fbbe-472c-48cf-9d7d-0e34b324c290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6b6be82-278b-48f4-a079-b4e20e08b15b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da1714f9-cb9a-4708-af22-037c4b315ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75f699b0-6845-4dab-8314-692552c54186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82e52ca6-6e69-48ac-9b61-97fe8145d880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c9719ec-536a-46e6-9585-16814ff05d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0d074c2-1516-4c83-8134-06641cc6ed3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d0cf8b1-8072-4097-9d92-c516ea7143f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c643259-c96b-4093-a028-d440454b0ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50c48b8b-eeb3-4af9-a977-485dac4f155b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffc29b49-2c85-4edb-9513-4a588815a55e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa9b65af-3844-4333-9eb7-e5fe5b5e2d1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c997dc9-31d2-470c-810a-51c289e63a5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b605c7f6-b7fb-4250-9f85-3be41b1e9165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4dd5f5e-eb23-443a-92c7-5af23190efd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a0c9a77-db1d-4102-9c52-521d5937a595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 185034fe-315f-4f0f-8c0c-4cb1c07987a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb9087cb-b4da-49d7-ae58-cc7f847843b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1efaee1b-1ba3-426f-a063-c070690f3ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 575585f8-6d52-4fba-b62e-2332e981ac04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0e4d440-f867-4510-b0b5-66320c417324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16d1377f-88b0-4390-b6a0-5ef3735f8418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb0720ab-dbdc-4ef0-a87f-100d4910d03c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 136f1903-55ef-4df7-aea2-2b50a8700d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d7419f5-e5f5-4ac4-858a-a4a954803457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84dd61ba-1d0e-43ca-8fbe-cde7b36fac68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 767683e0-1d13-4ded-90ff-60c90302766b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e736e8d-d71d-45d9-b9c7-a705378b4802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 115118da-bb19-419f-a874-7ba518bf34d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eed5b78-4483-468d-9b2b-da012370d58e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c21f24ed-8808-4213-bff6-24739696fe5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c751d5c-0503-4728-b3e6-86192994b099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb8d6747-0110-4f93-a859-a0f02e5d5ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c6e92af-b7ce-4a4f-ba61-0b344ba96b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04769e87-a92a-4d78-bb67-dcd04b3907c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b509ffff-40c6-4b97-9069-91345303e176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 107a0d62-98b9-40e3-952c-f063b99d6298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85a9e244-eaea-44eb-82ac-793f20f86471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d390525-3a44-45bb-a37d-478f7965f264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32d52400-dd2f-4f58-a67e-ec6cb2651f69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deba089e-480b-4622-bcdd-449029f71b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65745126-aeac-4f75-8f47-3f7c627d44e6
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_54
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/test_labels.txt

📊 Raw data loaded:
   Train: X=(3010, 24), y=(3010,)
   Test:  X=(753, 24), y=(753,)

⚠️  Limiting training data: 3010 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  744 samples, 5 features
✅ Client client_54 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1766, RMSE: 0.4202, MAE: 0.3395, R²: -0.9799

============================================================
🔄 Round 8 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1140, val=0.0841 (↓), lr=0.001000
   • Epoch   2/100: train=0.0838, val=0.0840, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0832, val=0.0824 (↓), lr=0.001000
   • Epoch   4/100: train=0.0833, val=0.0824, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0831, val=0.0824, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0822, val=0.0819, patience=8/15, lr=0.001000
   • Epoch  21/100: train=0.0791, val=0.0817, patience=9/15, lr=0.001000
   • Epoch  31/100: train=0.0719, val=0.0793, patience=2/15, lr=0.001000
   📉 Epoch 40: LR reduced 0.001000 → 0.000500
   • Epoch  41/100: train=0.0638, val=0.0819, patience=12/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 8 Summary - Client client_54
   Epochs: 44/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0719, RMSE=0.2681, R²=0.1360
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0269
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1738, RMSE: 0.4169, MAE: 0.3368, R²: -0.9482

============================================================
🔄 Round 9 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1272, val=0.0848 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0849, val=0.0838 (↓), lr=0.000500
   • Epoch   3/100: train=0.0839, val=0.0838, patience=1/15, lr=0.000500
   📉 Epoch 4: LR reduced 0.000500 → 0.000250
   • Epoch   4/100: train=0.0830, val=0.0835, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0830, val=0.0836, patience=3/15, lr=0.000250
   • Epoch  11/100: train=0.0828, val=0.0838, patience=9/15, lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 9 Summary - Client client_54
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0119
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0067
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1700, RMSE: 0.4123, MAE: 0.3332, R²: -0.9060

============================================================
🔄 Round 10 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1584, val=0.1104 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.1144, val=0.0770 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.0893, val=0.0713 (↓), lr=0.000125
   • Epoch   4/100: train=0.0861, val=0.0720, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0856, val=0.0719, patience=2/15, lr=0.000125
   📉 Epoch 9: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0853, val=0.0733, patience=8/15, lr=0.000063
   📉 Epoch 17: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 10 Summary - Client client_54
   Epochs: 18/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0017
   Val:   Loss=0.0713, RMSE=0.2670, R²=-0.0055
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.1551, RMSE: 0.3939, MAE: 0.3193, R²: -0.7392

============================================================
🔄 Round 13 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1503, val=0.1468 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.1385, val=0.1334 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.1269, val=0.1215 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.1168, val=0.1111 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.1081, val=0.1020 (↓), lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   ✓ Epoch  11/100: train=0.0873, val=0.0812 (↓), lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008
   ✓ Epoch  21/100: train=0.0849, val=0.0778 (↓), lr=0.000008
   📉 Epoch 23: LR reduced 0.000008 → 0.000004
   📉 Epoch 31: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0848, val=0.0776, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 13 Summary - Client client_54
   Epochs: 36/100 (early stopped)
   LR: 0.000031 → 0.000002 (4 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0021
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0160
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1496, RMSE: 0.3868, MAE: 0.3141, R²: -0.6771

============================================================
🔄 Round 14 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1537, val=0.1297 (↓), lr=0.000002
   ✓ Epoch   2/100: train=0.1529, val=0.1290 (↓), lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   ✓ Epoch   3/100: train=0.1521, val=0.1284 (↓), lr=0.000001
   • Epoch   4/100: train=0.1515, val=0.1280, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1511, val=0.1277 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1491, val=0.1260 (↓), lr=0.000001
   • Epoch  21/100: train=0.1461, val=0.1236, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1434, val=0.1214 (↓), lr=0.000001
   • Epoch  41/100: train=0.1409, val=0.1194, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1385, val=0.1174, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1362, val=0.1155 (↓), lr=0.000001
   • Epoch  71/100: train=0.1339, val=0.1137, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1317, val=0.1119, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1295, val=0.1101 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_54
   Epochs: 100/100
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.1274, RMSE=0.3569, R²=-0.5318
   Val:   Loss=0.1086, RMSE=0.3295, R²=-0.3336
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1398, RMSE: 0.3739, MAE: 0.3050, R²: -0.5677

============================================================
🔄 Round 15 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1432, val=0.1216 (↓), lr=0.000001
   • Epoch   2/100: train=0.1429, val=0.1214, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1427, val=0.1212, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1425, val=0.1210 (↓), lr=0.000001
   • Epoch   5/100: train=0.1423, val=0.1208, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1409, val=0.1197, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1387, val=0.1178, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1365, val=0.1160 (↓), lr=0.000001
   • Epoch  41/100: train=0.1343, val=0.1142, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1322, val=0.1124, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1300, val=0.1106 (↓), lr=0.000001
   • Epoch  71/100: train=0.1278, val=0.1088, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1257, val=0.1071, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1235, val=0.1053 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_54
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1214, RMSE=0.3484, R²=-0.4499
   Val:   Loss=0.1038, RMSE=0.3221, R²=-0.3020
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1351, RMSE: 0.3676, MAE: 0.3008, R²: -0.5150

📊 Round 15 Test Metrics:
   Loss: 0.1173, RMSE: 0.3425, MAE: 0.2845, R²: -0.3150

============================================================
🔄 Round 18 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1133, val=0.1204 (↓), lr=0.000001
   • Epoch   2/100: train=0.1131, val=0.1202, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1129, val=0.1200, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1127, val=0.1198 (↓), lr=0.000001
   • Epoch   5/100: train=0.1126, val=0.1196, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1115, val=0.1184, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1097, val=0.1163, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1080, val=0.1142 (↓), lr=0.000001
   • Epoch  41/100: train=0.1063, val=0.1122, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1046, val=0.1102, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1029, val=0.1082 (↓), lr=0.000001
   • Epoch  71/100: train=0.1013, val=0.1063, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0997, val=0.1043, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0982, val=0.1025 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_54
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0971, RMSE=0.3115, R²=-0.1613
   Val:   Loss=0.1009, RMSE=0.3176, R²=-0.2476
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0965, RMSE: 0.3107, MAE: 0.2662, R²: -0.0823

📊 Round 18 Test Metrics:
   Loss: 0.0915, RMSE: 0.3025, MAE: 0.2618, R²: -0.0256

============================================================
🔄 Round 23 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 23 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0127
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0267
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0898, RMSE: 0.2996, MAE: 0.2605, R²: -0.0065

============================================================
🔄 Round 27 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 27 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0122
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0028
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0897, RMSE: 0.2994, MAE: 0.2604, R²: -0.0051

============================================================
🔄 Round 28 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 28 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0130
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0082
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2604, R²: -0.0048

============================================================
🔄 Round 29 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 29 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0078
   Val:   Loss=0.0967, RMSE=0.3109, R²=-0.0115
============================================================


============================================================
🔄 Round 30 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 30 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0127
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0066
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0896, RMSE: 0.2993, MAE: 0.2604, R²: -0.0044

📊 Round 30 Test Metrics:
   Loss: 0.0896, RMSE: 0.2993, MAE: 0.2603, R²: -0.0041

📊 Round 30 Test Metrics:
   Loss: 0.0896, RMSE: 0.2993, MAE: 0.2603, R²: -0.0039

============================================================
🔄 Round 35 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 35 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0058
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0098
============================================================


============================================================
🔄 Round 36 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 36 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0024
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0314
============================================================


============================================================
🔄 Round 37 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 37 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0093
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0003
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0895, RMSE: 0.2992, MAE: 0.2603, R²: -0.0035

============================================================
🔄 Round 40 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 40 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0073
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0011
============================================================


============================================================
🔄 Round 41 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 41 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0019
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0200
============================================================


============================================================
🔄 Round 42 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 42 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0078
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0028
============================================================


============================================================
🔄 Round 43 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 43 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0003
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0444
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0895, RMSE: 0.2992, MAE: 0.2603, R²: -0.0033

📊 Round 43 Test Metrics:
   Loss: 0.0895, RMSE: 0.2992, MAE: 0.2603, R²: -0.0033

============================================================
🔄 Round 49 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 49 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0082
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0004
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2603, R²: -0.0032

📊 Round 49 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2603, R²: -0.0032

============================================================
🔄 Round 52 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 52 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0087
   Val:   Loss=0.0891, RMSE=0.2986, R²=0.0085
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2603, R²: -0.0031

📊 Round 52 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2603, R²: -0.0031

============================================================
🔄 Round 56 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 56 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0074
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0001
============================================================


============================================================
🔄 Round 58 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 58 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0055
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0021
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2603, R²: -0.0031

============================================================
🔄 Round 61 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 61 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0054
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0038
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2603, R²: -0.0030

============================================================
🔄 Round 62 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 62 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0012
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0213
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2603, R²: -0.0030

📊 Round 62 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2603, R²: -0.0030

============================================================
🔄 Round 64 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 64 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0064
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0014
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2603, R²: -0.0030

============================================================
🔄 Round 66 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 66 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0043
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0047
============================================================


============================================================
🔄 Round 67 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 67 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=-0.0025
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0108
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2603, R²: -0.0029

📊 Round 67 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2603, R²: -0.0029

============================================================
🔄 Round 72 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 72 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0034
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0073
============================================================


============================================================
🔄 Round 76 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 76 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0008
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0213
============================================================


============================================================
🔄 Round 77 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 77 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0029
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0072
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2603, R²: -0.0027

============================================================
🔄 Round 82 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 82 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0039
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0046
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2603, R²: -0.0027

📊 Round 82 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2603, R²: -0.0027

============================================================
🔄 Round 84 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 84 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0008
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0240
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2603, R²: -0.0027

============================================================
🔄 Round 85 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 85 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0034
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0050
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2603, R²: -0.0027

============================================================
🔄 Round 86 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 86 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0016
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0161
============================================================


============================================================
🔄 Round 87 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 87 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0089
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0029
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2603, R²: -0.0026

📊 Round 87 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2603, R²: -0.0026

📊 Round 87 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2603, R²: -0.0026

============================================================
🔄 Round 92 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 92 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0071
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0016
============================================================


============================================================
🔄 Round 94 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 94 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0004
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0263
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0026

============================================================
🔄 Round 96 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 96 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0013
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0113
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0026

📊 Round 96 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0026

============================================================
🔄 Round 99 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 99 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0053
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0022
============================================================


============================================================
🔄 Round 100 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 100 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2909, R²=-0.0082
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0030
============================================================


============================================================
🔄 Round 101 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 101 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0017
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0098
============================================================


============================================================
🔄 Round 102 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 102 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0052
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0033
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0025

============================================================
🔄 Round 103 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 103 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0057
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0026
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0025

📊 Round 103 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0025

============================================================
🔄 Round 105 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 105 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0049
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0040
============================================================


============================================================
🔄 Round 106 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 106 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0010
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0177
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0025

============================================================
🔄 Round 108 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 108 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0082
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0163
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0024

============================================================
🔄 Round 112 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 112 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0030
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0045
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0024

============================================================
🔄 Round 115 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 115 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0025
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0095
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0024

📊 Round 115 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0024

📊 Round 115 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0024

============================================================
🔄 Round 120 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 120 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0018
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0077
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0024

============================================================
🔄 Round 122 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 122 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0013
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0089
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0024

📊 Round 122 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0024

============================================================
🔄 Round 125 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 125 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0038
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0026
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0023

📊 Round 125 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0023

============================================================
🔄 Round 129 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 129 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0054
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0044
============================================================


============================================================
🔄 Round 131 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 131 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0010
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0143
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0023

📊 Round 131 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0023

============================================================
🔄 Round 139 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 139 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0002
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0267
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0023

📊 Round 139 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0022

📊 Round 139 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0022

============================================================
🔄 Round 144 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 144 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0048
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0034
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0022

============================================================
🔄 Round 150 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 150 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0040
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0025
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0022

============================================================
🔄 Round 152 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 152 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0041
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0027
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0022

📊 Round 152 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0022

============================================================
🔄 Round 154 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 154 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0039
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0091
============================================================


============================================================
🔄 Round 155 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 155 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0003
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0165
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0022

📊 Round 155 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0022

============================================================
🔄 Round 159 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 159 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0048
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0057
============================================================


============================================================
🔄 Round 161 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 161 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0002
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0221
============================================================


============================================================
🔄 Round 164 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 164 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0045
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0040
============================================================


============================================================
🔄 Round 166 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 166 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0011
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0216
============================================================


============================================================
🔄 Round 167 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 167 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0019
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0054
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0021

============================================================
🔄 Round 174 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 174 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0035
   Val:   Loss=0.0941, RMSE=0.3068, R²=0.0015
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0021

📊 Round 174 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0021

📊 Round 174 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0021

============================================================
🔄 Round 182 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 182 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0017
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0069
============================================================


============================================================
🔄 Round 184 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 184 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0033
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0026
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0021

============================================================
🔄 Round 187 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 187 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0033
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0028
============================================================


============================================================
🔄 Round 188 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 188 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0010
   Val:   Loss=0.0765, RMSE=0.2767, R²=-0.0103
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0021

📊 Round 188 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0020

📊 Round 188 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0020

============================================================
🔄 Round 193 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 193 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0065
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0112
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0020

📊 Round 193 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0020

============================================================
🔄 Round 200 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 200 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0022
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0027
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0020

📊 Round 200 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0020

📊 Round 200 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0020

📊 Round 200 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0020

============================================================
🔄 Round 205 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 205 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0035
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0016
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0020

============================================================
🔄 Round 206 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 206 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0033
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0011
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0020

📊 Round 206 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0020

============================================================
🔄 Round 209 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 209 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0067
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0022
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2603, R²: -0.0020

============================================================
🔄 Round 211 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 211 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0046
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0021
============================================================


❌ Client client_54 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
