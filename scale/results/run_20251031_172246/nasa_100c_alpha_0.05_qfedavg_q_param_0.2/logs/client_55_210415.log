[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac17e86c-78cc-4839-8ee9-c1bcc880913d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fe1f1fd-0d3b-4004-9646-c75d18a90a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c364b94f-68a1-46c2-81ad-f74ec4af30e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaebc5ce-5186-4ce5-ab69-7b363e52e207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eccd8072-6ab7-41e5-9efa-f1956a1e88da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6301e8fe-4509-4b36-a065-4a0d772fd6ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca50a290-04cc-43b2-bf62-820b3dce4202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22997d84-6c07-4973-bdb6-be0760ebeab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c98829-fbd0-4d02-b72d-15281b8acbd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cd1a3c1-5a43-4dce-8170-e514e3ad4dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eb7ed62-fea0-4f03-8584-f8547ce9ace9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14e478c6-dc20-4b6c-87ea-ab2a600a9a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb579f29-ae04-4939-9edb-eb7b815d43d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e69ac364-c524-4d06-8878-56feac4e6eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 740929c3-b0cc-4f7a-9d17-e1052962477e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c488ae13-7322-4439-b014-cb9ca49b1299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb11981d-bb5f-4dfe-92b6-a22b201f570f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0dede79-2264-454c-8b40-feee41fa1635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37e8400a-c137-4fc9-9c19-a618654aab64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5302c6d0-a864-4807-a09f-5cdae366b56a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a5e2843-d6e9-4790-8e99-fd07beeeb451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bb22703-588f-44bc-9851-35922c8af757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 176f61e6-a96a-4361-97a0-377ca8d7d9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f272748-a0fd-4a5b-a54f-5ab8de19eaca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 263aa977-bb51-4e26-ac03-5fdc86668533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed0cff9a-1df1-4eb9-a4e6-e42a4d3d21d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 615fa2ba-ef59-4b20-92c8-09eb1c596d5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 913cf5f8-9e4e-4869-bb55-dc8dea69df07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47adb91a-7c0b-4bc1-901d-612202a8690e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1b21f1a-e4f0-41ae-871d-c079557164cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 419730bf-33fe-4298-a260-8f4dfa74067c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 195c54d6-548d-400b-acc0-2649d8ed3163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4191bc8a-240a-499b-961b-b2a52af13f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c07cecae-f303-4a7e-83c8-3457027d5708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8883d19-c78a-4662-b278-f054186c180b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 048b4a9a-7dc4-4544-87ed-83ad4277ae9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4eaca69-775e-4427-895b-310afb736c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71905373-78cd-442a-a2fb-e792f0e97229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c293fa0-36f0-4eca-8e63-a199a3ecdfdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2825bf82-c4e9-482b-b137-04be5b913fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e9470c4-d246-412c-a0e2-92189850ee3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8be14e67-f19b-4df8-9a76-f073aed1f94a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deffa8e0-7272-4e0f-bc38-dce1d42c10a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b611011-e4ed-46ad-a893-9d3d17b3fa94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 640bb94d-ea6e-4810-9e99-40e17256166a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad907cf7-1daa-4604-aaf1-3fc90080b0fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c57ef36c-93e6-4fd2-8fdf-2626e1406b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a307719d-dbe9-424b-97ca-9fcfc16225fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3402fc93-e2c2-4eea-a021-9cfc3d665ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bf01355-ab1d-4491-bd1f-553647b5748b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 853dc666-27d5-4939-8c12-336749be366e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9005288-965d-4018-8f7a-60e8ebaa09cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6114d40-0a12-49f5-9b9d-9b73fa90bc56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cbae68f-e0d1-408f-8907-b30756d317ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c611ab2-7263-4c8e-82aa-00657b93c03c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95250700-bc2b-47f2-a746-9ab1324eae88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69a37776-4615-48f3-af8e-b912472a7d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e82b7ca3-aab2-4e03-8e0d-18cfaf9579f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82dd5612-8f23-4804-9df2-8ec466b7996b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 047e2460-dd9c-468c-a859-eb0a69cc63cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 414f4085-5b66-46ce-a1f0-4569e923b7de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f915c8c0-9206-4c4c-ab32-e5dda9857fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ffdd2dc-bdba-4b18-a7e5-8bd63144c4d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 704b1b27-a833-4933-8786-bc434798cae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b006909-68f9-4028-9c7a-d78182f06efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f8bab86-c38c-4e0d-8d20-98e4ee7137f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd678585-3bd0-449d-bbe2-500157713f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69ebcddb-1487-4be2-bc9e-cc8f015e5ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af6ae7fd-e156-42c0-b0d8-a97bf393b0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f3263a-ea46-4f9b-b167-ee440b489397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6150955-71bc-462e-88e7-1dd7c1775ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a053e6dc-d3ce-4f24-b5d6-5a131fbb6de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d574fcc0-fced-481e-b1fa-2d63b7c23ed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc750a34-fd17-45b7-b184-7cd097c6964a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25586c87-bfc5-48e6-b90f-7f824e470d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6a981c5-99ed-4e05-a783-477a79920578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a843b9c7-f3c4-46d6-9817-07e943f69f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd6c7de4-2647-4b8f-9e37-efd426b7111c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 010a5549-0a28-4370-a0d7-145427749d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4bc9912-570a-4906-883f-5e8899df4c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bce41cb-2f90-4c01-9326-c012f342a11f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a403cfe2-5337-4a86-97a6-c0c3c1cfd376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c170491-f42a-4adf-b975-8b2032ff38e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 435f84e1-8f0e-44de-80d7-51c8440bd920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a587d2d-5f90-4c64-9b1f-2a0e0b265c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be834ea7-4baf-4625-92ac-2ddcdd8a269a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1172f6c0-c7b5-4fa0-bb1a-134dd5b81b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c18eaaf-aef1-4256-ba2a-c06dca916e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f17a00ee-1a60-435e-8c5f-3e6b9e6fdbdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35081ca8-b3e1-4936-a5de-1ad735dab542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f58be21b-fefe-4fec-8349-06497c3733f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac066aad-be01-468d-b254-324c9fa063bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611f9a78-49e5-4f3f-9cf5-e563c3b95fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b041ef9-6ab8-4386-854a-5b8649922a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3679360d-48e7-4bcb-ab02-b85409e97e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f175c562-690e-428a-8981-3583f7cc5f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85011c22-34e7-4a2d-a394-00e797eaee42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47e5ddfe-d721-4c48-8ef3-1918fd146b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70bb2f14-c14b-46e5-83d3-de180da3d4b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 022d04a1-c092-412f-9b36-490d33f3484c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08109f06-8c4b-4f43-bb5e-281f6ff12a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a0c85ec-e19c-43db-8c1f-677d9cab99ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c5550b1-65bc-477e-8658-fe69327e8173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4624e765-9225-44a7-a96a-3e250d8c2f5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d95c678c-27e2-4b75-a414-a016f483b650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c4c93ba-d570-4394-9bc1-17b023543c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01b1718d-f039-4342-b6c1-bdaa6e6929bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7349013e-32a6-443e-8c9a-21d488c15ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c49ca64-7e8b-42c4-a4e5-ea911d06c9be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64160f12-1a71-47d2-bca4-a043811f2e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf6fdb97-3aca-430b-aeef-feb951d1114d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5f50f7f-5c21-499d-a428-f46d4a254253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 643fa0aa-adc1-4fcb-9505-9cba484a7e05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68a9b976-8387-42dc-8aef-fdc361a15dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 833e3126-fb7a-48f9-bdee-1d166a3f1db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8707369-6efe-4a25-a6c5-82ef5a163166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b126ad4-3e57-4a9b-9e67-b9395a1e0b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 340e2327-bfe7-4eb7-be91-fe80dd4517d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c784b7a3-65ef-4cae-8c66-d2681898516d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56e9615b-a3a7-4133-8df8-f3f46b09951d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24efeb70-34e5-4173-b425-72f9e71eeb40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37130d68-64b4-4e58-a5ed-5a4eda7adfca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6493a8bd-2660-49ea-96df-ae925c3972ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8718689b-edd1-4876-a44e-638d51d81dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 519ee5e2-a91f-47bc-820a-6311ea06f582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29aac45e-6300-4800-99c2-bb8258a95a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 032de0f6-cc45-443e-8f78-015d17a50813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebecb8ca-65c4-462c-adc2-eaef2345aed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee043fda-e3f4-4e62-a88b-f5012e59ea0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 469a7d4b-4982-4060-b8ba-017aa6abcc4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 438b00e7-57c8-4d57-a209-dcbc8914577e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b6c2c3e-b95a-40d3-931f-eacff917dcd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff851ab2-77ea-447b-802e-ac5e20b54c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ecac7da-79cf-43b9-984d-c880fb16189b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c05041bd-9e9b-4a2c-8e4b-29c326ded1ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 808bdf7a-3fc6-4e4a-ac33-c2203b9a4e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04203619-b521-42c0-90bd-b36cc3814d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 778e95fc-b753-4b72-9b5b-f68a7a60d1ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f52e71e-cfb4-4f6b-af5c-9c9385badb27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 409d2e98-4cfd-4a65-a773-2a029405a821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b0fe4a2-4642-4455-a922-201018cd53db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6e3fbb7-7245-4a1e-ae13-dc428e41b13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3fed5c8-ed5f-46a6-9e1a-a14d7159158d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a00a6dbb-e95c-4d9e-adfc-eeb0a09a8b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4e93ff0-3242-4c39-b2c9-c343f5dd6817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4ddcc08-52f6-473c-a950-57189f90f953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a1cbb36-1d86-4032-8fdc-134bce9f6adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4d2b699-e78c-405b-a2de-d1296bbb0c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c230c47-a304-41c7-9dac-3373cb0f25e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b248ceb-3bd7-42c4-9111-46332e12fc64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab0728be-54a2-4bf1-b56e-b9f8d0828bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c09b54e-5b90-465c-95c1-83e939a928aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c8ebe55-bb02-407c-8255-1cd94be128e1
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_55
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_55
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_55/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_55/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_55/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_55/test_labels.txt

📊 Raw data loaded:
   Train: X=(1940, 24), y=(1940,)
   Test:  X=(486, 24), y=(486,)

⚠️  Limiting training data: 1940 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  477 samples, 5 features
✅ Client client_55 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 9 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1076, val=0.0768 (↓), lr=0.001000
   • Epoch   2/100: train=0.0850, val=0.0765, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0831, val=0.0778, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0833, val=0.0772, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0831, val=0.0772, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0824, val=0.0774, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 9 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0003
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0124
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1644, RMSE: 0.4054, MAE: 0.3336, R²: -0.9218

============================================================
🔄 Round 12 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1319, val=0.0933 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0869, val=0.0854 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0824, val=0.0816 (↓), lr=0.000250
   • Epoch   4/100: train=0.0816, val=0.0822, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0815, val=0.0823, patience=2/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0812, val=0.0824, patience=8/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 12 Summary - Client client_55
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0016
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0077
============================================================


============================================================
🔄 Round 13 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1366, val=0.1394 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1164, val=0.1174 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0991, val=0.1005 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0875, val=0.0899 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0823, val=0.0859 (↓), lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0809, val=0.0850, patience=5/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0808, val=0.0849, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 13 Summary - Client client_55
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0011
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0145
============================================================


============================================================
🔄 Round 14 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.1405, val=0.1342 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1366, val=0.1314 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1339, val=0.1286 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1313, val=0.1261 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1288, val=0.1237 (↓), lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1175, val=0.1129 (↓), lr=0.000004
   📉 Epoch 17: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.1102, val=0.1058 (↓), lr=0.000002
   📉 Epoch 25: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.1074, val=0.1030 (↓), lr=0.000001
   • Epoch  41/100: train=0.1055, val=0.1011, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1038, val=0.0993, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1021, val=0.0976 (↓), lr=0.000001
   • Epoch  71/100: train=0.1005, val=0.0959, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0990, val=0.0944 (↓), lr=0.000001
   • Epoch  91/100: train=0.0975, val=0.0929, patience=2/15, lr=0.000001

============================================================
📊 Round 14 Summary - Client client_55
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0960, RMSE=0.3098, R²=-0.1574
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.1829
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1376, RMSE: 0.3710, MAE: 0.3077, R²: -0.6091

📊 Round 14 Test Metrics:
   Loss: 0.1335, RMSE: 0.3653, MAE: 0.3036, R²: -0.5604

📊 Round 14 Test Metrics:
   Loss: 0.1184, RMSE: 0.3441, MAE: 0.2887, R²: -0.3844

============================================================
🔄 Round 19 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0969, val=0.0999 (↓), lr=0.000001
   • Epoch   2/100: train=0.0967, val=0.0997, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0966, val=0.0996, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.0964, val=0.0994 (↓), lr=0.000001
   • Epoch   5/100: train=0.0963, val=0.0992, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.0954, val=0.0982, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0940, val=0.0966, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0927, val=0.0951, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0915, val=0.0936, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0903, val=0.0922, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0893, val=0.0909, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.0883, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0873, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0865, val=0.0875, patience=4/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_55
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0432
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0889
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0953, RMSE: 0.3086, MAE: 0.2657, R²: -0.1138

📊 Round 19 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2592, R²: -0.0416

📊 Round 19 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2570, R²: -0.0155

============================================================
🔄 Round 24 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 24 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0037
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0153
============================================================


============================================================
🔄 Round 26 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 26 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0025
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0078
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0865, RMSE: 0.2940, MAE: 0.2566, R²: -0.0109

📊 Round 26 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2566, R²: -0.0108

📊 Round 26 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2564, R²: -0.0087

📊 Round 26 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2564, R²: -0.0083

============================================================
🔄 Round 35 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 35 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0055
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0178
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2563, R²: -0.0075

📊 Round 35 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2563, R²: -0.0073

📊 Round 35 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2563, R²: -0.0071

============================================================
🔄 Round 41 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 41 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0051
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0214
============================================================


============================================================
🔄 Round 42 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 42 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0010
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0041
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2562, R²: -0.0067

============================================================
🔄 Round 46 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 46 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0005
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0109
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2562, R²: -0.0066

📊 Round 46 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2562, R²: -0.0065

============================================================
🔄 Round 48 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 48 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0030
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0030
============================================================


============================================================
🔄 Round 50 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 50 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0016
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0010
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2562, R²: -0.0062

============================================================
🔄 Round 52 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 52 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0023
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0025
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0861, RMSE: 0.2933, MAE: 0.2562, R²: -0.0062

📊 Round 52 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2562, R²: -0.0063

📊 Round 52 Test Metrics:
   Loss: 0.0861, RMSE: 0.2933, MAE: 0.2562, R²: -0.0062

============================================================
🔄 Round 58 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 58 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0027
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0038
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2562, R²: -0.0061

============================================================
🔄 Round 61 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 61 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0028
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0008
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2561, R²: -0.0059

📊 Round 61 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2561, R²: -0.0058

============================================================
🔄 Round 68 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 68 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0012
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0144
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2561, R²: -0.0057

============================================================
🔄 Round 69 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 69 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0002
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0066
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0055

============================================================
🔄 Round 72 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 72 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0019
   Val:   Loss=0.0714, RMSE=0.2672, R²=-0.0114
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0054

============================================================
🔄 Round 73 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 73 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0011
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0032
============================================================


============================================================
🔄 Round 74 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 74 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0002
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0079
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0053

============================================================
🔄 Round 76 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 76 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0018
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0057
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0052

📊 Round 76 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0051

============================================================
🔄 Round 78 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 78 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0013
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0025
============================================================


============================================================
🔄 Round 79 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 79 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0022
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0001
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0859, RMSE: 0.2932, MAE: 0.2560, R²: -0.0050

📊 Round 79 Test Metrics:
   Loss: 0.0859, RMSE: 0.2932, MAE: 0.2560, R²: -0.0050

============================================================
🔄 Round 84 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 84 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0009
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0022
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0859, RMSE: 0.2932, MAE: 0.2560, R²: -0.0050

📊 Round 84 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0051

📊 Round 84 Test Metrics:
   Loss: 0.0859, RMSE: 0.2932, MAE: 0.2560, R²: -0.0050

📊 Round 84 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2560, R²: -0.0048

============================================================
🔄 Round 92 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 92 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0002
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0055
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2560, R²: -0.0047

============================================================
🔄 Round 94 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 94 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0009
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0019
============================================================


============================================================
🔄 Round 95 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 95 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0014
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0004
============================================================


============================================================
🔄 Round 96 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 96 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0022
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0012
============================================================


============================================================
🔄 Round 99 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 99 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0012
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0046
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2560, R²: -0.0045

============================================================
🔄 Round 101 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 101 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0009
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0037
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2560, R²: -0.0045

📊 Round 101 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2560, R²: -0.0043

============================================================
🔄 Round 108 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 108 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0018
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0140
============================================================


============================================================
🔄 Round 110 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 110 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0005
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0137
============================================================


============================================================
🔄 Round 111 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 111 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0011
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0014
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2559, R²: -0.0041

============================================================
🔄 Round 114 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 114 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0011
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0005
============================================================


============================================================
🔄 Round 115 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 115 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0017
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0037
============================================================


============================================================
🔄 Round 117 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 117 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0014
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0007
============================================================


============================================================
🔄 Round 120 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 120 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0007
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0019
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2559, R²: -0.0041

============================================================
🔄 Round 121 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 121 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0008
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0020
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2559, R²: -0.0040

============================================================
🔄 Round 123 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 123 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0014
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0009
============================================================


============================================================
🔄 Round 125 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 125 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0024
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0043
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2559, R²: -0.0040

============================================================
🔄 Round 129 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 129 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0014
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0030
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2559, R²: -0.0039

============================================================
🔄 Round 130 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 130 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0009
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0025
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2559, R²: -0.0039

============================================================
🔄 Round 132 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 132 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0017
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0218
============================================================


============================================================
🔄 Round 133 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 133 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0006
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0042
============================================================


============================================================
🔄 Round 134 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 134 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0002
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0035
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2559, R²: -0.0038

============================================================
🔄 Round 137 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 137 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0009
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0106
============================================================


============================================================
🔄 Round 138 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 138 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0005
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0065
============================================================


============================================================
🔄 Round 139 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 139 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0005
   Val:   Loss=0.0809, RMSE=0.2843, R²=-0.0024
============================================================


============================================================
🔄 Round 141 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 141 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0006
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0030
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2559, R²: -0.0038

============================================================
🔄 Round 145 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 145 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0028
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0047
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2559, R²: -0.0039

============================================================
🔄 Round 147 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 147 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0005
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0065
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2559, R²: -0.0038

📊 Round 147 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2559, R²: -0.0039

📊 Round 147 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2559, R²: -0.0038

📊 Round 147 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2559, R²: -0.0039

============================================================
🔄 Round 154 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 154 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0001
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0035
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2559, R²: -0.0039

📊 Round 154 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2559, R²: -0.0038

============================================================
🔄 Round 156 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 156 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0004
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0076
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2559, R²: -0.0038

📊 Round 156 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2559, R²: -0.0038

📊 Round 156 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2559, R²: -0.0038

============================================================
🔄 Round 159 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 159 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0009
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0149
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2559, R²: -0.0037

============================================================
🔄 Round 160 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 160 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0030
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0067
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2559, R²: -0.0037

============================================================
🔄 Round 163 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 163 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0002
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0076
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2559, R²: -0.0037

📊 Round 163 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2559, R²: -0.0036

============================================================
🔄 Round 169 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 169 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0020
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0033
============================================================


============================================================
🔄 Round 170 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 170 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0041
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0229
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2559, R²: -0.0035

📊 Round 170 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2559, R²: -0.0034

============================================================
🔄 Round 172 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 172 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0022
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0046
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2558, R²: -0.0034

============================================================
🔄 Round 173 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 173 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0008
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0133
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2558, R²: -0.0034

============================================================
🔄 Round 175 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 175 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0003
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0163
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2558, R²: -0.0034

============================================================
🔄 Round 176 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 176 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0009
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0028
============================================================


============================================================
🔄 Round 177 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 177 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0016
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0019
============================================================


============================================================
🔄 Round 178 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 178 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0026
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0036
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2559, R²: -0.0035

============================================================
🔄 Round 180 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 180 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0016
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0034
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2558, R²: -0.0034

============================================================
🔄 Round 181 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 181 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0015
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0124
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2558, R²: -0.0034

📊 Round 181 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2558, R²: -0.0034

📊 Round 181 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2559, R²: -0.0034

📊 Round 181 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2558, R²: -0.0034

============================================================
🔄 Round 186 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 186 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0006
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0091
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2559, R²: -0.0035

============================================================
🔄 Round 190 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 190 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0014
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0200
============================================================


============================================================
🔄 Round 196 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 196 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0012
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0010
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2559, R²: -0.0034

============================================================
🔄 Round 201 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 201 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0010
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0001
============================================================


============================================================
🔄 Round 203 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 203 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0006
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0086
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2558, R²: -0.0033

📊 Round 203 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2558, R²: -0.0033

============================================================
🔄 Round 207 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 207 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=-0.0004
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0030
============================================================


============================================================
🔄 Round 208 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 208 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0011
   Val:   Loss=0.0697, RMSE=0.2640, R²=-0.0145
============================================================


============================================================
🔄 Round 209 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 209 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0018
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0032
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2558, R²: -0.0033

❌ Client client_55 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
