[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dce0d9da-989a-4990-9b09-b0fd63c67dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdd8b772-3ae8-4b76-9f69-39433e5f6a43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d03ce57-e6f7-49e0-8dc1-a63c915a6eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 035c9578-4d47-4952-8261-dd1d809f2a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d617f23e-ee44-45c2-b2a0-8617f31592ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03ee72ca-d278-46fd-8852-60b450064f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6ce5813-55f9-45ea-8db6-ef79ae0a584e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b28c3ac8-73e1-4c7e-809d-7333aa4d1421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66d2f44d-bd44-46bd-add5-d1a7a7f474df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7856a564-52fa-49e3-8003-8f7a84f51276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f65deb55-1ea5-41f7-a5e8-bca0cdcabd70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cba26737-8b3f-48e5-80ae-cf5d532ecef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb24fcf1-fd6d-47ef-8b20-92cefc3c9b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 087e0705-17e5-44c8-a3cd-391eae52e62e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e082f485-b1dc-45e4-a4ed-9ba869609a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d3723b4-8f5e-402d-8161-8f9e0f4064b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2a37e10-1229-4af8-914f-94f7a9f46ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14fe7c5b-73e8-4674-a237-f428ff32a1a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6151ad0e-607b-47cb-a7e3-16a9ff9e8da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c012e09-6b1d-4947-89ef-63187e5be0b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a03943-5cf3-4b2e-9a21-2e020609dab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 316021a1-d25c-4f78-91dd-ae3cea99ec1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d77f9da7-f52a-4c9d-a20a-74076392a6e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 104594f2-156f-44b8-b504-81a28f622fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62c0f887-c4ba-4787-b67f-7dc69d2b4d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d30a871-526d-499e-b740-8cb1e1cbca66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39f414a0-539e-4b47-a78e-55faa9b106fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b6b0d3d-873d-4438-a620-1b35815a2fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50ad2960-3f80-47f4-b765-65eb5e931043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70351dde-9871-4cb7-a9ba-41a80e3e6253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 395c3cbf-e84a-48b3-b0a5-de76470b943d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b7a1142-18e1-47c9-8100-f9d7c153cf8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b1a7663-e45d-47ef-8dc1-2e59b37b6b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e2e4573-1220-4d1d-8a13-97d5d98bc79e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 292afa71-b33c-464c-8099-e72f67fe8646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afdc180b-0349-4ea4-b06e-276a07c2c8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ae52710-43eb-4ae1-be31-b21aab9cfba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edde3f6c-527c-423a-b135-e218fb064adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8050ab53-0125-4396-8099-d86a9b72840e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97c301ae-14b9-423b-b5f2-f22c45d3be50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82080748-7917-41a9-add0-913b07e3ffb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b06eedd-6a68-49d6-bcaf-37bd4c1f9aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09e66313-33e6-4c0e-a025-d0b446a30b1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acc37f6b-6f16-4b1e-a86a-30b7a9282080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bedc66a2-7618-438a-870e-012e9f78ef85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cfe2746-44f6-4873-b9b4-3231d45642f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e659702f-129e-49ee-8498-0c8c85aad64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7750780-689a-4b98-aa43-11829a49cc33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a49ddf59-cafb-4bf3-a05f-664902d435af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6346c08-6317-4bbe-ab07-391c6318f21a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 261253bd-5631-4795-be55-54ccc2463222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eef0cb9-f814-4bf7-850e-d2a72da37a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 719b3fed-19f3-48b2-8732-abdd314fe661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df3c242a-cd03-4ea0-9124-8db48acbb8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8be85e5b-bdda-4e31-ac67-20b1d5d86ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 752d54cb-c4b3-498b-a625-e7276e696ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcb6ffdb-43e9-4ca4-bd63-712c4f4802f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c9a6e95-8e9c-4a4b-b0cd-23f3f16407ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3755216-2e6b-46f0-88ab-396a658bc2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b6af3c2-46eb-4ac7-901a-5d29549c5f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13e2aa0d-d34d-418d-9079-aa948e16207f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85eac201-7d1f-4e1c-a869-d5e437f13606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2b0cf65-911c-41b0-90a8-d953c9ae7000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc9d1ab0-5d9b-44be-ab91-cb015b4fd47d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d282b42c-7f12-42b0-b1e5-df5d5134b031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39ecf3eb-101c-4cc9-8cc3-b3e035c4bf00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55441c92-2de9-43da-8808-625921311842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18925aab-1c92-4e90-a98a-a42f6e7b9e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45baa431-f33e-4692-9981-a72a79da56db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2284aa7a-82fa-4647-9f77-8923f689ea6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08492622-4436-4c06-a52d-599c96e3eef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66f0aef2-f8a6-4ef7-a9f1-1b4dc7c366a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5653a2bc-2fbd-40f3-b8ff-a89426d00c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6199ee5-f6d3-45fd-a233-45a14924a79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90a53b9f-5e78-4900-b361-b92fed01dd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2567be54-0b90-4a84-89d1-7f05d330d0a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 884edba4-2e87-4385-a1cb-9783628e49b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 383a567a-ac0c-4bd2-9b93-e34557043d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dec0c012-1af6-4141-b544-e26fc03ce0ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e4b4e87-6f1a-466c-9f69-3cbc04097775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c02a6376-7251-4acd-8663-949ba6be11b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 198147e3-9d4d-41c6-94c1-c7bffa838e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d7147ef-f925-4bbf-87f2-23cad31ec765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c9a4d70-a7ae-4d34-813c-55741ee760ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fc563f7-db01-434e-8dfb-627e478e0405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8cb96df-29db-429d-ba62-69285acb59dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65fabeb3-c091-459a-b767-5b242ee3af1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eee2cfe-1b4d-4ffa-9094-6e9ffe545a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e2c2de7-28cc-406e-91dd-7d0f8c4e7c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f9dfb5c-4a51-4f13-ae6f-5af1390c4976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae6041fe-60d6-440e-ae59-5a4ab7ab1438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdb9f1a9-43b7-48c2-8ec7-658d1c3184b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f304ef5c-3b87-4842-8639-326ce8edd363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40968e41-9b7f-41eb-9bf9-39c15afd3f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c0739cd-bc21-48b1-ade7-239d3c212a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02f4c5d4-28c6-41a6-a8eb-25f1d367d375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08ab2f04-b392-4f31-8941-30260a5e8b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ef5e93f-1404-41fa-bb6d-b03e846f0401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b14ba42-8b87-4b07-8218-0b44c8b29602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 991245b1-3543-44b4-bb6f-7d3ee66b7bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 710765f7-2728-47e0-9ce9-b647656f0002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01df438b-1228-4d13-9992-71d43e844684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bbd4f1e-8897-420b-a5fd-ed27cdc4f1bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69dcf7db-4218-42a0-adc7-229ec78c9648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44625142-d2c2-41a4-8cd3-c91fa0fddcd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a4b891d-027b-46d1-abcb-222b1dc6cfa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cd0b1f9-64aa-43bf-aebc-befed2ddc5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dcb3514-1dac-4619-b665-394e069a1d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9848e84-8fae-4e70-a656-3843215707aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f383e769-d4b7-4b52-8fdd-50d6be7c8939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5801e223-30a1-4025-9453-f2932477d0c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0d906e1-9c04-4a3b-a2a1-97d9d9e3e41f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99e0da74-0174-459f-95bd-75e3db332c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e40bc9d-d348-458b-94fe-0e3221c1645f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fa8e530-feca-477c-89c0-a0140528a661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f3acc30-b489-4dd6-a4a3-570611d3ea03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d43d8cc5-1724-49d8-947e-8064202a1cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ca01314-21f6-4684-98bb-2dc902ee9cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc6452a3-cfd7-48f3-bcbd-896fdf7ba894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45e9c3b9-d89e-4ad4-9c67-3e9718c82cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2af3deff-83c8-4f90-94b9-6e39b3cf71a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0438dedb-5384-4eda-9a7d-39a70b8508d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb961685-6ddf-4e75-8ee4-2931a967bd6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4289771d-3f50-4d3f-95a3-681c84e07cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9564136-2cc3-4f06-824a-f2ecd25e0d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 635f4dac-7597-4ad6-b873-4a34519255fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7abfaac4-2397-4493-ae02-e01fb545c118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 854d0b18-7975-456f-aba6-173a8898d095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e4754a3-b2d7-4bc0-a574-c19b873dd549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2110bc66-ff47-4bee-8fe8-7c5085c91a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d2c600c-0ad6-4505-95a5-55848c13a957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6df08fa0-1aac-44ba-9086-bbcaf0de6410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07faabf6-a2f8-4429-ab54-a598ad75bea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39839515-b62b-403e-92a5-b90dcacbb0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c008a4f0-f71d-4c72-8106-c248bb1ed8f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1ed54f0-265c-4149-9abc-dbe5020ef2a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74c6bc1b-0891-465e-9f47-b8d1fee4ad4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa47198f-c2d5-463e-a828-93a96c8b35bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e79e04f-66f5-48b3-9d80-a429ecfc2069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a25060a0-c6b3-46fe-8ecf-cdc0bd7fb49c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d5fb699-1443-4e5e-bc81-95dc4bf3a619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00c102f9-0795-4809-b074-f8af619049e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dc5e1a1-cf3f-4388-a198-5f8f33b16d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 273b3f7f-8670-47bf-8a79-ee1bf258b7d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c70ea572-1d50-47f0-8096-331ebab6eefb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_56
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/test_labels.txt

📊 Raw data loaded:
   Train: X=(1226, 24), y=(1226,)
   Test:  X=(307, 24), y=(307,)

⚠️  Limiting training data: 1226 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  298 samples, 5 features
✅ Client client_56 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1650, RMSE: 0.4062, MAE: 0.3276, R²: -0.9333

============================================================
🔄 Round 9 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1092, val=0.0813 (↓), lr=0.001000
   • Epoch   2/100: train=0.0820, val=0.0820, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0801, val=0.0801 (↓), lr=0.001000
   • Epoch   4/100: train=0.0805, val=0.0804, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0803, val=0.0804, patience=2/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0795, val=0.0795 (↓), lr=0.001000
   • Epoch  21/100: train=0.0743, val=0.0802, patience=7/15, lr=0.001000
   📉 Epoch 22: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 9 Summary - Client client_56
   Epochs: 29/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0327
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0141
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1614, RMSE: 0.4018, MAE: 0.3240, R²: -0.8909

============================================================
🔄 Round 10 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.1241, val=0.0818 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0818, val=0.0763 (↓), lr=0.000250
   • Epoch   3/100: train=0.0812, val=0.0781, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0810, val=0.0777, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0808, val=0.0779, patience=3/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0803, val=0.0786, patience=9/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 10 Summary - Client client_56
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0120
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0036
============================================================


============================================================
🔄 Round 11 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1451, val=0.1571 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1247, val=0.1350 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1069, val=0.1169 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0931, val=0.1030 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0841, val=0.0943 (↓), lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0787, val=0.0892, patience=4/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0785, val=0.0890, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 11 Summary - Client client_56
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=-0.0003
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0225
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1520, RMSE: 0.3899, MAE: 0.3148, R²: -0.7811

📊 Round 11 Test Metrics:
   Loss: 0.1471, RMSE: 0.3835, MAE: 0.3099, R²: -0.7232

📊 Round 11 Test Metrics:
   Loss: 0.1418, RMSE: 0.3765, MAE: 0.3046, R²: -0.6609

📊 Round 11 Test Metrics:
   Loss: 0.1279, RMSE: 0.3576, MAE: 0.2913, R²: -0.4982

============================================================
🔄 Round 20 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0833 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.0862, val=0.0821 (↓), lr=0.000008
   • Epoch   3/100: train=0.0846, val=0.0817, patience=1/15, lr=0.000008
   ✓ Epoch   4/100: train=0.0838, val=0.0814 (↓), lr=0.000008
   • Epoch   5/100: train=0.0831, val=0.0812, patience=1/15, lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0808, val=0.0811, patience=7/15, lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 20 Summary - Client client_56
   Epochs: 19/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0441
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0056
============================================================


============================================================
🔄 Round 21 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0795 (↓), lr=0.000002
   • Epoch   2/100: train=0.0834, val=0.0793, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0834, val=0.0791, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0833, val=0.0790, patience=3/15, lr=0.000002
   ✓ Epoch   5/100: train=0.0832, val=0.0788 (↓), lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   ✓ Epoch  11/100: train=0.0830, val=0.0783 (↓), lr=0.000001
   • Epoch  21/100: train=0.0828, val=0.0777, patience=1/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0826, val=0.0772 (↓), lr=0.000001
   • Epoch  41/100: train=0.0825, val=0.0769, patience=10/15, lr=0.000001
   • Epoch  51/100: train=0.0824, val=0.0765, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 21 Summary - Client client_56
   Epochs: 60/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0049
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0662
============================================================


============================================================
🔄 Round 22 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0793, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0817, val=0.0789, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0815, val=0.0787, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 22 Summary - Client client_56
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0085
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0362
============================================================


============================================================
🔄 Round 23 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 23 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0127
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0024
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2539, R²: -0.0013

============================================================
🔄 Round 24 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 24 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0134
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0006
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2540, R²: 0.0003

📊 Round 24 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2540, R²: 0.0004

📊 Round 24 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2540, R²: 0.0005

============================================================
🔄 Round 29 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 29 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0012
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0332
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2540, R²: 0.0007

📊 Round 29 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2540, R²: 0.0007

============================================================
🔄 Round 31 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 31 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0017
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0317
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2540, R²: 0.0008

📊 Round 31 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2540, R²: 0.0009

📊 Round 31 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2541, R²: 0.0009

============================================================
🔄 Round 35 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 35 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0067
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0084
============================================================


============================================================
🔄 Round 36 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 36 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0022
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0135
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2541, R²: 0.0011

============================================================
🔄 Round 40 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 40 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=-0.0011
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0179
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2541, R²: 0.0011

============================================================
🔄 Round 41 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 41 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0025
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0136
============================================================


============================================================
🔄 Round 42 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 42 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=-0.0016
   Val:   Loss=0.0953, RMSE=0.3086, R²=-0.0192
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2542, R²: 0.0011

📊 Round 42 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2542, R²: 0.0011

============================================================
🔄 Round 47 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 47 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=-0.0027
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0044
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2542, R²: 0.0011

📊 Round 47 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2542, R²: 0.0012

============================================================
🔄 Round 49 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 49 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0036
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0003
============================================================


============================================================
🔄 Round 52 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 52 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0020
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0059
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2542, R²: 0.0012

📊 Round 52 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2542, R²: 0.0012

📊 Round 52 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2542, R²: 0.0012

📊 Round 52 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2542, R²: 0.0012

============================================================
🔄 Round 59 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 59 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0068
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0059
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2542, R²: 0.0012

============================================================
🔄 Round 60 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 60 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0063
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0247
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2542, R²: 0.0012

📊 Round 60 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2542, R²: 0.0012

============================================================
🔄 Round 69 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 69 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0013
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0074
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2543, R²: 0.0012

============================================================
🔄 Round 70 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 70 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0017
   Val:   Loss=0.0699, RMSE=0.2645, R²=-0.0105
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2543, R²: 0.0012

============================================================
🔄 Round 72 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 72 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0034
   Val:   Loss=0.0696, RMSE=0.2638, R²=-0.0058
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2543, R²: 0.0012

📊 Round 72 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2543, R²: 0.0012

📊 Round 72 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2543, R²: 0.0011

============================================================
🔄 Round 77 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 77 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0015
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0053
============================================================


============================================================
🔄 Round 79 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 79 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0012
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0214
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2543, R²: 0.0011

============================================================
🔄 Round 80 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 80 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0017
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0048
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2543, R²: 0.0011

============================================================
🔄 Round 86 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 86 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0036
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0025
============================================================


============================================================
🔄 Round 87 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 87 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0054
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0046
============================================================


============================================================
🔄 Round 91 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 91 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0019
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0027
============================================================


============================================================
🔄 Round 96 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 96 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0021
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0032
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0011

📊 Round 96 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0011

📊 Round 96 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0011

📊 Round 96 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0011

============================================================
🔄 Round 102 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 102 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0026
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0010
============================================================


============================================================
🔄 Round 107 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 107 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0020
   Val:   Loss=0.0780, RMSE=0.2794, R²=-0.0013
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 108 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 108 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0039
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0046
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 110 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 110 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0028
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0069
============================================================


============================================================
🔄 Round 112 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 112 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0018
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0015
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

📊 Round 112 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 115 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 115 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0016
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0030
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 121 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 121 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0011
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0311
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 125 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 125 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0081
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0335
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

📊 Round 125 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 127 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 127 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0008
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0064
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 130 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 130 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0007
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0066
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 134 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 134 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0002
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0076
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0010

📊 Round 134 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

============================================================
🔄 Round 136 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 136 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0042
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0054
============================================================


============================================================
🔄 Round 137 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 137 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0050
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0064
============================================================


============================================================
🔄 Round 138 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 138 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0011
   Val:   Loss=0.0803, RMSE=0.2835, R²=-0.0037
============================================================


============================================================
🔄 Round 139 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 139 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0010
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0142
============================================================


============================================================
🔄 Round 140 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 140 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0024
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0059
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

📊 Round 140 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

============================================================
🔄 Round 143 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 143 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0028
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0042
============================================================


============================================================
🔄 Round 144 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 144 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2820, R²=-0.0035
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0023
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 146 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 146 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0004
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0066
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 147 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 147 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0005
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0097
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 148 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 148 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0011
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0043
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

📊 Round 148 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 151 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 151 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0013
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0049
============================================================


============================================================
🔄 Round 153 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 153 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0020
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0007
============================================================


============================================================
🔄 Round 154 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 154 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0029
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0023
============================================================


============================================================
🔄 Round 155 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 155 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0014
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0178
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

📊 Round 155 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2544, R²: 0.0010

============================================================
🔄 Round 157 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 157 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0030
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0056
============================================================


============================================================
🔄 Round 158 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 158 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0015
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0060
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0010

============================================================
🔄 Round 162 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 162 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0022
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0012
============================================================


============================================================
🔄 Round 163 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 163 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0049
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0131
============================================================


============================================================
🔄 Round 164 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 164 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0028
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0010
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0010

============================================================
🔄 Round 166 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 166 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=-0.0026
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0129
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

============================================================
🔄 Round 168 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 168 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0003
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0070
============================================================


============================================================
🔄 Round 170 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 170 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0012
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0025
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

============================================================
🔄 Round 174 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 174 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0019
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0028
============================================================


============================================================
🔄 Round 175 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 175 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0005
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0059
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

📊 Round 175 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

📊 Round 175 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

📊 Round 175 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

============================================================
🔄 Round 181 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 181 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0008
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0146
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

============================================================
🔄 Round 185 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 185 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0021
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0004
============================================================


============================================================
🔄 Round 187 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 187 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0019
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0021
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

📊 Round 187 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

📊 Round 187 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

📊 Round 187 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

============================================================
🔄 Round 201 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 201 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0016
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0128
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

============================================================
🔄 Round 207 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 207 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0014
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0065
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2545, R²: 0.0009

❌ Client client_56 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
